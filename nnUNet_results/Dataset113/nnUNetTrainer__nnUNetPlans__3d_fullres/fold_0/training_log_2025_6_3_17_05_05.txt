
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2025-06-03 17:05:07.157133: do_dummy_2d_data_aug: True 
2025-06-03 17:05:07.194982: Creating new 5-fold cross-validation split... 
2025-06-03 17:05:07.267678: Desired fold for training: 0 
2025-06-03 17:05:07.281735: This split has 960 training and 240 validation cases. 

This is the configuration used by this training:
Configuration name: 3d_fullres
 {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [56, 192, 192], 'median_image_size_in_voxels': [80.0, 256.0, 256.0], 'spacing': [2.0, 0.7031000256538391, 0.7031000256538391], 'normalization_schemes': ['ZScoreNormalization', 'ZScoreNormalization', 'ZScoreNormalization'], 'use_mask_for_norm': [False, False, False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[1, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [1, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': False} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset113', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [2.0, 0.7031000256538391, 0.7031000256538391], 'original_median_shape_after_transp': [80, 256, 256], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 24.687700271606445, 'mean': 2.595021963119507, 'median': 2.36936354637146, 'min': -1.709751844406128, 'percentile_00_5': -0.25866907835006714, 'percentile_99_5': 8.015562057495117, 'std': 1.4617289304733276}, '1': {'max': 23.832199096679688, 'mean': 4.020498752593994, 'median': 3.5716843605041504, 'min': -1.6504470109939575, 'percentile_00_5': -0.011447281576693058, 'percentile_99_5': 12.636001586914062, 'std': 2.413132667541504}, '2': {'max': 57.53712844848633, 'mean': 3.6045539379119873, 'median': 2.833742380142212, 'min': -11.494463920593262, 'percentile_00_5': -1.8330446481704712, 'percentile_99_5': 16.915315628051758, 'std': 3.431992769241333}}} 
 
2025-06-03 17:15:40.799436: Unable to plot network architecture: 
2025-06-03 17:15:40.813585: No module named 'hiddenlayer' 
2025-06-03 17:15:40.872768:  
2025-06-03 17:15:40.887762: Epoch 0 
2025-06-03 17:15:40.899563: Current learning rate: 0.01 
2025-06-03 17:18:37.012710: train_loss -0.2502 
2025-06-03 17:18:37.026824: val_loss -0.39 
2025-06-03 17:18:37.039917: Pseudo dice [np.float32(0.4781)] 
2025-06-03 17:18:37.053014: Epoch time: 176.14 s 
2025-06-03 17:18:37.066590: Yayy! New best EMA pseudo Dice: 0.4781000018119812 
2025-06-03 17:18:46.016180:  
2025-06-03 17:18:46.033516: Epoch 1 
2025-06-03 17:18:46.047088: Current learning rate: 0.00999 
2025-06-03 17:21:00.696438: train_loss -0.5067 
2025-06-03 17:21:01.174594: val_loss -0.4628 
2025-06-03 17:21:01.436162: Pseudo dice [np.float32(0.5049)] 
2025-06-03 17:21:01.451557: Epoch time: 134.76 s 
2025-06-03 17:21:01.464948: Yayy! New best EMA pseudo Dice: 0.48080000281333923 
2025-06-03 17:21:08.927265:  
2025-06-03 17:21:08.943581: Epoch 2 
2025-06-03 17:21:08.955143: Current learning rate: 0.00998 
2025-06-03 17:23:22.460075: train_loss -0.4807 
2025-06-03 17:23:22.474213: val_loss -0.4993 
2025-06-03 17:23:22.487625: Pseudo dice [np.float32(0.5206)] 
2025-06-03 17:23:22.500404: Epoch time: 133.58 s 
2025-06-03 17:23:22.513284: Yayy! New best EMA pseudo Dice: 0.4846999943256378 
2025-06-03 17:23:24.996073:  
2025-06-03 17:23:25.013634: Epoch 3 
2025-06-03 17:23:25.049806: Current learning rate: 0.00997 
2025-06-03 17:25:35.876037: train_loss -0.5225 
2025-06-03 17:25:35.890999: val_loss -0.4987 
2025-06-03 17:25:35.904030: Pseudo dice [np.float32(0.5107)] 
2025-06-03 17:25:35.916997: Epoch time: 130.88 s 
2025-06-03 17:25:35.929276: Yayy! New best EMA pseudo Dice: 0.48730000853538513 
2025-06-03 17:25:42.114939:  
2025-06-03 17:25:42.480968: Epoch 4 
2025-06-03 17:25:42.635648: Current learning rate: 0.00996 
2025-06-03 17:27:52.943859: train_loss -0.5122 
2025-06-03 17:27:53.073153: val_loss -0.4634 
2025-06-03 17:27:53.086883: Pseudo dice [np.float32(0.4983)] 
2025-06-03 17:27:53.099756: Epoch time: 130.83 s 
2025-06-03 17:27:53.112356: Yayy! New best EMA pseudo Dice: 0.48840001225471497 
2025-06-03 17:28:01.184688:  
2025-06-03 17:28:01.308753: Epoch 5 
2025-06-03 17:28:01.441084: Current learning rate: 0.00995 
2025-06-03 17:30:14.482007: train_loss -0.5209 
2025-06-03 17:30:14.625518: val_loss -0.5542 
2025-06-03 17:30:14.641102: Pseudo dice [np.float32(0.6219)] 
2025-06-03 17:30:14.654043: Epoch time: 133.3 s 
2025-06-03 17:30:14.667557: Yayy! New best EMA pseudo Dice: 0.501800000667572 
2025-06-03 17:30:20.413360:  
2025-06-03 17:30:20.432322: Epoch 6 
2025-06-03 17:30:20.444931: Current learning rate: 0.00995 
2025-06-03 17:32:32.752186: train_loss -0.4857 
2025-06-03 17:32:33.268400: val_loss -0.4481 
2025-06-03 17:32:33.495612: Pseudo dice [np.float32(0.4767)] 
2025-06-03 17:32:33.510013: Epoch time: 132.34 s 
2025-06-03 17:32:37.902550:  
2025-06-03 17:32:37.919029: Epoch 7 
2025-06-03 17:32:37.931307: Current learning rate: 0.00994 
2025-06-03 17:34:51.718396: train_loss -0.5703 
2025-06-03 17:34:51.736094: val_loss -0.5332 
2025-06-03 17:34:51.749141: Pseudo dice [np.float32(0.5193)] 
2025-06-03 17:34:51.761466: Epoch time: 133.92 s 
2025-06-03 17:35:00.560135:  
2025-06-03 17:35:00.812858: Epoch 8 
2025-06-03 17:35:01.039086: Current learning rate: 0.00993 
2025-06-03 17:37:10.233940: train_loss -0.5782 
2025-06-03 17:37:10.724676: val_loss -0.5577 
2025-06-03 17:37:10.739945: Pseudo dice [np.float32(0.6633)] 
2025-06-03 17:37:10.753372: Epoch time: 129.68 s 
2025-06-03 17:37:10.767799: Yayy! New best EMA pseudo Dice: 0.5174999833106995 
2025-06-03 17:37:18.710842:  
2025-06-03 17:37:18.901849: Epoch 9 
2025-06-03 17:37:18.990796: Current learning rate: 0.00992 
2025-06-03 17:39:31.565704: train_loss -0.5458 
2025-06-03 17:39:31.582672: val_loss -0.5821 
2025-06-03 17:39:31.595522: Pseudo dice [np.float32(0.6212)] 
2025-06-03 17:39:31.608325: Epoch time: 132.86 s 
2025-06-03 17:39:31.620141: Yayy! New best EMA pseudo Dice: 0.527899980545044 
2025-06-03 17:39:39.157210:  
2025-06-03 17:39:39.217958: Epoch 10 
2025-06-03 17:39:39.274290: Current learning rate: 0.00991 
2025-06-03 17:41:53.465006: train_loss -0.543 
2025-06-03 17:41:53.486792: val_loss -0.4973 
2025-06-03 17:41:53.503739: Pseudo dice [np.float32(0.5221)] 
2025-06-03 17:41:53.524391: Epoch time: 134.31 s 
2025-06-03 17:42:00.170855:  
2025-06-03 17:42:00.327032: Epoch 11 
2025-06-03 17:42:00.347539: Current learning rate: 0.0099 
2025-06-03 17:44:14.576377: train_loss -0.5671 
2025-06-03 17:44:14.596377: val_loss -0.6023 
2025-06-03 17:44:14.612321: Pseudo dice [np.float32(0.6593)] 
2025-06-03 17:44:14.625880: Epoch time: 134.41 s 
2025-06-03 17:44:14.643299: Yayy! New best EMA pseudo Dice: 0.5404999852180481 
2025-06-03 17:44:20.567105:  
2025-06-03 17:44:20.738991: Epoch 12 
2025-06-03 17:44:20.911731: Current learning rate: 0.00989 
2025-06-03 17:46:36.272971: train_loss -0.5564 
2025-06-03 17:46:36.296631: val_loss -0.6407 
2025-06-03 17:46:36.310445: Pseudo dice [np.float32(0.691)] 
2025-06-03 17:46:36.326324: Epoch time: 135.71 s 
2025-06-03 17:46:36.339646: Yayy! New best EMA pseudo Dice: 0.5554999709129333 
2025-06-03 17:46:42.642328:  
2025-06-03 17:46:42.705543: Epoch 13 
2025-06-03 17:46:42.804947: Current learning rate: 0.00988 
2025-06-03 17:48:53.604384: train_loss -0.552 
2025-06-03 17:48:53.624255: val_loss -0.5375 
2025-06-03 17:48:53.636968: Pseudo dice [np.float32(0.5115)] 
2025-06-03 17:48:53.648485: Epoch time: 130.96 s 
2025-06-03 17:48:59.526310:  
2025-06-03 17:48:59.717151: Epoch 14 
2025-06-03 17:48:59.927367: Current learning rate: 0.00987 
2025-06-03 17:51:15.141842: train_loss -0.5542 
2025-06-03 17:51:15.158480: val_loss -0.5331 
2025-06-03 17:51:15.173136: Pseudo dice [np.float32(0.5691)] 
2025-06-03 17:51:15.186946: Epoch time: 135.62 s 
2025-06-03 17:51:22.135334:  
2025-06-03 17:51:22.360184: Epoch 15 
2025-06-03 17:51:22.542318: Current learning rate: 0.00986 
2025-06-03 17:53:40.372316: train_loss -0.5873 
2025-06-03 17:53:40.537111: val_loss -0.5685 
2025-06-03 17:53:40.555288: Pseudo dice [np.float32(0.5814)] 
2025-06-03 17:53:40.568330: Epoch time: 138.24 s 
2025-06-03 17:53:40.581371: Yayy! New best EMA pseudo Dice: 0.5558000206947327 
2025-06-03 17:53:47.373062:  
2025-06-03 17:53:47.652206: Epoch 16 
2025-06-03 17:53:47.998327: Current learning rate: 0.00986 
2025-06-03 17:56:00.821288: train_loss -0.5762 
2025-06-03 17:56:00.845125: val_loss -0.594 
2025-06-03 17:56:00.858166: Pseudo dice [np.float32(0.6293)] 
2025-06-03 17:56:00.871034: Epoch time: 133.45 s 
2025-06-03 17:56:00.884046: Yayy! New best EMA pseudo Dice: 0.5630999803543091 
2025-06-03 17:56:10.384593:  
2025-06-03 17:56:10.502093: Epoch 17 
2025-06-03 17:56:10.707860: Current learning rate: 0.00985 
2025-06-03 17:58:26.141402: train_loss -0.5873 
2025-06-03 17:58:26.442706: val_loss -0.6298 
2025-06-03 17:58:26.969288: Pseudo dice [np.float32(0.6266)] 
2025-06-03 17:58:27.368884: Epoch time: 135.76 s 
2025-06-03 17:58:27.385050: Yayy! New best EMA pseudo Dice: 0.5695000290870667 
2025-06-03 17:58:35.750506:  
2025-06-03 17:58:35.767827: Epoch 18 
2025-06-03 17:58:35.781048: Current learning rate: 0.00984 
2025-06-03 18:00:52.908159: train_loss -0.5679 
2025-06-03 18:00:53.306651: val_loss -0.5299 
2025-06-03 18:00:53.490470: Pseudo dice [np.float32(0.5931)] 
2025-06-03 18:00:53.504313: Epoch time: 137.16 s 
2025-06-03 18:00:53.517836: Yayy! New best EMA pseudo Dice: 0.5717999935150146 
2025-06-03 18:00:58.575391:  
2025-06-03 18:00:58.799703: Epoch 19 
2025-06-03 18:00:58.994917: Current learning rate: 0.00983 
2025-06-03 18:03:17.455546: train_loss -0.5948 
2025-06-03 18:03:17.473272: val_loss -0.6035 
2025-06-03 18:03:17.485762: Pseudo dice [np.float32(0.7203)] 
2025-06-03 18:03:17.498488: Epoch time: 138.88 s 
2025-06-03 18:03:17.512331: Yayy! New best EMA pseudo Dice: 0.5867000222206116 
2025-06-03 18:03:23.588352:  
2025-06-03 18:03:23.817057: Epoch 20 
2025-06-03 18:03:24.099388: Current learning rate: 0.00982 
2025-06-03 18:05:36.151917: train_loss -0.533 
2025-06-03 18:05:36.170166: val_loss -0.6068 
2025-06-03 18:05:36.183650: Pseudo dice [np.float32(0.6516)] 
2025-06-03 18:05:36.197391: Epoch time: 132.57 s 
2025-06-03 18:05:36.212756: Yayy! New best EMA pseudo Dice: 0.5932000279426575 
2025-06-03 18:05:45.548225:  
2025-06-03 18:05:45.756953: Epoch 21 
2025-06-03 18:05:46.008937: Current learning rate: 0.00981 
2025-06-03 18:07:57.915975: train_loss -0.6002 
2025-06-03 18:07:57.936893: val_loss -0.5913 
2025-06-03 18:07:57.950004: Pseudo dice [np.float32(0.6841)] 
2025-06-03 18:07:57.962775: Epoch time: 132.37 s 
2025-06-03 18:07:57.977021: Yayy! New best EMA pseudo Dice: 0.6022999882698059 
2025-06-03 18:08:04.591513:  
2025-06-03 18:08:04.602062: Epoch 22 
2025-06-03 18:08:04.611014: Current learning rate: 0.0098 
2025-06-03 18:10:19.215583: train_loss -0.5827 
2025-06-03 18:10:19.264419: val_loss -0.6073 
2025-06-03 18:10:19.301851: Pseudo dice [np.float32(0.6041)] 
2025-06-03 18:10:19.314993: Epoch time: 134.63 s 
2025-06-03 18:10:19.327821: Yayy! New best EMA pseudo Dice: 0.602400004863739 
2025-06-03 18:10:23.083006:  
2025-06-03 18:10:23.098974: Epoch 23 
2025-06-03 18:10:23.112900: Current learning rate: 0.00979 
2025-06-03 18:12:35.533799: train_loss -0.6077 
2025-06-03 18:12:35.549092: val_loss -0.5987 
2025-06-03 18:12:35.561104: Pseudo dice [np.float32(0.6265)] 
2025-06-03 18:12:35.574223: Epoch time: 132.45 s 
2025-06-03 18:12:35.585852: Yayy! New best EMA pseudo Dice: 0.6049000024795532 
2025-06-03 18:12:42.417921:  
2025-06-03 18:12:42.440790: Epoch 24 
2025-06-03 18:12:42.457811: Current learning rate: 0.00978 
2025-06-03 18:14:53.656684: train_loss -0.5879 
2025-06-03 18:14:53.680765: val_loss -0.5413 
2025-06-03 18:14:53.693789: Pseudo dice [np.float32(0.5421)] 
2025-06-03 18:14:53.707179: Epoch time: 131.24 s 
2025-06-03 18:15:00.247024:  
2025-06-03 18:15:00.394440: Epoch 25 
2025-06-03 18:15:00.592905: Current learning rate: 0.00977 
2025-06-03 18:17:10.661810: train_loss -0.5813 
2025-06-03 18:17:10.679246: val_loss -0.5708 
2025-06-03 18:17:10.693154: Pseudo dice [np.float32(0.6286)] 
2025-06-03 18:17:10.705263: Epoch time: 130.42 s 
2025-06-03 18:17:16.304762:  
2025-06-03 18:17:16.532195: Epoch 26 
2025-06-03 18:17:16.718239: Current learning rate: 0.00977 
2025-06-03 18:19:32.752459: train_loss -0.6222 
2025-06-03 18:19:33.294871: val_loss -0.6514 
2025-06-03 18:19:33.722985: Pseudo dice [np.float32(0.7271)] 
2025-06-03 18:19:34.110667: Epoch time: 136.45 s 
2025-06-03 18:19:34.535844: Yayy! New best EMA pseudo Dice: 0.6140999794006348 
2025-06-03 18:19:41.602081:  
2025-06-03 18:19:41.782309: Epoch 27 
2025-06-03 18:19:41.798719: Current learning rate: 0.00976 
2025-06-03 18:22:00.146194: train_loss -0.6247 
2025-06-03 18:22:00.684552: val_loss -0.6754 
2025-06-03 18:22:01.203120: Pseudo dice [np.float32(0.7655)] 
2025-06-03 18:22:01.778256: Epoch time: 138.55 s 
2025-06-03 18:22:02.168730: Yayy! New best EMA pseudo Dice: 0.6292999982833862 
2025-06-03 18:22:06.660055:  
2025-06-03 18:22:06.678040: Epoch 28 
2025-06-03 18:22:06.691833: Current learning rate: 0.00975 
2025-06-03 18:24:23.303870: train_loss -0.6174 
2025-06-03 18:24:23.321088: val_loss -0.6072 
2025-06-03 18:24:23.333850: Pseudo dice [np.float32(0.6594)] 
2025-06-03 18:24:23.346446: Epoch time: 136.67 s 
2025-06-03 18:24:23.358884: Yayy! New best EMA pseudo Dice: 0.6323000192642212 
2025-06-03 18:24:33.799083:  
2025-06-03 18:24:34.210211: Epoch 29 
2025-06-03 18:24:34.225220: Current learning rate: 0.00974 
2025-06-03 18:26:47.945647: train_loss -0.6075 
2025-06-03 18:26:48.229975: val_loss -0.6265 
2025-06-03 18:26:48.621244: Pseudo dice [np.float32(0.7006)] 
2025-06-03 18:26:48.968892: Epoch time: 134.15 s 
2025-06-03 18:26:48.983373: Yayy! New best EMA pseudo Dice: 0.6391000151634216 
2025-06-03 18:26:56.258775:  
2025-06-03 18:26:56.695527: Epoch 30 
2025-06-03 18:26:56.959656: Current learning rate: 0.00973 
2025-06-03 18:29:14.993752: train_loss -0.6204 
2025-06-03 18:29:15.308827: val_loss -0.5832 
2025-06-03 18:29:15.326016: Pseudo dice [np.float32(0.5756)] 
2025-06-03 18:29:16.044113: Epoch time: 138.74 s 
2025-06-03 18:29:21.831327:  
2025-06-03 18:29:22.089471: Epoch 31 
2025-06-03 18:29:22.323663: Current learning rate: 0.00972 
2025-06-03 18:31:37.748616: train_loss -0.6251 
2025-06-03 18:31:38.080484: val_loss -0.6789 
2025-06-03 18:31:38.095666: Pseudo dice [np.float32(0.7256)] 
2025-06-03 18:31:38.110296: Epoch time: 135.92 s 
2025-06-03 18:31:38.123755: Yayy! New best EMA pseudo Dice: 0.6420999765396118 
2025-06-03 18:31:42.855317:  
2025-06-03 18:31:43.147906: Epoch 32 
2025-06-03 18:31:43.164694: Current learning rate: 0.00971 
2025-06-03 18:34:01.279701: train_loss -0.6291 
2025-06-03 18:34:01.302651: val_loss -0.6966 
2025-06-03 18:34:01.315236: Pseudo dice [np.float32(0.7894)] 
2025-06-03 18:34:01.327450: Epoch time: 138.43 s 
2025-06-03 18:34:01.341680: Yayy! New best EMA pseudo Dice: 0.6567999720573425 
2025-06-03 18:34:08.367080:  
2025-06-03 18:34:08.536258: Epoch 33 
2025-06-03 18:34:08.551321: Current learning rate: 0.0097 
2025-06-03 18:36:23.983554: train_loss -0.6306 
2025-06-03 18:36:24.698229: val_loss -0.6431 
2025-06-03 18:36:24.835208: Pseudo dice [np.float32(0.7092)] 
2025-06-03 18:36:25.248608: Epoch time: 135.62 s 
2025-06-03 18:36:25.926039: Yayy! New best EMA pseudo Dice: 0.6620000004768372 
2025-06-03 18:36:31.612240:  
2025-06-03 18:36:31.641380: Epoch 34 
2025-06-03 18:36:31.739064: Current learning rate: 0.00969 
2025-06-03 18:38:50.421649: train_loss -0.6468 
2025-06-03 18:38:50.830350: val_loss -0.6525 
2025-06-03 18:38:51.290233: Pseudo dice [np.float32(0.719)] 
2025-06-03 18:38:51.670431: Epoch time: 138.81 s 
2025-06-03 18:38:52.130957: Yayy! New best EMA pseudo Dice: 0.6676999926567078 
2025-06-03 18:38:58.036550:  
2025-06-03 18:38:58.145803: Epoch 35 
2025-06-03 18:38:58.217069: Current learning rate: 0.00968 
2025-06-03 18:41:15.355135: train_loss -0.6442 
2025-06-03 18:41:15.572724: val_loss -0.5847 
2025-06-03 18:41:15.965528: Pseudo dice [np.float32(0.6379)] 
2025-06-03 18:41:16.348369: Epoch time: 137.32 s 
2025-06-03 18:41:23.213454:  
2025-06-03 18:41:23.342254: Epoch 36 
2025-06-03 18:41:23.507067: Current learning rate: 0.00968 
2025-06-03 18:43:39.161997: train_loss -0.6216 
2025-06-03 18:43:39.187361: val_loss -0.5834 
2025-06-03 18:43:39.202152: Pseudo dice [np.float32(0.6022)] 
2025-06-03 18:43:39.215679: Epoch time: 135.95 s 
2025-06-03 18:43:45.379296:  
2025-06-03 18:43:45.423851: Epoch 37 
2025-06-03 18:43:45.533071: Current learning rate: 0.00967 
2025-06-03 18:45:59.403932: train_loss -0.6505 
2025-06-03 18:45:59.427630: val_loss -0.6044 
2025-06-03 18:45:59.441994: Pseudo dice [np.float32(0.622)] 
2025-06-03 18:45:59.455522: Epoch time: 134.03 s 
2025-06-03 18:46:07.114691:  
2025-06-03 18:46:07.430037: Epoch 38 
2025-06-03 18:46:07.720504: Current learning rate: 0.00966 
2025-06-03 18:48:20.496865: train_loss -0.6121 
2025-06-03 18:48:20.520823: val_loss -0.6251 
2025-06-03 18:48:20.535303: Pseudo dice [np.float32(0.7436)] 
2025-06-03 18:48:20.549287: Epoch time: 133.38 s 
2025-06-03 18:48:27.591957:  
2025-06-03 18:48:27.825828: Epoch 39 
2025-06-03 18:48:27.967236: Current learning rate: 0.00965 
2025-06-03 18:50:44.442683: train_loss -0.6119 
2025-06-03 18:50:44.456784: val_loss -0.6331 
2025-06-03 18:50:44.469196: Pseudo dice [np.float32(0.6061)] 
2025-06-03 18:50:44.481834: Epoch time: 136.86 s 
2025-06-03 18:50:45.953588:  
2025-06-03 18:50:45.970687: Epoch 40 
2025-06-03 18:50:45.984731: Current learning rate: 0.00964 
2025-06-03 18:53:00.455376: train_loss -0.6284 
2025-06-03 18:53:00.482550: val_loss -0.608 
2025-06-03 18:53:00.497172: Pseudo dice [np.float32(0.6736)] 
2025-06-03 18:53:00.511049: Epoch time: 134.5 s 
2025-06-03 18:53:05.931309:  
2025-06-03 18:53:06.207784: Epoch 41 
2025-06-03 18:53:06.423988: Current learning rate: 0.00963 
2025-06-03 18:55:15.816792: train_loss -0.6624 
2025-06-03 18:55:16.271241: val_loss -0.683 
2025-06-03 18:55:16.804329: Pseudo dice [np.float32(0.7278)] 
2025-06-03 18:55:17.227915: Epoch time: 129.89 s 
2025-06-03 18:55:21.461052:  
2025-06-03 18:55:21.553948: Epoch 42 
2025-06-03 18:55:21.654180: Current learning rate: 0.00962 
2025-06-03 18:57:31.187555: train_loss -0.6506 
2025-06-03 18:57:31.206234: val_loss -0.6728 
2025-06-03 18:57:31.221794: Pseudo dice [np.float32(0.6962)] 
2025-06-03 18:57:31.238225: Epoch time: 129.73 s 
2025-06-03 18:57:31.252807: Yayy! New best EMA pseudo Dice: 0.6693000197410583 
2025-06-03 18:57:40.676213:  
2025-06-03 18:57:40.695977: Epoch 43 
2025-06-03 18:57:40.711711: Current learning rate: 0.00961 
2025-06-03 18:59:53.427900: train_loss -0.6427 
2025-06-03 18:59:53.795591: val_loss -0.6301 
2025-06-03 18:59:54.376872: Pseudo dice [np.float32(0.6206)] 
2025-06-03 18:59:54.842750: Epoch time: 132.75 s 
2025-06-03 19:00:02.044133:  
2025-06-03 19:00:02.060131: Epoch 44 
2025-06-03 19:00:02.073022: Current learning rate: 0.0096 
2025-06-03 19:02:09.084759: train_loss -0.6381 
2025-06-03 19:02:09.102066: val_loss -0.6125 
2025-06-03 19:02:09.115303: Pseudo dice [np.float32(0.6833)] 
2025-06-03 19:02:09.128929: Epoch time: 127.04 s 
2025-06-03 19:02:16.231532:  
2025-06-03 19:02:16.367878: Epoch 45 
2025-06-03 19:02:16.556634: Current learning rate: 0.00959 
2025-06-03 19:04:28.481320: train_loss -0.6293 
2025-06-03 19:04:28.819464: val_loss -0.6498 
2025-06-03 19:04:28.946900: Pseudo dice [np.float32(0.6729)] 
2025-06-03 19:04:28.961503: Epoch time: 132.25 s 
2025-06-03 19:04:35.432634:  
2025-06-03 19:04:35.560119: Epoch 46 
2025-06-03 19:04:35.723133: Current learning rate: 0.00959 
2025-06-03 19:06:51.293266: train_loss -0.6494 
2025-06-03 19:06:51.603984: val_loss -0.6438 
2025-06-03 19:06:51.619324: Pseudo dice [np.float32(0.7636)] 
2025-06-03 19:06:52.188606: Epoch time: 135.86 s 
2025-06-03 19:06:52.524816: Yayy! New best EMA pseudo Dice: 0.6766999959945679 
2025-06-03 19:06:58.347698:  
2025-06-03 19:06:58.407192: Epoch 47 
2025-06-03 19:06:58.453886: Current learning rate: 0.00958 
2025-06-03 19:09:12.797844: train_loss -0.6114 
2025-06-03 19:09:13.004166: val_loss -0.6458 
2025-06-03 19:09:13.385258: Pseudo dice [np.float32(0.6942)] 
2025-06-03 19:09:13.818399: Epoch time: 134.45 s 
2025-06-03 19:09:14.279263: Yayy! New best EMA pseudo Dice: 0.6783999800682068 
2025-06-03 19:09:22.220865:  
2025-06-03 19:09:22.493582: Epoch 48 
2025-06-03 19:09:22.821367: Current learning rate: 0.00957 
2025-06-03 19:11:43.092538: train_loss -0.6678 
2025-06-03 19:11:43.482375: val_loss -0.6529 
2025-06-03 19:11:43.897303: Pseudo dice [np.float32(0.7437)] 
2025-06-03 19:11:44.058731: Epoch time: 140.87 s 
2025-06-03 19:11:44.071199: Yayy! New best EMA pseudo Dice: 0.6848999857902527 
2025-06-03 19:11:49.988599:  
2025-06-03 19:11:50.222308: Epoch 49 
2025-06-03 19:11:50.313919: Current learning rate: 0.00956 
2025-06-03 19:14:01.719634: train_loss -0.6249 
2025-06-03 19:14:01.740658: val_loss -0.6074 
2025-06-03 19:14:01.753462: Pseudo dice [np.float32(0.6716)] 
2025-06-03 19:14:01.766520: Epoch time: 131.73 s 
2025-06-03 19:14:07.900832:  
2025-06-03 19:14:07.958999: Epoch 50 
2025-06-03 19:14:08.030700: Current learning rate: 0.00955 
2025-06-03 19:16:21.160480: train_loss -0.6281 
2025-06-03 19:16:21.515176: val_loss -0.6057 
2025-06-03 19:16:22.006901: Pseudo dice [np.float32(0.6824)] 
2025-06-03 19:16:22.398511: Epoch time: 133.26 s 
2025-06-03 19:16:27.980224:  
2025-06-03 19:16:28.233006: Epoch 51 
2025-06-03 19:16:28.248054: Current learning rate: 0.00954 
2025-06-03 19:18:45.108793: train_loss -0.6581 
2025-06-03 19:18:45.324746: val_loss -0.6152 
2025-06-03 19:18:45.338081: Pseudo dice [np.float32(0.6632)] 
2025-06-03 19:18:45.721831: Epoch time: 137.13 s 
2025-06-03 19:18:51.282625:  
2025-06-03 19:18:51.298831: Epoch 52 
2025-06-03 19:18:51.311825: Current learning rate: 0.00953 
2025-06-03 19:21:03.771482: train_loss -0.6595 
2025-06-03 19:21:04.069312: val_loss -0.6082 
2025-06-03 19:21:04.533609: Pseudo dice [np.float32(0.6186)] 
2025-06-03 19:21:04.926469: Epoch time: 132.49 s 
2025-06-03 19:21:09.559363:  
2025-06-03 19:21:09.576792: Epoch 53 
2025-06-03 19:21:09.592564: Current learning rate: 0.00952 
2025-06-03 19:23:25.194554: train_loss -0.6273 
2025-06-03 19:23:25.405338: val_loss -0.5697 
2025-06-03 19:23:25.689388: Pseudo dice [np.float32(0.6273)] 
2025-06-03 19:23:26.075891: Epoch time: 135.64 s 
2025-06-03 19:23:32.220721:  
2025-06-03 19:23:32.238239: Epoch 54 
2025-06-03 19:23:32.254136: Current learning rate: 0.00951 
2025-06-03 19:25:49.207375: train_loss -0.6477 
2025-06-03 19:25:49.559875: val_loss -0.6226 
2025-06-03 19:25:50.055172: Pseudo dice [np.float32(0.7174)] 
2025-06-03 19:25:50.558857: Epoch time: 137.03 s 
2025-06-03 19:25:55.814964:  
2025-06-03 19:25:56.038338: Epoch 55 
2025-06-03 19:25:56.053701: Current learning rate: 0.0095 
2025-06-03 19:28:12.946792: train_loss -0.6426 
2025-06-03 19:28:12.968341: val_loss -0.6564 
2025-06-03 19:28:12.980639: Pseudo dice [np.float32(0.8085)] 
2025-06-03 19:28:12.992613: Epoch time: 137.13 s 
2025-06-03 19:28:13.005050: Yayy! New best EMA pseudo Dice: 0.6883999705314636 
2025-06-03 19:28:19.442986:  
2025-06-03 19:28:19.547861: Epoch 56 
2025-06-03 19:28:19.666357: Current learning rate: 0.00949 
2025-06-03 19:30:38.588165: train_loss -0.6625 
2025-06-03 19:30:38.615222: val_loss -0.6825 
2025-06-03 19:30:38.633442: Pseudo dice [np.float32(0.8087)] 
2025-06-03 19:30:38.647175: Epoch time: 139.15 s 
2025-06-03 19:30:38.659779: Yayy! New best EMA pseudo Dice: 0.7005000114440918 
2025-06-03 19:30:45.888688:  
2025-06-03 19:30:46.240560: Epoch 57 
2025-06-03 19:30:46.499108: Current learning rate: 0.00949 
2025-06-03 19:32:59.950918: train_loss -0.6856 
2025-06-03 19:33:00.328310: val_loss -0.6193 
2025-06-03 19:33:00.621047: Pseudo dice [np.float32(0.6499)] 
2025-06-03 19:33:00.965721: Epoch time: 134.06 s 
2025-06-03 19:33:07.312579:  
2025-06-03 19:33:07.327973: Epoch 58 
2025-06-03 19:33:07.340095: Current learning rate: 0.00948 
2025-06-03 19:35:18.594877: train_loss -0.6189 
2025-06-03 19:35:18.724132: val_loss -0.6373 
2025-06-03 19:35:18.820353: Pseudo dice [np.float32(0.7255)] 
2025-06-03 19:35:18.859211: Epoch time: 131.28 s 
2025-06-03 19:35:20.486749:  
2025-06-03 19:35:20.502982: Epoch 59 
2025-06-03 19:35:20.516930: Current learning rate: 0.00947 
2025-06-03 19:37:33.257233: train_loss -0.6444 
2025-06-03 19:37:33.276802: val_loss -0.6159 
2025-06-03 19:37:33.290937: Pseudo dice [np.float32(0.7234)] 
2025-06-03 19:37:33.304106: Epoch time: 132.77 s 
2025-06-03 19:37:33.316502: Yayy! New best EMA pseudo Dice: 0.7009000182151794 
2025-06-03 19:37:36.408826:  
2025-06-03 19:37:36.443177: Epoch 60 
2025-06-03 19:37:36.459243: Current learning rate: 0.00946 
2025-06-03 19:39:48.308405: train_loss -0.6542 
2025-06-03 19:39:48.498548: val_loss -0.692 
2025-06-03 19:39:48.513638: Pseudo dice [np.float32(0.7696)] 
2025-06-03 19:39:48.527617: Epoch time: 131.9 s 
2025-06-03 19:39:48.541944: Yayy! New best EMA pseudo Dice: 0.7077999711036682 
2025-06-03 19:39:54.121631:  
2025-06-03 19:39:54.148894: Epoch 61 
2025-06-03 19:39:54.289381: Current learning rate: 0.00945 
2025-06-03 19:42:05.309070: train_loss -0.6472 
2025-06-03 19:42:05.325122: val_loss -0.6334 
2025-06-03 19:42:05.337810: Pseudo dice [np.float32(0.7813)] 
2025-06-03 19:42:05.351693: Epoch time: 131.19 s 
2025-06-03 19:42:05.363691: Yayy! New best EMA pseudo Dice: 0.7150999903678894 
2025-06-03 19:42:14.690846:  
2025-06-03 19:42:14.707583: Epoch 62 
2025-06-03 19:42:14.846432: Current learning rate: 0.00944 
2025-06-03 19:44:24.245754: train_loss -0.6468 
2025-06-03 19:44:24.631235: val_loss -0.5618 
2025-06-03 19:44:24.648616: Pseudo dice [np.float32(0.6434)] 
2025-06-03 19:44:24.662435: Epoch time: 129.56 s 
2025-06-03 19:44:30.196995:  
2025-06-03 19:44:30.397652: Epoch 63 
2025-06-03 19:44:30.495589: Current learning rate: 0.00943 
2025-06-03 19:46:44.709214: train_loss -0.6197 
2025-06-03 19:46:45.286502: val_loss -0.5276 
2025-06-03 19:46:45.490273: Pseudo dice [np.float32(0.4943)] 
2025-06-03 19:46:45.505248: Epoch time: 134.51 s 
2025-06-03 19:46:50.740555:  
2025-06-03 19:46:50.757376: Epoch 64 
2025-06-03 19:46:50.771281: Current learning rate: 0.00942 
2025-06-03 19:49:03.824962: train_loss -0.6315 
2025-06-03 19:49:03.842089: val_loss -0.6028 
2025-06-03 19:49:03.859034: Pseudo dice [np.float32(0.6072)] 
2025-06-03 19:49:03.872596: Epoch time: 133.09 s 
2025-06-03 19:49:08.198150:  
2025-06-03 19:49:08.254034: Epoch 65 
2025-06-03 19:49:08.317781: Current learning rate: 0.00941 
2025-06-03 19:51:19.504807: train_loss -0.6408 
2025-06-03 19:51:19.521127: val_loss -0.6543 
2025-06-03 19:51:19.533739: Pseudo dice [np.float32(0.6976)] 
2025-06-03 19:51:19.545501: Epoch time: 131.31 s 
2025-06-03 19:51:26.248827:  
2025-06-03 19:51:26.346416: Epoch 66 
2025-06-03 19:51:26.452283: Current learning rate: 0.0094 
2025-06-03 19:53:35.656502: train_loss -0.644 
2025-06-03 19:53:35.673206: val_loss -0.6805 
2025-06-03 19:53:35.685827: Pseudo dice [np.float32(0.7545)] 
2025-06-03 19:53:35.698798: Epoch time: 129.41 s 
2025-06-03 19:53:41.895899:  
2025-06-03 19:53:42.013162: Epoch 67 
2025-06-03 19:53:42.143765: Current learning rate: 0.00939 
2025-06-03 19:55:57.625017: train_loss -0.6462 
2025-06-03 19:55:57.968430: val_loss -0.6105 
2025-06-03 19:55:58.093716: Pseudo dice [np.float32(0.719)] 
2025-06-03 19:55:58.543800: Epoch time: 135.73 s 
2025-06-03 19:56:03.558056:  
2025-06-03 19:56:03.989264: Epoch 68 
2025-06-03 19:56:04.289036: Current learning rate: 0.00939 
2025-06-03 19:58:13.757148: train_loss -0.6674 
2025-06-03 19:58:13.779011: val_loss -0.6147 
2025-06-03 19:58:13.797816: Pseudo dice [np.float32(0.6504)] 
2025-06-03 19:58:13.810320: Epoch time: 130.2 s 
2025-06-03 19:58:17.640083:  
2025-06-03 19:58:17.719699: Epoch 69 
2025-06-03 19:58:17.816590: Current learning rate: 0.00938 
2025-06-03 20:00:30.498327: train_loss -0.626 
2025-06-03 20:00:30.515512: val_loss -0.6196 
2025-06-03 20:00:30.528028: Pseudo dice [np.float32(0.732)] 
2025-06-03 20:00:30.541498: Epoch time: 132.86 s 
2025-06-03 20:00:37.045491:  
2025-06-03 20:00:37.330122: Epoch 70 
2025-06-03 20:00:37.499548: Current learning rate: 0.00937 
2025-06-03 20:02:48.013067: train_loss -0.6494 
2025-06-03 20:02:48.029203: val_loss -0.637 
2025-06-03 20:02:48.042066: Pseudo dice [np.float32(0.75)] 
2025-06-03 20:02:48.055379: Epoch time: 130.97 s 
2025-06-03 20:02:53.924847:  
2025-06-03 20:02:53.942061: Epoch 71 
2025-06-03 20:02:53.955571: Current learning rate: 0.00936 
2025-06-03 20:05:05.769906: train_loss -0.6576 
2025-06-03 20:05:06.376688: val_loss -0.5976 
2025-06-03 20:05:06.596078: Pseudo dice [np.float32(0.6734)] 
2025-06-03 20:05:06.612201: Epoch time: 131.85 s 
2025-06-03 20:05:11.137766:  
2025-06-03 20:05:11.155031: Epoch 72 
2025-06-03 20:05:11.168117: Current learning rate: 0.00935 
2025-06-03 20:07:24.412456: train_loss -0.6543 
2025-06-03 20:07:24.430758: val_loss -0.6138 
2025-06-03 20:07:24.443702: Pseudo dice [np.float32(0.7001)] 
2025-06-03 20:07:24.458660: Epoch time: 133.28 s 
2025-06-03 20:07:30.738247:  
2025-06-03 20:07:30.875463: Epoch 73 
2025-06-03 20:07:30.892765: Current learning rate: 0.00934 
2025-06-03 20:09:47.887278: train_loss -0.6437 
2025-06-03 20:09:47.902924: val_loss -0.6659 
2025-06-03 20:09:47.918299: Pseudo dice [np.float32(0.6856)] 
2025-06-03 20:09:47.931700: Epoch time: 137.15 s 
2025-06-03 20:09:55.540425:  
2025-06-03 20:09:55.784479: Epoch 74 
2025-06-03 20:09:56.220119: Current learning rate: 0.00933 
2025-06-03 20:12:12.057784: train_loss -0.6405 
2025-06-03 20:12:12.320241: val_loss -0.6154 
2025-06-03 20:12:12.512179: Pseudo dice [np.float32(0.5698)] 
2025-06-03 20:12:12.527353: Epoch time: 136.52 s 
2025-06-03 20:12:19.334285:  
2025-06-03 20:12:19.353347: Epoch 75 
2025-06-03 20:12:19.369646: Current learning rate: 0.00932 
2025-06-03 20:14:29.153620: train_loss -0.6619 
2025-06-03 20:14:29.170508: val_loss -0.6601 
2025-06-03 20:14:29.183019: Pseudo dice [np.float32(0.7418)] 
2025-06-03 20:14:29.196352: Epoch time: 129.82 s 
2025-06-03 20:14:34.503228:  
2025-06-03 20:14:34.568622: Epoch 76 
2025-06-03 20:14:34.611775: Current learning rate: 0.00931 
2025-06-03 20:16:45.668908: train_loss -0.6551 
2025-06-03 20:16:45.902139: val_loss -0.662 
2025-06-03 20:16:45.916913: Pseudo dice [np.float32(0.7104)] 
2025-06-03 20:16:45.929251: Epoch time: 131.17 s 
2025-06-03 20:16:51.183844:  
2025-06-03 20:16:51.334717: Epoch 77 
2025-06-03 20:16:51.349525: Current learning rate: 0.0093 
2025-06-03 20:19:06.226349: train_loss -0.6303 
2025-06-03 20:19:06.575238: val_loss -0.6192 
2025-06-03 20:19:06.970291: Pseudo dice [np.float32(0.6668)] 
2025-06-03 20:19:07.371060: Epoch time: 135.04 s 
2025-06-03 20:19:14.374106:  
2025-06-03 20:19:14.547787: Epoch 78 
2025-06-03 20:19:14.833470: Current learning rate: 0.0093 
2025-06-03 20:21:32.792296: train_loss -0.6458 
2025-06-03 20:21:33.299532: val_loss -0.6668 
2025-06-03 20:21:33.772791: Pseudo dice [np.float32(0.7535)] 
2025-06-03 20:21:34.241318: Epoch time: 138.42 s 
2025-06-03 20:21:39.770349:  
2025-06-03 20:21:40.058015: Epoch 79 
2025-06-03 20:21:40.328037: Current learning rate: 0.00929 
2025-06-03 20:23:52.750981: train_loss -0.6567 
2025-06-03 20:23:52.897854: val_loss -0.6714 
2025-06-03 20:23:53.152297: Pseudo dice [np.float32(0.7738)] 
2025-06-03 20:23:53.390001: Epoch time: 132.98 s 
2025-06-03 20:23:58.392367:  
2025-06-03 20:23:58.545733: Epoch 80 
2025-06-03 20:23:58.671741: Current learning rate: 0.00928 
2025-06-03 20:26:16.713562: train_loss -0.6705 
2025-06-03 20:26:16.735955: val_loss -0.6496 
2025-06-03 20:26:16.749047: Pseudo dice [np.float32(0.697)] 
2025-06-03 20:26:16.761473: Epoch time: 138.32 s 
2025-06-03 20:26:25.119203:  
2025-06-03 20:26:25.287644: Epoch 81 
2025-06-03 20:26:25.417622: Current learning rate: 0.00927 
2025-06-03 20:28:44.016553: train_loss -0.652 
2025-06-03 20:28:44.579218: val_loss -0.6107 
2025-06-03 20:28:44.985312: Pseudo dice [np.float32(0.7006)] 
2025-06-03 20:28:45.484857: Epoch time: 138.9 s 
2025-06-03 20:28:49.775438:  
2025-06-03 20:28:49.926644: Epoch 82 
2025-06-03 20:28:50.174338: Current learning rate: 0.00926 
2025-06-03 20:31:05.010307: train_loss -0.669 
2025-06-03 20:31:05.198647: val_loss -0.6595 
2025-06-03 20:31:05.366183: Pseudo dice [np.float32(0.7166)] 
2025-06-03 20:31:05.676315: Epoch time: 135.24 s 
2025-06-03 20:31:11.898289:  
2025-06-03 20:31:12.115723: Epoch 83 
2025-06-03 20:31:12.430292: Current learning rate: 0.00925 
2025-06-03 20:33:27.755692: train_loss -0.6529 
2025-06-03 20:33:27.777846: val_loss -0.674 
2025-06-03 20:33:27.791782: Pseudo dice [np.float32(0.7552)] 
2025-06-03 20:33:27.805073: Epoch time: 135.86 s 
2025-06-03 20:33:35.954834:  
2025-06-03 20:33:36.185736: Epoch 84 
2025-06-03 20:33:36.396586: Current learning rate: 0.00924 
2025-06-03 20:35:55.650484: train_loss -0.6907 
2025-06-03 20:35:55.957911: val_loss -0.6524 
2025-06-03 20:35:55.972977: Pseudo dice [np.float32(0.7696)] 
2025-06-03 20:35:55.986676: Epoch time: 139.7 s 
2025-06-03 20:36:02.562597:  
2025-06-03 20:36:02.662772: Epoch 85 
2025-06-03 20:36:02.760420: Current learning rate: 0.00923 
2025-06-03 20:38:17.567622: train_loss -0.6849 
2025-06-03 20:38:17.888936: val_loss -0.6703 
2025-06-03 20:38:18.191316: Pseudo dice [np.float32(0.7628)] 
2025-06-03 20:38:18.425895: Epoch time: 135.01 s 
2025-06-03 20:38:18.618984: Yayy! New best EMA pseudo Dice: 0.7193999886512756 
2025-06-03 20:38:21.161179:  
2025-06-03 20:38:21.187464: Epoch 86 
2025-06-03 20:38:21.202824: Current learning rate: 0.00922 
2025-06-03 20:40:33.910648: train_loss -0.6604 
2025-06-03 20:40:33.929229: val_loss -0.6106 
2025-06-03 20:40:33.942889: Pseudo dice [np.float32(0.7189)] 
2025-06-03 20:40:33.956675: Epoch time: 132.75 s 
2025-06-03 20:40:35.797924:  
2025-06-03 20:40:35.829018: Epoch 87 
2025-06-03 20:40:35.844187: Current learning rate: 0.00921 
2025-06-03 20:42:49.161313: train_loss -0.6723 
2025-06-03 20:42:49.200028: val_loss -0.6234 
2025-06-03 20:42:49.256731: Pseudo dice [np.float32(0.7565)] 
2025-06-03 20:42:49.292381: Epoch time: 133.36 s 
2025-06-03 20:42:49.306231: Yayy! New best EMA pseudo Dice: 0.7229999899864197 
2025-06-03 20:42:52.048484:  
2025-06-03 20:42:52.170615: Epoch 88 
2025-06-03 20:42:52.271090: Current learning rate: 0.0092 
2025-06-03 20:44:59.227073: train_loss -0.6586 
2025-06-03 20:44:59.621667: val_loss -0.6648 
2025-06-03 20:45:00.024471: Pseudo dice [np.float32(0.7677)] 
2025-06-03 20:45:00.541848: Epoch time: 127.18 s 
2025-06-03 20:45:01.022928: Yayy! New best EMA pseudo Dice: 0.7275000214576721 
2025-06-03 20:45:06.535190:  
2025-06-03 20:45:06.642060: Epoch 89 
2025-06-03 20:45:06.656324: Current learning rate: 0.0092 
2025-06-03 20:47:19.615477: train_loss -0.6642 
2025-06-03 20:47:19.634375: val_loss -0.6389 
2025-06-03 20:47:19.649572: Pseudo dice [np.float32(0.656)] 
2025-06-03 20:47:19.668814: Epoch time: 133.08 s 
2025-06-03 20:47:24.218913:  
2025-06-03 20:47:24.493260: Epoch 90 
2025-06-03 20:47:24.759201: Current learning rate: 0.00919 
2025-06-03 20:49:37.437296: train_loss -0.6479 
2025-06-03 20:49:37.458280: val_loss -0.6565 
2025-06-03 20:49:37.474028: Pseudo dice [np.float32(0.7783)] 
2025-06-03 20:49:37.489682: Epoch time: 133.22 s 
2025-06-03 20:49:44.126793:  
2025-06-03 20:49:44.314844: Epoch 91 
2025-06-03 20:49:44.490081: Current learning rate: 0.00918 
2025-06-03 20:51:55.457732: train_loss -0.6809 
2025-06-03 20:51:55.475427: val_loss -0.657 
2025-06-03 20:51:55.489688: Pseudo dice [np.float32(0.73)] 
2025-06-03 20:51:55.505605: Epoch time: 131.33 s 
2025-06-03 20:52:04.058928:  
2025-06-03 20:52:04.439679: Epoch 92 
2025-06-03 20:52:04.885290: Current learning rate: 0.00917 
2025-06-03 20:54:15.894443: train_loss -0.7032 
2025-06-03 20:54:15.912169: val_loss -0.6401 
2025-06-03 20:54:15.925165: Pseudo dice [np.float32(0.6873)] 
2025-06-03 20:54:15.937997: Epoch time: 131.84 s 
2025-06-03 20:54:20.981253:  
2025-06-03 20:54:20.997656: Epoch 93 
2025-06-03 20:54:21.009830: Current learning rate: 0.00916 
2025-06-03 20:56:35.232652: train_loss -0.6491 
2025-06-03 20:56:35.252759: val_loss -0.6682 
2025-06-03 20:56:35.267162: Pseudo dice [np.float32(0.6993)] 
2025-06-03 20:56:35.279679: Epoch time: 134.25 s 
2025-06-03 20:56:40.517870:  
2025-06-03 20:56:40.819489: Epoch 94 
2025-06-03 20:56:40.835639: Current learning rate: 0.00915 
2025-06-03 20:58:53.217265: train_loss -0.6603 
2025-06-03 20:58:53.234450: val_loss -0.7025 
2025-06-03 20:58:53.247369: Pseudo dice [np.float32(0.8226)] 
2025-06-03 20:58:53.261570: Epoch time: 132.7 s 
2025-06-03 20:58:53.275341: Yayy! New best EMA pseudo Dice: 0.7304999828338623 
2025-06-03 20:59:03.736520:  
2025-06-03 20:59:03.755337: Epoch 95 
2025-06-03 20:59:03.767864: Current learning rate: 0.00914 
2025-06-03 21:01:18.269399: train_loss -0.6896 
2025-06-03 21:01:18.731090: val_loss -0.6259 
2025-06-03 21:01:19.136296: Pseudo dice [np.float32(0.7612)] 
2025-06-03 21:01:19.462416: Epoch time: 134.61 s 
2025-06-03 21:01:19.477264: Yayy! New best EMA pseudo Dice: 0.7336000204086304 
2025-06-03 21:01:25.340173:  
2025-06-03 21:01:25.357588: Epoch 96 
2025-06-03 21:01:25.369718: Current learning rate: 0.00913 
2025-06-03 21:03:42.692636: train_loss -0.6411 
2025-06-03 21:03:43.071390: val_loss -0.6223 
2025-06-03 21:03:43.240001: Pseudo dice [np.float32(0.6274)] 
2025-06-03 21:03:43.254582: Epoch time: 137.35 s 
2025-06-03 21:03:46.745792:  
2025-06-03 21:03:46.942209: Epoch 97 
2025-06-03 21:03:47.270528: Current learning rate: 0.00912 
2025-06-03 21:06:04.947351: train_loss -0.6864 
2025-06-03 21:06:04.965897: val_loss -0.6366 
2025-06-03 21:06:04.981576: Pseudo dice [np.float32(0.6711)] 
2025-06-03 21:06:04.995276: Epoch time: 138.2 s 
2025-06-03 21:06:09.625095:  
2025-06-03 21:06:09.827711: Epoch 98 
2025-06-03 21:06:09.842503: Current learning rate: 0.00911 
2025-06-03 21:08:24.658132: train_loss -0.6643 
2025-06-03 21:08:25.034490: val_loss -0.633 
2025-06-03 21:08:25.054641: Pseudo dice [np.float32(0.6692)] 
2025-06-03 21:08:25.067574: Epoch time: 135.04 s 
2025-06-03 21:08:30.463792:  
2025-06-03 21:08:30.613139: Epoch 99 
2025-06-03 21:08:30.738737: Current learning rate: 0.0091 
2025-06-03 21:10:47.291422: train_loss -0.6697 
2025-06-03 21:10:47.311109: val_loss -0.6718 
2025-06-03 21:10:47.325122: Pseudo dice [np.float32(0.7365)] 
2025-06-03 21:10:47.341364: Epoch time: 136.83 s 
2025-06-03 21:10:55.293347:  
2025-06-03 21:10:55.667074: Epoch 100 
2025-06-03 21:10:56.044554: Current learning rate: 0.0091 
2025-06-03 21:13:13.003053: train_loss -0.6822 
2025-06-03 21:13:13.198463: val_loss -0.6518 
2025-06-03 21:13:13.355440: Pseudo dice [np.float32(0.6947)] 
2025-06-03 21:13:13.725951: Epoch time: 137.71 s 
2025-06-03 21:13:18.514632:  
2025-06-03 21:13:18.723937: Epoch 101 
2025-06-03 21:13:18.921057: Current learning rate: 0.00909 
2025-06-03 21:15:28.479427: train_loss -0.6581 
2025-06-03 21:15:28.799646: val_loss -0.6745 
2025-06-03 21:15:29.207218: Pseudo dice [np.float32(0.7389)] 
2025-06-03 21:15:29.714031: Epoch time: 129.97 s 
2025-06-03 21:15:34.640961:  
2025-06-03 21:15:34.658203: Epoch 102 
2025-06-03 21:15:34.671269: Current learning rate: 0.00908 
2025-06-03 21:17:51.016934: train_loss -0.6341 
2025-06-03 21:17:51.349797: val_loss -0.6238 
2025-06-03 21:17:51.365813: Pseudo dice [np.float32(0.7174)] 
2025-06-03 21:17:51.378471: Epoch time: 136.38 s 
2025-06-03 21:17:57.668653:  
2025-06-03 21:17:57.836569: Epoch 103 
2025-06-03 21:17:58.057444: Current learning rate: 0.00907 
2025-06-03 21:20:11.459011: train_loss -0.662 
2025-06-03 21:20:11.600582: val_loss -0.6232 
2025-06-03 21:20:11.746316: Pseudo dice [np.float32(0.6772)] 
2025-06-03 21:20:11.760803: Epoch time: 133.79 s 
2025-06-03 21:20:15.838232:  
2025-06-03 21:20:16.120854: Epoch 104 
2025-06-03 21:20:16.236106: Current learning rate: 0.00906 
2025-06-03 21:22:31.631278: train_loss -0.6785 
2025-06-03 21:22:31.925716: val_loss -0.6186 
2025-06-03 21:22:32.328707: Pseudo dice [np.float32(0.6746)] 
2025-06-03 21:22:32.345649: Epoch time: 135.8 s 
2025-06-03 21:22:37.145931:  
2025-06-03 21:22:37.163987: Epoch 105 
2025-06-03 21:22:37.176313: Current learning rate: 0.00905 
2025-06-03 21:24:52.131079: train_loss -0.6448 
2025-06-03 21:24:52.150988: val_loss -0.6863 
2025-06-03 21:24:52.165271: Pseudo dice [np.float32(0.7529)] 
2025-06-03 21:24:52.176561: Epoch time: 134.99 s 
2025-06-03 21:24:55.632072:  
2025-06-03 21:24:55.864813: Epoch 106 
2025-06-03 21:24:55.881966: Current learning rate: 0.00904 
2025-06-03 21:27:06.825471: train_loss -0.6721 
2025-06-03 21:27:06.849491: val_loss -0.6387 
2025-06-03 21:27:06.980251: Pseudo dice [np.float32(0.7182)] 
2025-06-03 21:27:06.995565: Epoch time: 131.2 s 
2025-06-03 21:27:11.029531:  
2025-06-03 21:27:11.047306: Epoch 107 
2025-06-03 21:27:11.060182: Current learning rate: 0.00903 
2025-06-03 21:29:28.934498: train_loss -0.6628 
2025-06-03 21:29:28.956390: val_loss -0.6557 
2025-06-03 21:29:28.969357: Pseudo dice [np.float32(0.7255)] 
2025-06-03 21:29:28.982174: Epoch time: 137.91 s 
2025-06-03 21:29:34.068734:  
2025-06-03 21:29:34.229887: Epoch 108 
2025-06-03 21:29:34.367883: Current learning rate: 0.00902 
2025-06-03 21:31:49.841761: train_loss -0.6653 
2025-06-03 21:31:49.868956: val_loss -0.7014 
2025-06-03 21:31:50.009089: Pseudo dice [np.float32(0.7958)] 
2025-06-03 21:31:50.179900: Epoch time: 135.77 s 
2025-06-03 21:31:56.317039:  
2025-06-03 21:31:56.455993: Epoch 109 
2025-06-03 21:31:56.558071: Current learning rate: 0.00901 
2025-06-03 21:34:14.270959: train_loss -0.6625 
2025-06-03 21:34:14.630121: val_loss -0.5697 
2025-06-03 21:34:14.961627: Pseudo dice [np.float32(0.7348)] 
2025-06-03 21:34:14.977035: Epoch time: 137.96 s 
2025-06-03 21:34:21.576940:  
2025-06-03 21:34:21.792441: Epoch 110 
2025-06-03 21:34:21.809351: Current learning rate: 0.009 
2025-06-03 21:36:34.590600: train_loss -0.6242 
2025-06-03 21:36:34.615457: val_loss -0.6829 
2025-06-03 21:36:34.628552: Pseudo dice [np.float32(0.7392)] 
2025-06-03 21:36:34.642456: Epoch time: 133.02 s 
2025-06-03 21:36:38.913518:  
2025-06-03 21:36:38.924722: Epoch 111 
2025-06-03 21:36:38.934341: Current learning rate: 0.009 
2025-06-03 21:38:50.091328: train_loss -0.6706 
2025-06-03 21:38:50.106018: val_loss -0.6333 
2025-06-03 21:38:50.119438: Pseudo dice [np.float32(0.7335)] 
2025-06-03 21:38:50.132045: Epoch time: 131.18 s 
2025-06-03 21:38:51.945417:  
2025-06-03 21:38:51.968565: Epoch 112 
2025-06-03 21:38:51.997148: Current learning rate: 0.00899 
2025-06-03 21:41:06.888757: train_loss -0.6948 
2025-06-03 21:41:06.904570: val_loss -0.6609 
2025-06-03 21:41:06.917718: Pseudo dice [np.float32(0.7394)] 
2025-06-03 21:41:06.930891: Epoch time: 134.94 s 
2025-06-03 21:41:10.752292:  
2025-06-03 21:41:10.840644: Epoch 113 
2025-06-03 21:41:10.936695: Current learning rate: 0.00898 
2025-06-03 21:43:24.279531: train_loss -0.6859 
2025-06-03 21:43:24.297912: val_loss -0.6337 
2025-06-03 21:43:24.311325: Pseudo dice [np.float32(0.7196)] 
2025-06-03 21:43:24.324734: Epoch time: 133.53 s 
2025-06-03 21:43:30.280268:  
2025-06-03 21:43:30.668970: Epoch 114 
2025-06-03 21:43:31.074653: Current learning rate: 0.00897 
2025-06-03 21:45:44.836441: train_loss -0.672 
2025-06-03 21:45:44.854319: val_loss -0.5977 
2025-06-03 21:45:44.868195: Pseudo dice [np.float32(0.7056)] 
2025-06-03 21:45:44.881670: Epoch time: 134.56 s 
2025-06-03 21:45:53.342334:  
2025-06-03 21:45:53.360719: Epoch 115 
2025-06-03 21:45:53.373796: Current learning rate: 0.00896 
2025-06-03 21:48:00.295966: train_loss -0.6861 
2025-06-03 21:48:00.313115: val_loss -0.6771 
2025-06-03 21:48:00.325808: Pseudo dice [np.float32(0.7747)] 
2025-06-03 21:48:00.338187: Epoch time: 126.96 s 
2025-06-03 21:48:06.182514:  
2025-06-03 21:48:06.352502: Epoch 116 
2025-06-03 21:48:06.456316: Current learning rate: 0.00895 
2025-06-03 21:50:21.916059: train_loss -0.6574 
2025-06-03 21:50:21.932598: val_loss -0.6252 
2025-06-03 21:50:21.945947: Pseudo dice [np.float32(0.6411)] 
2025-06-03 21:50:21.958531: Epoch time: 135.74 s 
2025-06-03 21:50:26.253665:  
2025-06-03 21:50:26.270047: Epoch 117 
2025-06-03 21:50:26.283051: Current learning rate: 0.00894 
2025-06-03 21:52:43.235979: train_loss -0.6568 
2025-06-03 21:52:43.253560: val_loss -0.6624 
2025-06-03 21:52:43.265960: Pseudo dice [np.float32(0.7451)] 
2025-06-03 21:52:43.278845: Epoch time: 136.98 s 
2025-06-03 21:52:48.000453:  
2025-06-03 21:52:48.102144: Epoch 118 
2025-06-03 21:52:48.181304: Current learning rate: 0.00893 
2025-06-03 21:55:02.865321: train_loss -0.68 
2025-06-03 21:55:02.984270: val_loss -0.7305 
2025-06-03 21:55:02.999158: Pseudo dice [np.float32(0.7897)] 
2025-06-03 21:55:03.012073: Epoch time: 134.87 s 
2025-06-03 21:55:09.852968:  
2025-06-03 21:55:10.045638: Epoch 119 
2025-06-03 21:55:10.250404: Current learning rate: 0.00892 
2025-06-03 21:57:26.187717: train_loss -0.696 
2025-06-03 21:57:26.597559: val_loss -0.6235 
2025-06-03 21:57:26.611634: Pseudo dice [np.float32(0.7061)] 
2025-06-03 21:57:26.624482: Epoch time: 136.34 s 
2025-06-03 21:57:33.670474:  
2025-06-03 21:57:34.078428: Epoch 120 
2025-06-03 21:57:34.521187: Current learning rate: 0.00891 
2025-06-03 21:59:55.322426: train_loss -0.6719 
2025-06-03 21:59:55.339149: val_loss -0.6924 
2025-06-03 21:59:55.351913: Pseudo dice [np.float32(0.79)] 
2025-06-03 21:59:55.364795: Epoch time: 141.65 s 
2025-06-03 21:59:55.377903: Yayy! New best EMA pseudo Dice: 0.7336999773979187 
2025-06-03 22:00:02.841368:  
2025-06-03 22:00:03.066396: Epoch 121 
2025-06-03 22:00:03.292624: Current learning rate: 0.0089 
2025-06-03 22:02:18.236792: train_loss -0.6947 
2025-06-03 22:02:18.252815: val_loss -0.6484 
2025-06-03 22:02:18.266631: Pseudo dice [np.float32(0.7733)] 
2025-06-03 22:02:18.279464: Epoch time: 135.4 s 
2025-06-03 22:02:18.292318: Yayy! New best EMA pseudo Dice: 0.7376999855041504 
2025-06-03 22:02:25.261892:  
2025-06-03 22:02:25.363700: Epoch 122 
2025-06-03 22:02:25.515774: Current learning rate: 0.00889 
2025-06-03 22:04:40.993021: train_loss -0.6607 
2025-06-03 22:04:41.011436: val_loss -0.6253 
2025-06-03 22:04:41.024625: Pseudo dice [np.float32(0.7208)] 
2025-06-03 22:04:41.037584: Epoch time: 135.73 s 
2025-06-03 22:04:45.833888:  
2025-06-03 22:04:45.850571: Epoch 123 
2025-06-03 22:04:45.864311: Current learning rate: 0.00889 
2025-06-03 22:07:01.656266: train_loss -0.629 
2025-06-03 22:07:02.189479: val_loss -0.6832 
2025-06-03 22:07:02.370374: Pseudo dice [np.float32(0.7234)] 
2025-06-03 22:07:02.384138: Epoch time: 135.82 s 
2025-06-03 22:07:09.593790:  
2025-06-03 22:07:09.788431: Epoch 124 
2025-06-03 22:07:10.062164: Current learning rate: 0.00888 
2025-06-03 22:09:25.063380: train_loss -0.683 
2025-06-03 22:09:25.515864: val_loss -0.6497 
2025-06-03 22:09:25.878198: Pseudo dice [np.float32(0.756)] 
2025-06-03 22:09:25.893507: Epoch time: 135.47 s 
2025-06-03 22:09:31.725449:  
2025-06-03 22:09:32.041552: Epoch 125 
2025-06-03 22:09:32.457453: Current learning rate: 0.00887 
2025-06-03 22:11:50.152238: train_loss -0.6788 
2025-06-03 22:11:50.175344: val_loss -0.6469 
2025-06-03 22:11:50.194131: Pseudo dice [np.float32(0.7227)] 
2025-06-03 22:11:50.207842: Epoch time: 138.43 s 
2025-06-03 22:11:57.389387:  
2025-06-03 22:11:57.664343: Epoch 126 
2025-06-03 22:11:57.679843: Current learning rate: 0.00886 
2025-06-03 22:14:13.616434: train_loss -0.6658 
2025-06-03 22:14:13.640123: val_loss -0.6535 
2025-06-03 22:14:13.653032: Pseudo dice [np.float32(0.7219)] 
2025-06-03 22:14:13.665902: Epoch time: 136.23 s 
2025-06-03 22:14:17.630010:  
2025-06-03 22:14:17.936444: Epoch 127 
2025-06-03 22:14:18.262240: Current learning rate: 0.00885 
2025-06-03 22:16:35.766104: train_loss -0.685 
2025-06-03 22:16:36.029411: val_loss -0.6732 
2025-06-03 22:16:36.046731: Pseudo dice [np.float32(0.7421)] 
2025-06-03 22:16:36.059500: Epoch time: 138.14 s 
2025-06-03 22:16:40.609404:  
2025-06-03 22:16:40.807954: Epoch 128 
2025-06-03 22:16:41.054306: Current learning rate: 0.00884 
2025-06-03 22:18:56.115172: train_loss -0.6689 
2025-06-03 22:18:56.138897: val_loss -0.6916 
2025-06-03 22:18:56.154757: Pseudo dice [np.float32(0.7421)] 
2025-06-03 22:18:56.169553: Epoch time: 135.51 s 
2025-06-03 22:19:03.112810:  
2025-06-03 22:19:03.324199: Epoch 129 
2025-06-03 22:19:03.555472: Current learning rate: 0.00883 
2025-06-03 22:21:18.762457: train_loss -0.6875 
2025-06-03 22:21:18.785793: val_loss -0.6731 
2025-06-03 22:21:18.800983: Pseudo dice [np.float32(0.6792)] 
2025-06-03 22:21:18.815374: Epoch time: 135.65 s 
2025-06-03 22:21:26.063819:  
2025-06-03 22:21:26.175238: Epoch 130 
2025-06-03 22:21:26.317285: Current learning rate: 0.00882 
2025-06-03 22:23:41.689104: train_loss -0.6866 
2025-06-03 22:23:41.951678: val_loss -0.6797 
2025-06-03 22:23:42.088713: Pseudo dice [np.float32(0.734)] 
2025-06-03 22:23:42.103657: Epoch time: 135.63 s 
2025-06-03 22:23:48.056621:  
2025-06-03 22:23:48.165936: Epoch 131 
2025-06-03 22:23:48.323197: Current learning rate: 0.00881 
2025-06-03 22:26:04.686047: train_loss -0.692 
2025-06-03 22:26:04.935499: val_loss -0.637 
2025-06-03 22:26:05.237233: Pseudo dice [np.float32(0.7083)] 
2025-06-03 22:26:05.836425: Epoch time: 136.63 s 
2025-06-03 22:26:12.029290:  
2025-06-03 22:26:12.304956: Epoch 132 
2025-06-03 22:26:12.564447: Current learning rate: 0.0088 
2025-06-03 22:28:28.530824: train_loss -0.681 
2025-06-03 22:28:28.942796: val_loss -0.6095 
2025-06-03 22:28:29.280912: Pseudo dice [np.float32(0.6674)] 
2025-06-03 22:28:29.684041: Epoch time: 136.51 s 
2025-06-03 22:28:37.395583:  
2025-06-03 22:28:37.530035: Epoch 133 
2025-06-03 22:28:37.622327: Current learning rate: 0.00879 
2025-06-03 22:30:52.924537: train_loss -0.6859 
2025-06-03 22:30:53.050119: val_loss -0.6771 
2025-06-03 22:30:53.124323: Pseudo dice [np.float32(0.7775)] 
2025-06-03 22:30:53.140381: Epoch time: 135.53 s 
2025-06-03 22:30:54.560131:  
2025-06-03 22:30:54.575526: Epoch 134 
2025-06-03 22:30:54.588991: Current learning rate: 0.00879 
2025-06-03 22:33:05.431544: train_loss -0.6952 
2025-06-03 22:33:05.468049: val_loss -0.6627 
2025-06-03 22:33:05.496799: Pseudo dice [np.float32(0.7882)] 
2025-06-03 22:33:05.549531: Epoch time: 130.87 s 
2025-06-03 22:33:07.581828:  
2025-06-03 22:33:07.680424: Epoch 135 
2025-06-03 22:33:07.750638: Current learning rate: 0.00878 
2025-06-03 22:35:18.188422: train_loss -0.6759 
2025-06-03 22:35:18.206332: val_loss -0.678 
2025-06-03 22:35:18.220133: Pseudo dice [np.float32(0.7516)] 
2025-06-03 22:35:18.234308: Epoch time: 130.61 s 
2025-06-03 22:35:20.452186:  
2025-06-03 22:35:20.530725: Epoch 136 
2025-06-03 22:35:20.547617: Current learning rate: 0.00877 
2025-06-03 22:37:33.744420: train_loss -0.6614 
2025-06-03 22:37:33.761283: val_loss -0.6692 
2025-06-03 22:37:33.774418: Pseudo dice [np.float32(0.7108)] 
2025-06-03 22:37:33.787746: Epoch time: 133.29 s 
2025-06-03 22:37:38.122969:  
2025-06-03 22:37:38.319218: Epoch 137 
2025-06-03 22:37:38.504730: Current learning rate: 0.00876 
2025-06-03 22:39:51.018421: train_loss -0.6678 
2025-06-03 22:39:51.313181: val_loss -0.6381 
2025-06-03 22:39:51.328300: Pseudo dice [np.float32(0.6684)] 
2025-06-03 22:39:51.340394: Epoch time: 132.9 s 
2025-06-03 22:39:56.213319:  
2025-06-03 22:39:56.508220: Epoch 138 
2025-06-03 22:39:56.762666: Current learning rate: 0.00875 
2025-06-03 22:42:08.215028: train_loss -0.6813 
2025-06-03 22:42:08.431158: val_loss -0.7454 
2025-06-03 22:42:08.722972: Pseudo dice [np.float32(0.8111)] 
2025-06-03 22:42:09.239303: Epoch time: 132.0 s 
2025-06-03 22:42:14.748347:  
2025-06-03 22:42:14.984018: Epoch 139 
2025-06-03 22:42:15.166152: Current learning rate: 0.00874 
2025-06-03 22:44:28.226332: train_loss -0.671 
2025-06-03 22:44:28.245597: val_loss -0.6202 
2025-06-03 22:44:28.259590: Pseudo dice [np.float32(0.7182)] 
2025-06-03 22:44:28.273940: Epoch time: 133.48 s 
2025-06-03 22:44:34.000171:  
2025-06-03 22:44:34.231870: Epoch 140 
2025-06-03 22:44:34.482780: Current learning rate: 0.00873 
2025-06-03 22:46:46.156939: train_loss -0.6614 
2025-06-03 22:46:46.174753: val_loss -0.6754 
2025-06-03 22:46:46.187699: Pseudo dice [np.float32(0.728)] 
2025-06-03 22:46:46.200500: Epoch time: 132.16 s 
2025-06-03 22:46:52.313065:  
2025-06-03 22:46:52.332005: Epoch 141 
2025-06-03 22:46:52.345703: Current learning rate: 0.00872 
2025-06-03 22:49:05.361268: train_loss -0.6932 
2025-06-03 22:49:05.378486: val_loss -0.6817 
2025-06-03 22:49:05.392749: Pseudo dice [np.float32(0.7441)] 
2025-06-03 22:49:05.405984: Epoch time: 133.11 s 
2025-06-03 22:49:09.299728:  
2025-06-03 22:49:09.447501: Epoch 142 
2025-06-03 22:49:09.460619: Current learning rate: 0.00871 
2025-06-03 22:51:25.591243: train_loss -0.6698 
2025-06-03 22:51:25.909618: val_loss -0.6556 
2025-06-03 22:51:25.924948: Pseudo dice [np.float32(0.7457)] 
2025-06-03 22:51:25.938427: Epoch time: 136.29 s 
2025-06-03 22:51:33.062927:  
2025-06-03 22:51:33.169498: Epoch 143 
2025-06-03 22:51:33.184269: Current learning rate: 0.0087 
2025-06-03 22:53:42.263078: train_loss -0.6911 
2025-06-03 22:53:42.524464: val_loss -0.6651 
2025-06-03 22:53:42.843110: Pseudo dice [np.float32(0.7894)] 
2025-06-03 22:53:43.240087: Epoch time: 129.2 s 
2025-06-03 22:53:43.255985: Yayy! New best EMA pseudo Dice: 0.7404999732971191 
2025-06-03 22:53:49.190432:  
2025-06-03 22:53:49.388698: Epoch 144 
2025-06-03 22:53:49.533140: Current learning rate: 0.00869 
2025-06-03 22:55:58.519565: train_loss -0.6833 
2025-06-03 22:55:58.540901: val_loss -0.6835 
2025-06-03 22:55:58.554511: Pseudo dice [np.float32(0.8067)] 
2025-06-03 22:55:58.567090: Epoch time: 129.33 s 
2025-06-03 22:55:58.580656: Yayy! New best EMA pseudo Dice: 0.7472000122070312 
2025-06-03 22:56:06.653901:  
2025-06-03 22:56:06.901143: Epoch 145 
2025-06-03 22:56:07.120800: Current learning rate: 0.00868 
2025-06-03 22:58:17.908316: train_loss -0.6935 
2025-06-03 22:58:18.441951: val_loss -0.7055 
2025-06-03 22:58:19.098960: Pseudo dice [np.float32(0.8236)] 
2025-06-03 22:58:19.559513: Epoch time: 131.26 s 
2025-06-03 22:58:19.576331: Yayy! New best EMA pseudo Dice: 0.754800021648407 
2025-06-03 22:58:25.106349:  
2025-06-03 22:58:25.153834: Epoch 146 
2025-06-03 22:58:25.277057: Current learning rate: 0.00868 
2025-06-03 23:00:37.290394: train_loss -0.6795 
2025-06-03 23:00:37.308161: val_loss -0.6906 
2025-06-03 23:00:37.321240: Pseudo dice [np.float32(0.6115)] 
2025-06-03 23:00:37.333881: Epoch time: 132.19 s 
2025-06-03 23:00:42.783489:  
2025-06-03 23:00:43.083647: Epoch 147 
2025-06-03 23:00:43.339951: Current learning rate: 0.00867 
2025-06-03 23:02:57.637514: train_loss -0.6908 
2025-06-03 23:02:57.971736: val_loss -0.6533 
2025-06-03 23:02:57.987128: Pseudo dice [np.float32(0.6889)] 
2025-06-03 23:02:58.000039: Epoch time: 134.86 s 
2025-06-03 23:03:05.658836:  
2025-06-03 23:03:05.809871: Epoch 148 
2025-06-03 23:03:06.031849: Current learning rate: 0.00866 
2025-06-03 23:05:17.136505: train_loss -0.6764 
2025-06-03 23:05:17.653258: val_loss -0.7009 
2025-06-03 23:05:17.974127: Pseudo dice [np.float32(0.7993)] 
2025-06-03 23:05:17.995532: Epoch time: 131.48 s 
2025-06-03 23:05:23.560656:  
2025-06-03 23:05:23.784183: Epoch 149 
2025-06-03 23:05:23.996330: Current learning rate: 0.00865 
2025-06-03 23:07:46.040735: train_loss -0.6855 
2025-06-03 23:07:46.506118: val_loss -0.6819 
2025-06-03 23:07:46.831689: Pseudo dice [np.float32(0.7426)] 
2025-06-03 23:07:46.849352: Epoch time: 142.48 s 
2025-06-03 23:07:53.372176:  
2025-06-03 23:07:53.578531: Epoch 150 
2025-06-03 23:07:53.791585: Current learning rate: 0.00864 
2025-06-03 23:10:10.671655: train_loss -0.6901 
2025-06-03 23:10:10.696080: val_loss -0.643 
2025-06-03 23:10:10.713665: Pseudo dice [np.float32(0.7264)] 
2025-06-03 23:10:10.727426: Epoch time: 137.3 s 
2025-06-03 23:10:16.625515:  
2025-06-03 23:10:16.643777: Epoch 151 
2025-06-03 23:10:16.657262: Current learning rate: 0.00863 
2025-06-03 23:12:29.166500: train_loss -0.6857 
2025-06-03 23:12:29.376618: val_loss -0.6571 
2025-06-03 23:12:29.394982: Pseudo dice [np.float32(0.7447)] 
2025-06-03 23:12:29.410406: Epoch time: 132.54 s 
2025-06-03 23:12:36.939241:  
2025-06-03 23:12:36.956892: Epoch 152 
2025-06-03 23:12:36.973742: Current learning rate: 0.00862 
2025-06-03 23:14:54.690344: train_loss -0.6634 
2025-06-03 23:14:55.198429: val_loss -0.6404 
2025-06-03 23:14:55.667134: Pseudo dice [np.float32(0.6726)] 
2025-06-03 23:14:56.169019: Epoch time: 137.79 s 
2025-06-03 23:15:01.697711:  
2025-06-03 23:15:02.147615: Epoch 153 
2025-06-03 23:15:02.402907: Current learning rate: 0.00861 
2025-06-03 23:17:20.031226: train_loss -0.6863 
2025-06-03 23:17:20.598958: val_loss -0.6472 
2025-06-03 23:17:21.117607: Pseudo dice [np.float32(0.7085)] 
2025-06-03 23:17:21.501529: Epoch time: 138.34 s 
2025-06-03 23:17:27.824792:  
2025-06-03 23:17:27.978231: Epoch 154 
2025-06-03 23:17:28.098317: Current learning rate: 0.0086 
2025-06-03 23:19:48.383825: train_loss -0.6714 
2025-06-03 23:19:48.405274: val_loss -0.6578 
2025-06-03 23:19:48.418119: Pseudo dice [np.float32(0.7865)] 
2025-06-03 23:19:48.431582: Epoch time: 140.56 s 
2025-06-03 23:19:54.864512:  
2025-06-03 23:19:55.044234: Epoch 155 
2025-06-03 23:19:55.218493: Current learning rate: 0.00859 
2025-06-03 23:22:11.120905: train_loss -0.695 
2025-06-03 23:22:11.139914: val_loss -0.6705 
2025-06-03 23:22:11.153728: Pseudo dice [np.float32(0.7682)] 
2025-06-03 23:22:11.166566: Epoch time: 136.26 s 
2025-06-03 23:22:16.229815:  
2025-06-03 23:22:16.383298: Epoch 156 
2025-06-03 23:22:16.630585: Current learning rate: 0.00858 
2025-06-03 23:24:34.865756: train_loss -0.6993 
2025-06-03 23:24:35.154474: val_loss -0.685 
2025-06-03 23:24:35.396839: Pseudo dice [np.float32(0.7652)] 
2025-06-03 23:24:35.875052: Epoch time: 138.64 s 
2025-06-03 23:24:42.387593:  
2025-06-03 23:24:42.527306: Epoch 157 
2025-06-03 23:24:42.780876: Current learning rate: 0.00858 
2025-06-03 23:27:01.657716: train_loss -0.6846 
2025-06-03 23:27:02.155334: val_loss -0.6131 
2025-06-03 23:27:02.383343: Pseudo dice [np.float32(0.7575)] 
2025-06-03 23:27:02.400614: Epoch time: 139.27 s 
2025-06-03 23:27:09.657418:  
2025-06-03 23:27:09.797894: Epoch 158 
2025-06-03 23:27:10.041092: Current learning rate: 0.00857 
2025-06-03 23:29:19.500082: train_loss -0.7069 
2025-06-03 23:29:19.880257: val_loss -0.6525 
2025-06-03 23:29:20.247308: Pseudo dice [np.float32(0.7052)] 
2025-06-03 23:29:20.393828: Epoch time: 129.85 s 
2025-06-03 23:29:25.663368:  
2025-06-03 23:29:25.675798: Epoch 159 
2025-06-03 23:29:25.685158: Current learning rate: 0.00856 
2025-06-03 23:31:38.833754: train_loss -0.6692 
2025-06-03 23:31:38.850779: val_loss -0.6604 
2025-06-03 23:31:38.863209: Pseudo dice [np.float32(0.7634)] 
2025-06-03 23:31:38.875611: Epoch time: 133.17 s 
2025-06-03 23:31:41.344218:  
2025-06-03 23:31:41.359605: Epoch 160 
2025-06-03 23:31:41.371520: Current learning rate: 0.00855 
2025-06-03 23:33:55.355731: train_loss -0.7018 
2025-06-03 23:33:55.373446: val_loss -0.626 
2025-06-03 23:33:55.386800: Pseudo dice [np.float32(0.7525)] 
2025-06-03 23:33:55.399482: Epoch time: 134.01 s 
2025-06-03 23:33:57.315138:  
2025-06-03 23:33:57.332193: Epoch 161 
2025-06-03 23:33:57.345484: Current learning rate: 0.00854 
2025-06-03 23:36:10.268346: train_loss -0.6397 
2025-06-03 23:36:10.379358: val_loss -0.6304 
2025-06-03 23:36:10.468780: Pseudo dice [np.float32(0.6624)] 
2025-06-03 23:36:10.555336: Epoch time: 132.95 s 
2025-06-03 23:36:13.479722:  
2025-06-03 23:36:13.671682: Epoch 162 
2025-06-03 23:36:13.712628: Current learning rate: 0.00853 
2025-06-03 23:38:23.410693: train_loss -0.6666 
2025-06-03 23:38:23.427522: val_loss -0.6689 
2025-06-03 23:38:23.440654: Pseudo dice [np.float32(0.6946)] 
2025-06-03 23:38:23.452425: Epoch time: 129.93 s 
2025-06-03 23:38:29.284472:  
2025-06-03 23:38:29.368720: Epoch 163 
2025-06-03 23:38:29.387580: Current learning rate: 0.00852 
2025-06-03 23:40:41.445274: train_loss -0.6693 
2025-06-03 23:40:41.464065: val_loss -0.6749 
2025-06-03 23:40:41.479831: Pseudo dice [np.float32(0.7071)] 
2025-06-03 23:40:41.494571: Epoch time: 132.16 s 
2025-06-03 23:40:48.502723:  
2025-06-03 23:40:48.749706: Epoch 164 
2025-06-03 23:40:48.926419: Current learning rate: 0.00851 
2025-06-03 23:42:59.502054: train_loss -0.6713 
2025-06-03 23:42:59.918255: val_loss -0.652 
2025-06-03 23:43:00.333677: Pseudo dice [np.float32(0.7092)] 
2025-06-03 23:43:00.605403: Epoch time: 131.0 s 
2025-06-03 23:43:06.080307:  
2025-06-03 23:43:06.387663: Epoch 165 
2025-06-03 23:43:06.698549: Current learning rate: 0.0085 
2025-06-03 23:45:20.540841: train_loss -0.6775 
2025-06-03 23:45:20.559121: val_loss -0.6841 
2025-06-03 23:45:20.572366: Pseudo dice [np.float32(0.7207)] 
2025-06-03 23:45:20.586087: Epoch time: 134.46 s 
2025-06-03 23:45:25.809359:  
2025-06-03 23:45:25.995078: Epoch 166 
2025-06-03 23:45:26.167936: Current learning rate: 0.00849 
2025-06-03 23:47:37.926268: train_loss -0.661 
2025-06-03 23:47:38.404795: val_loss -0.6871 
2025-06-03 23:47:38.420211: Pseudo dice [np.float32(0.7623)] 
2025-06-03 23:47:38.432925: Epoch time: 132.12 s 
2025-06-03 23:47:43.817861:  
2025-06-03 23:47:44.170841: Epoch 167 
2025-06-03 23:47:44.189507: Current learning rate: 0.00848 
2025-06-03 23:49:59.976795: train_loss -0.6798 
2025-06-03 23:49:59.993966: val_loss -0.6528 
2025-06-03 23:50:00.007591: Pseudo dice [np.float32(0.7569)] 
2025-06-03 23:50:00.021688: Epoch time: 136.16 s 
2025-06-03 23:50:06.639723:  
2025-06-03 23:50:06.848780: Epoch 168 
2025-06-03 23:50:07.240603: Current learning rate: 0.00847 
2025-06-03 23:52:22.791633: train_loss -0.665 
2025-06-03 23:52:23.132965: val_loss -0.6163 
2025-06-03 23:52:23.629431: Pseudo dice [np.float32(0.7114)] 
2025-06-03 23:52:24.190721: Epoch time: 136.16 s 
2025-06-03 23:52:30.799048:  
2025-06-03 23:52:31.004646: Epoch 169 
2025-06-03 23:52:31.059865: Current learning rate: 0.00847 
2025-06-03 23:54:53.913344: train_loss -0.6395 
2025-06-03 23:54:54.140498: val_loss -0.6195 
2025-06-03 23:54:54.499191: Pseudo dice [np.float32(0.6674)] 
2025-06-03 23:54:54.541199: Epoch time: 143.12 s 
2025-06-03 23:54:58.031963:  
2025-06-03 23:54:58.311634: Epoch 170 
2025-06-03 23:54:58.615924: Current learning rate: 0.00846 
2025-06-03 23:57:15.990391: train_loss -0.6871 
2025-06-03 23:57:16.305866: val_loss -0.6728 
2025-06-03 23:57:16.678251: Pseudo dice [np.float32(0.7827)] 
2025-06-03 23:57:16.692927: Epoch time: 137.96 s 
2025-06-03 23:57:24.052224:  
2025-06-03 23:57:24.070473: Epoch 171 
2025-06-03 23:57:24.083539: Current learning rate: 0.00845 
2025-06-03 23:59:38.283252: train_loss -0.6633 
2025-06-03 23:59:38.680716: val_loss -0.6981 
2025-06-03 23:59:39.070391: Pseudo dice [np.float32(0.7819)] 
2025-06-03 23:59:39.374720: Epoch time: 134.34 s 
2025-06-03 23:59:45.321700:  
2025-06-03 23:59:45.469318: Epoch 172 
2025-06-03 23:59:45.625248: Current learning rate: 0.00844 
2025-06-04 00:02:02.173919: train_loss -0.6743 
2025-06-04 00:02:02.197290: val_loss -0.6564 
2025-06-04 00:02:02.614159: Pseudo dice [np.float32(0.7783)] 
2025-06-04 00:02:02.629803: Epoch time: 136.85 s 
2025-06-04 00:02:08.277975:  
2025-06-04 00:02:08.566862: Epoch 173 
2025-06-04 00:02:08.881225: Current learning rate: 0.00843 
2025-06-04 00:04:28.323977: train_loss -0.6774 
2025-06-04 00:04:28.343039: val_loss -0.6495 
2025-06-04 00:04:28.356394: Pseudo dice [np.float32(0.7477)] 
2025-06-04 00:04:28.369632: Epoch time: 140.05 s 
2025-06-04 00:04:35.148077:  
2025-06-04 00:04:35.314691: Epoch 174 
2025-06-04 00:04:35.329579: Current learning rate: 0.00842 
2025-06-04 00:06:54.848493: train_loss -0.68 
2025-06-04 00:06:54.870816: val_loss -0.7063 
2025-06-04 00:06:54.883908: Pseudo dice [np.float32(0.7649)] 
2025-06-04 00:06:54.896896: Epoch time: 139.7 s 
2025-06-04 00:07:00.015897:  
2025-06-04 00:07:00.258216: Epoch 175 
2025-06-04 00:07:00.377425: Current learning rate: 0.00841 
2025-06-04 00:09:15.661170: train_loss -0.6658 
2025-06-04 00:09:15.682598: val_loss -0.7002 
2025-06-04 00:09:15.695890: Pseudo dice [np.float32(0.7918)] 
2025-06-04 00:09:15.709151: Epoch time: 135.65 s 
2025-06-04 00:09:24.020860:  
2025-06-04 00:09:24.066432: Epoch 176 
2025-06-04 00:09:24.105889: Current learning rate: 0.0084 
2025-06-04 00:11:38.582169: train_loss -0.6834 
2025-06-04 00:11:38.814225: val_loss -0.6906 
2025-06-04 00:11:39.024949: Pseudo dice [np.float32(0.8016)] 
2025-06-04 00:11:39.282462: Epoch time: 134.56 s 
2025-06-04 00:11:44.651241:  
2025-06-04 00:11:44.687856: Epoch 177 
2025-06-04 00:11:44.757448: Current learning rate: 0.00839 
2025-06-04 00:13:58.807448: train_loss -0.6723 
2025-06-04 00:13:59.267330: val_loss -0.6692 
2025-06-04 00:13:59.880141: Pseudo dice [np.float32(0.7687)] 
2025-06-04 00:14:00.242551: Epoch time: 134.16 s 
2025-06-04 00:14:05.454665:  
2025-06-04 00:14:05.598711: Epoch 178 
2025-06-04 00:14:05.613475: Current learning rate: 0.00838 
2025-06-04 00:16:28.897456: train_loss -0.6804 
2025-06-04 00:16:29.099614: val_loss -0.6363 
2025-06-04 00:16:29.448365: Pseudo dice [np.float32(0.7175)] 
2025-06-04 00:16:29.596942: Epoch time: 143.44 s 
2025-06-04 00:16:36.869793:  
2025-06-04 00:16:36.891199: Epoch 179 
2025-06-04 00:16:36.905479: Current learning rate: 0.00837 
2025-06-04 00:18:48.947799: train_loss -0.6831 
2025-06-04 00:18:48.975095: val_loss -0.6836 
2025-06-04 00:18:49.004315: Pseudo dice [np.float32(0.7646)] 
2025-06-04 00:18:49.023786: Epoch time: 132.08 s 
2025-06-04 00:18:54.368144:  
2025-06-04 00:18:54.589536: Epoch 180 
2025-06-04 00:18:54.807356: Current learning rate: 0.00836 
2025-06-04 00:21:07.208095: train_loss -0.6823 
2025-06-04 00:21:07.659445: val_loss -0.6925 
2025-06-04 00:21:08.120334: Pseudo dice [np.float32(0.7845)] 
2025-06-04 00:21:08.580227: Epoch time: 132.84 s 
2025-06-04 00:21:09.001349: Yayy! New best EMA pseudo Dice: 0.7555000185966492 
2025-06-04 00:21:17.147283:  
2025-06-04 00:21:17.161486: Epoch 181 
2025-06-04 00:21:17.178308: Current learning rate: 0.00836 
2025-06-04 00:23:32.189668: train_loss -0.6927 
2025-06-04 00:23:32.207801: val_loss -0.6556 
2025-06-04 00:23:32.220775: Pseudo dice [np.float32(0.7234)] 
2025-06-04 00:23:32.233114: Epoch time: 135.04 s 
2025-06-04 00:23:34.703175:  
2025-06-04 00:23:34.714141: Epoch 182 
2025-06-04 00:23:34.723300: Current learning rate: 0.00835 
2025-06-04 00:25:49.232241: train_loss -0.6854 
2025-06-04 00:25:49.247584: val_loss -0.6586 
2025-06-04 00:25:49.260419: Pseudo dice [np.float32(0.768)] 
2025-06-04 00:25:49.274734: Epoch time: 134.53 s 
2025-06-04 00:25:54.316409:  
2025-06-04 00:25:54.422106: Epoch 183 
2025-06-04 00:25:54.497677: Current learning rate: 0.00834 
2025-06-04 00:28:01.743284: train_loss -0.6929 
2025-06-04 00:28:01.756469: val_loss -0.6179 
2025-06-04 00:28:01.767932: Pseudo dice [np.float32(0.7289)] 
2025-06-04 00:28:01.781269: Epoch time: 127.43 s 
2025-06-04 00:28:06.498131:  
2025-06-04 00:28:06.514314: Epoch 184 
2025-06-04 00:28:06.527950: Current learning rate: 0.00833 
2025-06-04 00:30:10.234681: train_loss -0.6786 
2025-06-04 00:30:10.326339: val_loss -0.6281 
2025-06-04 00:30:10.495697: Pseudo dice [np.float32(0.6038)] 
2025-06-04 00:30:10.529080: Epoch time: 123.74 s 
2025-06-04 00:30:15.639523:  
2025-06-04 00:30:15.654935: Epoch 185 
2025-06-04 00:30:15.667111: Current learning rate: 0.00832 
2025-06-04 00:32:26.890620: train_loss -0.6653 
2025-06-04 00:32:26.922775: val_loss -0.6586 
2025-06-04 00:32:26.940612: Pseudo dice [np.float32(0.7645)] 
2025-06-04 00:32:26.959187: Epoch time: 131.25 s 
2025-06-04 00:32:32.544300:  
2025-06-04 00:32:32.561116: Epoch 186 
2025-06-04 00:32:32.575416: Current learning rate: 0.00831 
2025-06-04 00:34:42.792023: train_loss -0.6843 
2025-06-04 00:34:42.807125: val_loss -0.6566 
2025-06-04 00:34:42.821248: Pseudo dice [np.float32(0.7561)] 
2025-06-04 00:34:42.836898: Epoch time: 130.25 s 
2025-06-04 00:34:47.306943:  
2025-06-04 00:34:47.531111: Epoch 187 
2025-06-04 00:34:47.544626: Current learning rate: 0.0083 
2025-06-04 00:36:55.668586: train_loss -0.6737 
2025-06-04 00:36:55.684391: val_loss -0.682 
2025-06-04 00:36:55.697697: Pseudo dice [np.float32(0.8215)] 
2025-06-04 00:36:55.710222: Epoch time: 128.36 s 
2025-06-04 00:37:01.977211:  
2025-06-04 00:37:02.002145: Epoch 188 
2025-06-04 00:37:02.022399: Current learning rate: 0.00829 
2025-06-04 00:39:14.855853: train_loss -0.6972 
2025-06-04 00:39:14.872709: val_loss -0.6765 
2025-06-04 00:39:14.885502: Pseudo dice [np.float32(0.7816)] 
2025-06-04 00:39:14.897246: Epoch time: 132.88 s 
2025-06-04 00:39:19.633916:  
2025-06-04 00:39:19.692619: Epoch 189 
2025-06-04 00:39:19.750630: Current learning rate: 0.00828 
2025-06-04 00:41:35.923670: train_loss -0.6869 
2025-06-04 00:41:35.941696: val_loss -0.6156 
2025-06-04 00:41:35.954817: Pseudo dice [np.float32(0.6908)] 
2025-06-04 00:41:35.967948: Epoch time: 136.29 s 
2025-06-04 00:41:41.768259:  
2025-06-04 00:41:41.783641: Epoch 190 
2025-06-04 00:41:41.799044: Current learning rate: 0.00827 
2025-06-04 00:43:56.231779: train_loss -0.6831 
2025-06-04 00:43:56.741765: val_loss -0.6583 
2025-06-04 00:43:57.056644: Pseudo dice [np.float32(0.771)] 
2025-06-04 00:43:57.071455: Epoch time: 134.47 s 
2025-06-04 00:44:02.090499:  
2025-06-04 00:44:02.205333: Epoch 191 
2025-06-04 00:44:02.383747: Current learning rate: 0.00826 
2025-06-04 00:46:14.367369: train_loss -0.6885 
2025-06-04 00:46:14.566865: val_loss -0.6745 
2025-06-04 00:46:15.087374: Pseudo dice [np.float32(0.7821)] 
2025-06-04 00:46:15.520086: Epoch time: 132.28 s 
2025-06-04 00:46:19.257107:  
2025-06-04 00:46:19.361913: Epoch 192 
2025-06-04 00:46:19.399380: Current learning rate: 0.00825 
2025-06-04 00:48:34.828441: train_loss -0.6968 
2025-06-04 00:48:34.845688: val_loss -0.643 
2025-06-04 00:48:34.859404: Pseudo dice [np.float32(0.7614)] 
2025-06-04 00:48:34.873206: Epoch time: 135.57 s 
2025-06-04 00:48:39.851084:  
2025-06-04 00:48:40.122262: Epoch 193 
2025-06-04 00:48:40.427254: Current learning rate: 0.00824 
2025-06-04 00:50:53.824047: train_loss -0.6955 
2025-06-04 00:50:53.842536: val_loss -0.7434 
2025-06-04 00:50:53.855905: Pseudo dice [np.float32(0.8024)] 
2025-06-04 00:50:53.868427: Epoch time: 133.98 s 
2025-06-04 00:50:53.880675: Yayy! New best EMA pseudo Dice: 0.7578999996185303 
2025-06-04 00:51:00.077732:  
2025-06-04 00:51:00.098315: Epoch 194 
2025-06-04 00:51:00.110860: Current learning rate: 0.00824 
2025-06-04 00:53:06.335489: train_loss -0.6701 
2025-06-04 00:53:06.689368: val_loss -0.6515 
2025-06-04 00:53:07.419032: Pseudo dice [np.float32(0.6611)] 
2025-06-04 00:53:07.917220: Epoch time: 126.26 s 
2025-06-04 00:53:15.382420:  
2025-06-04 00:53:15.634114: Epoch 195 
2025-06-04 00:53:15.928893: Current learning rate: 0.00823 
2025-06-04 00:55:29.977987: train_loss -0.6796 
2025-06-04 00:55:30.204903: val_loss -0.712 
2025-06-04 00:55:30.302110: Pseudo dice [np.float32(0.8024)] 
2025-06-04 00:55:30.538952: Epoch time: 134.6 s 
2025-06-04 00:55:35.976146:  
2025-06-04 00:55:36.253272: Epoch 196 
2025-06-04 00:55:36.294311: Current learning rate: 0.00822 
2025-06-04 00:57:58.781998: train_loss -0.681 
2025-06-04 00:57:59.087252: val_loss -0.6621 
2025-06-04 00:57:59.249435: Pseudo dice [np.float32(0.7459)] 
2025-06-04 00:57:59.264137: Epoch time: 142.81 s 
2025-06-04 00:58:05.482419:  
2025-06-04 00:58:05.725309: Epoch 197 
2025-06-04 00:58:05.960372: Current learning rate: 0.00821 
2025-06-04 01:00:21.943124: train_loss -0.6921 
2025-06-04 01:00:22.440013: val_loss -0.7082 
2025-06-04 01:00:22.922257: Pseudo dice [np.float32(0.77)] 
2025-06-04 01:00:23.216827: Epoch time: 136.46 s 
2025-06-04 01:00:29.492862:  
2025-06-04 01:00:29.673675: Epoch 198 
2025-06-04 01:00:29.829025: Current learning rate: 0.0082 
2025-06-04 01:02:44.198227: train_loss -0.6902 
2025-06-04 01:02:44.725020: val_loss -0.6476 
2025-06-04 01:02:44.740418: Pseudo dice [np.float32(0.7439)] 
2025-06-04 01:02:44.752206: Epoch time: 134.71 s 
2025-06-04 01:02:52.338686:  
2025-06-04 01:02:52.360053: Epoch 199 
2025-06-04 01:02:52.372563: Current learning rate: 0.00819 
2025-06-04 01:05:15.873748: train_loss -0.6722 
2025-06-04 01:05:15.895170: val_loss -0.6146 
2025-06-04 01:05:15.908968: Pseudo dice [np.float32(0.6423)] 
2025-06-04 01:05:15.921265: Epoch time: 143.62 s 
2025-06-04 01:05:22.840408:  
2025-06-04 01:05:23.156113: Epoch 200 
2025-06-04 01:05:23.194021: Current learning rate: 0.00818 
2025-06-04 01:07:41.718043: train_loss -0.7191 
2025-06-04 01:07:42.337540: val_loss -0.6964 
2025-06-04 01:07:42.870992: Pseudo dice [np.float32(0.7848)] 
2025-06-04 01:07:43.072024: Epoch time: 138.88 s 
2025-06-04 01:07:47.325060:  
2025-06-04 01:07:47.527577: Epoch 201 
2025-06-04 01:07:47.733708: Current learning rate: 0.00817 
2025-06-04 01:10:02.363960: train_loss -0.7067 
2025-06-04 01:10:02.386828: val_loss -0.7225 
2025-06-04 01:10:02.407190: Pseudo dice [np.float32(0.8362)] 
2025-06-04 01:10:02.421003: Epoch time: 135.04 s 
2025-06-04 01:10:08.361443:  
2025-06-04 01:10:08.378804: Epoch 202 
2025-06-04 01:10:08.392575: Current learning rate: 0.00816 
2025-06-04 01:12:20.168360: train_loss -0.6889 
2025-06-04 01:12:20.364349: val_loss -0.637 
2025-06-04 01:12:20.390263: Pseudo dice [np.float32(0.6802)] 
2025-06-04 01:12:20.405386: Epoch time: 131.91 s 
2025-06-04 01:12:25.657378:  
2025-06-04 01:12:25.952171: Epoch 203 
2025-06-04 01:12:26.283245: Current learning rate: 0.00815 
2025-06-04 01:14:44.547716: train_loss -0.6675 
2025-06-04 01:14:44.569251: val_loss -0.6475 
2025-06-04 01:14:44.581993: Pseudo dice [np.float32(0.7189)] 
2025-06-04 01:14:44.596780: Epoch time: 138.89 s 
2025-06-04 01:14:51.667058:  
2025-06-04 01:14:51.696582: Epoch 204 
2025-06-04 01:14:51.716973: Current learning rate: 0.00814 
2025-06-04 01:17:05.850796: train_loss -0.6673 
2025-06-04 01:17:06.210502: val_loss -0.6435 
2025-06-04 01:17:06.745415: Pseudo dice [np.float32(0.7582)] 
2025-06-04 01:17:07.221850: Epoch time: 134.19 s 
2025-06-04 01:17:12.522649:  
2025-06-04 01:17:12.672204: Epoch 205 
2025-06-04 01:17:12.850568: Current learning rate: 0.00813 
2025-06-04 01:19:27.871935: train_loss -0.7045 
2025-06-04 01:19:27.890322: val_loss -0.6676 
2025-06-04 01:19:27.904512: Pseudo dice [np.float32(0.7392)] 
2025-06-04 01:19:27.917355: Epoch time: 135.35 s 
2025-06-04 01:19:32.203802:  
2025-06-04 01:19:32.397344: Epoch 206 
2025-06-04 01:19:32.616561: Current learning rate: 0.00813 
2025-06-04 01:21:51.044192: train_loss -0.6869 
2025-06-04 01:21:51.399244: val_loss -0.6588 
2025-06-04 01:21:51.854489: Pseudo dice [np.float32(0.6274)] 
2025-06-04 01:21:52.159801: Epoch time: 138.84 s 
2025-06-04 01:21:59.009126:  
2025-06-04 01:21:59.294941: Epoch 207 
2025-06-04 01:21:59.497836: Current learning rate: 0.00812 
2025-06-04 01:24:19.376010: train_loss -0.6873 
2025-06-04 01:24:19.390647: val_loss -0.6542 
2025-06-04 01:24:19.403313: Pseudo dice [np.float32(0.7925)] 
2025-06-04 01:24:19.415425: Epoch time: 140.37 s 
2025-06-04 01:24:21.220516:  
2025-06-04 01:24:21.232499: Epoch 208 
2025-06-04 01:24:21.242605: Current learning rate: 0.00811 
2025-06-04 01:26:34.223514: train_loss -0.6877 
2025-06-04 01:26:34.265396: val_loss -0.675 
2025-06-04 01:26:34.278074: Pseudo dice [np.float32(0.7075)] 
2025-06-04 01:26:34.297460: Epoch time: 133.0 s 
2025-06-04 01:26:35.891585:  
2025-06-04 01:26:35.911848: Epoch 209 
2025-06-04 01:26:35.927364: Current learning rate: 0.0081 
2025-06-04 01:28:49.128741: train_loss -0.6869 
2025-06-04 01:28:49.143120: val_loss -0.6553 
2025-06-04 01:28:49.156370: Pseudo dice [np.float32(0.7296)] 
2025-06-04 01:28:49.171017: Epoch time: 133.24 s 
2025-06-04 01:28:53.538113:  
2025-06-04 01:28:53.892487: Epoch 210 
2025-06-04 01:28:54.067873: Current learning rate: 0.00809 
2025-06-04 01:31:04.698926: train_loss -0.6723 
2025-06-04 01:31:04.716298: val_loss -0.6275 
2025-06-04 01:31:04.729622: Pseudo dice [np.float32(0.687)] 
2025-06-04 01:31:04.742400: Epoch time: 131.16 s 
2025-06-04 01:31:11.618026:  
2025-06-04 01:31:11.854691: Epoch 211 
2025-06-04 01:31:12.144121: Current learning rate: 0.00808 
2025-06-04 01:33:22.153885: train_loss -0.6847 
2025-06-04 01:33:22.582502: val_loss -0.6413 
2025-06-04 01:33:22.815233: Pseudo dice [np.float32(0.7218)] 
2025-06-04 01:33:22.830245: Epoch time: 130.54 s 
2025-06-04 01:33:28.658133:  
2025-06-04 01:33:28.806545: Epoch 212 
2025-06-04 01:33:28.821313: Current learning rate: 0.00807 
2025-06-04 01:35:42.868385: train_loss -0.6864 
2025-06-04 01:35:43.175873: val_loss -0.6887 
2025-06-04 01:35:43.687897: Pseudo dice [np.float32(0.7918)] 
2025-06-04 01:35:44.212586: Epoch time: 134.21 s 
2025-06-04 01:35:50.584190:  
2025-06-04 01:35:50.602209: Epoch 213 
2025-06-04 01:35:50.614293: Current learning rate: 0.00806 
2025-06-04 01:38:05.857429: train_loss -0.6941 
2025-06-04 01:38:05.882992: val_loss -0.697 
2025-06-04 01:38:05.899964: Pseudo dice [np.float32(0.7621)] 
2025-06-04 01:38:05.916218: Epoch time: 135.28 s 
2025-06-04 01:38:10.988058:  
2025-06-04 01:38:11.193368: Epoch 214 
2025-06-04 01:38:11.230547: Current learning rate: 0.00805 
2025-06-04 01:40:24.351917: train_loss -0.6929 
2025-06-04 01:40:24.368757: val_loss -0.702 
2025-06-04 01:40:24.382188: Pseudo dice [np.float32(0.7643)] 
2025-06-04 01:40:24.396559: Epoch time: 133.37 s 
2025-06-04 01:40:31.647913:  
2025-06-04 01:40:31.915294: Epoch 215 
2025-06-04 01:40:32.260281: Current learning rate: 0.00804 
2025-06-04 01:42:50.873250: train_loss -0.6999 
2025-06-04 01:42:51.038792: val_loss -0.6837 
2025-06-04 01:42:51.052057: Pseudo dice [np.float32(0.6894)] 
2025-06-04 01:42:51.064341: Epoch time: 139.23 s 
2025-06-04 01:42:55.944343:  
2025-06-04 01:42:56.067146: Epoch 216 
2025-06-04 01:42:56.096380: Current learning rate: 0.00803 
2025-06-04 01:45:07.472431: train_loss -0.7027 
2025-06-04 01:45:07.749685: val_loss -0.6646 
2025-06-04 01:45:08.184112: Pseudo dice [np.float32(0.6603)] 
2025-06-04 01:45:08.464003: Epoch time: 131.53 s 
2025-06-04 01:45:13.953180:  
2025-06-04 01:45:14.041224: Epoch 217 
2025-06-04 01:45:14.057022: Current learning rate: 0.00802 
2025-06-04 01:47:35.960983: train_loss -0.6951 
2025-06-04 01:47:36.363719: val_loss -0.6324 
2025-06-04 01:47:36.515217: Pseudo dice [np.float32(0.7554)] 
2025-06-04 01:47:36.529469: Epoch time: 142.01 s 
2025-06-04 01:47:42.144268:  
2025-06-04 01:47:42.481460: Epoch 218 
2025-06-04 01:47:42.647546: Current learning rate: 0.00801 
2025-06-04 01:49:59.500241: train_loss -0.6757 
2025-06-04 01:49:59.521971: val_loss -0.6879 
2025-06-04 01:49:59.535158: Pseudo dice [np.float32(0.7669)] 
2025-06-04 01:49:59.547716: Epoch time: 137.36 s 
2025-06-04 01:50:06.218270:  
2025-06-04 01:50:06.359602: Epoch 219 
2025-06-04 01:50:06.636182: Current learning rate: 0.00801 
2025-06-04 01:52:21.361773: train_loss -0.7129 
2025-06-04 01:52:21.822711: val_loss -0.6938 
2025-06-04 01:52:22.286321: Pseudo dice [np.float32(0.7842)] 
2025-06-04 01:52:22.604840: Epoch time: 135.15 s 
2025-06-04 01:52:27.518267:  
2025-06-04 01:52:27.996760: Epoch 220 
2025-06-04 01:52:28.355169: Current learning rate: 0.008 
2025-06-04 01:54:44.633176: train_loss -0.7085 
2025-06-04 01:54:44.655211: val_loss -0.6978 
2025-06-04 01:54:44.672415: Pseudo dice [np.float32(0.7568)] 
2025-06-04 01:54:44.684968: Epoch time: 137.12 s 
2025-06-04 01:54:50.900395:  
2025-06-04 01:54:51.211175: Epoch 221 
2025-06-04 01:54:51.546907: Current learning rate: 0.00799 
2025-06-04 01:57:15.621884: train_loss -0.6738 
2025-06-04 01:57:15.892315: val_loss -0.6554 
2025-06-04 01:57:16.146829: Pseudo dice [np.float32(0.7707)] 
2025-06-04 01:57:16.278468: Epoch time: 144.72 s 
2025-06-04 01:57:19.521899:  
2025-06-04 01:57:19.773704: Epoch 222 
2025-06-04 01:57:19.993128: Current learning rate: 0.00798 
2025-06-04 01:59:37.766444: train_loss -0.6879 
2025-06-04 01:59:38.143839: val_loss -0.6485 
2025-06-04 01:59:38.584903: Pseudo dice [np.float32(0.71)] 
2025-06-04 01:59:38.936280: Epoch time: 138.25 s 
2025-06-04 01:59:43.894948:  
2025-06-04 01:59:44.352288: Epoch 223 
2025-06-04 01:59:44.536653: Current learning rate: 0.00797 
2025-06-04 02:01:56.409390: train_loss -0.7029 
2025-06-04 02:01:56.718941: val_loss -0.6819 
2025-06-04 02:01:56.733561: Pseudo dice [np.float32(0.7636)] 
2025-06-04 02:01:56.746944: Epoch time: 132.52 s 
2025-06-04 02:02:02.267881:  
2025-06-04 02:02:02.284754: Epoch 224 
2025-06-04 02:02:02.298565: Current learning rate: 0.00796 
2025-06-04 02:04:23.509435: train_loss -0.6605 
2025-06-04 02:04:23.724178: val_loss -0.6577 
2025-06-04 02:04:24.044694: Pseudo dice [np.float32(0.7524)] 
2025-06-04 02:04:24.389757: Epoch time: 141.35 s 
2025-06-04 02:04:30.357347:  
2025-06-04 02:04:31.167953: Epoch 225 
2025-06-04 02:04:31.590692: Current learning rate: 0.00795 
2025-06-04 02:06:48.822987: train_loss -0.6915 
2025-06-04 02:06:49.211415: val_loss -0.6758 
2025-06-04 02:06:49.227018: Pseudo dice [np.float32(0.7053)] 
2025-06-04 02:06:49.239904: Epoch time: 138.47 s 
2025-06-04 02:06:54.738781:  
2025-06-04 02:06:54.877069: Epoch 226 
2025-06-04 02:06:55.020672: Current learning rate: 0.00794 
2025-06-04 02:09:10.012508: train_loss -0.6978 
2025-06-04 02:09:10.034638: val_loss -0.7216 
2025-06-04 02:09:10.048753: Pseudo dice [np.float32(0.8059)] 
2025-06-04 02:09:10.061443: Epoch time: 135.28 s 
2025-06-04 02:09:16.493562:  
2025-06-04 02:09:17.040512: Epoch 227 
2025-06-04 02:09:17.349509: Current learning rate: 0.00793 
2025-06-04 02:11:37.006828: train_loss -0.6531 
2025-06-04 02:11:37.331943: val_loss -0.6451 
2025-06-04 02:11:37.348740: Pseudo dice [np.float32(0.7026)] 
2025-06-04 02:11:37.361825: Epoch time: 140.52 s 
2025-06-04 02:11:43.900197:  
2025-06-04 02:11:44.083882: Epoch 228 
2025-06-04 02:11:44.312227: Current learning rate: 0.00792 
2025-06-04 02:13:58.223066: train_loss -0.6488 
2025-06-04 02:13:58.237821: val_loss -0.6478 
2025-06-04 02:13:58.252506: Pseudo dice [np.float32(0.6658)] 
2025-06-04 02:13:58.264339: Epoch time: 134.33 s 
2025-06-04 02:14:00.449060:  
2025-06-04 02:14:00.471265: Epoch 229 
2025-06-04 02:14:00.481573: Current learning rate: 0.00791 
2025-06-04 02:16:13.448653: train_loss -0.6861 
2025-06-04 02:16:13.465557: val_loss -0.6907 
2025-06-04 02:16:13.478295: Pseudo dice [np.float32(0.7703)] 
2025-06-04 02:16:13.490472: Epoch time: 133.0 s 
2025-06-04 02:16:15.549345:  
2025-06-04 02:16:15.567458: Epoch 230 
2025-06-04 02:16:15.581144: Current learning rate: 0.0079 
2025-06-04 02:18:28.644831: train_loss -0.686 
2025-06-04 02:18:28.710901: val_loss -0.698 
2025-06-04 02:18:28.812158: Pseudo dice [np.float32(0.7789)] 
2025-06-04 02:18:28.853877: Epoch time: 133.1 s 
2025-06-04 02:18:34.642955:  
2025-06-04 02:18:34.989931: Epoch 231 
2025-06-04 02:18:35.126301: Current learning rate: 0.00789 
2025-06-04 02:20:44.426042: train_loss -0.6936 
2025-06-04 02:20:44.549055: val_loss -0.6401 
2025-06-04 02:20:44.621240: Pseudo dice [np.float32(0.7278)] 
2025-06-04 02:20:44.714480: Epoch time: 129.79 s 
2025-06-04 02:20:46.533756:  
2025-06-04 02:20:46.556381: Epoch 232 
2025-06-04 02:20:46.571277: Current learning rate: 0.00789 
2025-06-04 02:23:02.120305: train_loss -0.6924 
2025-06-04 02:23:02.142278: val_loss -0.6907 
2025-06-04 02:23:02.155495: Pseudo dice [np.float32(0.7102)] 
2025-06-04 02:23:02.168541: Epoch time: 135.59 s 
2025-06-04 02:23:06.963736:  
2025-06-04 02:23:07.253824: Epoch 233 
2025-06-04 02:23:07.269029: Current learning rate: 0.00788 
2025-06-04 02:25:21.295658: train_loss -0.6924 
2025-06-04 02:25:21.421392: val_loss -0.7111 
2025-06-04 02:25:21.649081: Pseudo dice [np.float32(0.7799)] 
2025-06-04 02:25:21.886645: Epoch time: 134.33 s 
2025-06-04 02:25:27.972080:  
2025-06-04 02:25:28.198950: Epoch 234 
2025-06-04 02:25:28.451387: Current learning rate: 0.00787 
2025-06-04 02:27:44.687459: train_loss -0.6974 
2025-06-04 02:27:44.864087: val_loss -0.6738 
2025-06-04 02:27:45.148272: Pseudo dice [np.float32(0.7226)] 
2025-06-04 02:27:45.431372: Epoch time: 136.72 s 
2025-06-04 02:27:50.067653:  
2025-06-04 02:27:50.247150: Epoch 235 
2025-06-04 02:27:50.415644: Current learning rate: 0.00786 
2025-06-04 02:30:01.280659: train_loss -0.6973 
2025-06-04 02:30:01.297493: val_loss -0.711 
2025-06-04 02:30:01.311220: Pseudo dice [np.float32(0.7764)] 
2025-06-04 02:30:01.324600: Epoch time: 131.22 s 
2025-06-04 02:30:07.031808:  
2025-06-04 02:30:07.049175: Epoch 236 
2025-06-04 02:30:07.063168: Current learning rate: 0.00785 
2025-06-04 02:32:21.503394: train_loss -0.6859 
2025-06-04 02:32:21.736827: val_loss -0.6728 
2025-06-04 02:32:21.751600: Pseudo dice [np.float32(0.7432)] 
2025-06-04 02:32:21.765057: Epoch time: 134.47 s 
2025-06-04 02:32:28.379327:  
2025-06-04 02:32:28.619068: Epoch 237 
2025-06-04 02:32:28.867352: Current learning rate: 0.00784 
2025-06-04 02:34:41.652399: train_loss -0.6796 
2025-06-04 02:34:41.670287: val_loss -0.661 
2025-06-04 02:34:41.685572: Pseudo dice [np.float32(0.7695)] 
2025-06-04 02:34:41.700561: Epoch time: 133.28 s 
2025-06-04 02:34:47.442662:  
2025-06-04 02:34:47.535614: Epoch 238 
2025-06-04 02:34:47.622563: Current learning rate: 0.00783 
2025-06-04 02:37:06.698142: train_loss -0.6817 
2025-06-04 02:37:07.054032: val_loss -0.7454 
2025-06-04 02:37:07.194663: Pseudo dice [np.float32(0.792)] 
2025-06-04 02:37:07.208341: Epoch time: 139.26 s 
2025-06-04 02:37:12.270421:  
2025-06-04 02:37:12.489845: Epoch 239 
2025-06-04 02:37:12.809498: Current learning rate: 0.00782 
2025-06-04 02:39:26.194805: train_loss -0.7009 
2025-06-04 02:39:26.675643: val_loss -0.6603 
2025-06-04 02:39:26.833278: Pseudo dice [np.float32(0.7512)] 
2025-06-04 02:39:26.848670: Epoch time: 133.93 s 
2025-06-04 02:39:32.638699:  
2025-06-04 02:39:32.768313: Epoch 240 
2025-06-04 02:39:33.050396: Current learning rate: 0.00781 
2025-06-04 02:41:49.958431: train_loss -0.6899 
2025-06-04 02:41:49.975198: val_loss -0.7153 
2025-06-04 02:41:49.990399: Pseudo dice [np.float32(0.8206)] 
2025-06-04 02:41:50.003761: Epoch time: 137.32 s 
2025-06-04 02:41:56.915738:  
2025-06-04 02:41:57.048733: Epoch 241 
2025-06-04 02:41:57.159514: Current learning rate: 0.0078 
2025-06-04 02:44:16.532198: train_loss -0.655 
2025-06-04 02:44:17.004974: val_loss -0.5557 
2025-06-04 02:44:17.413760: Pseudo dice [np.float32(0.729)] 
2025-06-04 02:44:17.834136: Epoch time: 139.62 s 
2025-06-04 02:44:23.495381:  
2025-06-04 02:44:23.751558: Epoch 242 
2025-06-04 02:44:24.061636: Current learning rate: 0.00779 
2025-06-04 02:46:41.929312: train_loss -0.7095 
2025-06-04 02:46:42.220731: val_loss -0.653 
2025-06-04 02:46:42.504316: Pseudo dice [np.float32(0.7799)] 
2025-06-04 02:46:42.889146: Epoch time: 138.44 s 
2025-06-04 02:46:48.931666:  
2025-06-04 02:46:49.069146: Epoch 243 
2025-06-04 02:46:49.082705: Current learning rate: 0.00778 
2025-06-04 02:49:02.424535: train_loss -0.6907 
2025-06-04 02:49:02.855671: val_loss -0.639 
2025-06-04 02:49:03.311161: Pseudo dice [np.float32(0.7309)] 
2025-06-04 02:49:03.605690: Epoch time: 133.5 s 
2025-06-04 02:49:09.958955:  
2025-06-04 02:49:09.977609: Epoch 244 
2025-06-04 02:49:09.992914: Current learning rate: 0.00777 
2025-06-04 02:51:28.424594: train_loss -0.677 
2025-06-04 02:51:28.446790: val_loss -0.6427 
2025-06-04 02:51:28.460738: Pseudo dice [np.float32(0.7319)] 
2025-06-04 02:51:28.473838: Epoch time: 138.47 s 
2025-06-04 02:51:33.142154:  
2025-06-04 02:51:33.681572: Epoch 245 
2025-06-04 02:51:33.979824: Current learning rate: 0.00777 
2025-06-04 02:53:52.402761: train_loss -0.703 
2025-06-04 02:53:52.446784: val_loss -0.6509 
2025-06-04 02:53:52.462038: Pseudo dice [np.float32(0.7998)] 
2025-06-04 02:53:52.476726: Epoch time: 139.26 s 
2025-06-04 02:53:58.165175:  
2025-06-04 02:53:58.333048: Epoch 246 
2025-06-04 02:53:58.524366: Current learning rate: 0.00776 
2025-06-04 02:56:18.782802: train_loss -0.6868 
2025-06-04 02:56:18.806961: val_loss -0.6939 
2025-06-04 02:56:18.823224: Pseudo dice [np.float32(0.8009)] 
2025-06-04 02:56:18.838478: Epoch time: 140.62 s 
2025-06-04 02:56:18.853130: Yayy! New best EMA pseudo Dice: 0.7616000175476074 
2025-06-04 02:56:28.942755:  
2025-06-04 02:56:29.124938: Epoch 247 
2025-06-04 02:56:29.311699: Current learning rate: 0.00775 
2025-06-04 02:58:42.945818: train_loss -0.6849 
2025-06-04 02:58:43.227926: val_loss -0.6466 
2025-06-04 02:58:43.548564: Pseudo dice [np.float32(0.8418)] 
2025-06-04 02:58:43.854039: Epoch time: 134.01 s 
2025-06-04 02:58:44.212241: Yayy! New best EMA pseudo Dice: 0.769599974155426 
2025-06-04 02:58:49.248299:  
2025-06-04 02:58:49.259165: Epoch 248 
2025-06-04 02:58:49.268391: Current learning rate: 0.00774 
2025-06-04 03:01:06.891355: train_loss -0.6942 
2025-06-04 03:01:06.912737: val_loss -0.6826 
2025-06-04 03:01:06.926969: Pseudo dice [np.float32(0.7687)] 
2025-06-04 03:01:06.941907: Epoch time: 137.64 s 
2025-06-04 03:01:09.038882:  
2025-06-04 03:01:09.058615: Epoch 249 
2025-06-04 03:01:09.072984: Current learning rate: 0.00773 
2025-06-04 03:03:23.405610: train_loss -0.6802 
2025-06-04 03:03:23.424061: val_loss -0.6593 
2025-06-04 03:03:23.456994: Pseudo dice [np.float32(0.7471)] 
2025-06-04 03:03:23.471342: Epoch time: 134.37 s 
2025-06-04 03:03:27.313250:  
2025-06-04 03:03:27.531728: Epoch 250 
2025-06-04 03:03:27.733356: Current learning rate: 0.00772 
2025-06-04 03:05:41.150526: train_loss -0.6582 
2025-06-04 03:05:41.616202: val_loss -0.6447 
2025-06-04 03:05:42.092521: Pseudo dice [np.float32(0.7356)] 
2025-06-04 03:05:42.107317: Epoch time: 133.84 s 
2025-06-04 03:05:47.322593:  
2025-06-04 03:05:47.615937: Epoch 251 
2025-06-04 03:05:47.868691: Current learning rate: 0.00771 
2025-06-04 03:08:02.394984: train_loss -0.7097 
2025-06-04 03:08:02.412603: val_loss -0.7282 
2025-06-04 03:08:02.426013: Pseudo dice [np.float32(0.7798)] 
2025-06-04 03:08:02.438441: Epoch time: 135.07 s 
2025-06-04 03:08:08.118292:  
2025-06-04 03:08:08.307832: Epoch 252 
2025-06-04 03:08:08.581670: Current learning rate: 0.0077 
2025-06-04 03:10:23.003350: train_loss -0.685 
2025-06-04 03:10:23.021850: val_loss -0.7224 
2025-06-04 03:10:23.034250: Pseudo dice [np.float32(0.8142)] 
2025-06-04 03:10:23.047350: Epoch time: 134.89 s 
2025-06-04 03:10:23.058982: Yayy! New best EMA pseudo Dice: 0.7705000042915344 
2025-06-04 03:10:30.375859:  
2025-06-04 03:10:30.648898: Epoch 253 
2025-06-04 03:10:30.764346: Current learning rate: 0.00769 
2025-06-04 03:12:45.416394: train_loss -0.6993 
2025-06-04 03:12:45.434368: val_loss -0.6802 
2025-06-04 03:12:45.448062: Pseudo dice [np.float32(0.7375)] 
2025-06-04 03:12:45.462314: Epoch time: 135.04 s 
2025-06-04 03:12:51.633446:  
2025-06-04 03:12:52.205308: Epoch 254 
2025-06-04 03:12:52.690673: Current learning rate: 0.00768 
2025-06-04 03:15:08.455456: train_loss -0.6863 
2025-06-04 03:15:08.473332: val_loss -0.6679 
2025-06-04 03:15:08.485570: Pseudo dice [np.float32(0.8109)] 
2025-06-04 03:15:08.497943: Epoch time: 136.82 s 
2025-06-04 03:15:08.508822: Yayy! New best EMA pseudo Dice: 0.7716000080108643 
2025-06-04 03:15:16.191865:  
2025-06-04 03:15:16.423921: Epoch 255 
2025-06-04 03:15:16.618802: Current learning rate: 0.00767 
2025-06-04 03:17:35.282389: train_loss -0.6978 
2025-06-04 03:17:35.538829: val_loss -0.6216 
2025-06-04 03:17:35.700663: Pseudo dice [np.float32(0.6935)] 
2025-06-04 03:17:35.716477: Epoch time: 139.09 s 
2025-06-04 03:17:40.896753:  
2025-06-04 03:17:41.123500: Epoch 256 
2025-06-04 03:17:41.341329: Current learning rate: 0.00766 
2025-06-04 03:19:53.500233: train_loss -0.6695 
2025-06-04 03:19:53.517742: val_loss -0.6911 
2025-06-04 03:19:53.532443: Pseudo dice [np.float32(0.7867)] 
2025-06-04 03:19:53.545297: Epoch time: 132.61 s 
2025-06-04 03:20:01.984471:  
2025-06-04 03:20:02.143557: Epoch 257 
2025-06-04 03:20:02.185642: Current learning rate: 0.00765 
2025-06-04 03:22:19.827540: train_loss -0.6991 
2025-06-04 03:22:19.846907: val_loss -0.6575 
2025-06-04 03:22:19.860361: Pseudo dice [np.float32(0.7444)] 
2025-06-04 03:22:19.873896: Epoch time: 137.84 s 
2025-06-04 03:22:25.741997:  
2025-06-04 03:22:25.759499: Epoch 258 
2025-06-04 03:22:25.774233: Current learning rate: 0.00764 
2025-06-04 03:24:38.290803: train_loss -0.7045 
2025-06-04 03:24:38.536760: val_loss -0.7018 
2025-06-04 03:24:38.550025: Pseudo dice [np.float32(0.8197)] 
2025-06-04 03:24:38.562775: Epoch time: 132.55 s 
2025-06-04 03:24:44.228260:  
2025-06-04 03:24:44.339803: Epoch 259 
2025-06-04 03:24:44.571184: Current learning rate: 0.00764 
2025-06-04 03:27:01.831460: train_loss -0.6962 
2025-06-04 03:27:02.490990: val_loss -0.7095 
2025-06-04 03:27:02.746611: Pseudo dice [np.float32(0.7443)] 
2025-06-04 03:27:02.762180: Epoch time: 137.61 s 
2025-06-04 03:27:08.912122:  
2025-06-04 03:27:09.005023: Epoch 260 
2025-06-04 03:27:09.182198: Current learning rate: 0.00763 
2025-06-04 03:29:28.324804: train_loss -0.7025 
2025-06-04 03:29:28.350840: val_loss -0.706 
2025-06-04 03:29:28.371942: Pseudo dice [np.float32(0.8151)] 
2025-06-04 03:29:28.387908: Epoch time: 139.41 s 
2025-06-04 03:29:28.401565: Yayy! New best EMA pseudo Dice: 0.7717999815940857 
2025-06-04 03:29:35.647382:  
2025-06-04 03:29:35.664847: Epoch 261 
2025-06-04 03:29:35.678666: Current learning rate: 0.00762 
2025-06-04 03:31:54.789595: train_loss -0.7175 
2025-06-04 03:31:54.811103: val_loss -0.6952 
2025-06-04 03:31:54.828973: Pseudo dice [np.float32(0.7553)] 
2025-06-04 03:31:54.841622: Epoch time: 139.14 s 
2025-06-04 03:32:00.947211:  
2025-06-04 03:32:01.142310: Epoch 262 
2025-06-04 03:32:01.395398: Current learning rate: 0.00761 
2025-06-04 03:34:18.748547: train_loss -0.7025 
2025-06-04 03:34:19.087438: val_loss -0.6952 
2025-06-04 03:34:19.211941: Pseudo dice [np.float32(0.7905)] 
2025-06-04 03:34:19.226806: Epoch time: 137.8 s 
2025-06-04 03:34:19.240746: Yayy! New best EMA pseudo Dice: 0.7721999883651733 
2025-06-04 03:34:26.549015:  
2025-06-04 03:34:26.808771: Epoch 263 
2025-06-04 03:34:26.993070: Current learning rate: 0.0076 
2025-06-04 03:36:46.585981: train_loss -0.7218 
2025-06-04 03:36:46.947735: val_loss -0.7234 
2025-06-04 03:36:47.003375: Pseudo dice [np.float32(0.7889)] 
2025-06-04 03:36:47.020300: Epoch time: 140.04 s 
2025-06-04 03:36:47.035020: Yayy! New best EMA pseudo Dice: 0.7738000154495239 
2025-06-04 03:36:53.879286:  
2025-06-04 03:36:54.019964: Epoch 264 
2025-06-04 03:36:54.072587: Current learning rate: 0.00759 
2025-06-04 03:39:14.120272: train_loss -0.7044 
2025-06-04 03:39:14.306571: val_loss -0.6893 
2025-06-04 03:39:14.322447: Pseudo dice [np.float32(0.6962)] 
2025-06-04 03:39:14.893157: Epoch time: 140.24 s 
2025-06-04 03:39:21.145269:  
2025-06-04 03:39:21.162516: Epoch 265 
2025-06-04 03:39:21.176113: Current learning rate: 0.00758 
2025-06-04 03:41:38.734156: train_loss -0.7002 
2025-06-04 03:41:39.346109: val_loss -0.6557 
2025-06-04 03:41:39.729054: Pseudo dice [np.float32(0.7029)] 
2025-06-04 03:41:39.744294: Epoch time: 137.59 s 
2025-06-04 03:41:49.186354:  
2025-06-04 03:41:49.787679: Epoch 266 
2025-06-04 03:41:49.804491: Current learning rate: 0.00757 
2025-06-04 03:44:06.854636: train_loss -0.6965 
2025-06-04 03:44:07.253470: val_loss -0.6637 
2025-06-04 03:44:07.554943: Pseudo dice [np.float32(0.8031)] 
2025-06-04 03:44:07.893833: Epoch time: 137.67 s 
2025-06-04 03:44:14.427700:  
2025-06-04 03:44:14.639070: Epoch 267 
2025-06-04 03:44:14.906297: Current learning rate: 0.00756 
2025-06-04 03:46:28.631562: train_loss -0.6817 
2025-06-04 03:46:28.795425: val_loss -0.6389 
2025-06-04 03:46:28.872844: Pseudo dice [np.float32(0.7713)] 
2025-06-04 03:46:28.896821: Epoch time: 134.21 s 
2025-06-04 03:46:30.327327:  
2025-06-04 03:46:30.340683: Epoch 268 
2025-06-04 03:46:30.351551: Current learning rate: 0.00755 
2025-06-04 03:48:46.271329: train_loss -0.6824 
2025-06-04 03:48:46.287005: val_loss -0.7107 
2025-06-04 03:48:46.301299: Pseudo dice [np.float32(0.7989)] 
2025-06-04 03:48:46.436734: Epoch time: 135.95 s 
2025-06-04 03:48:52.181093:  
2025-06-04 03:48:52.212038: Epoch 269 
2025-06-04 03:48:52.232358: Current learning rate: 0.00754 
2025-06-04 03:51:03.848869: train_loss -0.7331 
2025-06-04 03:51:04.204323: val_loss -0.6665 
2025-06-04 03:51:04.540544: Pseudo dice [np.float32(0.7486)] 
2025-06-04 03:51:04.569359: Epoch time: 131.67 s 
2025-06-04 03:51:11.201184:  
2025-06-04 03:51:11.401713: Epoch 270 
2025-06-04 03:51:11.541961: Current learning rate: 0.00753 
2025-06-04 03:53:28.456372: train_loss -0.6815 
2025-06-04 03:53:28.731345: val_loss -0.6507 
2025-06-04 03:53:28.974084: Pseudo dice [np.float32(0.7324)] 
2025-06-04 03:53:28.989204: Epoch time: 137.26 s 
2025-06-04 03:53:31.855037:  
2025-06-04 03:53:32.017406: Epoch 271 
2025-06-04 03:53:32.186660: Current learning rate: 0.00752 
2025-06-04 03:55:44.404718: train_loss -0.685 
2025-06-04 03:55:44.819490: val_loss -0.6798 
2025-06-04 03:55:45.187001: Pseudo dice [np.float32(0.7337)] 
2025-06-04 03:55:45.514404: Epoch time: 132.55 s 
2025-06-04 03:55:51.693141:  
2025-06-04 03:55:51.711031: Epoch 272 
2025-06-04 03:55:51.723732: Current learning rate: 0.00751 
2025-06-04 03:58:04.946848: train_loss -0.7001 
2025-06-04 03:58:04.964392: val_loss -0.6869 
2025-06-04 03:58:04.977750: Pseudo dice [np.float32(0.7514)] 
2025-06-04 03:58:04.990647: Epoch time: 133.31 s 
2025-06-04 03:58:11.192541:  
2025-06-04 03:58:11.370004: Epoch 273 
2025-06-04 03:58:11.609708: Current learning rate: 0.00751 
2025-06-04 04:00:19.114529: train_loss -0.6827 
2025-06-04 04:00:19.764004: val_loss -0.7112 
2025-06-04 04:00:19.779495: Pseudo dice [np.float32(0.7652)] 
2025-06-04 04:00:20.263534: Epoch time: 127.92 s 
2025-06-04 04:00:27.845571:  
2025-06-04 04:00:27.956275: Epoch 274 
2025-06-04 04:00:28.023259: Current learning rate: 0.0075 
2025-06-04 04:02:38.250301: train_loss -0.6802 
2025-06-04 04:02:38.585416: val_loss -0.5592 
2025-06-04 04:02:39.003990: Pseudo dice [np.float32(0.5588)] 
2025-06-04 04:02:39.469121: Epoch time: 130.41 s 
2025-06-04 04:02:44.440846:  
2025-06-04 04:02:45.014160: Epoch 275 
2025-06-04 04:02:45.337877: Current learning rate: 0.00749 
2025-06-04 04:04:58.578165: train_loss -0.6729 
2025-06-04 04:04:59.035101: val_loss -0.7055 
2025-06-04 04:04:59.688187: Pseudo dice [np.float32(0.7509)] 
2025-06-04 04:04:59.863627: Epoch time: 134.14 s 
2025-06-04 04:05:04.543612:  
2025-06-04 04:05:04.717639: Epoch 276 
2025-06-04 04:05:04.736752: Current learning rate: 0.00748 
2025-06-04 04:07:19.952289: train_loss -0.6787 
2025-06-04 04:07:20.288925: val_loss -0.6734 
2025-06-04 04:07:20.653076: Pseudo dice [np.float32(0.804)] 
2025-06-04 04:07:20.883536: Epoch time: 135.41 s 
2025-06-04 04:07:24.345670:  
2025-06-04 04:07:24.651155: Epoch 277 
2025-06-04 04:07:24.666551: Current learning rate: 0.00747 
2025-06-04 04:09:40.678456: train_loss -0.6958 
2025-06-04 04:09:41.306836: val_loss -0.6825 
2025-06-04 04:09:41.784590: Pseudo dice [np.float32(0.7604)] 
2025-06-04 04:09:42.060959: Epoch time: 136.33 s 
2025-06-04 04:09:48.757891:  
2025-06-04 04:09:48.932453: Epoch 278 
2025-06-04 04:09:49.130236: Current learning rate: 0.00746 
2025-06-04 04:12:03.972136: train_loss -0.6904 
2025-06-04 04:12:04.300073: val_loss -0.6981 
2025-06-04 04:12:04.456475: Pseudo dice [np.float32(0.8035)] 
2025-06-04 04:12:04.809576: Epoch time: 135.22 s 
2025-06-04 04:12:09.836870:  
2025-06-04 04:12:09.968969: Epoch 279 
2025-06-04 04:12:09.985085: Current learning rate: 0.00745 
2025-06-04 04:14:27.384486: train_loss -0.7216 
2025-06-04 04:14:27.950616: val_loss -0.6576 
2025-06-04 04:14:28.307013: Pseudo dice [np.float32(0.7708)] 
2025-06-04 04:14:28.836951: Epoch time: 137.55 s 
2025-06-04 04:14:35.869499:  
2025-06-04 04:14:35.890868: Epoch 280 
2025-06-04 04:14:35.904168: Current learning rate: 0.00744 
2025-06-04 04:16:49.892350: train_loss -0.702 
2025-06-04 04:16:49.913810: val_loss -0.6127 
2025-06-04 04:16:49.926796: Pseudo dice [np.float32(0.6648)] 
2025-06-04 04:16:49.939789: Epoch time: 134.02 s 
2025-06-04 04:16:57.453791:  
2025-06-04 04:16:57.472311: Epoch 281 
2025-06-04 04:16:57.487153: Current learning rate: 0.00743 
2025-06-04 04:19:19.563364: train_loss -0.7015 
2025-06-04 04:19:19.582702: val_loss -0.6284 
2025-06-04 04:19:19.597001: Pseudo dice [np.float32(0.7256)] 
2025-06-04 04:19:19.610816: Epoch time: 142.11 s 
2025-06-04 04:19:24.807707:  
2025-06-04 04:19:24.823673: Epoch 282 
2025-06-04 04:19:24.836306: Current learning rate: 0.00742 
2025-06-04 04:21:41.740976: train_loss -0.663 
2025-06-04 04:21:42.087945: val_loss -0.674 
2025-06-04 04:21:42.429059: Pseudo dice [np.float32(0.839)] 
2025-06-04 04:21:42.444457: Epoch time: 136.94 s 
2025-06-04 04:21:49.090478:  
2025-06-04 04:21:49.108012: Epoch 283 
2025-06-04 04:21:49.134484: Current learning rate: 0.00741 
2025-06-04 04:24:06.693928: train_loss -0.6968 
2025-06-04 04:24:06.715887: val_loss -0.6953 
2025-06-04 04:24:06.728429: Pseudo dice [np.float32(0.7911)] 
2025-06-04 04:24:06.742245: Epoch time: 137.61 s 
2025-06-04 04:24:10.636909:  
2025-06-04 04:24:10.815639: Epoch 284 
2025-06-04 04:24:10.959459: Current learning rate: 0.0074 
2025-06-04 04:26:26.874153: train_loss -0.6517 
2025-06-04 04:26:27.314181: val_loss -0.6182 
2025-06-04 04:26:27.648404: Pseudo dice [np.float32(0.6396)] 
2025-06-04 04:26:28.056299: Epoch time: 136.24 s 
2025-06-04 04:26:36.314583:  
2025-06-04 04:26:36.486403: Epoch 285 
2025-06-04 04:26:36.712342: Current learning rate: 0.00739 
2025-06-04 04:28:52.270040: train_loss -0.6867 
2025-06-04 04:28:52.292049: val_loss -0.5962 
2025-06-04 04:28:52.304817: Pseudo dice [np.float32(0.7066)] 
2025-06-04 04:28:52.317866: Epoch time: 135.96 s 
2025-06-04 04:28:57.707937:  
2025-06-04 04:28:57.725299: Epoch 286 
2025-06-04 04:28:57.737464: Current learning rate: 0.00738 
2025-06-04 04:31:13.289314: train_loss -0.6974 
2025-06-04 04:31:13.644640: val_loss -0.7062 
2025-06-04 04:31:14.072646: Pseudo dice [np.float32(0.7972)] 
2025-06-04 04:31:14.528334: Epoch time: 135.58 s 
2025-06-04 04:31:24.106534:  
2025-06-04 04:31:24.637710: Epoch 287 
2025-06-04 04:31:25.078827: Current learning rate: 0.00738 
2025-06-04 04:33:40.764613: train_loss -0.6929 
2025-06-04 04:33:41.223990: val_loss -0.6598 
2025-06-04 04:33:41.656666: Pseudo dice [np.float32(0.8169)] 
2025-06-04 04:33:42.031017: Epoch time: 136.66 s 
2025-06-04 04:33:49.636599:  
2025-06-04 04:33:49.857199: Epoch 288 
2025-06-04 04:33:50.033082: Current learning rate: 0.00737 
2025-06-04 04:36:03.044487: train_loss -0.6997 
2025-06-04 04:36:03.425750: val_loss -0.6531 
2025-06-04 04:36:03.550771: Pseudo dice [np.float32(0.7304)] 
2025-06-04 04:36:03.563914: Epoch time: 133.41 s 
2025-06-04 04:36:09.765243:  
2025-06-04 04:36:09.782113: Epoch 289 
2025-06-04 04:36:09.792886: Current learning rate: 0.00736 
2025-06-04 04:38:21.385415: train_loss -0.6874 
2025-06-04 04:38:21.466306: val_loss -0.6157 
2025-06-04 04:38:21.479005: Pseudo dice [np.float32(0.7021)] 
2025-06-04 04:38:21.490785: Epoch time: 131.62 s 
2025-06-04 04:38:23.396108:  
2025-06-04 04:38:23.456913: Epoch 290 
2025-06-04 04:38:23.524210: Current learning rate: 0.00735 
2025-06-04 04:40:36.271639: train_loss -0.688 
2025-06-04 04:40:36.289683: val_loss -0.6815 
2025-06-04 04:40:36.303576: Pseudo dice [np.float32(0.669)] 
2025-06-04 04:40:36.315488: Epoch time: 132.88 s 
2025-06-04 04:40:38.277979:  
2025-06-04 04:40:38.292890: Epoch 291 
2025-06-04 04:40:38.306675: Current learning rate: 0.00734 
2025-06-04 04:42:48.505714: train_loss -0.6496 
2025-06-04 04:42:48.522494: val_loss -0.6859 
2025-06-04 04:42:48.537212: Pseudo dice [np.float32(0.7526)] 
2025-06-04 04:42:48.552479: Epoch time: 130.23 s 
2025-06-04 04:42:50.444208:  
2025-06-04 04:42:50.535292: Epoch 292 
2025-06-04 04:42:50.551650: Current learning rate: 0.00733 
2025-06-04 04:45:00.524091: train_loss -0.6928 
2025-06-04 04:45:00.543322: val_loss -0.6654 
2025-06-04 04:45:00.556051: Pseudo dice [np.float32(0.7403)] 
2025-06-04 04:45:00.568802: Epoch time: 130.08 s 
2025-06-04 04:45:05.290109:  
2025-06-04 04:45:05.495688: Epoch 293 
2025-06-04 04:45:05.803639: Current learning rate: 0.00732 
2025-06-04 04:47:22.525044: train_loss -0.7123 
2025-06-04 04:47:22.542428: val_loss -0.6931 
2025-06-04 04:47:22.556317: Pseudo dice [np.float32(0.6864)] 
2025-06-04 04:47:22.568127: Epoch time: 137.24 s 
2025-06-04 04:47:28.643726:  
2025-06-04 04:47:28.660674: Epoch 294 
2025-06-04 04:47:28.672720: Current learning rate: 0.00731 
2025-06-04 04:49:40.075775: train_loss -0.6995 
2025-06-04 04:49:40.388715: val_loss -0.6657 
2025-06-04 04:49:40.405937: Pseudo dice [np.float32(0.7164)] 
2025-06-04 04:49:40.418492: Epoch time: 131.51 s 
2025-06-04 04:49:47.941957:  
2025-06-04 04:49:47.959604: Epoch 295 
2025-06-04 04:49:47.972827: Current learning rate: 0.0073 
2025-06-04 04:52:00.027230: train_loss -0.6928 
2025-06-04 04:52:00.526036: val_loss -0.6977 
2025-06-04 04:52:00.863004: Pseudo dice [np.float32(0.7509)] 
2025-06-04 04:52:01.332645: Epoch time: 132.09 s 
2025-06-04 04:52:06.437994:  
2025-06-04 04:52:06.454836: Epoch 296 
2025-06-04 04:52:06.468023: Current learning rate: 0.00729 
2025-06-04 04:54:14.911118: train_loss -0.7169 
2025-06-04 04:54:14.927943: val_loss -0.6767 
2025-06-04 04:54:14.941022: Pseudo dice [np.float32(0.7824)] 
2025-06-04 04:54:14.954369: Epoch time: 128.48 s 
2025-06-04 04:54:20.085856:  
2025-06-04 04:54:20.430164: Epoch 297 
2025-06-04 04:54:20.446620: Current learning rate: 0.00728 
2025-06-04 04:56:28.039423: train_loss -0.6809 
2025-06-04 04:56:28.151356: val_loss -0.6138 
2025-06-04 04:56:28.277629: Pseudo dice [np.float32(0.6655)] 
2025-06-04 04:56:28.317818: Epoch time: 127.96 s 
2025-06-04 04:56:32.531943:  
2025-06-04 04:56:32.683191: Epoch 298 
2025-06-04 04:56:32.908566: Current learning rate: 0.00727 
2025-06-04 04:58:44.851461: train_loss -0.6751 
2025-06-04 04:58:44.868914: val_loss -0.6819 
2025-06-04 04:58:44.882404: Pseudo dice [np.float32(0.7849)] 
2025-06-04 04:58:44.896214: Epoch time: 132.32 s 
2025-06-04 04:58:49.404129:  
2025-06-04 04:58:49.505384: Epoch 299 
2025-06-04 04:58:49.617412: Current learning rate: 0.00726 
2025-06-04 05:00:59.503284: train_loss -0.7089 
2025-06-04 05:00:59.864841: val_loss -0.6916 
2025-06-04 05:01:00.143551: Pseudo dice [np.float32(0.7854)] 
2025-06-04 05:01:00.158832: Epoch time: 130.1 s 
2025-06-04 05:01:08.012066:  
2025-06-04 05:01:08.150551: Epoch 300 
2025-06-04 05:01:08.163786: Current learning rate: 0.00725 
2025-06-04 05:03:15.165489: train_loss -0.6908 
2025-06-04 05:03:15.182941: val_loss -0.645 
2025-06-04 05:03:15.197042: Pseudo dice [np.float32(0.6849)] 
2025-06-04 05:03:15.210113: Epoch time: 127.16 s 
2025-06-04 05:03:21.925455:  
2025-06-04 05:03:22.173681: Epoch 301 
2025-06-04 05:03:22.234092: Current learning rate: 0.00724 
2025-06-04 05:05:37.265924: train_loss -0.6903 
2025-06-04 05:05:37.743350: val_loss -0.6868 
2025-06-04 05:05:38.059384: Pseudo dice [np.float32(0.8025)] 
2025-06-04 05:05:38.598358: Epoch time: 135.34 s 
2025-06-04 05:05:43.843892:  
2025-06-04 05:05:44.050093: Epoch 302 
2025-06-04 05:05:44.211134: Current learning rate: 0.00724 
2025-06-04 05:07:58.389702: train_loss -0.6989 
2025-06-04 05:07:58.407494: val_loss -0.6266 
2025-06-04 05:07:58.422716: Pseudo dice [np.float32(0.6106)] 
2025-06-04 05:07:58.436965: Epoch time: 134.55 s 
2025-06-04 05:08:04.928526:  
2025-06-04 05:08:05.027100: Epoch 303 
2025-06-04 05:08:05.043228: Current learning rate: 0.00723 
2025-06-04 05:10:21.480299: train_loss -0.7131 
2025-06-04 05:10:22.099163: val_loss -0.6996 
2025-06-04 05:10:22.643712: Pseudo dice [np.float32(0.8194)] 
2025-06-04 05:10:23.199807: Epoch time: 136.56 s 
2025-06-04 05:10:28.519500:  
2025-06-04 05:10:28.767192: Epoch 304 
2025-06-04 05:10:29.213621: Current learning rate: 0.00722 
2025-06-04 05:12:47.251462: train_loss -0.7351 
2025-06-04 05:12:47.268818: val_loss -0.7074 
2025-06-04 05:12:47.281569: Pseudo dice [np.float32(0.8136)] 
2025-06-04 05:12:47.295443: Epoch time: 138.73 s 
2025-06-04 05:12:52.874631:  
2025-06-04 05:12:53.539249: Epoch 305 
2025-06-04 05:12:53.908982: Current learning rate: 0.00721 
2025-06-04 05:15:06.416714: train_loss -0.6976 
2025-06-04 05:15:06.725553: val_loss -0.706 
2025-06-04 05:15:07.011601: Pseudo dice [np.float32(0.7724)] 
2025-06-04 05:15:07.246017: Epoch time: 133.54 s 
2025-06-04 05:15:12.620110:  
2025-06-04 05:15:12.639380: Epoch 306 
2025-06-04 05:15:12.654857: Current learning rate: 0.0072 
2025-06-04 05:17:27.082885: train_loss -0.7067 
2025-06-04 05:17:27.100378: val_loss -0.6396 
2025-06-04 05:17:27.114662: Pseudo dice [np.float32(0.7259)] 
2025-06-04 05:17:27.128034: Epoch time: 134.46 s 
2025-06-04 05:17:34.685714:  
2025-06-04 05:17:34.848415: Epoch 307 
2025-06-04 05:17:35.052883: Current learning rate: 0.00719 
2025-06-04 05:19:55.015012: train_loss -0.6981 
2025-06-04 05:19:55.040259: val_loss -0.663 
2025-06-04 05:19:55.058511: Pseudo dice [np.float32(0.7631)] 
2025-06-04 05:19:55.071091: Epoch time: 140.33 s 
2025-06-04 05:20:00.169021:  
2025-06-04 05:20:00.186003: Epoch 308 
2025-06-04 05:20:00.199692: Current learning rate: 0.00718 
2025-06-04 05:22:23.855384: train_loss -0.7096 
2025-06-04 05:22:23.882314: val_loss -0.678 
2025-06-04 05:22:24.015077: Pseudo dice [np.float32(0.7332)] 
2025-06-04 05:22:24.030286: Epoch time: 143.69 s 
2025-06-04 05:22:30.741353:  
2025-06-04 05:22:31.057661: Epoch 309 
2025-06-04 05:22:31.307142: Current learning rate: 0.00717 
2025-06-04 05:24:50.719770: train_loss -0.6932 
2025-06-04 05:24:50.740899: val_loss -0.6901 
2025-06-04 05:24:50.754277: Pseudo dice [np.float32(0.7857)] 
2025-06-04 05:24:50.767336: Epoch time: 139.98 s 
2025-06-04 05:24:56.509893:  
2025-06-04 05:24:56.679517: Epoch 310 
2025-06-04 05:24:56.694377: Current learning rate: 0.00716 
2025-06-04 05:27:14.838081: train_loss -0.6627 
2025-06-04 05:27:14.859574: val_loss -0.5492 
2025-06-04 05:27:14.872581: Pseudo dice [np.float32(0.5635)] 
2025-06-04 05:27:14.884942: Epoch time: 138.33 s 
2025-06-04 05:27:21.267587:  
2025-06-04 05:27:21.285086: Epoch 311 
2025-06-04 05:27:21.298571: Current learning rate: 0.00715 
2025-06-04 05:29:36.812547: train_loss -0.6299 
2025-06-04 05:29:36.860053: val_loss -0.635 
2025-06-04 05:29:37.071276: Pseudo dice [np.float32(0.7523)] 
2025-06-04 05:29:37.289688: Epoch time: 135.55 s 
2025-06-04 05:29:42.088557:  
2025-06-04 05:29:42.296996: Epoch 312 
2025-06-04 05:29:42.613100: Current learning rate: 0.00714 
2025-06-04 05:32:05.992381: train_loss -0.676 
2025-06-04 05:32:06.014407: val_loss -0.5715 
2025-06-04 05:32:06.027189: Pseudo dice [np.float32(0.5883)] 
2025-06-04 05:32:06.041010: Epoch time: 143.91 s 
2025-06-04 05:32:12.063858:  
2025-06-04 05:32:12.128302: Epoch 313 
2025-06-04 05:32:12.148471: Current learning rate: 0.00713 
2025-06-04 05:34:28.901719: train_loss -0.6759 
2025-06-04 05:34:29.140589: val_loss -0.6336 
2025-06-04 05:34:29.468499: Pseudo dice [np.float32(0.75)] 
2025-06-04 05:34:29.935469: Epoch time: 136.84 s 
2025-06-04 05:34:34.455950:  
2025-06-04 05:34:34.475647: Epoch 314 
2025-06-04 05:34:34.489149: Current learning rate: 0.00712 
2025-06-04 05:36:50.810568: train_loss -0.6914 
2025-06-04 05:36:50.832479: val_loss -0.6981 
2025-06-04 05:36:50.846032: Pseudo dice [np.float32(0.8301)] 
2025-06-04 05:36:50.857584: Epoch time: 136.36 s 
2025-06-04 05:36:59.550607:  
2025-06-04 05:36:59.810318: Epoch 315 
2025-06-04 05:37:00.007372: Current learning rate: 0.00711 
2025-06-04 05:39:13.542417: train_loss -0.6967 
2025-06-04 05:39:13.888444: val_loss -0.6837 
2025-06-04 05:39:14.260524: Pseudo dice [np.float32(0.667)] 
2025-06-04 05:39:14.620173: Epoch time: 133.99 s 
2025-06-04 05:39:19.018448:  
2025-06-04 05:39:19.034790: Epoch 316 
2025-06-04 05:39:19.044882: Current learning rate: 0.0071 
2025-06-04 05:41:34.409600: train_loss -0.7029 
2025-06-04 05:41:34.537843: val_loss -0.6591 
2025-06-04 05:41:34.552807: Pseudo dice [np.float32(0.694)] 
2025-06-04 05:41:34.565217: Epoch time: 135.39 s 
2025-06-04 05:41:40.080530:  
2025-06-04 05:41:40.098318: Epoch 317 
2025-06-04 05:41:40.112158: Current learning rate: 0.0071 
2025-06-04 05:43:55.995458: train_loss -0.7095 
2025-06-04 05:43:56.012449: val_loss -0.7094 
2025-06-04 05:43:56.035378: Pseudo dice [np.float32(0.7872)] 
2025-06-04 05:43:56.050619: Epoch time: 136.01 s 
2025-06-04 05:44:00.450000:  
2025-06-04 05:44:00.778386: Epoch 318 
2025-06-04 05:44:00.823266: Current learning rate: 0.00709 
2025-06-04 05:46:16.620966: train_loss -0.6706 
2025-06-04 05:46:16.828723: val_loss -0.6926 
2025-06-04 05:46:16.845805: Pseudo dice [np.float32(0.7796)] 
2025-06-04 05:46:16.862419: Epoch time: 136.17 s 
2025-06-04 05:46:22.323424:  
2025-06-04 05:46:22.507273: Epoch 319 
2025-06-04 05:46:22.698767: Current learning rate: 0.00708 
2025-06-04 05:48:29.825583: train_loss -0.6955 
2025-06-04 05:48:29.843481: val_loss -0.6706 
2025-06-04 05:48:29.856783: Pseudo dice [np.float32(0.7689)] 
2025-06-04 05:48:29.870108: Epoch time: 127.5 s 
2025-06-04 05:48:35.554282:  
2025-06-04 05:48:35.571451: Epoch 320 
2025-06-04 05:48:35.584240: Current learning rate: 0.00707 
2025-06-04 05:50:44.090409: train_loss -0.7184 
2025-06-04 05:50:44.109043: val_loss -0.6855 
2025-06-04 05:50:44.124066: Pseudo dice [np.float32(0.8022)] 
2025-06-04 05:50:44.137520: Epoch time: 128.54 s 
2025-06-04 05:50:49.515491:  
2025-06-04 05:50:49.690862: Epoch 321 
2025-06-04 05:50:49.865581: Current learning rate: 0.00706 
2025-06-04 05:53:03.104628: train_loss -0.6779 
2025-06-04 05:53:03.305780: val_loss -0.6885 
2025-06-04 05:53:03.324609: Pseudo dice [np.float32(0.7816)] 
2025-06-04 05:53:03.338042: Epoch time: 133.59 s 
2025-06-04 05:53:09.435922:  
2025-06-04 05:53:09.633617: Epoch 322 
2025-06-04 05:53:09.767803: Current learning rate: 0.00705 
2025-06-04 05:55:21.534931: train_loss -0.6913 
2025-06-04 05:55:21.941005: val_loss -0.6224 
2025-06-04 05:55:22.522238: Pseudo dice [np.float32(0.76)] 
2025-06-04 05:55:22.821292: Epoch time: 132.1 s 
2025-06-04 05:55:27.714675:  
2025-06-04 05:55:27.979795: Epoch 323 
2025-06-04 05:55:28.089067: Current learning rate: 0.00704 
2025-06-04 05:57:40.562747: train_loss -0.708 
2025-06-04 05:57:40.581928: val_loss -0.6715 
2025-06-04 05:57:40.595487: Pseudo dice [np.float32(0.7339)] 
2025-06-04 05:57:40.607419: Epoch time: 132.85 s 
2025-06-04 05:57:48.465180:  
2025-06-04 05:57:48.912576: Epoch 324 
2025-06-04 05:57:49.045619: Current learning rate: 0.00703 
2025-06-04 06:00:00.780455: train_loss -0.7118 
2025-06-04 06:00:00.798125: val_loss -0.6514 
2025-06-04 06:00:00.811600: Pseudo dice [np.float32(0.8013)] 
2025-06-04 06:00:00.824491: Epoch time: 132.32 s 
2025-06-04 06:00:06.694863:  
2025-06-04 06:00:06.825632: Epoch 325 
2025-06-04 06:00:07.016717: Current learning rate: 0.00702 
2025-06-04 06:02:19.280902: train_loss -0.7098 
2025-06-04 06:02:19.297497: val_loss -0.7148 
2025-06-04 06:02:19.310750: Pseudo dice [np.float32(0.8059)] 
2025-06-04 06:02:19.322977: Epoch time: 132.59 s 
2025-06-04 06:02:25.567320:  
2025-06-04 06:02:25.706464: Epoch 326 
2025-06-04 06:02:25.995373: Current learning rate: 0.00701 
2025-06-04 06:04:40.008975: train_loss -0.6801 
2025-06-04 06:04:40.026026: val_loss -0.6715 
2025-06-04 06:04:40.040058: Pseudo dice [np.float32(0.7517)] 
2025-06-04 06:04:40.053531: Epoch time: 134.44 s 
2025-06-04 06:04:43.565321:  
2025-06-04 06:04:43.700347: Epoch 327 
2025-06-04 06:04:43.741867: Current learning rate: 0.007 
2025-06-04 06:06:55.739562: train_loss -0.7145 
2025-06-04 06:06:56.245256: val_loss -0.6877 
2025-06-04 06:06:56.726006: Pseudo dice [np.float32(0.6983)] 
2025-06-04 06:06:57.265952: Epoch time: 132.18 s 
2025-06-04 06:07:05.364723:  
2025-06-04 06:07:05.538391: Epoch 328 
2025-06-04 06:07:05.729401: Current learning rate: 0.00699 
2025-06-04 06:09:15.719334: train_loss -0.7223 
2025-06-04 06:09:16.125761: val_loss -0.6385 
2025-06-04 06:09:16.367279: Pseudo dice [np.float32(0.7158)] 
2025-06-04 06:09:16.768981: Epoch time: 130.36 s 
2025-06-04 06:09:22.228961:  
2025-06-04 06:09:22.544683: Epoch 329 
2025-06-04 06:09:22.558951: Current learning rate: 0.00698 
2025-06-04 06:11:39.542929: train_loss -0.7141 
2025-06-04 06:11:39.560581: val_loss -0.7164 
2025-06-04 06:11:39.573498: Pseudo dice [np.float32(0.7807)] 
2025-06-04 06:11:39.585929: Epoch time: 137.32 s 
2025-06-04 06:11:46.071992:  
2025-06-04 06:11:46.205336: Epoch 330 
2025-06-04 06:11:46.222576: Current learning rate: 0.00697 
2025-06-04 06:14:02.760528: train_loss -0.7119 
2025-06-04 06:14:03.129296: val_loss -0.7022 
2025-06-04 06:14:03.551232: Pseudo dice [np.float32(0.7982)] 
2025-06-04 06:14:03.849512: Epoch time: 136.69 s 
2025-06-04 06:14:09.603326:  
2025-06-04 06:14:09.868917: Epoch 331 
2025-06-04 06:14:10.237872: Current learning rate: 0.00696 
2025-06-04 06:16:35.173948: train_loss -0.6979 
2025-06-04 06:16:35.195357: val_loss -0.6397 
2025-06-04 06:16:35.211576: Pseudo dice [np.float32(0.7318)] 
2025-06-04 06:16:35.226874: Epoch time: 145.57 s 
2025-06-04 06:16:39.599463:  
2025-06-04 06:16:39.803968: Epoch 332 
2025-06-04 06:16:39.955624: Current learning rate: 0.00696 
2025-06-04 06:18:53.341975: train_loss -0.6917 
2025-06-04 06:18:53.359394: val_loss -0.6546 
2025-06-04 06:18:53.373271: Pseudo dice [np.float32(0.7598)] 
2025-06-04 06:18:53.389631: Epoch time: 133.74 s 
2025-06-04 06:19:00.595851:  
2025-06-04 06:19:00.818480: Epoch 333 
2025-06-04 06:19:00.834648: Current learning rate: 0.00695 
2025-06-04 06:21:13.480742: train_loss -0.694 
2025-06-04 06:21:13.818455: val_loss -0.7259 
2025-06-04 06:21:14.343286: Pseudo dice [np.float32(0.7703)] 
2025-06-04 06:21:14.916903: Epoch time: 132.89 s 
2025-06-04 06:21:21.729201:  
2025-06-04 06:21:21.786116: Epoch 334 
2025-06-04 06:21:21.930504: Current learning rate: 0.00694 
2025-06-04 06:23:38.146467: train_loss -0.7132 
2025-06-04 06:23:38.171094: val_loss -0.7438 
2025-06-04 06:23:38.185093: Pseudo dice [np.float32(0.8425)] 
2025-06-04 06:23:38.197068: Epoch time: 136.42 s 
2025-06-04 06:23:44.393902:  
2025-06-04 06:23:45.202405: Epoch 335 
2025-06-04 06:23:45.697262: Current learning rate: 0.00693 
2025-06-04 06:26:04.447394: train_loss -0.6877 
2025-06-04 06:26:04.671126: val_loss -0.6244 
2025-06-04 06:26:04.989381: Pseudo dice [np.float32(0.7346)] 
2025-06-04 06:26:05.052232: Epoch time: 140.06 s 
2025-06-04 06:26:10.990335:  
2025-06-04 06:26:11.007238: Epoch 336 
2025-06-04 06:26:11.020880: Current learning rate: 0.00692 
2025-06-04 06:28:23.348742: train_loss -0.7002 
2025-06-04 06:28:23.370763: val_loss -0.681 
2025-06-04 06:28:23.384581: Pseudo dice [np.float32(0.7472)] 
2025-06-04 06:28:23.397665: Epoch time: 132.36 s 
2025-06-04 06:28:30.009405:  
2025-06-04 06:28:30.026189: Epoch 337 
2025-06-04 06:28:30.039078: Current learning rate: 0.00691 
2025-06-04 06:30:39.393788: train_loss -0.7141 
2025-06-04 06:30:39.420104: val_loss -0.6685 
2025-06-04 06:30:39.433854: Pseudo dice [np.float32(0.7657)] 
2025-06-04 06:30:39.447402: Epoch time: 129.39 s 
2025-06-04 06:30:47.903815:  
2025-06-04 06:30:48.506510: Epoch 338 
2025-06-04 06:30:48.957698: Current learning rate: 0.0069 
2025-06-04 06:33:03.865890: train_loss -0.7139 
2025-06-04 06:33:03.887932: val_loss -0.6774 
2025-06-04 06:33:03.905274: Pseudo dice [np.float32(0.7233)] 
2025-06-04 06:33:03.917877: Epoch time: 135.96 s 
2025-06-04 06:33:10.877909:  
2025-06-04 06:33:10.898507: Epoch 339 
2025-06-04 06:33:10.915225: Current learning rate: 0.00689 
2025-06-04 06:35:28.737854: train_loss -0.7019 
2025-06-04 06:35:28.760316: val_loss -0.6384 
2025-06-04 06:35:28.774184: Pseudo dice [np.float32(0.7375)] 
2025-06-04 06:35:28.788489: Epoch time: 137.86 s 
2025-06-04 06:35:35.067809:  
2025-06-04 06:35:35.286407: Epoch 340 
2025-06-04 06:35:35.437415: Current learning rate: 0.00688 
2025-06-04 06:37:50.936735: train_loss -0.7114 
2025-06-04 06:37:51.199706: val_loss -0.6905 
2025-06-04 06:37:51.689029: Pseudo dice [np.float32(0.8613)] 
2025-06-04 06:37:51.861474: Epoch time: 135.87 s 
2025-06-04 06:37:59.552295:  
2025-06-04 06:38:00.069351: Epoch 341 
2025-06-04 06:38:00.443599: Current learning rate: 0.00687 
2025-06-04 06:40:18.820043: train_loss -0.7041 
2025-06-04 06:40:19.102776: val_loss -0.6703 
2025-06-04 06:40:19.416671: Pseudo dice [np.float32(0.7442)] 
2025-06-04 06:40:19.764196: Epoch time: 139.27 s 
2025-06-04 06:40:26.529701:  
2025-06-04 06:40:26.676439: Epoch 342 
2025-06-04 06:40:26.803901: Current learning rate: 0.00686 
2025-06-04 06:42:40.242746: train_loss -0.664 
2025-06-04 06:42:40.261878: val_loss -0.6543 
2025-06-04 06:42:40.276243: Pseudo dice [np.float32(0.7593)] 
2025-06-04 06:42:40.296372: Epoch time: 133.72 s 
2025-06-04 06:42:42.346041:  
2025-06-04 06:42:42.362582: Epoch 343 
2025-06-04 06:42:42.378162: Current learning rate: 0.00685 
2025-06-04 06:44:50.641059: train_loss -0.6911 
2025-06-04 06:44:50.659234: val_loss -0.6737 
2025-06-04 06:44:50.673606: Pseudo dice [np.float32(0.7563)] 
2025-06-04 06:44:50.703353: Epoch time: 128.3 s 
2025-06-04 06:44:52.521101:  
2025-06-04 06:44:52.541227: Epoch 344 
2025-06-04 06:44:52.555639: Current learning rate: 0.00684 
2025-06-04 06:47:05.651841: train_loss -0.6662 
2025-06-04 06:47:05.668795: val_loss -0.6679 
2025-06-04 06:47:05.683534: Pseudo dice [np.float32(0.7629)] 
2025-06-04 06:47:05.696714: Epoch time: 133.13 s 
2025-06-04 06:47:08.385853:  
2025-06-04 06:47:08.451676: Epoch 345 
2025-06-04 06:47:08.477106: Current learning rate: 0.00683 
2025-06-04 06:49:20.381067: train_loss -0.6649 
2025-06-04 06:49:20.399457: val_loss -0.6639 
2025-06-04 06:49:20.415112: Pseudo dice [np.float32(0.6832)] 
2025-06-04 06:49:20.431354: Epoch time: 132.0 s 
2025-06-04 06:49:27.183392:  
2025-06-04 06:49:27.551007: Epoch 346 
2025-06-04 06:49:27.618908: Current learning rate: 0.00682 
2025-06-04 06:51:38.881563: train_loss -0.7171 
2025-06-04 06:51:38.898939: val_loss -0.5901 
2025-06-04 06:51:38.911691: Pseudo dice [np.float32(0.6926)] 
2025-06-04 06:51:38.924491: Epoch time: 131.7 s 
2025-06-04 06:51:44.787554:  
2025-06-04 06:51:45.018281: Epoch 347 
2025-06-04 06:51:45.254303: Current learning rate: 0.00681 
2025-06-04 06:53:58.445403: train_loss -0.695 
2025-06-04 06:53:58.486492: val_loss -0.6743 
2025-06-04 06:53:58.506155: Pseudo dice [np.float32(0.7465)] 
2025-06-04 06:53:58.522637: Epoch time: 133.66 s 
2025-06-04 06:54:03.729452:  
2025-06-04 06:54:03.974899: Epoch 348 
2025-06-04 06:54:04.185707: Current learning rate: 0.0068 
2025-06-04 06:56:14.546510: train_loss -0.7213 
2025-06-04 06:56:14.944895: val_loss -0.6824 
2025-06-04 06:56:14.965859: Pseudo dice [np.float32(0.7421)] 
2025-06-04 06:56:14.979677: Epoch time: 130.82 s 
2025-06-04 06:56:20.622626:  
2025-06-04 06:56:20.788879: Epoch 349 
2025-06-04 06:56:20.904185: Current learning rate: 0.0068 
2025-06-04 06:58:28.503212: train_loss -0.6874 
2025-06-04 06:58:29.019230: val_loss -0.7143 
2025-06-04 06:58:29.526114: Pseudo dice [np.float32(0.8141)] 
2025-06-04 06:58:30.049645: Epoch time: 127.89 s 
2025-06-04 06:58:38.103598:  
2025-06-04 06:58:38.313039: Epoch 350 
2025-06-04 06:58:38.501059: Current learning rate: 0.00679 
2025-06-04 07:00:49.399202: train_loss -0.7271 
2025-06-04 07:00:49.808346: val_loss -0.6858 
2025-06-04 07:00:50.182928: Pseudo dice [np.float32(0.7194)] 
2025-06-04 07:00:50.538937: Epoch time: 131.3 s 
2025-06-04 07:00:56.747586:  
2025-06-04 07:00:56.830066: Epoch 351 
2025-06-04 07:00:56.845358: Current learning rate: 0.00678 
2025-06-04 07:03:07.179194: train_loss -0.6972 
2025-06-04 07:03:07.197139: val_loss -0.6106 
2025-06-04 07:03:07.212515: Pseudo dice [np.float32(0.734)] 
2025-06-04 07:03:07.235317: Epoch time: 130.43 s 
2025-06-04 07:03:11.876208:  
2025-06-04 07:03:11.893116: Epoch 352 
2025-06-04 07:03:11.907916: Current learning rate: 0.00677 
2025-06-04 07:05:24.520739: train_loss -0.6901 
2025-06-04 07:05:24.538568: val_loss -0.6889 
2025-06-04 07:05:24.551999: Pseudo dice [np.float32(0.7571)] 
2025-06-04 07:05:24.564528: Epoch time: 132.65 s 
2025-06-04 07:05:34.606234:  
2025-06-04 07:05:34.632135: Epoch 353 
2025-06-04 07:05:34.652660: Current learning rate: 0.00676 
2025-06-04 07:07:49.778780: train_loss -0.7098 
2025-06-04 07:07:49.796148: val_loss -0.6904 
2025-06-04 07:07:49.809954: Pseudo dice [np.float32(0.8283)] 
2025-06-04 07:07:49.822739: Epoch time: 135.18 s 
2025-06-04 07:07:54.239008:  
2025-06-04 07:07:54.258878: Epoch 354 
2025-06-04 07:07:54.274116: Current learning rate: 0.00675 
2025-06-04 07:10:10.294401: train_loss -0.7174 
2025-06-04 07:10:10.562180: val_loss -0.6613 
2025-06-04 07:10:10.876571: Pseudo dice [np.float32(0.7137)] 
2025-06-04 07:10:11.151435: Epoch time: 136.06 s 
2025-06-04 07:10:16.144871:  
2025-06-04 07:10:16.318009: Epoch 355 
2025-06-04 07:10:16.422560: Current learning rate: 0.00674 
2025-06-04 07:12:32.017389: train_loss -0.7141 
2025-06-04 07:12:32.041768: val_loss -0.6453 
2025-06-04 07:12:32.059532: Pseudo dice [np.float32(0.7765)] 
2025-06-04 07:12:32.081813: Epoch time: 135.87 s 
2025-06-04 07:12:38.628710:  
2025-06-04 07:12:38.807706: Epoch 356 
2025-06-04 07:12:39.016495: Current learning rate: 0.00673 
2025-06-04 07:14:52.274546: train_loss -0.7221 
2025-06-04 07:14:52.939540: val_loss -0.6842 
2025-06-04 07:14:53.256460: Pseudo dice [np.float32(0.7219)] 
2025-06-04 07:14:53.271496: Epoch time: 133.65 s 
2025-06-04 07:14:58.709355:  
2025-06-04 07:14:58.727023: Epoch 357 
2025-06-04 07:14:58.740716: Current learning rate: 0.00672 
2025-06-04 07:17:14.918640: train_loss -0.6794 
2025-06-04 07:17:14.939538: val_loss -0.664 
2025-06-04 07:17:14.953821: Pseudo dice [np.float32(0.7723)] 
2025-06-04 07:17:14.967623: Epoch time: 136.21 s 
2025-06-04 07:17:20.879987:  
2025-06-04 07:17:21.128106: Epoch 358 
2025-06-04 07:17:21.323215: Current learning rate: 0.00671 
2025-06-04 07:19:35.640406: train_loss -0.7058 
2025-06-04 07:19:35.658661: val_loss -0.704 
2025-06-04 07:19:35.672949: Pseudo dice [np.float32(0.8458)] 
2025-06-04 07:19:35.686977: Epoch time: 134.76 s 
2025-06-04 07:19:40.223189:  
2025-06-04 07:19:40.364993: Epoch 359 
2025-06-04 07:19:40.380576: Current learning rate: 0.0067 
2025-06-04 07:22:00.169961: train_loss -0.7078 
2025-06-04 07:22:00.200734: val_loss -0.6648 
2025-06-04 07:22:00.218234: Pseudo dice [np.float32(0.7296)] 
2025-06-04 07:22:00.233245: Epoch time: 139.95 s 
2025-06-04 07:22:07.460345:  
2025-06-04 07:22:07.579690: Epoch 360 
2025-06-04 07:22:07.594992: Current learning rate: 0.00669 
2025-06-04 07:24:25.638678: train_loss -0.708 
2025-06-04 07:24:25.662546: val_loss -0.6951 
2025-06-04 07:24:25.677081: Pseudo dice [np.float32(0.7765)] 
2025-06-04 07:24:25.691638: Epoch time: 138.18 s 
2025-06-04 07:24:32.448895:  
2025-06-04 07:24:32.657190: Epoch 361 
2025-06-04 07:24:32.909325: Current learning rate: 0.00668 
2025-06-04 07:26:46.452224: train_loss -0.6777 
2025-06-04 07:26:46.550512: val_loss -0.7039 
2025-06-04 07:26:46.567199: Pseudo dice [np.float32(0.6965)] 
2025-06-04 07:26:46.582602: Epoch time: 134.01 s 
2025-06-04 07:26:52.979653:  
2025-06-04 07:26:53.000241: Epoch 362 
2025-06-04 07:26:53.014951: Current learning rate: 0.00667 
2025-06-04 07:29:08.687405: train_loss -0.688 
2025-06-04 07:29:08.871726: val_loss -0.6499 
2025-06-04 07:29:08.886659: Pseudo dice [np.float32(0.7905)] 
2025-06-04 07:29:08.899536: Epoch time: 135.71 s 
2025-06-04 07:29:13.840427:  
2025-06-04 07:29:13.984797: Epoch 363 
2025-06-04 07:29:14.071557: Current learning rate: 0.00666 
2025-06-04 07:31:30.679976: train_loss -0.7177 
2025-06-04 07:31:30.866080: val_loss -0.6814 
2025-06-04 07:31:30.880610: Pseudo dice [np.float32(0.8112)] 
2025-06-04 07:31:30.893035: Epoch time: 136.84 s 
2025-06-04 07:31:36.677268:  
2025-06-04 07:31:36.847188: Epoch 364 
2025-06-04 07:31:37.137216: Current learning rate: 0.00665 
2025-06-04 07:33:53.008834: train_loss -0.7155 
2025-06-04 07:33:53.368449: val_loss -0.6878 
2025-06-04 07:33:53.384567: Pseudo dice [np.float32(0.7704)] 
2025-06-04 07:33:53.399461: Epoch time: 136.33 s 
2025-06-04 07:34:00.717052:  
2025-06-04 07:34:00.735987: Epoch 365 
2025-06-04 07:34:00.751339: Current learning rate: 0.00665 
2025-06-04 07:36:23.604749: train_loss -0.7079 
2025-06-04 07:36:23.956640: val_loss -0.638 
2025-06-04 07:36:24.077781: Pseudo dice [np.float32(0.6942)] 
2025-06-04 07:36:24.090803: Epoch time: 142.89 s 
2025-06-04 07:36:31.024826:  
2025-06-04 07:36:31.040738: Epoch 366 
2025-06-04 07:36:31.053676: Current learning rate: 0.00664 
2025-06-04 07:38:45.997787: train_loss -0.6984 
2025-06-04 07:38:46.102408: val_loss -0.6491 
2025-06-04 07:38:46.117484: Pseudo dice [np.float32(0.7515)] 
2025-06-04 07:38:46.130278: Epoch time: 134.98 s 
2025-06-04 07:38:47.826616:  
2025-06-04 07:38:47.838081: Epoch 367 
2025-06-04 07:38:47.851157: Current learning rate: 0.00663 
2025-06-04 07:41:00.923397: train_loss -0.6792 
2025-06-04 07:41:00.958828: val_loss -0.6627 
2025-06-04 07:41:00.996464: Pseudo dice [np.float32(0.7904)] 
2025-06-04 07:41:01.040036: Epoch time: 133.1 s 
2025-06-04 07:41:04.982228:  
2025-06-04 07:41:04.999637: Epoch 368 
2025-06-04 07:41:05.013885: Current learning rate: 0.00662 
2025-06-04 07:43:17.697020: train_loss -0.6956 
2025-06-04 07:43:17.761482: val_loss -0.6997 
2025-06-04 07:43:17.908076: Pseudo dice [np.float32(0.7506)] 
2025-06-04 07:43:17.980114: Epoch time: 132.72 s 
2025-06-04 07:43:21.330297:  
2025-06-04 07:43:21.519267: Epoch 369 
2025-06-04 07:43:21.663740: Current learning rate: 0.00661 
2025-06-04 07:45:33.923042: train_loss -0.7026 
2025-06-04 07:45:34.172519: val_loss -0.6834 
2025-06-04 07:45:34.434003: Pseudo dice [np.float32(0.7571)] 
2025-06-04 07:45:34.706830: Epoch time: 132.59 s 
2025-06-04 07:45:42.276585:  
2025-06-04 07:45:42.710789: Epoch 370 
2025-06-04 07:45:42.998571: Current learning rate: 0.0066 
2025-06-04 07:47:51.353721: train_loss -0.7193 
2025-06-04 07:47:51.371597: val_loss -0.6853 
2025-06-04 07:47:51.384299: Pseudo dice [np.float32(0.7233)] 
2025-06-04 07:47:51.397527: Epoch time: 129.08 s 
2025-06-04 07:47:59.800761:  
2025-06-04 07:47:59.921071: Epoch 371 
2025-06-04 07:48:00.195197: Current learning rate: 0.00659 
2025-06-04 07:50:18.086687: train_loss -0.6918 
2025-06-04 07:50:18.108669: val_loss -0.6462 
2025-06-04 07:50:18.122817: Pseudo dice [np.float32(0.7707)] 
2025-06-04 07:50:18.135907: Epoch time: 138.29 s 
2025-06-04 07:50:24.715242:  
2025-06-04 07:50:24.733131: Epoch 372 
2025-06-04 07:50:24.747381: Current learning rate: 0.00658 
2025-06-04 07:52:39.030085: train_loss -0.6794 
2025-06-04 07:52:39.047185: val_loss -0.7184 
2025-06-04 07:52:39.059974: Pseudo dice [np.float32(0.7925)] 
2025-06-04 07:52:39.074373: Epoch time: 134.32 s 
2025-06-04 07:52:45.004488:  
2025-06-04 07:52:45.120287: Epoch 373 
2025-06-04 07:52:45.216051: Current learning rate: 0.00657 
2025-06-04 07:55:00.809943: train_loss -0.6915 
2025-06-04 07:55:01.175047: val_loss -0.6823 
2025-06-04 07:55:01.586842: Pseudo dice [np.float32(0.7811)] 
2025-06-04 07:55:02.092795: Epoch time: 135.81 s 
2025-06-04 07:55:10.039961:  
2025-06-04 07:55:10.332500: Epoch 374 
2025-06-04 07:55:10.715539: Current learning rate: 0.00656 
2025-06-04 07:57:26.446388: train_loss -0.7038 
2025-06-04 07:57:26.865566: val_loss -0.6878 
2025-06-04 07:57:27.012760: Pseudo dice [np.float32(0.7772)] 
2025-06-04 07:57:27.414273: Epoch time: 136.41 s 
2025-06-04 07:57:32.614586:  
2025-06-04 07:57:32.776092: Epoch 375 
2025-06-04 07:57:32.973631: Current learning rate: 0.00655 
2025-06-04 07:59:47.945839: train_loss -0.6897 
2025-06-04 07:59:48.555912: val_loss -0.6896 
2025-06-04 07:59:48.948891: Pseudo dice [np.float32(0.7323)] 
2025-06-04 07:59:48.964912: Epoch time: 135.33 s 
2025-06-04 07:59:53.855922:  
2025-06-04 07:59:54.126383: Epoch 376 
2025-06-04 07:59:54.332248: Current learning rate: 0.00654 
2025-06-04 08:02:14.257948: train_loss -0.6792 
2025-06-04 08:02:14.279844: val_loss -0.6611 
2025-06-04 08:02:14.292260: Pseudo dice [np.float32(0.7362)] 
2025-06-04 08:02:14.304514: Epoch time: 140.4 s 
2025-06-04 08:02:20.413287:  
2025-06-04 08:02:20.561295: Epoch 377 
2025-06-04 08:02:20.577013: Current learning rate: 0.00653 
2025-06-04 08:04:37.345319: train_loss -0.7025 
2025-06-04 08:04:37.370324: val_loss -0.6571 
2025-06-04 08:04:37.383353: Pseudo dice [np.float32(0.7406)] 
2025-06-04 08:04:37.394815: Epoch time: 136.93 s 
2025-06-04 08:04:43.593754:  
2025-06-04 08:04:43.743303: Epoch 378 
2025-06-04 08:04:43.815631: Current learning rate: 0.00652 
2025-06-04 08:07:00.822051: train_loss -0.7097 
2025-06-04 08:07:01.137520: val_loss -0.703 
2025-06-04 08:07:01.152968: Pseudo dice [np.float32(0.7773)] 
2025-06-04 08:07:01.166312: Epoch time: 137.23 s 
2025-06-04 08:07:06.317137:  
2025-06-04 08:07:06.363687: Epoch 379 
2025-06-04 08:07:06.379673: Current learning rate: 0.00651 
2025-06-04 08:09:25.807452: train_loss -0.7075 
2025-06-04 08:09:25.830587: val_loss -0.6743 
2025-06-04 08:09:25.844462: Pseudo dice [np.float32(0.8133)] 
2025-06-04 08:09:25.859302: Epoch time: 139.49 s 
2025-06-04 08:09:30.674009:  
2025-06-04 08:09:30.690500: Epoch 380 
2025-06-04 08:09:30.703351: Current learning rate: 0.0065 
2025-06-04 08:11:46.791058: train_loss -0.7041 
2025-06-04 08:11:46.814135: val_loss -0.6941 
2025-06-04 08:11:46.827711: Pseudo dice [np.float32(0.8163)] 
2025-06-04 08:11:46.841319: Epoch time: 136.12 s 
2025-06-04 08:11:54.074819:  
2025-06-04 08:11:54.234087: Epoch 381 
2025-06-04 08:11:54.426406: Current learning rate: 0.00649 
2025-06-04 08:14:10.681096: train_loss -0.6988 
2025-06-04 08:14:10.699968: val_loss -0.6967 
2025-06-04 08:14:10.714990: Pseudo dice [np.float32(0.8093)] 
2025-06-04 08:14:10.728509: Epoch time: 136.61 s 
2025-06-04 08:14:18.244724:  
2025-06-04 08:14:18.414692: Epoch 382 
2025-06-04 08:14:18.609089: Current learning rate: 0.00648 
2025-06-04 08:16:31.309919: train_loss -0.7113 
2025-06-04 08:16:31.332196: val_loss -0.6742 
2025-06-04 08:16:31.345369: Pseudo dice [np.float32(0.7844)] 
2025-06-04 08:16:31.359218: Epoch time: 133.07 s 
2025-06-04 08:16:31.371408: Yayy! New best EMA pseudo Dice: 0.7745000123977661 
2025-06-04 08:16:39.138036:  
2025-06-04 08:16:39.154556: Epoch 383 
2025-06-04 08:16:39.165925: Current learning rate: 0.00648 
2025-06-04 08:18:49.624256: train_loss -0.6831 
2025-06-04 08:18:49.646696: val_loss -0.6906 
2025-06-04 08:18:49.659230: Pseudo dice [np.float32(0.7747)] 
2025-06-04 08:18:49.671048: Epoch time: 130.49 s 
2025-06-04 08:18:49.683425: Yayy! New best EMA pseudo Dice: 0.7745000123977661 
2025-06-04 08:18:55.931234:  
2025-06-04 08:18:55.949246: Epoch 384 
2025-06-04 08:18:55.963762: Current learning rate: 0.00647 
2025-06-04 08:21:10.627418: train_loss -0.6805 
2025-06-04 08:21:10.807042: val_loss -0.6859 
2025-06-04 08:21:10.824722: Pseudo dice [np.float32(0.7678)] 
2025-06-04 08:21:10.839720: Epoch time: 134.7 s 
2025-06-04 08:21:15.879816:  
2025-06-04 08:21:16.010523: Epoch 385 
2025-06-04 08:21:16.276425: Current learning rate: 0.00646 
2025-06-04 08:23:29.899313: train_loss -0.6854 
2025-06-04 08:23:29.918039: val_loss -0.6593 
2025-06-04 08:23:29.933681: Pseudo dice [np.float32(0.7334)] 
2025-06-04 08:23:29.947847: Epoch time: 134.02 s 
2025-06-04 08:23:39.347693:  
2025-06-04 08:23:39.858823: Epoch 386 
2025-06-04 08:23:40.151731: Current learning rate: 0.00645 
2025-06-04 08:25:57.910245: train_loss -0.7003 
2025-06-04 08:25:58.043107: val_loss -0.6516 
2025-06-04 08:25:58.058241: Pseudo dice [np.float32(0.7053)] 
2025-06-04 08:25:58.071431: Epoch time: 138.57 s 
2025-06-04 08:26:04.436505:  
2025-06-04 08:26:04.583614: Epoch 387 
2025-06-04 08:26:04.653993: Current learning rate: 0.00644 
2025-06-04 08:28:20.826218: train_loss -0.6993 
2025-06-04 08:28:20.844114: val_loss -0.6804 
2025-06-04 08:28:20.858245: Pseudo dice [np.float32(0.7819)] 
2025-06-04 08:28:20.870604: Epoch time: 136.39 s 
2025-06-04 08:28:22.532786:  
2025-06-04 08:28:22.558211: Epoch 388 
2025-06-04 08:28:22.571961: Current learning rate: 0.00643 
2025-06-04 08:30:32.309029: train_loss -0.6962 
2025-06-04 08:30:32.326319: val_loss -0.5972 
2025-06-04 08:30:32.339592: Pseudo dice [np.float32(0.7115)] 
2025-06-04 08:30:32.352404: Epoch time: 129.78 s 
2025-06-04 08:30:37.804786:  
2025-06-04 08:30:37.821907: Epoch 389 
2025-06-04 08:30:37.833662: Current learning rate: 0.00642 
2025-06-04 08:32:55.150682: train_loss -0.7116 
2025-06-04 08:32:55.435387: val_loss -0.6697 
2025-06-04 08:32:55.450502: Pseudo dice [np.float32(0.7343)] 
2025-06-04 08:32:55.463770: Epoch time: 137.35 s 
2025-06-04 08:33:02.292561:  
2025-06-04 08:33:02.658327: Epoch 390 
2025-06-04 08:33:02.915524: Current learning rate: 0.00641 
2025-06-04 08:35:18.374462: train_loss -0.7069 
2025-06-04 08:35:18.684859: val_loss -0.6678 
2025-06-04 08:35:18.792130: Pseudo dice [np.float32(0.7391)] 
2025-06-04 08:35:18.976708: Epoch time: 136.08 s 
2025-06-04 08:35:25.402132:  
2025-06-04 08:35:25.746245: Epoch 391 
2025-06-04 08:35:26.236602: Current learning rate: 0.0064 
2025-06-04 08:37:34.035646: train_loss -0.7187 
2025-06-04 08:37:34.236792: val_loss -0.709 
2025-06-04 08:37:34.605907: Pseudo dice [np.float32(0.7807)] 
2025-06-04 08:37:34.861787: Epoch time: 128.64 s 
2025-06-04 08:37:40.350521:  
2025-06-04 08:37:40.377051: Epoch 392 
2025-06-04 08:37:40.392403: Current learning rate: 0.00639 
2025-06-04 08:39:50.830444: train_loss -0.7395 
2025-06-04 08:39:51.393101: val_loss -0.6785 
2025-06-04 08:39:51.961701: Pseudo dice [np.float32(0.7562)] 
2025-06-04 08:39:52.616318: Epoch time: 130.48 s 
2025-06-04 08:39:59.350909:  
2025-06-04 08:39:59.369915: Epoch 393 
2025-06-04 08:39:59.383271: Current learning rate: 0.00638 
2025-06-04 08:42:08.791524: train_loss -0.7226 
2025-06-04 08:42:09.060842: val_loss -0.6713 
2025-06-04 08:42:09.082366: Pseudo dice [np.float32(0.8102)] 
2025-06-04 08:42:09.097595: Epoch time: 129.44 s 
2025-06-04 08:42:16.590401:  
2025-06-04 08:42:16.747260: Epoch 394 
2025-06-04 08:42:16.932317: Current learning rate: 0.00637 
2025-06-04 08:44:30.178112: train_loss -0.7077 
2025-06-04 08:44:30.195862: val_loss -0.637 
2025-06-04 08:44:30.210401: Pseudo dice [np.float32(0.7773)] 
2025-06-04 08:44:30.223833: Epoch time: 133.59 s 
2025-06-04 08:44:35.560922:  
2025-06-04 08:44:35.578701: Epoch 395 
2025-06-04 08:44:35.592825: Current learning rate: 0.00636 
2025-06-04 08:46:53.802653: train_loss -0.7155 
2025-06-04 08:46:54.179546: val_loss -0.6914 
2025-06-04 08:46:54.653445: Pseudo dice [np.float32(0.7892)] 
2025-06-04 08:46:55.093406: Epoch time: 138.24 s 
2025-06-04 08:46:59.637380:  
2025-06-04 08:46:59.906354: Epoch 396 
2025-06-04 08:47:00.096059: Current learning rate: 0.00635 
2025-06-04 08:49:15.609345: train_loss -0.7222 
2025-06-04 08:49:15.628057: val_loss -0.6631 
2025-06-04 08:49:15.641626: Pseudo dice [np.float32(0.7582)] 
2025-06-04 08:49:15.655039: Epoch time: 135.97 s 
2025-06-04 08:49:22.089308:  
2025-06-04 08:49:22.246663: Epoch 397 
2025-06-04 08:49:22.316545: Current learning rate: 0.00634 
2025-06-04 08:51:40.103978: train_loss -0.6882 
2025-06-04 08:51:40.127970: val_loss -0.6584 
2025-06-04 08:51:40.146611: Pseudo dice [np.float32(0.7686)] 
2025-06-04 08:51:40.159103: Epoch time: 138.02 s 
2025-06-04 08:51:45.825731:  
2025-06-04 08:51:46.054704: Epoch 398 
2025-06-04 08:51:46.294311: Current learning rate: 0.00633 
2025-06-04 08:54:00.824014: train_loss -0.6886 
2025-06-04 08:54:00.844395: val_loss -0.6829 
2025-06-04 08:54:00.859561: Pseudo dice [np.float32(0.7316)] 
2025-06-04 08:54:00.873828: Epoch time: 135.0 s 
2025-06-04 08:54:09.823768:  
2025-06-04 08:54:09.843671: Epoch 399 
2025-06-04 08:54:09.856996: Current learning rate: 0.00632 
2025-06-04 08:56:32.054178: train_loss -0.6958 
2025-06-04 08:56:32.553331: val_loss -0.6688 
2025-06-04 08:56:33.004175: Pseudo dice [np.float32(0.7458)] 
2025-06-04 08:56:33.482767: Epoch time: 142.23 s 
2025-06-04 08:56:40.002111:  
2025-06-04 08:56:40.234903: Epoch 400 
2025-06-04 08:56:40.334604: Current learning rate: 0.00631 
2025-06-04 08:58:58.926602: train_loss -0.7095 
2025-06-04 08:58:58.951829: val_loss -0.6344 
2025-06-04 08:58:59.352683: Pseudo dice [np.float32(0.7662)] 
2025-06-04 08:58:59.922510: Epoch time: 138.93 s 
2025-06-04 08:59:07.678189:  
2025-06-04 08:59:07.695459: Epoch 401 
2025-06-04 08:59:07.709613: Current learning rate: 0.0063 
2025-06-04 09:01:23.783674: train_loss -0.7046 
2025-06-04 09:01:24.274796: val_loss -0.7087 
2025-06-04 09:01:24.833621: Pseudo dice [np.float32(0.82)] 
2025-06-04 09:01:25.387739: Epoch time: 136.11 s 
2025-06-04 09:01:32.233088:  
2025-06-04 09:01:32.436055: Epoch 402 
2025-06-04 09:01:32.656325: Current learning rate: 0.0063 
2025-06-04 09:03:47.171948: train_loss -0.7102 
2025-06-04 09:03:47.678397: val_loss -0.6865 
2025-06-04 09:03:48.093072: Pseudo dice [np.float32(0.7622)] 
2025-06-04 09:03:48.496648: Epoch time: 134.94 s 
2025-06-04 09:03:53.773919:  
2025-06-04 09:03:53.890106: Epoch 403 
2025-06-04 09:03:54.070684: Current learning rate: 0.00629 
2025-06-04 09:06:09.602995: train_loss -0.7083 
2025-06-04 09:06:09.773947: val_loss -0.6653 
2025-06-04 09:06:10.114278: Pseudo dice [np.float32(0.7097)] 
2025-06-04 09:06:10.401120: Epoch time: 135.83 s 
2025-06-04 09:06:17.138566:  
2025-06-04 09:06:17.433852: Epoch 404 
2025-06-04 09:06:17.449160: Current learning rate: 0.00628 
2025-06-04 09:08:30.522802: train_loss -0.7172 
2025-06-04 09:08:30.546287: val_loss -0.6742 
2025-06-04 09:08:30.793702: Pseudo dice [np.float32(0.6961)] 
2025-06-04 09:08:31.178514: Epoch time: 133.39 s 
2025-06-04 09:08:38.629799:  
2025-06-04 09:08:38.860458: Epoch 405 
2025-06-04 09:08:39.152853: Current learning rate: 0.00627 
2025-06-04 09:10:54.679080: train_loss -0.6914 
2025-06-04 09:10:55.046669: val_loss -0.682 
2025-06-04 09:10:55.357074: Pseudo dice [np.float32(0.8392)] 
2025-06-04 09:10:55.661276: Epoch time: 136.05 s 
2025-06-04 09:10:59.348506:  
2025-06-04 09:10:59.360317: Epoch 406 
2025-06-04 09:10:59.370062: Current learning rate: 0.00626 
2025-06-04 09:13:16.128468: train_loss -0.6816 
2025-06-04 09:13:16.303438: val_loss -0.6284 
2025-06-04 09:13:16.436422: Pseudo dice [np.float32(0.694)] 
2025-06-04 09:13:16.542124: Epoch time: 136.78 s 
2025-06-04 09:13:18.882837:  
2025-06-04 09:13:18.945665: Epoch 407 
2025-06-04 09:13:19.012110: Current learning rate: 0.00625 
2025-06-04 09:15:34.111320: train_loss -0.6891 
2025-06-04 09:15:34.237013: val_loss -0.6777 
2025-06-04 09:15:34.405274: Pseudo dice [np.float32(0.7718)] 
2025-06-04 09:15:34.624343: Epoch time: 135.23 s 
2025-06-04 09:15:40.224660:  
2025-06-04 09:15:40.241680: Epoch 408 
2025-06-04 09:15:40.254508: Current learning rate: 0.00624 
2025-06-04 09:17:50.362840: train_loss -0.721 
2025-06-04 09:17:50.379546: val_loss -0.673 
2025-06-04 09:17:50.392707: Pseudo dice [np.float32(0.7579)] 
2025-06-04 09:17:50.404850: Epoch time: 130.19 s 
2025-06-04 09:17:55.625490:  
2025-06-04 09:17:55.712502: Epoch 409 
2025-06-04 09:17:55.947900: Current learning rate: 0.00623 
2025-06-04 09:20:06.673098: train_loss -0.7022 
2025-06-04 09:20:06.691885: val_loss -0.669 
2025-06-04 09:20:06.705302: Pseudo dice [np.float32(0.6611)] 
2025-06-04 09:20:06.717899: Epoch time: 131.05 s 
2025-06-04 09:20:13.214293:  
2025-06-04 09:20:13.388610: Epoch 410 
2025-06-04 09:20:13.623936: Current learning rate: 0.00622 
2025-06-04 09:22:26.210232: train_loss -0.706 
2025-06-04 09:22:26.228644: val_loss -0.7379 
2025-06-04 09:22:26.242985: Pseudo dice [np.float32(0.8103)] 
2025-06-04 09:22:26.256794: Epoch time: 133.0 s 
2025-06-04 09:22:31.581310:  
2025-06-04 09:22:31.826670: Epoch 411 
2025-06-04 09:22:31.844534: Current learning rate: 0.00621 
2025-06-04 09:24:40.134786: train_loss -0.7294 
2025-06-04 09:24:40.151742: val_loss -0.6729 
2025-06-04 09:24:40.164014: Pseudo dice [np.float32(0.8171)] 
2025-06-04 09:24:40.177170: Epoch time: 128.56 s 
2025-06-04 09:24:44.600344:  
2025-06-04 09:24:44.617115: Epoch 412 
2025-06-04 09:24:44.630883: Current learning rate: 0.0062 
2025-06-04 09:26:54.408232: train_loss -0.6892 
2025-06-04 09:26:54.423944: val_loss -0.6861 
2025-06-04 09:26:54.547795: Pseudo dice [np.float32(0.7328)] 
2025-06-04 09:26:54.564090: Epoch time: 129.81 s 
2025-06-04 09:26:59.800165:  
2025-06-04 09:26:59.964449: Epoch 413 
2025-06-04 09:27:00.077693: Current learning rate: 0.00619 
2025-06-04 09:29:13.804410: train_loss -0.699 
2025-06-04 09:29:13.823803: val_loss -0.6713 
2025-06-04 09:29:13.839217: Pseudo dice [np.float32(0.7922)] 
2025-06-04 09:29:13.853654: Epoch time: 134.01 s 
2025-06-04 09:29:18.327893:  
2025-06-04 09:29:18.601587: Epoch 414 
2025-06-04 09:29:19.031308: Current learning rate: 0.00618 
2025-06-04 09:31:32.481521: train_loss -0.7197 
2025-06-04 09:31:32.499336: val_loss -0.6957 
2025-06-04 09:31:32.515584: Pseudo dice [np.float32(0.868)] 
2025-06-04 09:31:32.528697: Epoch time: 134.16 s 
2025-06-04 09:31:38.310630:  
2025-06-04 09:31:38.626516: Epoch 415 
2025-06-04 09:31:38.907191: Current learning rate: 0.00617 
2025-06-04 09:33:50.918800: train_loss -0.715 
2025-06-04 09:33:51.044321: val_loss -0.6964 
2025-06-04 09:33:51.060620: Pseudo dice [np.float32(0.7937)] 
2025-06-04 09:33:51.074697: Epoch time: 132.61 s 
2025-06-04 09:33:56.372049:  
2025-06-04 09:33:56.547687: Epoch 416 
2025-06-04 09:33:56.728014: Current learning rate: 0.00616 
2025-06-04 09:36:09.056475: train_loss -0.7185 
2025-06-04 09:36:09.483419: val_loss -0.6975 
2025-06-04 09:36:10.004703: Pseudo dice [np.float32(0.7614)] 
2025-06-04 09:36:10.607452: Epoch time: 132.69 s 
2025-06-04 09:36:16.558645:  
2025-06-04 09:36:16.729966: Epoch 417 
2025-06-04 09:36:16.938684: Current learning rate: 0.00615 
2025-06-04 09:38:26.638757: train_loss -0.73 
2025-06-04 09:38:26.964689: val_loss -0.73 
2025-06-04 09:38:27.337451: Pseudo dice [np.float32(0.7861)] 
2025-06-04 09:38:27.601270: Epoch time: 130.08 s 
2025-06-04 09:38:32.835930:  
2025-06-04 09:38:32.990701: Epoch 418 
2025-06-04 09:38:33.208982: Current learning rate: 0.00614 
2025-06-04 09:40:43.168090: train_loss -0.7059 
2025-06-04 09:40:43.365065: val_loss -0.7175 
2025-06-04 09:40:43.807938: Pseudo dice [np.float32(0.8015)] 
2025-06-04 09:40:44.217949: Epoch time: 130.33 s 
2025-06-04 09:40:44.233425: Yayy! New best EMA pseudo Dice: 0.7768999934196472 
2025-06-04 09:40:52.102336:  
2025-06-04 09:40:52.217901: Epoch 419 
2025-06-04 09:40:52.379599: Current learning rate: 0.00613 
2025-06-04 09:43:10.054200: train_loss -0.7043 
2025-06-04 09:43:10.502742: val_loss -0.5944 
2025-06-04 09:43:11.084228: Pseudo dice [np.float32(0.6569)] 
2025-06-04 09:43:11.493372: Epoch time: 137.95 s 
2025-06-04 09:43:19.255367:  
2025-06-04 09:43:19.464439: Epoch 420 
2025-06-04 09:43:19.534265: Current learning rate: 0.00612 
2025-06-04 09:45:29.944666: train_loss -0.7024 
2025-06-04 09:45:29.963325: val_loss -0.6513 
2025-06-04 09:45:29.976418: Pseudo dice [np.float32(0.6868)] 
2025-06-04 09:45:29.990936: Epoch time: 130.69 s 
2025-06-04 09:45:33.908494:  
2025-06-04 09:45:33.927378: Epoch 421 
2025-06-04 09:45:33.941741: Current learning rate: 0.00612 
2025-06-04 09:47:52.400152: train_loss -0.7042 
2025-06-04 09:47:52.417035: val_loss -0.7293 
2025-06-04 09:47:52.429822: Pseudo dice [np.float32(0.7791)] 
2025-06-04 09:47:52.441308: Epoch time: 138.49 s 
2025-06-04 09:48:00.523877:  
2025-06-04 09:48:00.878513: Epoch 422 
2025-06-04 09:48:01.160423: Current learning rate: 0.00611 
2025-06-04 09:50:22.022565: train_loss -0.7041 
2025-06-04 09:50:22.210780: val_loss -0.7149 
2025-06-04 09:50:22.231426: Pseudo dice [np.float32(0.7882)] 
2025-06-04 09:50:22.245342: Epoch time: 141.5 s 
2025-06-04 09:50:30.714339:  
2025-06-04 09:50:30.854470: Epoch 423 
2025-06-04 09:50:31.019452: Current learning rate: 0.0061 
2025-06-04 09:52:48.113683: train_loss -0.7012 
2025-06-04 09:52:48.405653: val_loss -0.6958 
2025-06-04 09:52:48.421370: Pseudo dice [np.float32(0.8183)] 
2025-06-04 09:52:48.434646: Epoch time: 137.4 s 
2025-06-04 09:52:53.525949:  
2025-06-04 09:52:53.704005: Epoch 424 
2025-06-04 09:52:53.939662: Current learning rate: 0.00609 
2025-06-04 09:55:09.753199: train_loss -0.692 
2025-06-04 09:55:10.247439: val_loss -0.6671 
2025-06-04 09:55:10.262663: Pseudo dice [np.float32(0.7554)] 
2025-06-04 09:55:10.611188: Epoch time: 136.23 s 
2025-06-04 09:55:16.920730:  
2025-06-04 09:55:17.008102: Epoch 425 
2025-06-04 09:55:17.081859: Current learning rate: 0.00608 
2025-06-04 09:57:34.924182: train_loss -0.672 
2025-06-04 09:57:34.945686: val_loss -0.7012 
2025-06-04 09:57:34.958745: Pseudo dice [np.float32(0.8064)] 
2025-06-04 09:57:34.972408: Epoch time: 138.0 s 
2025-06-04 09:57:40.378251:  
2025-06-04 09:57:40.551320: Epoch 426 
2025-06-04 09:57:40.565698: Current learning rate: 0.00607 
2025-06-04 09:59:58.408683: train_loss -0.6961 
2025-06-04 09:59:58.751366: val_loss -0.7115 
2025-06-04 09:59:59.095587: Pseudo dice [np.float32(0.7865)] 
2025-06-04 09:59:59.536761: Epoch time: 138.03 s 
2025-06-04 10:00:07.058852:  
2025-06-04 10:00:07.226694: Epoch 427 
2025-06-04 10:00:07.244741: Current learning rate: 0.00606 
2025-06-04 10:02:18.741357: train_loss -0.7213 
2025-06-04 10:02:19.111225: val_loss -0.6929 
2025-06-04 10:02:19.510268: Pseudo dice [np.float32(0.8422)] 
2025-06-04 10:02:19.759733: Epoch time: 131.68 s 
2025-06-04 10:02:19.781132: Yayy! New best EMA pseudo Dice: 0.7791000008583069 
2025-06-04 10:02:25.287034:  
2025-06-04 10:02:25.352480: Epoch 428 
2025-06-04 10:02:25.440692: Current learning rate: 0.00605 
2025-06-04 10:04:42.633239: train_loss -0.7028 
2025-06-04 10:04:43.172162: val_loss -0.6976 
2025-06-04 10:04:43.196182: Pseudo dice [np.float32(0.7331)] 
2025-06-04 10:04:43.209709: Epoch time: 137.35 s 
2025-06-04 10:04:51.097270:  
2025-06-04 10:04:51.363981: Epoch 429 
2025-06-04 10:04:51.649945: Current learning rate: 0.00604 
2025-06-04 10:07:09.220132: train_loss -0.7109 
2025-06-04 10:07:09.549514: val_loss -0.6849 
2025-06-04 10:07:09.565597: Pseudo dice [np.float32(0.8014)] 
2025-06-04 10:07:09.578734: Epoch time: 138.12 s 
2025-06-04 10:07:17.139536:  
2025-06-04 10:07:17.158254: Epoch 430 
2025-06-04 10:07:17.171186: Current learning rate: 0.00603 
2025-06-04 10:09:37.082981: train_loss -0.711 
2025-06-04 10:09:37.429772: val_loss -0.6558 
2025-06-04 10:09:37.780191: Pseudo dice [np.float32(0.7425)] 
2025-06-04 10:09:38.089053: Epoch time: 139.95 s 
2025-06-04 10:09:44.836530:  
2025-06-04 10:09:45.057838: Epoch 431 
2025-06-04 10:09:45.289013: Current learning rate: 0.00602 
2025-06-04 10:11:56.815952: train_loss -0.7015 
2025-06-04 10:11:56.831756: val_loss -0.562 
2025-06-04 10:11:56.847122: Pseudo dice [np.float32(0.6046)] 
2025-06-04 10:11:56.861290: Epoch time: 131.98 s 
2025-06-04 10:11:58.287712:  
2025-06-04 10:11:58.307433: Epoch 432 
2025-06-04 10:11:58.321885: Current learning rate: 0.00601 
2025-06-04 10:14:09.453270: train_loss -0.6747 
2025-06-04 10:14:09.471186: val_loss -0.7416 
2025-06-04 10:14:09.485631: Pseudo dice [np.float32(0.7838)] 
2025-06-04 10:14:09.498924: Epoch time: 131.17 s 
2025-06-04 10:14:11.498204:  
2025-06-04 10:14:11.517189: Epoch 433 
2025-06-04 10:14:11.530520: Current learning rate: 0.006 
2025-06-04 10:16:23.891183: train_loss -0.7141 
2025-06-04 10:16:23.909139: val_loss -0.6914 
2025-06-04 10:16:23.922957: Pseudo dice [np.float32(0.812)] 
2025-06-04 10:16:23.943758: Epoch time: 132.39 s 
2025-06-04 10:16:28.280142:  
2025-06-04 10:16:28.420825: Epoch 434 
2025-06-04 10:16:28.574131: Current learning rate: 0.00599 
2025-06-04 10:18:43.274395: train_loss -0.6966 
2025-06-04 10:18:43.751118: val_loss -0.7076 
2025-06-04 10:18:43.766456: Pseudo dice [np.float32(0.7695)] 
2025-06-04 10:18:44.023634: Epoch time: 135.0 s 
2025-06-04 10:18:50.063275:  
2025-06-04 10:18:50.250640: Epoch 435 
2025-06-04 10:18:50.430424: Current learning rate: 0.00598 
2025-06-04 10:21:04.039224: train_loss -0.7198 
2025-06-04 10:21:04.059693: val_loss -0.6614 
2025-06-04 10:21:04.075691: Pseudo dice [np.float32(0.8222)] 
2025-06-04 10:21:04.092349: Epoch time: 133.98 s 
2025-06-04 10:21:11.802404:  
2025-06-04 10:21:11.913749: Epoch 436 
2025-06-04 10:21:12.125889: Current learning rate: 0.00597 
2025-06-04 10:23:36.070371: train_loss -0.6941 
2025-06-04 10:23:36.090422: val_loss -0.7055 
2025-06-04 10:23:36.117125: Pseudo dice [np.float32(0.8114)] 
2025-06-04 10:23:36.137914: Epoch time: 144.27 s 
2025-06-04 10:23:43.996200:  
2025-06-04 10:23:44.013843: Epoch 437 
2025-06-04 10:23:44.027774: Current learning rate: 0.00596 
2025-06-04 10:26:18.215290: train_loss -0.7182 
2025-06-04 10:26:18.239354: val_loss -0.6056 
2025-06-04 10:26:18.254962: Pseudo dice [np.float32(0.6905)] 
2025-06-04 10:26:18.269300: Epoch time: 154.22 s 
2025-06-04 10:26:23.687716:  
2025-06-04 10:26:24.025611: Epoch 438 
2025-06-04 10:26:24.308717: Current learning rate: 0.00595 
2025-06-04 10:28:46.781215: train_loss -0.7119 
2025-06-04 10:28:47.247161: val_loss -0.6819 
2025-06-04 10:28:47.725081: Pseudo dice [np.float32(0.7475)] 
2025-06-04 10:28:48.298442: Epoch time: 143.1 s 
2025-06-04 10:28:54.481602:  
2025-06-04 10:28:54.691595: Epoch 439 
2025-06-04 10:28:54.708456: Current learning rate: 0.00594 
2025-06-04 10:31:23.571079: train_loss -0.7039 
2025-06-04 10:31:23.594800: val_loss -0.6885 
2025-06-04 10:31:23.608368: Pseudo dice [np.float32(0.715)] 
2025-06-04 10:31:23.623065: Epoch time: 149.09 s 
2025-06-04 10:31:32.122500:  
2025-06-04 10:31:32.346830: Epoch 440 
2025-06-04 10:31:32.478610: Current learning rate: 0.00593 
2025-06-04 10:33:56.961159: train_loss -0.6917 
2025-06-04 10:33:57.418680: val_loss -0.6465 
2025-06-04 10:33:57.841778: Pseudo dice [np.float32(0.7159)] 
2025-06-04 10:33:58.414147: Epoch time: 144.84 s 
2025-06-04 10:34:04.626848:  
2025-06-04 10:34:04.911311: Epoch 441 
2025-06-04 10:34:04.951527: Current learning rate: 0.00592 
2025-06-04 10:36:30.882743: train_loss -0.711 
2025-06-04 10:36:30.911100: val_loss -0.6761 
2025-06-04 10:36:30.933095: Pseudo dice [np.float32(0.7222)] 
2025-06-04 10:36:30.949676: Epoch time: 146.26 s 
2025-06-04 10:36:38.593676:  
2025-06-04 10:36:38.835587: Epoch 442 
2025-06-04 10:36:38.852223: Current learning rate: 0.00592 
2025-06-04 10:39:06.542845: train_loss -0.7428 
2025-06-04 10:39:06.998864: val_loss -0.7552 
2025-06-04 10:39:07.017671: Pseudo dice [np.float32(0.844)] 
2025-06-04 10:39:07.045511: Epoch time: 147.95 s 
2025-06-04 10:39:13.837530:  
2025-06-04 10:39:14.287187: Epoch 443 
2025-06-04 10:39:14.303501: Current learning rate: 0.00591 
2025-06-04 10:41:40.901300: train_loss -0.7083 
2025-06-04 10:41:40.923093: val_loss -0.729 
2025-06-04 10:41:40.937405: Pseudo dice [np.float32(0.805)] 
2025-06-04 10:41:40.950380: Epoch time: 147.07 s 
2025-06-04 10:41:47.610154:  
2025-06-04 10:41:48.029740: Epoch 444 
2025-06-04 10:41:48.217162: Current learning rate: 0.0059 
2025-06-04 10:44:16.781795: train_loss -0.7095 
2025-06-04 10:44:17.292454: val_loss -0.6879 
2025-06-04 10:44:17.552759: Pseudo dice [np.float32(0.8092)] 
2025-06-04 10:44:18.058640: Epoch time: 149.17 s 
2025-06-04 10:44:26.258086:  
2025-06-04 10:44:26.747483: Epoch 445 
2025-06-04 10:44:27.076141: Current learning rate: 0.00589 
2025-06-04 10:46:57.312682: train_loss -0.7227 
2025-06-04 10:46:57.743618: val_loss -0.681 
2025-06-04 10:46:57.759205: Pseudo dice [np.float32(0.8062)] 
2025-06-04 10:46:57.773057: Epoch time: 151.06 s 
2025-06-04 10:47:03.493912:  
2025-06-04 10:47:03.904182: Epoch 446 
2025-06-04 10:47:04.229034: Current learning rate: 0.00588 
2025-06-04 10:49:30.431473: train_loss -0.7106 
2025-06-04 10:49:30.726277: val_loss -0.6675 
2025-06-04 10:49:30.741618: Pseudo dice [np.float32(0.809)] 
2025-06-04 10:49:30.754373: Epoch time: 146.94 s 
2025-06-04 10:49:36.689347:  
2025-06-04 10:49:36.820976: Epoch 447 
2025-06-04 10:49:37.052718: Current learning rate: 0.00587 
2025-06-04 10:52:03.859613: train_loss -0.7034 
2025-06-04 10:52:03.883080: val_loss -0.6867 
2025-06-04 10:52:03.897526: Pseudo dice [np.float32(0.6725)] 
2025-06-04 10:52:03.911843: Epoch time: 147.17 s 
2025-06-04 10:52:09.367408:  
2025-06-04 10:52:09.694832: Epoch 448 
2025-06-04 10:52:09.979656: Current learning rate: 0.00586 
2025-06-04 10:54:37.140166: train_loss -0.718 
2025-06-04 10:54:37.597779: val_loss -0.6843 
2025-06-04 10:54:38.123713: Pseudo dice [np.float32(0.8115)] 
2025-06-04 10:54:38.491498: Epoch time: 147.78 s 
2025-06-04 10:54:45.816169:  
2025-06-04 10:54:45.841045: Epoch 449 
2025-06-04 10:54:45.860838: Current learning rate: 0.00585 
2025-06-04 10:57:09.436255: train_loss -0.6955 
2025-06-04 10:57:09.751888: val_loss -0.7477 
2025-06-04 10:57:09.767537: Pseudo dice [np.float32(0.8003)] 
2025-06-04 10:57:09.781169: Epoch time: 143.77 s 
2025-06-04 10:57:22.181095:  
2025-06-04 10:57:22.554617: Epoch 450 
2025-06-04 10:57:22.884822: Current learning rate: 0.00584 
2025-06-04 10:59:54.999002: train_loss -0.7018 
2025-06-04 10:59:55.455987: val_loss -0.6974 
2025-06-04 10:59:55.845490: Pseudo dice [np.float32(0.7427)] 
2025-06-04 10:59:56.315909: Epoch time: 152.82 s 
2025-06-04 11:00:01.516402:  
2025-06-04 11:00:01.544502: Epoch 451 
2025-06-04 11:00:01.618953: Current learning rate: 0.00583 
2025-06-04 11:02:30.131977: train_loss -0.7078 
2025-06-04 11:02:30.403046: val_loss -0.6697 
2025-06-04 11:02:30.649984: Pseudo dice [np.float32(0.7324)] 
2025-06-04 11:02:30.826135: Epoch time: 148.62 s 
2025-06-04 11:02:37.116836:  
2025-06-04 11:02:37.377095: Epoch 452 
2025-06-04 11:02:37.393167: Current learning rate: 0.00582 
2025-06-04 11:04:59.349465: train_loss -0.7113 
2025-06-04 11:04:59.698410: val_loss -0.6694 
2025-06-04 11:04:59.715717: Pseudo dice [np.float32(0.7489)] 
2025-06-04 11:04:59.730436: Epoch time: 142.23 s 
2025-06-04 11:05:05.943057:  
2025-06-04 11:05:05.960659: Epoch 453 
2025-06-04 11:05:05.975056: Current learning rate: 0.00581 
2025-06-04 11:07:28.455126: train_loss -0.7065 
2025-06-04 11:07:28.473013: val_loss -0.6408 
2025-06-04 11:07:28.485620: Pseudo dice [np.float32(0.7545)] 
2025-06-04 11:07:28.528306: Epoch time: 142.51 s 
2025-06-04 11:07:32.473482:  
2025-06-04 11:07:32.694762: Epoch 454 
2025-06-04 11:07:32.957812: Current learning rate: 0.0058 
2025-06-04 11:09:58.188541: train_loss -0.714 
2025-06-04 11:09:58.209643: val_loss -0.6774 
2025-06-04 11:09:58.239828: Pseudo dice [np.float32(0.7857)] 
2025-06-04 11:09:58.253743: Epoch time: 145.72 s 
2025-06-04 11:10:06.147033:  
2025-06-04 11:10:06.349708: Epoch 455 
2025-06-04 11:10:06.364962: Current learning rate: 0.00579 
2025-06-04 11:12:31.795625: train_loss -0.722 
2025-06-04 11:12:32.154061: val_loss -0.7158 
2025-06-04 11:12:32.660265: Pseudo dice [np.float32(0.807)] 
2025-06-04 11:12:32.841491: Epoch time: 145.65 s 
2025-06-04 11:12:40.543766:  
2025-06-04 11:12:40.569722: Epoch 456 
2025-06-04 11:12:40.590846: Current learning rate: 0.00578 
2025-06-04 11:15:06.546727: train_loss -0.6897 
2025-06-04 11:15:06.566631: val_loss -0.6416 
2025-06-04 11:15:06.583235: Pseudo dice [np.float32(0.7077)] 
2025-06-04 11:15:06.598679: Epoch time: 146.01 s 
2025-06-04 11:15:13.901474:  
2025-06-04 11:15:14.180599: Epoch 457 
2025-06-04 11:15:14.391228: Current learning rate: 0.00577 
2025-06-04 11:17:34.035765: train_loss -0.6915 
2025-06-04 11:17:34.054187: val_loss -0.692 
2025-06-04 11:17:34.067294: Pseudo dice [np.float32(0.7638)] 
2025-06-04 11:17:34.079832: Epoch time: 140.14 s 
2025-06-04 11:17:39.157303:  
2025-06-04 11:17:39.400936: Epoch 458 
2025-06-04 11:17:39.659363: Current learning rate: 0.00576 
2025-06-04 11:19:56.082192: train_loss -0.7056 
2025-06-04 11:19:56.101138: val_loss -0.7013 
2025-06-04 11:19:56.114821: Pseudo dice [np.float32(0.695)] 
2025-06-04 11:19:56.127969: Epoch time: 136.93 s 
2025-06-04 11:20:01.890895:  
2025-06-04 11:20:02.227235: Epoch 459 
2025-06-04 11:20:02.591961: Current learning rate: 0.00575 
2025-06-04 11:22:25.683387: train_loss -0.7058 
2025-06-04 11:22:25.906559: val_loss -0.6566 
2025-06-04 11:22:25.920446: Pseudo dice [np.float32(0.7146)] 
2025-06-04 11:22:25.932331: Epoch time: 143.8 s 
2025-06-04 11:22:35.448835:  
2025-06-04 11:22:35.937197: Epoch 460 
2025-06-04 11:22:36.249745: Current learning rate: 0.00574 
2025-06-04 11:25:09.311484: train_loss -0.7101 
2025-06-04 11:25:09.336786: val_loss -0.7008 
2025-06-04 11:25:09.351091: Pseudo dice [np.float32(0.7728)] 
2025-06-04 11:25:09.368337: Epoch time: 153.87 s 
2025-06-04 11:25:17.001549:  
2025-06-04 11:25:17.398906: Epoch 461 
2025-06-04 11:25:17.416247: Current learning rate: 0.00573 
2025-06-04 11:27:46.247006: train_loss -0.6989 
2025-06-04 11:27:46.786948: val_loss -0.6594 
2025-06-04 11:27:47.400134: Pseudo dice [np.float32(0.7416)] 
2025-06-04 11:27:47.594296: Epoch time: 149.25 s 
2025-06-04 11:27:55.908230:  
2025-06-04 11:27:56.088701: Epoch 462 
2025-06-04 11:27:56.244665: Current learning rate: 0.00572 
2025-06-04 11:30:20.640197: train_loss -0.6757 
2025-06-04 11:30:20.661494: val_loss -0.6786 
2025-06-04 11:30:20.675333: Pseudo dice [np.float32(0.8109)] 
2025-06-04 11:30:20.688407: Epoch time: 144.73 s 
2025-06-04 11:30:25.512912:  
2025-06-04 11:30:25.798087: Epoch 463 
2025-06-04 11:30:25.813339: Current learning rate: 0.00571 
2025-06-04 11:32:56.134336: train_loss -0.7291 
2025-06-04 11:32:56.775312: val_loss -0.7007 
2025-06-04 11:32:57.270995: Pseudo dice [np.float32(0.8239)] 
2025-06-04 11:32:57.775604: Epoch time: 150.62 s 
2025-06-04 11:33:04.789407:  
2025-06-04 11:33:05.062763: Epoch 464 
2025-06-04 11:33:05.459214: Current learning rate: 0.0057 
2025-06-04 11:35:25.709208: train_loss -0.7054 
2025-06-04 11:35:25.727787: val_loss -0.6398 
2025-06-04 11:35:25.741739: Pseudo dice [np.float32(0.7274)] 
2025-06-04 11:35:25.755243: Epoch time: 140.92 s 
2025-06-04 11:35:31.670007:  
2025-06-04 11:35:31.786947: Epoch 465 
2025-06-04 11:35:31.893502: Current learning rate: 0.0057 
2025-06-04 11:37:41.932571: train_loss -0.7123 
2025-06-04 11:37:41.956088: val_loss -0.6672 
2025-06-04 11:37:41.970102: Pseudo dice [np.float32(0.7477)] 
2025-06-04 11:37:41.983468: Epoch time: 130.27 s 
2025-06-04 11:37:49.362032:  
2025-06-04 11:37:49.381467: Epoch 466 
2025-06-04 11:37:49.395731: Current learning rate: 0.00569 
2025-06-04 11:40:05.615618: train_loss -0.7189 
2025-06-04 11:40:05.967525: val_loss -0.6929 
2025-06-04 11:40:05.982642: Pseudo dice [np.float32(0.7813)] 
2025-06-04 11:40:05.996288: Epoch time: 136.26 s 
2025-06-04 11:40:12.878372:  
2025-06-04 11:40:12.895523: Epoch 467 
2025-06-04 11:40:12.909667: Current learning rate: 0.00568 
2025-06-04 11:42:40.375238: train_loss -0.7149 
2025-06-04 11:42:40.397763: val_loss -0.6438 
2025-06-04 11:42:40.414539: Pseudo dice [np.float32(0.7155)] 
2025-06-04 11:42:40.432452: Epoch time: 147.5 s 
2025-06-04 11:42:47.636305:  
2025-06-04 11:42:47.990918: Epoch 468 
2025-06-04 11:42:48.285194: Current learning rate: 0.00567 
2025-06-04 11:45:18.277869: train_loss -0.6876 
2025-06-04 11:45:18.300142: val_loss -0.6471 
2025-06-04 11:45:18.312678: Pseudo dice [np.float32(0.7911)] 
2025-06-04 11:45:18.326614: Epoch time: 150.64 s 
2025-06-04 11:45:25.303971:  
2025-06-04 11:45:25.739439: Epoch 469 
2025-06-04 11:45:26.112719: Current learning rate: 0.00566 
2025-06-04 11:47:50.953159: train_loss -0.6994 
2025-06-04 11:47:51.302600: val_loss -0.6905 
2025-06-04 11:47:51.914459: Pseudo dice [np.float32(0.7568)] 
2025-06-04 11:47:52.316583: Epoch time: 145.65 s 
2025-06-04 11:47:58.480011:  
2025-06-04 11:47:58.498975: Epoch 470 
2025-06-04 11:47:58.512446: Current learning rate: 0.00565 
2025-06-04 11:50:27.383876: train_loss -0.6661 
2025-06-04 11:50:27.866697: val_loss -0.7094 
2025-06-04 11:50:28.243971: Pseudo dice [np.float32(0.8024)] 
2025-06-04 11:50:28.414629: Epoch time: 148.91 s 
2025-06-04 11:50:35.550009:  
2025-06-04 11:50:35.822632: Epoch 471 
2025-06-04 11:50:36.171077: Current learning rate: 0.00564 
2025-06-04 11:53:03.638607: train_loss -0.7226 
2025-06-04 11:53:03.995581: val_loss -0.6457 
2025-06-04 11:53:04.429569: Pseudo dice [np.float32(0.7211)] 
2025-06-04 11:53:04.735644: Epoch time: 148.09 s 
2025-06-04 11:53:10.063321:  
2025-06-04 11:53:10.231023: Epoch 472 
2025-06-04 11:53:10.389191: Current learning rate: 0.00563 
2025-06-04 11:55:37.031512: train_loss -0.7032 
2025-06-04 11:55:37.434877: val_loss -0.714 
2025-06-04 11:55:37.450644: Pseudo dice [np.float32(0.83)] 
2025-06-04 11:55:37.464889: Epoch time: 146.97 s 
2025-06-04 11:55:45.859276:  
2025-06-04 11:55:46.236667: Epoch 473 
2025-06-04 11:55:46.606734: Current learning rate: 0.00562 
2025-06-04 11:58:14.191073: train_loss -0.7097 
2025-06-04 11:58:14.475203: val_loss -0.6967 
2025-06-04 11:58:14.910490: Pseudo dice [np.float32(0.7789)] 
2025-06-04 11:58:15.413585: Epoch time: 148.33 s 
2025-06-04 11:58:23.688444:  
2025-06-04 11:58:24.060094: Epoch 474 
2025-06-04 11:58:24.413862: Current learning rate: 0.00561 
2025-06-04 12:00:52.610975: train_loss -0.6992 
2025-06-04 12:00:52.869112: val_loss -0.7119 
2025-06-04 12:00:52.882252: Pseudo dice [np.float32(0.7838)] 
2025-06-04 12:00:52.895932: Epoch time: 148.93 s 
2025-06-04 12:00:57.437529:  
2025-06-04 12:00:57.450126: Epoch 475 
2025-06-04 12:00:57.462334: Current learning rate: 0.0056 
2025-06-04 12:03:24.346876: train_loss -0.7287 
2025-06-04 12:03:24.363700: val_loss -0.7009 
2025-06-04 12:03:24.377467: Pseudo dice [np.float32(0.7488)] 
2025-06-04 12:03:24.390347: Epoch time: 146.91 s 
2025-06-04 12:03:27.554278:  
2025-06-04 12:03:27.802741: Epoch 476 
2025-06-04 12:03:27.988509: Current learning rate: 0.00559 
2025-06-04 12:05:58.626879: train_loss -0.7162 
2025-06-04 12:05:58.645360: val_loss -0.6436 
2025-06-04 12:05:58.658945: Pseudo dice [np.float32(0.6976)] 
2025-06-04 12:05:58.671094: Epoch time: 151.07 s 
2025-06-04 12:06:02.243877:  
2025-06-04 12:06:02.414362: Epoch 477 
2025-06-04 12:06:02.588400: Current learning rate: 0.00558 
2025-06-04 12:08:26.502814: train_loss -0.7005 
2025-06-04 12:08:26.724044: val_loss -0.6738 
2025-06-04 12:08:26.740128: Pseudo dice [np.float32(0.7926)] 
2025-06-04 12:08:26.755089: Epoch time: 144.26 s 
2025-06-04 12:08:32.697940:  
2025-06-04 12:08:32.938717: Epoch 478 
2025-06-04 12:08:33.356902: Current learning rate: 0.00557 
2025-06-04 12:10:55.510739: train_loss -0.7262 
2025-06-04 12:10:55.922763: val_loss -0.7003 
2025-06-04 12:10:56.116849: Pseudo dice [np.float32(0.8071)] 
2025-06-04 12:10:56.148246: Epoch time: 142.81 s 
2025-06-04 12:11:02.951940:  
2025-06-04 12:11:02.986714: Epoch 479 
2025-06-04 12:11:03.194668: Current learning rate: 0.00556 
2025-06-04 12:13:30.764738: train_loss -0.7252 
2025-06-04 12:13:30.783914: val_loss -0.6834 
2025-06-04 12:13:30.797041: Pseudo dice [np.float32(0.7346)] 
2025-06-04 12:13:30.809535: Epoch time: 147.82 s 
2025-06-04 12:13:36.960248:  
2025-06-04 12:13:37.491585: Epoch 480 
2025-06-04 12:13:37.514105: Current learning rate: 0.00555 
2025-06-04 12:15:59.608185: train_loss -0.7224 
2025-06-04 12:15:59.623328: val_loss -0.7038 
2025-06-04 12:15:59.637005: Pseudo dice [np.float32(0.7966)] 
2025-06-04 12:15:59.649827: Epoch time: 142.65 s 
2025-06-04 12:16:06.867079:  
2025-06-04 12:16:07.732194: Epoch 481 
2025-06-04 12:16:07.747531: Current learning rate: 0.00554 
2025-06-04 12:18:28.478943: train_loss -0.6911 
2025-06-04 12:18:28.702499: val_loss -0.6865 
2025-06-04 12:18:28.718390: Pseudo dice [np.float32(0.7302)] 
2025-06-04 12:18:28.735269: Epoch time: 141.61 s 
2025-06-04 12:18:35.866374:  
2025-06-04 12:18:35.936651: Epoch 482 
2025-06-04 12:18:36.067227: Current learning rate: 0.00553 
2025-06-04 12:21:00.476794: train_loss -0.71 
2025-06-04 12:21:00.505056: val_loss -0.6401 
2025-06-04 12:21:00.525770: Pseudo dice [np.float32(0.7279)] 
2025-06-04 12:21:00.549318: Epoch time: 144.61 s 
2025-06-04 12:21:10.535962:  
2025-06-04 12:21:10.785870: Epoch 483 
2025-06-04 12:21:11.220620: Current learning rate: 0.00552 
2025-06-04 12:23:35.426176: train_loss -0.7147 
2025-06-04 12:23:35.441763: val_loss -0.6656 
2025-06-04 12:23:35.455838: Pseudo dice [np.float32(0.787)] 
2025-06-04 12:23:35.469475: Epoch time: 144.89 s 
2025-06-04 12:23:41.862687:  
2025-06-04 12:23:42.137631: Epoch 484 
2025-06-04 12:23:42.487250: Current learning rate: 0.00551 
2025-06-04 12:26:09.438162: train_loss -0.7214 
2025-06-04 12:26:09.916674: val_loss -0.6719 
2025-06-04 12:26:09.936686: Pseudo dice [np.float32(0.7579)] 
2025-06-04 12:26:09.958215: Epoch time: 147.58 s 
2025-06-04 12:26:14.728344:  
2025-06-04 12:26:15.017449: Epoch 485 
2025-06-04 12:26:15.181653: Current learning rate: 0.0055 
2025-06-04 12:28:39.763230: train_loss -0.6923 
2025-06-04 12:28:40.241898: val_loss -0.6856 
2025-06-04 12:28:40.726414: Pseudo dice [np.float32(0.7855)] 
2025-06-04 12:28:41.334288: Epoch time: 145.04 s 
2025-06-04 12:28:48.796521:  
2025-06-04 12:28:48.964348: Epoch 486 
2025-06-04 12:28:49.209578: Current learning rate: 0.00549 
2025-06-04 12:31:18.813851: train_loss -0.7303 
2025-06-04 12:31:18.941888: val_loss -0.7486 
2025-06-04 12:31:18.955491: Pseudo dice [np.float32(0.8787)] 
2025-06-04 12:31:18.969831: Epoch time: 150.02 s 
2025-06-04 12:31:25.131674:  
2025-06-04 12:31:25.170822: Epoch 487 
2025-06-04 12:31:25.211879: Current learning rate: 0.00548 
2025-06-04 12:33:49.000820: train_loss -0.7335 
2025-06-04 12:33:49.403841: val_loss -0.75 
2025-06-04 12:33:49.420737: Pseudo dice [np.float32(0.7918)] 
2025-06-04 12:33:49.434636: Epoch time: 143.87 s 
2025-06-04 12:33:56.366732:  
2025-06-04 12:33:56.504503: Epoch 488 
2025-06-04 12:33:56.519848: Current learning rate: 0.00547 
2025-06-04 12:36:22.588550: train_loss -0.7202 
2025-06-04 12:36:22.821374: val_loss -0.6593 
2025-06-04 12:36:23.384822: Pseudo dice [np.float32(0.7149)] 
2025-06-04 12:36:23.910525: Epoch time: 146.22 s 
2025-06-04 12:36:30.769190:  
2025-06-04 12:36:31.187114: Epoch 489 
2025-06-04 12:36:31.507905: Current learning rate: 0.00546 
2025-06-04 12:38:55.469492: train_loss -0.7134 
2025-06-04 12:38:55.822688: val_loss -0.6858 
2025-06-04 12:38:56.113989: Pseudo dice [np.float32(0.7514)] 
2025-06-04 12:38:56.129534: Epoch time: 144.7 s 
2025-06-04 12:39:04.529013:  
2025-06-04 12:39:04.730169: Epoch 490 
2025-06-04 12:39:04.745520: Current learning rate: 0.00546 
2025-06-04 12:41:30.307653: train_loss -0.7055 
2025-06-04 12:41:30.585776: val_loss -0.6633 
2025-06-04 12:41:30.741895: Pseudo dice [np.float32(0.8206)] 
2025-06-04 12:41:30.775148: Epoch time: 145.78 s 
2025-06-04 12:41:39.690477:  
2025-06-04 12:41:39.923667: Epoch 491 
2025-06-04 12:41:40.144974: Current learning rate: 0.00545 
2025-06-04 12:44:08.281784: train_loss -0.6841 
2025-06-04 12:44:08.768820: val_loss -0.6747 
2025-06-04 12:44:08.787521: Pseudo dice [np.float32(0.7293)] 
2025-06-04 12:44:08.802348: Epoch time: 148.59 s 
2025-06-04 12:44:14.360281:  
2025-06-04 12:44:14.725581: Epoch 492 
2025-06-04 12:44:15.058662: Current learning rate: 0.00544 
2025-06-04 12:46:43.206460: train_loss -0.6884 
2025-06-04 12:46:43.225035: val_loss -0.692 
2025-06-04 12:46:43.238051: Pseudo dice [np.float32(0.7147)] 
2025-06-04 12:46:43.251869: Epoch time: 148.85 s 
2025-06-04 12:46:52.259380:  
2025-06-04 12:46:52.276902: Epoch 493 
2025-06-04 12:46:52.290487: Current learning rate: 0.00543 
2025-06-04 12:49:24.135573: train_loss -0.6957 
2025-06-04 12:49:24.154108: val_loss -0.6742 
2025-06-04 12:49:24.166934: Pseudo dice [np.float32(0.7505)] 
2025-06-04 12:49:24.179920: Epoch time: 151.88 s 
2025-06-04 12:49:33.481270:  
2025-06-04 12:49:33.907778: Epoch 494 
2025-06-04 12:49:34.373069: Current learning rate: 0.00542 
2025-06-04 12:52:01.625923: train_loss -0.7071 
2025-06-04 12:52:02.166794: val_loss -0.6589 
2025-06-04 12:52:02.697771: Pseudo dice [np.float32(0.7252)] 
2025-06-04 12:52:03.203761: Epoch time: 148.15 s 
2025-06-04 12:52:10.478426:  
2025-06-04 12:52:10.643233: Epoch 495 
2025-06-04 12:52:10.892807: Current learning rate: 0.00541 
2025-06-04 12:54:34.300344: train_loss -0.6916 
2025-06-04 12:54:34.321474: val_loss -0.6993 
2025-06-04 12:54:34.334391: Pseudo dice [np.float32(0.6823)] 
2025-06-04 12:54:34.346816: Epoch time: 143.82 s 
2025-06-04 12:54:41.207069:  
2025-06-04 12:54:41.438816: Epoch 496 
2025-06-04 12:54:41.725425: Current learning rate: 0.0054 
2025-06-04 12:57:05.495681: train_loss -0.7281 
2025-06-04 12:57:06.038935: val_loss -0.7208 
2025-06-04 12:57:06.600664: Pseudo dice [np.float32(0.8068)] 
2025-06-04 12:57:06.618332: Epoch time: 144.29 s 
2025-06-04 12:57:14.828802:  
2025-06-04 12:57:14.853276: Epoch 497 
2025-06-04 12:57:14.873243: Current learning rate: 0.00539 
2025-06-04 12:59:42.438005: train_loss -0.6625 
2025-06-04 12:59:42.907956: val_loss -0.7137 
2025-06-04 12:59:43.410821: Pseudo dice [np.float32(0.8219)] 
2025-06-04 12:59:43.966684: Epoch time: 147.61 s 
2025-06-04 12:59:49.404439:  
2025-06-04 12:59:49.914211: Epoch 498 
2025-06-04 12:59:50.066497: Current learning rate: 0.00538 
2025-06-04 13:02:19.191275: train_loss -0.7132 
2025-06-04 13:02:19.214279: val_loss -0.6838 
2025-06-04 13:02:19.228272: Pseudo dice [np.float32(0.7995)] 
2025-06-04 13:02:19.242237: Epoch time: 149.79 s 
2025-06-04 13:02:26.485511:  
2025-06-04 13:02:26.930512: Epoch 499 
2025-06-04 13:02:27.269387: Current learning rate: 0.00537 
2025-06-04 13:04:53.231599: train_loss -0.7194 
2025-06-04 13:04:53.255376: val_loss -0.6178 
2025-06-04 13:04:53.270160: Pseudo dice [np.float32(0.6567)] 
2025-06-04 13:04:53.286539: Epoch time: 146.75 s 
2025-06-04 13:05:01.580196:  
2025-06-04 13:05:01.913215: Epoch 500 
2025-06-04 13:05:02.194842: Current learning rate: 0.00536 
2025-06-04 13:07:28.395196: train_loss -0.7007 
2025-06-04 13:07:28.823266: val_loss -0.7107 
2025-06-04 13:07:29.252497: Pseudo dice [np.float32(0.8079)] 
2025-06-04 13:07:29.771141: Epoch time: 146.82 s 
2025-06-04 13:07:32.357270:  
2025-06-04 13:07:32.377287: Epoch 501 
2025-06-04 13:07:32.395222: Current learning rate: 0.00535 
2025-06-04 13:10:02.489958: train_loss -0.7063 
2025-06-04 13:10:02.793461: val_loss -0.6896 
2025-06-04 13:10:02.813428: Pseudo dice [np.float32(0.7705)] 
2025-06-04 13:10:02.829047: Epoch time: 150.13 s 
2025-06-04 13:10:07.965878:  
2025-06-04 13:10:08.119766: Epoch 502 
2025-06-04 13:10:08.321501: Current learning rate: 0.00534 
2025-06-04 13:12:31.299667: train_loss -0.7266 
2025-06-04 13:12:31.317348: val_loss -0.6263 
2025-06-04 13:12:31.331162: Pseudo dice [np.float32(0.7736)] 
2025-06-04 13:12:31.347524: Epoch time: 143.34 s 
2025-06-04 13:12:39.076271:  
2025-06-04 13:12:39.093562: Epoch 503 
2025-06-04 13:12:39.109384: Current learning rate: 0.00533 
2025-06-04 13:15:02.841299: train_loss -0.6852 
2025-06-04 13:15:03.303230: val_loss -0.7055 
2025-06-04 13:15:03.651305: Pseudo dice [np.float32(0.8413)] 
2025-06-04 13:15:03.665617: Epoch time: 143.77 s 
2025-06-04 13:15:11.664187:  
2025-06-04 13:15:11.845914: Epoch 504 
2025-06-04 13:15:12.096083: Current learning rate: 0.00532 
2025-06-04 13:17:33.422299: train_loss -0.6911 
2025-06-04 13:17:33.867916: val_loss -0.6886 
2025-06-04 13:17:34.362461: Pseudo dice [np.float32(0.763)] 
2025-06-04 13:17:34.560127: Epoch time: 141.76 s 
2025-06-04 13:17:41.702309:  
2025-06-04 13:17:41.719983: Epoch 505 
2025-06-04 13:17:41.732632: Current learning rate: 0.00531 
2025-06-04 13:20:04.126061: train_loss -0.7161 
2025-06-04 13:20:04.143823: val_loss -0.6828 
2025-06-04 13:20:04.157911: Pseudo dice [np.float32(0.7366)] 
2025-06-04 13:20:04.171318: Epoch time: 142.49 s 
2025-06-04 13:20:12.466320:  
2025-06-04 13:20:12.636491: Epoch 506 
2025-06-04 13:20:12.757716: Current learning rate: 0.0053 
2025-06-04 13:22:31.988716: train_loss -0.6828 
2025-06-04 13:22:32.137514: val_loss -0.6576 
2025-06-04 13:22:32.158318: Pseudo dice [np.float32(0.7824)] 
2025-06-04 13:22:32.171118: Epoch time: 139.52 s 
2025-06-04 13:22:39.048012:  
2025-06-04 13:22:39.478459: Epoch 507 
2025-06-04 13:22:39.871175: Current learning rate: 0.00529 
2025-06-04 13:25:00.908075: train_loss -0.7216 
2025-06-04 13:25:01.251650: val_loss -0.6985 
2025-06-04 13:25:02.025696: Pseudo dice [np.float32(0.7726)] 
2025-06-04 13:25:02.250504: Epoch time: 141.86 s 
2025-06-04 13:25:06.696499:  
2025-06-04 13:25:07.026068: Epoch 508 
2025-06-04 13:25:07.343421: Current learning rate: 0.00528 
2025-06-04 13:27:29.362100: train_loss -0.73 
2025-06-04 13:27:29.479870: val_loss -0.708 
2025-06-04 13:27:29.496161: Pseudo dice [np.float32(0.8204)] 
2025-06-04 13:27:29.512986: Epoch time: 142.67 s 
2025-06-04 13:27:36.783540:  
2025-06-04 13:27:36.927380: Epoch 509 
2025-06-04 13:27:37.128965: Current learning rate: 0.00527 
2025-06-04 13:29:59.592336: train_loss -0.7086 
2025-06-04 13:30:00.048710: val_loss -0.7458 
2025-06-04 13:30:00.477382: Pseudo dice [np.float32(0.8468)] 
2025-06-04 13:30:00.753201: Epoch time: 142.81 s 
2025-06-04 13:30:00.771164: Yayy! New best EMA pseudo Dice: 0.7814000248908997 
2025-06-04 13:30:09.326352:  
2025-06-04 13:30:09.742535: Epoch 510 
2025-06-04 13:30:10.160207: Current learning rate: 0.00526 
2025-06-04 13:32:32.096202: train_loss -0.7348 
2025-06-04 13:32:32.463933: val_loss -0.7008 
2025-06-04 13:32:32.749748: Pseudo dice [np.float32(0.8233)] 
2025-06-04 13:32:32.765038: Epoch time: 142.77 s 
2025-06-04 13:32:32.779896: Yayy! New best EMA pseudo Dice: 0.7856000065803528 
2025-06-04 13:32:38.795147:  
2025-06-04 13:32:38.939541: Epoch 511 
2025-06-04 13:32:38.953686: Current learning rate: 0.00525 
2025-06-04 13:35:04.070983: train_loss -0.6941 
2025-06-04 13:35:04.168738: val_loss -0.6905 
2025-06-04 13:35:04.279406: Pseudo dice [np.float32(0.7902)] 
2025-06-04 13:35:04.295832: Epoch time: 145.28 s 
2025-06-04 13:35:04.310012: Yayy! New best EMA pseudo Dice: 0.7860000133514404 
2025-06-04 13:35:11.621942:  
2025-06-04 13:35:11.871633: Epoch 512 
2025-06-04 13:35:12.143933: Current learning rate: 0.00524 
2025-06-04 13:37:39.821066: train_loss -0.6836 
2025-06-04 13:37:39.843287: val_loss -0.7014 
2025-06-04 13:37:39.859833: Pseudo dice [np.float32(0.8025)] 
2025-06-04 13:37:39.876305: Epoch time: 148.2 s 
2025-06-04 13:37:39.892758: Yayy! New best EMA pseudo Dice: 0.7876999974250793 
2025-06-04 13:37:54.205708:  
2025-06-04 13:37:54.867901: Epoch 513 
2025-06-04 13:37:55.134003: Current learning rate: 0.00523 
2025-06-04 13:40:19.323160: train_loss -0.7184 
2025-06-04 13:40:19.791675: val_loss -0.6628 
2025-06-04 13:40:20.331865: Pseudo dice [np.float32(0.7792)] 
2025-06-04 13:40:20.693948: Epoch time: 145.12 s 
2025-06-04 13:40:29.020650:  
2025-06-04 13:40:29.577057: Epoch 514 
2025-06-04 13:40:29.851182: Current learning rate: 0.00522 
2025-06-04 13:42:57.460031: train_loss -0.6963 
2025-06-04 13:42:58.053093: val_loss -0.7014 
2025-06-04 13:42:58.657728: Pseudo dice [np.float32(0.8384)] 
2025-06-04 13:42:59.205952: Epoch time: 148.44 s 
2025-06-04 13:42:59.584606: Yayy! New best EMA pseudo Dice: 0.7919999957084656 
2025-06-04 13:43:08.517720:  
2025-06-04 13:43:08.652808: Epoch 515 
2025-06-04 13:43:08.669992: Current learning rate: 0.00521 
2025-06-04 13:45:41.124968: train_loss -0.6805 
2025-06-04 13:45:41.221529: val_loss -0.6997 
2025-06-04 13:45:41.241251: Pseudo dice [np.float32(0.8181)] 
2025-06-04 13:45:41.314567: Epoch time: 152.61 s 
2025-06-04 13:45:41.332598: Yayy! New best EMA pseudo Dice: 0.7946000099182129 
2025-06-04 13:45:50.372462:  
2025-06-04 13:45:50.662858: Epoch 516 
2025-06-04 13:45:50.791223: Current learning rate: 0.0052 
2025-06-04 13:48:21.437518: train_loss -0.6955 
2025-06-04 13:48:21.754304: val_loss -0.6624 
2025-06-04 13:48:22.379584: Pseudo dice [np.float32(0.7563)] 
2025-06-04 13:48:22.753106: Epoch time: 151.07 s 
2025-06-04 13:48:28.772544:  
2025-06-04 13:48:29.188841: Epoch 517 
2025-06-04 13:48:29.311095: Current learning rate: 0.00519 
2025-06-04 13:50:52.650146: train_loss -0.7025 
2025-06-04 13:50:52.669070: val_loss -0.6904 
2025-06-04 13:50:52.687416: Pseudo dice [np.float32(0.8056)] 
2025-06-04 13:50:52.703037: Epoch time: 143.88 s 
2025-06-04 13:50:58.276598:  
2025-06-04 13:50:58.514463: Epoch 518 
2025-06-04 13:50:58.529662: Current learning rate: 0.00518 
2025-06-04 13:53:26.947929: train_loss -0.732 
2025-06-04 13:53:26.970577: val_loss -0.743 
2025-06-04 13:53:26.985291: Pseudo dice [np.float32(0.8413)] 
2025-06-04 13:53:26.999222: Epoch time: 148.67 s 
2025-06-04 13:53:27.011837: Yayy! New best EMA pseudo Dice: 0.7972000241279602 
2025-06-04 13:53:33.857371:  
2025-06-04 13:53:33.995833: Epoch 519 
2025-06-04 13:53:34.186913: Current learning rate: 0.00518 
2025-06-04 13:55:55.261081: train_loss -0.7122 
2025-06-04 13:55:55.285883: val_loss -0.6705 
2025-06-04 13:55:55.303912: Pseudo dice [np.float32(0.7629)] 
2025-06-04 13:55:55.317058: Epoch time: 141.41 s 
2025-06-04 13:56:02.656611:  
2025-06-04 13:56:02.990391: Epoch 520 
2025-06-04 13:56:03.365973: Current learning rate: 0.00517 
2025-06-04 13:58:33.521044: train_loss -0.6874 
2025-06-04 13:58:33.983886: val_loss -0.6848 
2025-06-04 13:58:34.249371: Pseudo dice [np.float32(0.6701)] 
2025-06-04 13:58:34.596626: Epoch time: 150.87 s 
2025-06-04 13:58:39.950957:  
2025-06-04 13:58:40.089309: Epoch 521 
2025-06-04 13:58:40.262205: Current learning rate: 0.00516 
2025-06-04 14:01:10.375725: train_loss -0.6942 
2025-06-04 14:01:10.756195: val_loss -0.6792 
2025-06-04 14:01:11.031691: Pseudo dice [np.float32(0.7646)] 
2025-06-04 14:01:11.051952: Epoch time: 150.43 s 
2025-06-04 14:01:18.490375:  
2025-06-04 14:01:18.859200: Epoch 522 
2025-06-04 14:01:18.887450: Current learning rate: 0.00515 
2025-06-04 14:03:46.877095: train_loss -0.7171 
2025-06-04 14:03:47.167932: val_loss -0.622 
2025-06-04 14:03:47.779736: Pseudo dice [np.float32(0.7429)] 
2025-06-04 14:03:47.797537: Epoch time: 148.39 s 
2025-06-04 14:03:53.685689:  
2025-06-04 14:03:53.808181: Epoch 523 
2025-06-04 14:03:53.841963: Current learning rate: 0.00514 
2025-06-04 14:06:24.510440: train_loss -0.7033 
2025-06-04 14:06:25.000480: val_loss -0.6847 
2025-06-04 14:06:25.478679: Pseudo dice [np.float32(0.7793)] 
2025-06-04 14:06:25.494028: Epoch time: 150.83 s 
2025-06-04 14:06:34.604587:  
2025-06-04 14:06:35.197175: Epoch 524 
2025-06-04 14:06:35.639634: Current learning rate: 0.00513 
2025-06-04 14:09:02.404609: train_loss -0.7312 
2025-06-04 14:09:02.427884: val_loss -0.688 
2025-06-04 14:09:02.441182: Pseudo dice [np.float32(0.8189)] 
2025-06-04 14:09:02.453814: Epoch time: 147.8 s 
2025-06-04 14:09:10.344952:  
2025-06-04 14:09:10.697992: Epoch 525 
2025-06-04 14:09:10.825932: Current learning rate: 0.00512 
2025-06-04 14:11:32.541033: train_loss -0.7052 
2025-06-04 14:11:32.564684: val_loss -0.7338 
2025-06-04 14:11:32.579937: Pseudo dice [np.float32(0.832)] 
2025-06-04 14:11:32.595562: Epoch time: 142.2 s 
2025-06-04 14:11:42.088167:  
2025-06-04 14:11:42.401634: Epoch 526 
2025-06-04 14:11:42.734935: Current learning rate: 0.00511 
2025-06-04 14:14:04.352915: train_loss -0.7235 
2025-06-04 14:14:04.564536: val_loss -0.6863 
2025-06-04 14:14:04.598178: Pseudo dice [np.float32(0.7259)] 
2025-06-04 14:14:04.630366: Epoch time: 142.27 s 
2025-06-04 14:14:11.395581:  
2025-06-04 14:14:11.666276: Epoch 527 
2025-06-04 14:14:11.924528: Current learning rate: 0.0051 
2025-06-04 14:16:36.685711: train_loss -0.7052 
2025-06-04 14:16:36.841928: val_loss -0.7132 
2025-06-04 14:16:37.050164: Pseudo dice [np.float32(0.7986)] 
2025-06-04 14:16:37.439809: Epoch time: 145.29 s 
2025-06-04 14:16:41.230268:  
2025-06-04 14:16:41.246603: Epoch 528 
2025-06-04 14:16:41.260649: Current learning rate: 0.00509 
2025-06-04 14:19:03.007666: train_loss -0.7151 
2025-06-04 14:19:03.042571: val_loss -0.6759 
2025-06-04 14:19:03.259003: Pseudo dice [np.float32(0.8239)] 
2025-06-04 14:19:03.286917: Epoch time: 141.78 s 
2025-06-04 14:19:06.999657:  
2025-06-04 14:19:07.020168: Epoch 529 
2025-06-04 14:19:07.037001: Current learning rate: 0.00508 
2025-06-04 14:21:32.155760: train_loss -0.7166 
2025-06-04 14:21:32.537410: val_loss -0.7122 
2025-06-04 14:21:32.607638: Pseudo dice [np.float32(0.826)] 
2025-06-04 14:21:32.625005: Epoch time: 145.27 s 
2025-06-04 14:21:38.327955:  
2025-06-04 14:21:38.734765: Epoch 530 
2025-06-04 14:21:39.157554: Current learning rate: 0.00507 
2025-06-04 14:24:04.752129: train_loss -0.7086 
2025-06-04 14:24:04.876886: val_loss -0.6754 
2025-06-04 14:24:05.074251: Pseudo dice [np.float32(0.7794)] 
2025-06-04 14:24:05.317394: Epoch time: 146.43 s 
2025-06-04 14:24:11.550484:  
2025-06-04 14:24:12.035997: Epoch 531 
2025-06-04 14:24:12.415060: Current learning rate: 0.00506 
2025-06-04 14:26:37.824679: train_loss -0.6915 
2025-06-04 14:26:38.154045: val_loss -0.6631 
2025-06-04 14:26:38.308056: Pseudo dice [np.float32(0.7693)] 
2025-06-04 14:26:38.501680: Epoch time: 146.28 s 
2025-06-04 14:26:43.508151:  
2025-06-04 14:26:43.771420: Epoch 532 
2025-06-04 14:26:44.003746: Current learning rate: 0.00505 
2025-06-04 14:29:05.542004: train_loss -0.7088 
2025-06-04 14:29:05.559583: val_loss -0.727 
2025-06-04 14:29:05.572574: Pseudo dice [np.float32(0.8245)] 
2025-06-04 14:29:05.585378: Epoch time: 142.04 s 
2025-06-04 14:29:13.258454:  
2025-06-04 14:29:13.605875: Epoch 533 
2025-06-04 14:29:13.629037: Current learning rate: 0.00504 
2025-06-04 14:31:37.946763: train_loss -0.7212 
2025-06-04 14:31:37.964735: val_loss -0.661 
2025-06-04 14:31:37.976967: Pseudo dice [np.float32(0.778)] 
2025-06-04 14:31:37.989401: Epoch time: 144.69 s 
2025-06-04 14:31:45.129379:  
2025-06-04 14:31:45.146431: Epoch 534 
2025-06-04 14:31:45.159761: Current learning rate: 0.00503 
2025-06-04 14:34:09.617324: train_loss -0.7192 
2025-06-04 14:34:09.642647: val_loss -0.7143 
2025-06-04 14:34:09.873940: Pseudo dice [np.float32(0.826)] 
2025-06-04 14:34:10.275110: Epoch time: 144.49 s 
2025-06-04 14:34:18.498016:  
2025-06-04 14:34:18.515098: Epoch 535 
2025-06-04 14:34:18.527977: Current learning rate: 0.00502 
2025-06-04 14:36:33.195004: train_loss -0.7048 
2025-06-04 14:36:33.656589: val_loss -0.7196 
2025-06-04 14:36:34.181165: Pseudo dice [np.float32(0.782)] 
2025-06-04 14:36:34.389518: Epoch time: 134.7 s 
2025-06-04 14:36:40.862400:  
2025-06-04 14:36:41.374803: Epoch 536 
2025-06-04 14:36:41.906721: Current learning rate: 0.00501 
2025-06-04 14:39:03.268540: train_loss -0.719 
2025-06-04 14:39:03.292157: val_loss -0.6452 
2025-06-04 14:39:03.310556: Pseudo dice [np.float32(0.7416)] 
2025-06-04 14:39:03.325989: Epoch time: 142.41 s 
2025-06-04 14:39:09.774886:  
2025-06-04 14:39:09.792868: Epoch 537 
2025-06-04 14:39:09.806093: Current learning rate: 0.005 
2025-06-04 14:41:29.347147: train_loss -0.6869 
2025-06-04 14:41:29.368722: val_loss -0.7144 
2025-06-04 14:41:29.407222: Pseudo dice [np.float32(0.8154)] 
2025-06-04 14:41:29.601102: Epoch time: 139.57 s 
2025-06-04 14:41:36.778666:  
2025-06-04 14:41:37.105792: Epoch 538 
2025-06-04 14:41:37.506059: Current learning rate: 0.00499 
2025-06-04 14:44:00.978565: train_loss -0.7159 
2025-06-04 14:44:01.238534: val_loss -0.6613 
2025-06-04 14:44:01.714386: Pseudo dice [np.float32(0.7448)] 
2025-06-04 14:44:01.732089: Epoch time: 144.2 s 
2025-06-04 14:44:08.112471:  
2025-06-04 14:44:08.347963: Epoch 539 
2025-06-04 14:44:08.644921: Current learning rate: 0.00498 
2025-06-04 14:46:30.806621: train_loss -0.691 
2025-06-04 14:46:31.221572: val_loss -0.6626 
2025-06-04 14:46:31.579123: Pseudo dice [np.float32(0.7775)] 
2025-06-04 14:46:31.593832: Epoch time: 142.7 s 
2025-06-04 14:46:36.916034:  
2025-06-04 14:46:37.158126: Epoch 540 
2025-06-04 14:46:37.196738: Current learning rate: 0.00497 
2025-06-04 14:49:00.759588: train_loss -0.7151 
2025-06-04 14:49:01.146976: val_loss -0.7406 
2025-06-04 14:49:01.439320: Pseudo dice [np.float32(0.7874)] 
2025-06-04 14:49:01.455149: Epoch time: 143.85 s 
2025-06-04 14:49:10.248456:  
2025-06-04 14:49:10.611069: Epoch 541 
2025-06-04 14:49:11.011114: Current learning rate: 0.00496 
2025-06-04 14:51:35.382620: train_loss -0.7155 
2025-06-04 14:51:35.703771: val_loss -0.7124 
2025-06-04 14:51:35.720716: Pseudo dice [np.float32(0.8668)] 
2025-06-04 14:51:35.742971: Epoch time: 145.14 s 
2025-06-04 14:51:46.230305:  
2025-06-04 14:51:46.674279: Epoch 542 
2025-06-04 14:51:47.075719: Current learning rate: 0.00495 
2025-06-04 14:54:13.091735: train_loss -0.7305 
2025-06-04 14:54:13.109766: val_loss -0.6613 
2025-06-04 14:54:13.122597: Pseudo dice [np.float32(0.7532)] 
2025-06-04 14:54:13.135773: Epoch time: 146.86 s 
2025-06-04 14:54:20.019153:  
2025-06-04 14:54:20.181871: Epoch 543 
2025-06-04 14:54:20.371694: Current learning rate: 0.00494 
2025-06-04 14:56:46.340727: train_loss -0.6998 
2025-06-04 14:56:46.863072: val_loss -0.7209 
2025-06-04 14:56:46.878499: Pseudo dice [np.float32(0.8252)] 
2025-06-04 14:56:46.890827: Epoch time: 146.32 s 
2025-06-04 14:56:53.395273:  
2025-06-04 14:56:53.689274: Epoch 544 
2025-06-04 14:56:53.949007: Current learning rate: 0.00493 
2025-06-04 14:59:15.590113: train_loss -0.7045 
2025-06-04 14:59:15.695767: val_loss -0.6803 
2025-06-04 14:59:15.711948: Pseudo dice [np.float32(0.7773)] 
2025-06-04 14:59:15.727190: Epoch time: 142.2 s 
2025-06-04 14:59:24.056737:  
2025-06-04 14:59:24.074272: Epoch 545 
2025-06-04 14:59:24.088137: Current learning rate: 0.00492 
2025-06-04 15:01:49.459175: train_loss -0.684 
2025-06-04 15:01:49.480631: val_loss -0.7163 
2025-06-04 15:01:49.513390: Pseudo dice [np.float32(0.8477)] 
2025-06-04 15:01:49.546443: Epoch time: 145.57 s 
2025-06-04 15:01:56.185756:  
2025-06-04 15:01:56.374104: Epoch 546 
2025-06-04 15:01:56.843361: Current learning rate: 0.00491 
2025-06-04 15:04:30.379727: train_loss -0.7008 
2025-06-04 15:04:31.035521: val_loss -0.7053 
2025-06-04 15:04:31.681756: Pseudo dice [np.float32(0.8098)] 
2025-06-04 15:04:31.947515: Epoch time: 154.2 s 
2025-06-04 15:04:32.585829: Yayy! New best EMA pseudo Dice: 0.7979999780654907 
2025-06-04 15:04:41.323593:  
2025-06-04 15:04:41.649818: Epoch 547 
2025-06-04 15:04:41.915565: Current learning rate: 0.0049 
2025-06-04 15:07:10.593496: train_loss -0.7242 
2025-06-04 15:07:10.617557: val_loss -0.6887 
2025-06-04 15:07:10.633178: Pseudo dice [np.float32(0.7171)] 
2025-06-04 15:07:10.648256: Epoch time: 149.27 s 
2025-06-04 15:07:19.089213:  
2025-06-04 15:07:19.429270: Epoch 548 
2025-06-04 15:07:19.503211: Current learning rate: 0.00489 
2025-06-04 15:09:43.004098: train_loss -0.6964 
2025-06-04 15:09:43.038321: val_loss -0.6735 
2025-06-04 15:09:43.068266: Pseudo dice [np.float32(0.7344)] 
2025-06-04 15:09:43.101801: Epoch time: 143.92 s 
2025-06-04 15:09:53.941534:  
2025-06-04 15:09:54.174250: Epoch 549 
2025-06-04 15:09:54.479977: Current learning rate: 0.00488 
2025-06-04 15:12:17.888782: train_loss -0.7169 
2025-06-04 15:12:17.917557: val_loss -0.698 
2025-06-04 15:12:17.943992: Pseudo dice [np.float32(0.7619)] 
2025-06-04 15:12:17.980479: Epoch time: 143.95 s 
2025-06-04 15:12:27.771731:  
2025-06-04 15:12:27.790492: Epoch 550 
2025-06-04 15:12:27.806337: Current learning rate: 0.00487 
2025-06-04 15:14:50.102865: train_loss -0.7256 
2025-06-04 15:14:50.458222: val_loss -0.6662 
2025-06-04 15:14:50.911276: Pseudo dice [np.float32(0.7778)] 
2025-06-04 15:14:50.938833: Epoch time: 142.33 s 
2025-06-04 15:14:56.713560:  
2025-06-04 15:14:56.730168: Epoch 551 
2025-06-04 15:14:56.745079: Current learning rate: 0.00486 
2025-06-04 15:17:26.211375: train_loss -0.7037 
2025-06-04 15:17:26.670789: val_loss -0.6771 
2025-06-04 15:17:26.687420: Pseudo dice [np.float32(0.7918)] 
2025-06-04 15:17:26.700297: Epoch time: 149.5 s 
2025-06-04 15:17:32.273525:  
2025-06-04 15:17:32.320970: Epoch 552 
2025-06-04 15:17:32.424113: Current learning rate: 0.00485 
2025-06-04 15:19:52.732745: train_loss -0.7246 
2025-06-04 15:19:52.750961: val_loss -0.6779 
2025-06-04 15:19:52.763406: Pseudo dice [np.float32(0.7841)] 
2025-06-04 15:19:52.775914: Epoch time: 140.46 s 
2025-06-04 15:19:56.953687:  
2025-06-04 15:19:56.972211: Epoch 553 
2025-06-04 15:19:56.985232: Current learning rate: 0.00484 
2025-06-04 15:22:26.740592: train_loss -0.706 
2025-06-04 15:22:27.351713: val_loss -0.6788 
2025-06-04 15:22:28.041333: Pseudo dice [np.float32(0.7528)] 
2025-06-04 15:22:28.484849: Epoch time: 149.79 s 
2025-06-04 15:22:37.071261:  
2025-06-04 15:22:37.088976: Epoch 554 
2025-06-04 15:22:37.100889: Current learning rate: 0.00484 
2025-06-04 15:25:07.172373: train_loss -0.7289 
2025-06-04 15:25:07.190650: val_loss -0.7492 
2025-06-04 15:25:07.204532: Pseudo dice [np.float32(0.8346)] 
2025-06-04 15:25:07.216291: Epoch time: 150.1 s 
2025-06-04 15:25:13.152453:  
2025-06-04 15:25:13.331233: Epoch 555 
2025-06-04 15:25:13.517288: Current learning rate: 0.00483 
2025-06-04 15:27:37.431654: train_loss -0.7225 
2025-06-04 15:27:37.817048: val_loss -0.6889 
2025-06-04 15:27:38.174986: Pseudo dice [np.float32(0.7445)] 
2025-06-04 15:27:38.636863: Epoch time: 144.28 s 
2025-06-04 15:27:43.048823:  
2025-06-04 15:27:43.202138: Epoch 556 
2025-06-04 15:27:43.390579: Current learning rate: 0.00482 
2025-06-04 15:30:10.445185: train_loss -0.7055 
2025-06-04 15:30:10.463212: val_loss -0.6874 
2025-06-04 15:30:10.478595: Pseudo dice [np.float32(0.7783)] 
2025-06-04 15:30:10.493418: Epoch time: 147.42 s 
2025-06-04 15:30:13.235077:  
2025-06-04 15:30:13.251852: Epoch 557 
2025-06-04 15:30:13.265182: Current learning rate: 0.00481 
2025-06-04 15:32:36.817060: train_loss -0.7149 
2025-06-04 15:32:36.938097: val_loss -0.7173 
2025-06-04 15:32:37.218830: Pseudo dice [np.float32(0.7107)] 
2025-06-04 15:32:37.425874: Epoch time: 143.58 s 
2025-06-04 15:32:41.331470:  
2025-06-04 15:32:41.382452: Epoch 558 
2025-06-04 15:32:41.399598: Current learning rate: 0.0048 
2025-06-04 15:35:07.374080: train_loss -0.7059 
2025-06-04 15:35:07.847666: val_loss -0.7171 
2025-06-04 15:35:08.213148: Pseudo dice [np.float32(0.7929)] 
2025-06-04 15:35:08.601827: Epoch time: 146.04 s 
2025-06-04 15:35:17.765554:  
2025-06-04 15:35:18.196445: Epoch 559 
2025-06-04 15:35:18.468021: Current learning rate: 0.00479 
2025-06-04 15:37:42.699220: train_loss -0.7056 
2025-06-04 15:37:43.178870: val_loss -0.7121 
2025-06-04 15:37:43.808950: Pseudo dice [np.float32(0.7871)] 
2025-06-04 15:37:44.228934: Epoch time: 144.94 s 
2025-06-04 15:37:50.051081:  
2025-06-04 15:37:50.262698: Epoch 560 
2025-06-04 15:37:50.582230: Current learning rate: 0.00478 
2025-06-04 15:40:15.926247: train_loss -0.7145 
2025-06-04 15:40:16.521313: val_loss -0.7081 
2025-06-04 15:40:16.891898: Pseudo dice [np.float32(0.8165)] 
2025-06-04 15:40:17.168974: Epoch time: 145.88 s 
2025-06-04 15:40:24.770214:  
2025-06-04 15:40:25.284121: Epoch 561 
2025-06-04 15:40:25.488897: Current learning rate: 0.00477 
2025-06-04 15:42:52.770933: train_loss -0.7174 
2025-06-04 15:42:53.180533: val_loss -0.6959 
2025-06-04 15:42:53.195746: Pseudo dice [np.float32(0.7861)] 
2025-06-04 15:42:53.208565: Epoch time: 148.0 s 
2025-06-04 15:42:59.713561:  
2025-06-04 15:43:00.017381: Epoch 562 
2025-06-04 15:43:00.268100: Current learning rate: 0.00476 
2025-06-04 15:45:24.129594: train_loss -0.7167 
2025-06-04 15:45:24.403384: val_loss -0.7029 
2025-06-04 15:45:24.878234: Pseudo dice [np.float32(0.788)] 
2025-06-04 15:45:25.223686: Epoch time: 144.42 s 
2025-06-04 15:45:29.795729:  
2025-06-04 15:45:30.230328: Epoch 563 
2025-06-04 15:45:30.531671: Current learning rate: 0.00475 
2025-06-04 15:47:53.070693: train_loss -0.7229 
2025-06-04 15:47:53.511112: val_loss -0.6912 
2025-06-04 15:47:54.209166: Pseudo dice [np.float32(0.7848)] 
2025-06-04 15:47:54.568706: Epoch time: 143.28 s 
2025-06-04 15:48:00.889769:  
2025-06-04 15:48:01.087639: Epoch 564 
2025-06-04 15:48:01.365714: Current learning rate: 0.00474 
2025-06-04 15:50:26.963582: train_loss -0.7289 
2025-06-04 15:50:26.981520: val_loss -0.6734 
2025-06-04 15:50:26.993780: Pseudo dice [np.float32(0.7543)] 
2025-06-04 15:50:27.006588: Epoch time: 146.08 s 
2025-06-04 15:50:32.962943:  
2025-06-04 15:50:33.120481: Epoch 565 
2025-06-04 15:50:33.348648: Current learning rate: 0.00473 
2025-06-04 15:52:58.830984: train_loss -0.7098 
2025-06-04 15:52:59.364637: val_loss -0.6943 
2025-06-04 15:52:59.850097: Pseudo dice [np.float32(0.7671)] 
2025-06-04 15:53:00.297016: Epoch time: 145.87 s 
2025-06-04 15:53:05.855648:  
2025-06-04 15:53:05.871131: Epoch 566 
2025-06-04 15:53:05.885512: Current learning rate: 0.00472 
2025-06-04 15:55:35.828668: train_loss -0.6921 
2025-06-04 15:55:35.848325: val_loss -0.7266 
2025-06-04 15:55:35.861188: Pseudo dice [np.float32(0.7992)] 
2025-06-04 15:55:35.874382: Epoch time: 149.98 s 
2025-06-04 15:55:43.296924:  
2025-06-04 15:55:43.619156: Epoch 567 
2025-06-04 15:55:44.128333: Current learning rate: 0.00471 
2025-06-04 15:58:06.002576: train_loss -0.7128 
2025-06-04 15:58:06.598205: val_loss -0.6262 
2025-06-04 15:58:07.278561: Pseudo dice [np.float32(0.6433)] 
2025-06-04 15:58:08.093612: Epoch time: 142.71 s 
2025-06-04 15:58:15.529552:  
2025-06-04 15:58:15.778482: Epoch 568 
2025-06-04 15:58:15.793659: Current learning rate: 0.0047 
2025-06-04 16:00:46.305007: train_loss -0.7093 
2025-06-04 16:00:46.949589: val_loss -0.732 
2025-06-04 16:00:47.451164: Pseudo dice [np.float32(0.8363)] 
2025-06-04 16:00:47.952685: Epoch time: 150.78 s 
2025-06-04 16:00:53.342045:  
2025-06-04 16:00:53.400939: Epoch 569 
2025-06-04 16:00:53.417014: Current learning rate: 0.00469 
2025-06-04 16:03:20.187715: train_loss -0.7278 
2025-06-04 16:03:20.213591: val_loss -0.6642 
2025-06-04 16:03:20.240103: Pseudo dice [np.float32(0.6856)] 
2025-06-04 16:03:20.258120: Epoch time: 146.85 s 
2025-06-04 16:03:26.028701:  
2025-06-04 16:03:26.379742: Epoch 570 
2025-06-04 16:03:26.438760: Current learning rate: 0.00468 
2025-06-04 16:05:49.275352: train_loss -0.7493 
2025-06-04 16:05:49.295671: val_loss -0.7039 
2025-06-04 16:05:49.310116: Pseudo dice [np.float32(0.8274)] 
2025-06-04 16:05:49.324939: Epoch time: 143.25 s 
2025-06-04 16:05:58.032572:  
2025-06-04 16:05:58.319039: Epoch 571 
2025-06-04 16:05:58.577866: Current learning rate: 0.00467 
2025-06-04 16:08:22.834444: train_loss -0.7156 
2025-06-04 16:08:22.996844: val_loss -0.7062 
2025-06-04 16:08:23.359681: Pseudo dice [np.float32(0.8259)] 
2025-06-04 16:08:23.917556: Epoch time: 144.8 s 
2025-06-04 16:08:29.525540:  
2025-06-04 16:08:29.872405: Epoch 572 
2025-06-04 16:08:30.170434: Current learning rate: 0.00466 
2025-06-04 16:10:56.965241: train_loss -0.6981 
2025-06-04 16:10:56.986806: val_loss -0.7111 
2025-06-04 16:10:57.004940: Pseudo dice [np.float32(0.8116)] 
2025-06-04 16:10:57.020005: Epoch time: 147.44 s 
2025-06-04 16:11:03.530065:  
2025-06-04 16:11:03.815114: Epoch 573 
2025-06-04 16:11:03.960180: Current learning rate: 0.00465 
2025-06-04 16:13:35.691806: train_loss -0.7145 
2025-06-04 16:13:36.059166: val_loss -0.6679 
2025-06-04 16:13:36.483340: Pseudo dice [np.float32(0.7237)] 
2025-06-04 16:13:36.884039: Epoch time: 152.16 s 
2025-06-04 16:13:43.740959:  
2025-06-04 16:13:44.025512: Epoch 574 
2025-06-04 16:13:44.277187: Current learning rate: 0.00464 
2025-06-04 16:16:10.276443: train_loss -0.7224 
2025-06-04 16:16:10.298781: val_loss -0.7132 
2025-06-04 16:16:10.314640: Pseudo dice [np.float32(0.7529)] 
2025-06-04 16:16:10.330034: Epoch time: 146.54 s 
2025-06-04 16:16:18.742637:  
2025-06-04 16:16:19.177385: Epoch 575 
2025-06-04 16:16:19.574074: Current learning rate: 0.00463 
2025-06-04 16:18:45.704026: train_loss -0.6961 
2025-06-04 16:18:46.202080: val_loss -0.6205 
2025-06-04 16:18:46.480109: Pseudo dice [np.float32(0.7343)] 
2025-06-04 16:18:46.924682: Epoch time: 146.96 s 
2025-06-04 16:18:54.453697:  
2025-06-04 16:18:54.481994: Epoch 576 
2025-06-04 16:18:54.521426: Current learning rate: 0.00462 
2025-06-04 16:21:18.119561: train_loss -0.7228 
2025-06-04 16:21:18.272857: val_loss -0.6591 
2025-06-04 16:21:18.530388: Pseudo dice [np.float32(0.779)] 
2025-06-04 16:21:18.681522: Epoch time: 143.67 s 
2025-06-04 16:21:21.399386:  
2025-06-04 16:21:21.458368: Epoch 577 
2025-06-04 16:21:21.667466: Current learning rate: 0.00461 
2025-06-04 16:23:45.550275: train_loss -0.6997 
2025-06-04 16:23:45.568631: val_loss -0.6975 
2025-06-04 16:23:45.581261: Pseudo dice [np.float32(0.6584)] 
2025-06-04 16:23:45.594428: Epoch time: 144.15 s 
2025-06-04 16:23:51.693798:  
2025-06-04 16:23:51.837674: Epoch 578 
2025-06-04 16:23:52.026583: Current learning rate: 0.0046 
2025-06-04 16:26:16.101678: train_loss -0.6818 
2025-06-04 16:26:16.120593: val_loss -0.688 
2025-06-04 16:26:16.134284: Pseudo dice [np.float32(0.7269)] 
2025-06-04 16:26:16.147441: Epoch time: 144.41 s 
2025-06-04 16:26:23.541165:  
2025-06-04 16:26:23.945684: Epoch 579 
2025-06-04 16:26:24.375669: Current learning rate: 0.00459 
2025-06-04 16:28:45.429659: train_loss -0.7091 
2025-06-04 16:28:45.613168: val_loss -0.6953 
2025-06-04 16:28:45.627771: Pseudo dice [np.float32(0.8045)] 
2025-06-04 16:28:45.641095: Epoch time: 141.89 s 
2025-06-04 16:28:54.334801:  
2025-06-04 16:28:54.501604: Epoch 580 
2025-06-04 16:28:54.913718: Current learning rate: 0.00458 
2025-06-04 16:31:22.574337: train_loss -0.7143 
2025-06-04 16:31:22.916388: val_loss -0.7213 
2025-06-04 16:31:23.369339: Pseudo dice [np.float32(0.7625)] 
2025-06-04 16:31:23.868759: Epoch time: 148.24 s 
2025-06-04 16:31:30.273859:  
2025-06-04 16:31:30.526919: Epoch 581 
2025-06-04 16:31:30.830643: Current learning rate: 0.00457 
2025-06-04 16:33:50.766037: train_loss -0.7181 
2025-06-04 16:33:50.785938: val_loss -0.6472 
2025-06-04 16:33:50.799709: Pseudo dice [np.float32(0.7883)] 
2025-06-04 16:33:50.812416: Epoch time: 140.49 s 
2025-06-04 16:33:57.492903:  
2025-06-04 16:33:57.863053: Epoch 582 
2025-06-04 16:33:58.121059: Current learning rate: 0.00456 
2025-06-04 16:36:23.235901: train_loss -0.7223 
2025-06-04 16:36:23.254806: val_loss -0.7026 
2025-06-04 16:36:23.268094: Pseudo dice [np.float32(0.7962)] 
2025-06-04 16:36:23.281404: Epoch time: 145.75 s 
2025-06-04 16:36:30.853593:  
2025-06-04 16:36:31.013800: Epoch 583 
2025-06-04 16:36:31.031674: Current learning rate: 0.00455 
2025-06-04 16:38:55.805624: train_loss -0.7134 
2025-06-04 16:38:56.209012: val_loss -0.6664 
2025-06-04 16:38:56.562863: Pseudo dice [np.float32(0.7469)] 
2025-06-04 16:38:56.871428: Epoch time: 144.95 s 
2025-06-04 16:39:04.702072:  
2025-06-04 16:39:05.099281: Epoch 584 
2025-06-04 16:39:05.266097: Current learning rate: 0.00454 
2025-06-04 16:41:33.113340: train_loss -0.7215 
2025-06-04 16:41:33.138789: val_loss -0.613 
2025-06-04 16:41:33.153777: Pseudo dice [np.float32(0.6706)] 
2025-06-04 16:41:33.167408: Epoch time: 148.41 s 
2025-06-04 16:41:43.537679:  
2025-06-04 16:41:43.685973: Epoch 585 
2025-06-04 16:41:43.838068: Current learning rate: 0.00453 
2025-06-04 16:44:06.585536: train_loss -0.7006 
2025-06-04 16:44:07.061154: val_loss -0.6744 
2025-06-04 16:44:07.080445: Pseudo dice [np.float32(0.7834)] 
2025-06-04 16:44:07.097036: Epoch time: 143.05 s 
2025-06-04 16:44:15.116989:  
2025-06-04 16:44:15.562558: Epoch 586 
2025-06-04 16:44:15.580128: Current learning rate: 0.00452 
2025-06-04 16:46:39.613137: train_loss -0.7089 
2025-06-04 16:46:40.042153: val_loss -0.6462 
2025-06-04 16:46:40.060694: Pseudo dice [np.float32(0.7774)] 
2025-06-04 16:46:40.074136: Epoch time: 144.5 s 
2025-06-04 16:46:47.770941:  
2025-06-04 16:46:47.791096: Epoch 587 
2025-06-04 16:46:47.807568: Current learning rate: 0.00451 
2025-06-04 16:49:16.801506: train_loss -0.7378 
2025-06-04 16:49:17.371544: val_loss -0.6898 
2025-06-04 16:49:17.862015: Pseudo dice [np.float32(0.7531)] 
2025-06-04 16:49:17.877443: Epoch time: 149.03 s 
2025-06-04 16:49:25.592805:  
2025-06-04 16:49:25.840253: Epoch 588 
2025-06-04 16:49:26.044589: Current learning rate: 0.0045 
2025-06-04 16:51:50.753538: train_loss -0.7238 
2025-06-04 16:51:51.312126: val_loss -0.7138 
2025-06-04 16:51:51.693100: Pseudo dice [np.float32(0.7833)] 
2025-06-04 16:51:51.708971: Epoch time: 145.16 s 
2025-06-04 16:51:59.950098:  
2025-06-04 16:52:00.262283: Epoch 589 
2025-06-04 16:52:00.626149: Current learning rate: 0.00449 
2025-06-04 16:54:30.855691: train_loss -0.709 
2025-06-04 16:54:30.897437: val_loss -0.7102 
2025-06-04 16:54:30.915404: Pseudo dice [np.float32(0.7754)] 
2025-06-04 16:54:30.932833: Epoch time: 150.91 s 
2025-06-04 16:54:40.812511:  
2025-06-04 16:54:41.033541: Epoch 590 
2025-06-04 16:54:41.505726: Current learning rate: 0.00448 
2025-06-04 16:57:07.026188: train_loss -0.6822 
2025-06-04 16:57:07.643028: val_loss -0.6693 
2025-06-04 16:57:08.075770: Pseudo dice [np.float32(0.7731)] 
2025-06-04 16:57:08.456566: Epoch time: 146.22 s 
2025-06-04 16:57:15.766189:  
2025-06-04 16:57:15.907487: Epoch 591 
2025-06-04 16:57:16.028480: Current learning rate: 0.00447 
2025-06-04 16:59:42.756236: train_loss -0.6837 
2025-06-04 16:59:42.776101: val_loss -0.6705 
2025-06-04 16:59:42.789816: Pseudo dice [np.float32(0.7658)] 
2025-06-04 16:59:42.803583: Epoch time: 146.99 s 
2025-06-04 16:59:50.958024:  
2025-06-04 16:59:51.510013: Epoch 592 
2025-06-04 16:59:51.933120: Current learning rate: 0.00446 
2025-06-04 17:02:14.876297: train_loss -0.7023 
2025-06-04 17:02:15.186968: val_loss -0.6404 
2025-06-04 17:02:15.336928: Pseudo dice [np.float32(0.7399)] 
2025-06-04 17:02:15.349993: Epoch time: 143.92 s 
2025-06-04 17:02:21.830037:  
2025-06-04 17:02:22.037416: Epoch 593 
2025-06-04 17:02:22.060559: Current learning rate: 0.00445 
2025-06-04 17:04:48.719391: train_loss -0.6851 
2025-06-04 17:04:49.285558: val_loss -0.7325 
2025-06-04 17:04:49.703763: Pseudo dice [np.float32(0.7903)] 
2025-06-04 17:04:50.052745: Epoch time: 146.89 s 
2025-06-04 17:04:55.811175:  
2025-06-04 17:04:55.945721: Epoch 594 
2025-06-04 17:04:55.961773: Current learning rate: 0.00444 
2025-06-04 17:07:21.971151: train_loss -0.71 
2025-06-04 17:07:22.509232: val_loss -0.6974 
2025-06-04 17:07:22.864134: Pseudo dice [np.float32(0.8202)] 
2025-06-04 17:07:23.221096: Epoch time: 146.16 s 
2025-06-04 17:07:30.533453:  
2025-06-04 17:07:30.854142: Epoch 595 
2025-06-04 17:07:31.036193: Current learning rate: 0.00443 
2025-06-04 17:10:02.476795: train_loss -0.7035 
2025-06-04 17:10:03.113782: val_loss -0.6829 
2025-06-04 17:10:03.529832: Pseudo dice [np.float32(0.7455)] 
2025-06-04 17:10:03.545645: Epoch time: 151.95 s 
2025-06-04 17:10:09.555940:  
2025-06-04 17:10:09.707890: Epoch 596 
2025-06-04 17:10:09.726816: Current learning rate: 0.00442 
2025-06-04 17:12:37.849725: train_loss -0.6903 
2025-06-04 17:12:37.996590: val_loss -0.6626 
2025-06-04 17:12:38.019142: Pseudo dice [np.float32(0.7926)] 
2025-06-04 17:12:38.045661: Epoch time: 148.3 s 
2025-06-04 17:12:44.945636:  
2025-06-04 17:12:44.962871: Epoch 597 
2025-06-04 17:12:44.976004: Current learning rate: 0.00441 
2025-06-04 17:15:14.685554: train_loss -0.7193 
2025-06-04 17:15:15.140961: val_loss -0.7013 
2025-06-04 17:15:15.550660: Pseudo dice [np.float32(0.8303)] 
2025-06-04 17:15:15.878383: Epoch time: 149.74 s 
2025-06-04 17:15:22.733866:  
2025-06-04 17:15:22.857529: Epoch 598 
2025-06-04 17:15:23.112205: Current learning rate: 0.0044 
2025-06-04 17:17:49.792349: train_loss -0.7326 
2025-06-04 17:17:50.234362: val_loss -0.694 
2025-06-04 17:17:50.594474: Pseudo dice [np.float32(0.8135)] 
2025-06-04 17:17:51.166134: Epoch time: 147.06 s 
2025-06-04 17:17:54.915416:  
2025-06-04 17:17:54.933434: Epoch 599 
2025-06-04 17:17:54.949455: Current learning rate: 0.00439 
2025-06-04 17:20:23.694932: train_loss -0.7086 
2025-06-04 17:20:23.712851: val_loss -0.7309 
2025-06-04 17:20:23.727382: Pseudo dice [np.float32(0.813)] 
2025-06-04 17:20:23.740684: Epoch time: 148.78 s 
2025-06-04 17:20:26.659491:  
2025-06-04 17:20:26.678430: Epoch 600 
2025-06-04 17:20:26.693171: Current learning rate: 0.00438 
2025-06-04 17:22:50.674089: train_loss -0.7249 
2025-06-04 17:22:50.692470: val_loss -0.7162 
2025-06-04 17:22:50.718168: Pseudo dice [np.float32(0.8127)] 
2025-06-04 17:22:50.738327: Epoch time: 144.02 s 
2025-06-04 17:22:57.601652:  
2025-06-04 17:22:57.620895: Epoch 601 
2025-06-04 17:22:57.635040: Current learning rate: 0.00437 
2025-06-04 17:25:26.341136: train_loss -0.7303 
2025-06-04 17:25:26.359306: val_loss -0.6659 
2025-06-04 17:25:26.371786: Pseudo dice [np.float32(0.7665)] 
2025-06-04 17:25:26.383803: Epoch time: 148.74 s 
2025-06-04 17:25:34.444003:  
2025-06-04 17:25:34.698700: Epoch 602 
2025-06-04 17:25:34.713962: Current learning rate: 0.00436 
2025-06-04 17:28:00.415483: train_loss -0.7324 
2025-06-04 17:28:00.753351: val_loss -0.6465 
2025-06-04 17:28:01.095221: Pseudo dice [np.float32(0.6649)] 
2025-06-04 17:28:01.128234: Epoch time: 145.97 s 
2025-06-04 17:28:07.547055:  
2025-06-04 17:28:07.573390: Epoch 603 
2025-06-04 17:28:07.605837: Current learning rate: 0.00435 
2025-06-04 17:30:31.595250: train_loss -0.7312 
2025-06-04 17:30:31.617919: val_loss -0.6928 
2025-06-04 17:30:31.630460: Pseudo dice [np.float32(0.7653)] 
2025-06-04 17:30:31.642820: Epoch time: 144.05 s 
2025-06-04 17:30:37.121391:  
2025-06-04 17:30:37.203497: Epoch 604 
2025-06-04 17:30:37.544628: Current learning rate: 0.00434 
2025-06-04 17:33:01.217249: train_loss -0.7128 
2025-06-04 17:33:01.551628: val_loss -0.6815 
2025-06-04 17:33:01.885675: Pseudo dice [np.float32(0.7328)] 
2025-06-04 17:33:01.901690: Epoch time: 144.1 s 
2025-06-04 17:33:09.671335:  
2025-06-04 17:33:10.199572: Epoch 605 
2025-06-04 17:33:10.573725: Current learning rate: 0.00433 
2025-06-04 17:35:37.237571: train_loss -0.7343 
2025-06-04 17:35:37.608003: val_loss -0.6799 
2025-06-04 17:35:37.623192: Pseudo dice [np.float32(0.7822)] 
2025-06-04 17:35:37.636771: Epoch time: 147.57 s 
2025-06-04 17:35:43.537416:  
2025-06-04 17:35:43.631437: Epoch 606 
2025-06-04 17:35:44.013878: Current learning rate: 0.00432 
2025-06-04 17:38:03.632002: train_loss -0.7191 
2025-06-04 17:38:03.650413: val_loss -0.7231 
2025-06-04 17:38:03.665011: Pseudo dice [np.float32(0.8369)] 
2025-06-04 17:38:03.678598: Epoch time: 140.1 s 
2025-06-04 17:38:12.996521:  
2025-06-04 17:38:13.014857: Epoch 607 
2025-06-04 17:38:13.030087: Current learning rate: 0.00431 
2025-06-04 17:40:41.401937: train_loss -0.6951 
2025-06-04 17:40:41.960114: val_loss -0.7038 
2025-06-04 17:40:42.769167: Pseudo dice [np.float32(0.8246)] 
2025-06-04 17:40:43.247107: Epoch time: 148.41 s 
2025-06-04 17:40:48.672822:  
2025-06-04 17:40:49.125267: Epoch 608 
2025-06-04 17:40:49.485168: Current learning rate: 0.0043 
2025-06-04 17:43:13.659817: train_loss -0.6946 
2025-06-04 17:43:14.060378: val_loss -0.6555 
2025-06-04 17:43:14.488996: Pseudo dice [np.float32(0.7995)] 
2025-06-04 17:43:14.988472: Epoch time: 144.99 s 
2025-06-04 17:43:21.676830:  
2025-06-04 17:43:21.785089: Epoch 609 
2025-06-04 17:43:21.999191: Current learning rate: 0.00429 
2025-06-04 17:45:49.263509: train_loss -0.7011 
2025-06-04 17:45:49.829793: val_loss -0.7183 
2025-06-04 17:45:50.379724: Pseudo dice [np.float32(0.772)] 
2025-06-04 17:45:50.766830: Epoch time: 147.59 s 
2025-06-04 17:45:56.880854:  
2025-06-04 17:45:57.388341: Epoch 610 
2025-06-04 17:45:57.638789: Current learning rate: 0.00429 
2025-06-04 17:48:22.288550: train_loss -0.709 
2025-06-04 17:48:22.480727: val_loss -0.6935 
2025-06-04 17:48:22.675589: Pseudo dice [np.float32(0.8503)] 
2025-06-04 17:48:22.872667: Epoch time: 145.41 s 
2025-06-04 17:48:30.362218:  
2025-06-04 17:48:30.771795: Epoch 611 
2025-06-04 17:48:31.118238: Current learning rate: 0.00428 
2025-06-04 17:51:01.224586: train_loss -0.6703 
2025-06-04 17:51:01.650620: val_loss -0.7052 
2025-06-04 17:51:02.149993: Pseudo dice [np.float32(0.8237)] 
2025-06-04 17:51:02.745622: Epoch time: 150.86 s 
2025-06-04 17:51:10.287148:  
2025-06-04 17:51:10.903286: Epoch 612 
2025-06-04 17:51:11.069686: Current learning rate: 0.00427 
2025-06-04 17:53:36.285830: train_loss -0.7412 
2025-06-04 17:53:36.595760: val_loss -0.7245 
2025-06-04 17:53:37.086427: Pseudo dice [np.float32(0.7837)] 
2025-06-04 17:53:37.486744: Epoch time: 146.0 s 
2025-06-04 17:53:45.667355:  
2025-06-04 17:53:45.883875: Epoch 613 
2025-06-04 17:53:46.024607: Current learning rate: 0.00426 
2025-06-04 17:56:12.779456: train_loss -0.7038 
2025-06-04 17:56:12.803588: val_loss -0.6969 
2025-06-04 17:56:12.819408: Pseudo dice [np.float32(0.7308)] 
2025-06-04 17:56:12.836557: Epoch time: 147.11 s 
2025-06-04 17:56:22.745521:  
2025-06-04 17:56:23.063310: Epoch 614 
2025-06-04 17:56:23.285414: Current learning rate: 0.00425 
2025-06-04 17:58:50.761093: train_loss -0.7235 
2025-06-04 17:58:51.137894: val_loss -0.7283 
2025-06-04 17:58:51.699595: Pseudo dice [np.float32(0.8194)] 
2025-06-04 17:58:51.716164: Epoch time: 148.02 s 
2025-06-04 17:59:00.855535:  
2025-06-04 17:59:01.517965: Epoch 615 
2025-06-04 17:59:02.021595: Current learning rate: 0.00424 
2025-06-04 18:01:27.613825: train_loss -0.6977 
2025-06-04 18:01:28.065745: val_loss -0.7052 
2025-06-04 18:01:28.299937: Pseudo dice [np.float32(0.7848)] 
2025-06-04 18:01:28.316906: Epoch time: 146.76 s 
2025-06-04 18:01:33.885043:  
2025-06-04 18:01:34.331769: Epoch 616 
2025-06-04 18:01:34.760719: Current learning rate: 0.00423 
2025-06-04 18:04:03.674661: train_loss -0.72 
2025-06-04 18:04:03.699000: val_loss -0.7216 
2025-06-04 18:04:03.711772: Pseudo dice [np.float32(0.7382)] 
2025-06-04 18:04:03.724555: Epoch time: 149.79 s 
2025-06-04 18:04:10.469188:  
2025-06-04 18:04:11.323029: Epoch 617 
2025-06-04 18:04:11.736260: Current learning rate: 0.00422 
2025-06-04 18:06:38.440987: train_loss -0.7305 
2025-06-04 18:06:39.033776: val_loss -0.7387 
2025-06-04 18:06:39.719182: Pseudo dice [np.float32(0.7758)] 
2025-06-04 18:06:40.202723: Epoch time: 147.97 s 
2025-06-04 18:06:48.934735:  
2025-06-04 18:06:49.305272: Epoch 618 
2025-06-04 18:06:49.322801: Current learning rate: 0.00421 
2025-06-04 18:09:13.985967: train_loss -0.6981 
2025-06-04 18:09:14.008614: val_loss -0.701 
2025-06-04 18:09:14.023269: Pseudo dice [np.float32(0.7871)] 
2025-06-04 18:09:14.036747: Epoch time: 145.05 s 
2025-06-04 18:09:20.012492:  
2025-06-04 18:09:20.709031: Epoch 619 
2025-06-04 18:09:21.003187: Current learning rate: 0.0042 
2025-06-04 18:11:47.272602: train_loss -0.7194 
2025-06-04 18:11:47.736600: val_loss -0.674 
2025-06-04 18:11:48.125685: Pseudo dice [np.float32(0.8138)] 
2025-06-04 18:11:48.143638: Epoch time: 147.26 s 
2025-06-04 18:11:57.155176:  
2025-06-04 18:11:57.293795: Epoch 620 
2025-06-04 18:11:57.464078: Current learning rate: 0.00419 
2025-06-04 18:14:19.897037: train_loss -0.7672 
2025-06-04 18:14:20.321265: val_loss -0.7089 
2025-06-04 18:14:20.720751: Pseudo dice [np.float32(0.7974)] 
2025-06-04 18:14:21.120731: Epoch time: 142.74 s 
2025-06-04 18:14:30.215102:  
2025-06-04 18:14:30.233286: Epoch 621 
2025-06-04 18:14:30.248716: Current learning rate: 0.00418 
2025-06-04 18:16:54.813872: train_loss -0.7216 
2025-06-04 18:16:55.044881: val_loss -0.7275 
2025-06-04 18:16:55.099755: Pseudo dice [np.float32(0.7589)] 
2025-06-04 18:16:55.115172: Epoch time: 144.6 s 
2025-06-04 18:16:58.294530:  
2025-06-04 18:16:58.444123: Epoch 622 
2025-06-04 18:16:58.743157: Current learning rate: 0.00417 
2025-06-04 18:19:25.250801: train_loss -0.7415 
2025-06-04 18:19:25.272425: val_loss -0.6482 
2025-06-04 18:19:25.289381: Pseudo dice [np.float32(0.8218)] 
2025-06-04 18:19:25.305831: Epoch time: 146.96 s 
2025-06-04 18:19:32.795046:  
2025-06-04 18:19:33.377365: Epoch 623 
2025-06-04 18:19:33.675240: Current learning rate: 0.00416 
2025-06-04 18:21:58.052548: train_loss -0.7094 
2025-06-04 18:21:58.069347: val_loss -0.7174 
2025-06-04 18:21:58.083122: Pseudo dice [np.float32(0.8187)] 
2025-06-04 18:21:58.097368: Epoch time: 145.26 s 
2025-06-04 18:22:04.108585:  
2025-06-04 18:22:04.126409: Epoch 624 
2025-06-04 18:22:04.139065: Current learning rate: 0.00415 
2025-06-04 18:24:31.261655: train_loss -0.7414 
2025-06-04 18:24:31.286942: val_loss -0.7292 
2025-06-04 18:24:31.301721: Pseudo dice [np.float32(0.7835)] 
2025-06-04 18:24:31.314451: Epoch time: 147.16 s 
2025-06-04 18:24:39.701578:  
2025-06-04 18:24:39.898628: Epoch 625 
2025-06-04 18:24:40.122365: Current learning rate: 0.00414 
2025-06-04 18:27:03.842159: train_loss -0.7496 
2025-06-04 18:27:03.860625: val_loss -0.699 
2025-06-04 18:27:03.873484: Pseudo dice [np.float32(0.7583)] 
2025-06-04 18:27:03.888355: Epoch time: 144.14 s 
2025-06-04 18:27:10.762577:  
2025-06-04 18:27:11.142188: Epoch 626 
2025-06-04 18:27:11.157730: Current learning rate: 0.00413 
2025-06-04 18:29:29.833006: train_loss -0.721 
2025-06-04 18:29:30.063588: val_loss -0.6761 
2025-06-04 18:29:30.080436: Pseudo dice [np.float32(0.78)] 
2025-06-04 18:29:30.095836: Epoch time: 139.07 s 
2025-06-04 18:29:38.295152:  
2025-06-04 18:29:38.313032: Epoch 627 
2025-06-04 18:29:38.327277: Current learning rate: 0.00412 
2025-06-04 18:32:02.752176: train_loss -0.711 
2025-06-04 18:32:03.226040: val_loss -0.6734 
2025-06-04 18:32:03.416676: Pseudo dice [np.float32(0.7732)] 
2025-06-04 18:32:03.434550: Epoch time: 144.52 s 
2025-06-04 18:32:09.588016:  
2025-06-04 18:32:09.624941: Epoch 628 
2025-06-04 18:32:09.667084: Current learning rate: 0.00411 
2025-06-04 18:34:37.938310: train_loss -0.7184 
2025-06-04 18:34:38.375593: val_loss -0.6889 
2025-06-04 18:34:38.772001: Pseudo dice [np.float32(0.8286)] 
2025-06-04 18:34:39.299371: Epoch time: 148.35 s 
2025-06-04 18:34:49.223367:  
2025-06-04 18:34:49.243729: Epoch 629 
2025-06-04 18:34:49.257688: Current learning rate: 0.0041 
2025-06-04 18:37:14.340349: train_loss -0.7263 
2025-06-04 18:37:14.910040: val_loss -0.6975 
2025-06-04 18:37:15.494138: Pseudo dice [np.float32(0.8438)] 
2025-06-04 18:37:16.052279: Epoch time: 145.12 s 
2025-06-04 18:37:22.901894:  
2025-06-04 18:37:23.158395: Epoch 630 
2025-06-04 18:37:23.453721: Current learning rate: 0.00409 
2025-06-04 18:39:46.861533: train_loss -0.7194 
2025-06-04 18:39:46.882029: val_loss -0.5848 
2025-06-04 18:39:46.896869: Pseudo dice [np.float32(0.5646)] 
2025-06-04 18:39:46.910674: Epoch time: 143.96 s 
2025-06-04 18:39:55.127194:  
2025-06-04 18:39:55.663047: Epoch 631 
2025-06-04 18:39:56.083766: Current learning rate: 0.00408 
2025-06-04 18:42:16.531216: train_loss -0.7221 
2025-06-04 18:42:17.029061: val_loss -0.6756 
2025-06-04 18:42:17.404013: Pseudo dice [np.float32(0.7609)] 
2025-06-04 18:42:17.774117: Epoch time: 141.41 s 
2025-06-04 18:42:24.313344:  
2025-06-04 18:42:24.481664: Epoch 632 
2025-06-04 18:42:24.751945: Current learning rate: 0.00407 
2025-06-04 18:44:51.733735: train_loss -0.742 
2025-06-04 18:44:52.058519: val_loss -0.6488 
2025-06-04 18:44:52.081374: Pseudo dice [np.float32(0.7527)] 
2025-06-04 18:44:52.094230: Epoch time: 147.42 s 
2025-06-04 18:44:58.041929:  
2025-06-04 18:44:58.075057: Epoch 633 
2025-06-04 18:44:58.114447: Current learning rate: 0.00406 
2025-06-04 18:47:18.248188: train_loss -0.7229 
2025-06-04 18:47:18.271185: val_loss -0.6956 
2025-06-04 18:47:18.289085: Pseudo dice [np.float32(0.7963)] 
2025-06-04 18:47:18.302383: Epoch time: 140.32 s 
2025-06-04 18:47:24.353009:  
2025-06-04 18:47:24.944224: Epoch 634 
2025-06-04 18:47:25.285731: Current learning rate: 0.00405 
2025-06-04 18:49:51.412912: train_loss -0.7279 
2025-06-04 18:49:52.347967: val_loss -0.7111 
2025-06-04 18:49:52.846499: Pseudo dice [np.float32(0.7909)] 
2025-06-04 18:49:53.392059: Epoch time: 147.06 s 
2025-06-04 18:49:59.221046:  
2025-06-04 18:49:59.254447: Epoch 635 
2025-06-04 18:49:59.272969: Current learning rate: 0.00404 
2025-06-04 18:52:27.193540: train_loss -0.7349 
2025-06-04 18:52:27.574584: val_loss -0.701 
2025-06-04 18:52:27.943549: Pseudo dice [np.float32(0.7538)] 
2025-06-04 18:52:28.302589: Epoch time: 147.97 s 
2025-06-04 18:52:37.599827:  
2025-06-04 18:52:37.807408: Epoch 636 
2025-06-04 18:52:37.841027: Current learning rate: 0.00403 
2025-06-04 18:55:06.264492: train_loss -0.7252 
2025-06-04 18:55:06.974272: val_loss -0.6996 
2025-06-04 18:55:07.748619: Pseudo dice [np.float32(0.8118)] 
2025-06-04 18:55:08.233948: Epoch time: 148.67 s 
2025-06-04 18:55:15.297411:  
2025-06-04 18:55:15.485744: Epoch 637 
2025-06-04 18:55:15.502248: Current learning rate: 0.00402 
2025-06-04 18:57:44.301568: train_loss -0.6918 
2025-06-04 18:57:44.565168: val_loss -0.7013 
2025-06-04 18:57:45.219738: Pseudo dice [np.float32(0.7447)] 
2025-06-04 18:57:45.238109: Epoch time: 149.01 s 
2025-06-04 18:57:53.527901:  
2025-06-04 18:57:53.888780: Epoch 638 
2025-06-04 18:57:54.308138: Current learning rate: 0.00401 
2025-06-04 19:00:22.006520: train_loss -0.7096 
2025-06-04 19:00:22.478921: val_loss -0.7075 
2025-06-04 19:00:22.863443: Pseudo dice [np.float32(0.7267)] 
2025-06-04 19:00:23.265124: Epoch time: 148.48 s 
2025-06-04 19:00:29.585647:  
2025-06-04 19:00:30.113482: Epoch 639 
2025-06-04 19:00:30.263233: Current learning rate: 0.004 
2025-06-04 19:03:04.303961: train_loss -0.7223 
2025-06-04 19:03:04.336160: val_loss -0.697 
2025-06-04 19:03:04.359725: Pseudo dice [np.float32(0.8202)] 
2025-06-04 19:03:04.377028: Epoch time: 154.72 s 
2025-06-04 19:03:10.610992:  
2025-06-04 19:03:11.048457: Epoch 640 
2025-06-04 19:03:11.065282: Current learning rate: 0.00399 
2025-06-04 19:05:42.050455: train_loss -0.7281 
2025-06-04 19:05:42.364162: val_loss -0.6559 
2025-06-04 19:05:42.717898: Pseudo dice [np.float32(0.7654)] 
2025-06-04 19:05:42.936222: Epoch time: 151.44 s 
2025-06-04 19:05:50.652878:  
2025-06-04 19:05:50.942126: Epoch 641 
2025-06-04 19:05:51.094499: Current learning rate: 0.00398 
2025-06-04 19:08:14.126715: train_loss -0.7111 
2025-06-04 19:08:14.508305: val_loss -0.7264 
2025-06-04 19:08:14.662288: Pseudo dice [np.float32(0.8225)] 
2025-06-04 19:08:14.675132: Epoch time: 143.48 s 
2025-06-04 19:08:20.207305:  
2025-06-04 19:08:20.224898: Epoch 642 
2025-06-04 19:08:20.240350: Current learning rate: 0.00397 
2025-06-04 19:10:47.136096: train_loss -0.7236 
2025-06-04 19:10:47.352538: val_loss -0.7383 
2025-06-04 19:10:47.432918: Pseudo dice [np.float32(0.8321)] 
2025-06-04 19:10:47.449350: Epoch time: 146.93 s 
2025-06-04 19:10:52.831172:  
2025-06-04 19:10:53.215589: Epoch 643 
2025-06-04 19:10:53.682123: Current learning rate: 0.00396 
2025-06-04 19:13:08.785579: train_loss -0.7018 
2025-06-04 19:13:08.804404: val_loss -0.6671 
2025-06-04 19:13:08.820450: Pseudo dice [np.float32(0.6818)] 
2025-06-04 19:13:08.835112: Epoch time: 135.96 s 
2025-06-04 19:13:12.651542:  
2025-06-04 19:13:12.950462: Epoch 644 
2025-06-04 19:13:12.966759: Current learning rate: 0.00395 
2025-06-04 19:15:28.211988: train_loss -0.7121 
2025-06-04 19:15:28.364825: val_loss -0.6963 
2025-06-04 19:15:28.565997: Pseudo dice [np.float32(0.8252)] 
2025-06-04 19:15:28.804339: Epoch time: 135.56 s 
2025-06-04 19:15:32.714504:  
2025-06-04 19:15:32.887701: Epoch 645 
2025-06-04 19:15:33.155033: Current learning rate: 0.00394 
2025-06-04 19:17:52.399257: train_loss -0.7152 
2025-06-04 19:17:52.919692: val_loss -0.6893 
2025-06-04 19:17:53.492908: Pseudo dice [np.float32(0.8392)] 
2025-06-04 19:17:53.508340: Epoch time: 139.69 s 
2025-06-04 19:18:00.069651:  
2025-06-04 19:18:00.170808: Epoch 646 
2025-06-04 19:18:00.302557: Current learning rate: 0.00393 
2025-06-04 19:20:16.668363: train_loss -0.7306 
2025-06-04 19:20:17.013198: val_loss -0.7155 
2025-06-04 19:20:17.147430: Pseudo dice [np.float32(0.8302)] 
2025-06-04 19:20:17.160961: Epoch time: 136.6 s 
2025-06-04 19:20:23.936935:  
2025-06-04 19:20:24.160494: Epoch 647 
2025-06-04 19:20:24.248810: Current learning rate: 0.00392 
2025-06-04 19:22:35.700722: train_loss -0.7243 
2025-06-04 19:22:35.718349: val_loss -0.7241 
2025-06-04 19:22:35.731096: Pseudo dice [np.float32(0.8675)] 
2025-06-04 19:22:35.743956: Epoch time: 131.77 s 
2025-06-04 19:22:44.288244:  
2025-06-04 19:22:44.569793: Epoch 648 
2025-06-04 19:22:44.775398: Current learning rate: 0.00391 
2025-06-04 19:24:58.373286: train_loss -0.7506 
2025-06-04 19:24:58.735640: val_loss -0.7009 
2025-06-04 19:24:58.943506: Pseudo dice [np.float32(0.7511)] 
2025-06-04 19:24:58.962970: Epoch time: 134.09 s 
2025-06-04 19:25:04.405174:  
2025-06-04 19:25:04.596090: Epoch 649 
2025-06-04 19:25:04.783468: Current learning rate: 0.0039 
2025-06-04 19:27:17.818821: train_loss -0.7126 
2025-06-04 19:27:17.836287: val_loss -0.6872 
2025-06-04 19:27:17.850193: Pseudo dice [np.float32(0.7948)] 
2025-06-04 19:27:17.863411: Epoch time: 133.42 s 
2025-06-04 19:27:26.606972:  
2025-06-04 19:27:26.835053: Epoch 650 
2025-06-04 19:27:27.210255: Current learning rate: 0.00389 
2025-06-04 19:29:44.999079: train_loss -0.7234 
2025-06-04 19:29:45.018006: val_loss -0.6456 
2025-06-04 19:29:45.176992: Pseudo dice [np.float32(0.7583)] 
2025-06-04 19:29:45.564271: Epoch time: 138.39 s 
2025-06-04 19:29:53.780070:  
2025-06-04 19:29:53.973258: Epoch 651 
2025-06-04 19:29:53.988939: Current learning rate: 0.00388 
2025-06-04 19:32:16.314419: train_loss -0.7032 
2025-06-04 19:32:16.517881: val_loss -0.6676 
2025-06-04 19:32:16.531814: Pseudo dice [np.float32(0.8256)] 
2025-06-04 19:32:16.946274: Epoch time: 142.54 s 
2025-06-04 19:32:23.675503:  
2025-06-04 19:32:24.087412: Epoch 652 
2025-06-04 19:32:24.534469: Current learning rate: 0.00387 
2025-06-04 19:34:43.649771: train_loss -0.7143 
2025-06-04 19:34:44.219800: val_loss -0.6513 
2025-06-04 19:34:44.621920: Pseudo dice [np.float32(0.7486)] 
2025-06-04 19:34:44.806938: Epoch time: 139.98 s 
2025-06-04 19:34:50.047760:  
2025-06-04 19:34:50.262204: Epoch 653 
2025-06-04 19:34:50.277503: Current learning rate: 0.00386 
2025-06-04 19:37:12.621217: train_loss -0.7203 
2025-06-04 19:37:12.645158: val_loss -0.6448 
2025-06-04 19:37:12.658399: Pseudo dice [np.float32(0.7434)] 
2025-06-04 19:37:12.670600: Epoch time: 142.58 s 
2025-06-04 19:37:20.202002:  
2025-06-04 19:37:20.515131: Epoch 654 
2025-06-04 19:37:20.684411: Current learning rate: 0.00385 
2025-06-04 19:39:44.229068: train_loss -0.7401 
2025-06-04 19:39:44.664869: val_loss -0.6751 
2025-06-04 19:39:45.129614: Pseudo dice [np.float32(0.7472)] 
2025-06-04 19:39:45.547578: Epoch time: 144.03 s 
2025-06-04 19:39:51.522738:  
2025-06-04 19:39:51.557147: Epoch 655 
2025-06-04 19:39:51.573904: Current learning rate: 0.00384 
2025-06-04 19:42:13.479708: train_loss -0.7186 
2025-06-04 19:42:13.498775: val_loss -0.6666 
2025-06-04 19:42:13.512549: Pseudo dice [np.float32(0.757)] 
2025-06-04 19:42:13.525828: Epoch time: 141.96 s 
2025-06-04 19:42:19.744155:  
2025-06-04 19:42:20.027883: Epoch 656 
2025-06-04 19:42:20.309601: Current learning rate: 0.00383 
2025-06-04 19:44:38.465375: train_loss -0.7004 
2025-06-04 19:44:38.489946: val_loss -0.6633 
2025-06-04 19:44:38.636643: Pseudo dice [np.float32(0.7155)] 
2025-06-04 19:44:38.689628: Epoch time: 138.72 s 
2025-06-04 19:44:46.022566:  
2025-06-04 19:44:46.446667: Epoch 657 
2025-06-04 19:44:46.833416: Current learning rate: 0.00382 
2025-06-04 19:47:04.251724: train_loss -0.7323 
2025-06-04 19:47:04.271564: val_loss -0.6934 
2025-06-04 19:47:04.285296: Pseudo dice [np.float32(0.7397)] 
2025-06-04 19:47:04.297535: Epoch time: 138.23 s 
2025-06-04 19:47:12.593708:  
2025-06-04 19:47:12.828979: Epoch 658 
2025-06-04 19:47:13.192715: Current learning rate: 0.00381 
2025-06-04 19:49:32.909410: train_loss -0.7044 
2025-06-04 19:49:33.243055: val_loss -0.7324 
2025-06-04 19:49:33.682920: Pseudo dice [np.float32(0.8812)] 
2025-06-04 19:49:33.698735: Epoch time: 140.32 s 
2025-06-04 19:49:37.915752:  
2025-06-04 19:49:37.932654: Epoch 659 
2025-06-04 19:49:37.946826: Current learning rate: 0.0038 
2025-06-04 19:51:55.425785: train_loss -0.7527 
2025-06-04 19:51:55.442438: val_loss -0.6892 
2025-06-04 19:51:55.456264: Pseudo dice [np.float32(0.7935)] 
2025-06-04 19:51:55.471073: Epoch time: 137.51 s 
2025-06-04 19:52:01.579887:  
2025-06-04 19:52:01.934963: Epoch 660 
2025-06-04 19:52:02.180541: Current learning rate: 0.00379 
2025-06-04 19:54:27.832738: train_loss -0.7611 
2025-06-04 19:54:27.854252: val_loss -0.6628 
2025-06-04 19:54:27.886504: Pseudo dice [np.float32(0.7792)] 
2025-06-04 19:54:27.918431: Epoch time: 146.26 s 
2025-06-04 19:54:35.591200:  
2025-06-04 19:54:35.725431: Epoch 661 
2025-06-04 19:54:35.741502: Current learning rate: 0.00378 
2025-06-04 19:56:56.660120: train_loss -0.7119 
2025-06-04 19:56:57.236163: val_loss -0.7032 
2025-06-04 19:56:57.252377: Pseudo dice [np.float32(0.7672)] 
2025-06-04 19:56:57.266963: Epoch time: 141.07 s 
2025-06-04 19:57:03.455335:  
2025-06-04 19:57:03.618990: Epoch 662 
2025-06-04 19:57:03.755093: Current learning rate: 0.00377 
2025-06-04 19:59:27.565513: train_loss -0.7141 
2025-06-04 19:59:27.787886: val_loss -0.7032 
2025-06-04 19:59:28.000725: Pseudo dice [np.float32(0.7876)] 
2025-06-04 19:59:28.408673: Epoch time: 144.11 s 
2025-06-04 19:59:35.662420:  
2025-06-04 19:59:35.917436: Epoch 663 
2025-06-04 19:59:35.933245: Current learning rate: 0.00376 
2025-06-04 20:02:04.095675: train_loss -0.7357 
2025-06-04 20:02:04.294055: val_loss -0.7079 
2025-06-04 20:02:04.509258: Pseudo dice [np.float32(0.8113)] 
2025-06-04 20:02:04.820084: Epoch time: 148.44 s 
2025-06-04 20:02:11.804951:  
2025-06-04 20:02:12.082263: Epoch 664 
2025-06-04 20:02:12.097961: Current learning rate: 0.00375 
2025-06-04 20:04:34.937697: train_loss -0.7197 
2025-06-04 20:04:35.495028: val_loss -0.7052 
2025-06-04 20:04:35.676747: Pseudo dice [np.float32(0.8459)] 
2025-06-04 20:04:35.695016: Epoch time: 143.13 s 
2025-06-04 20:04:46.532234:  
2025-06-04 20:04:46.765490: Epoch 665 
2025-06-04 20:04:47.024544: Current learning rate: 0.00374 
2025-06-04 20:07:08.421139: train_loss -0.7165 
2025-06-04 20:07:08.439861: val_loss -0.7197 
2025-06-04 20:07:08.453544: Pseudo dice [np.float32(0.7462)] 
2025-06-04 20:07:08.466242: Epoch time: 141.89 s 
2025-06-04 20:07:14.812797:  
2025-06-04 20:07:14.836099: Epoch 666 
2025-06-04 20:07:14.854234: Current learning rate: 0.00373 
2025-06-04 20:09:34.154737: train_loss -0.7335 
2025-06-04 20:09:34.237097: val_loss -0.6967 
2025-06-04 20:09:34.381938: Pseudo dice [np.float32(0.7813)] 
2025-06-04 20:09:34.485217: Epoch time: 139.34 s 
2025-06-04 20:09:36.627073:  
2025-06-04 20:09:36.646586: Epoch 667 
2025-06-04 20:09:36.664122: Current learning rate: 0.00372 
2025-06-04 20:11:56.291706: train_loss -0.7431 
2025-06-04 20:11:56.336504: val_loss -0.6691 
2025-06-04 20:11:56.355813: Pseudo dice [np.float32(0.7183)] 
2025-06-04 20:11:56.380990: Epoch time: 139.67 s 
2025-06-04 20:11:58.341266:  
2025-06-04 20:11:58.575213: Epoch 668 
2025-06-04 20:11:58.593555: Current learning rate: 0.00371 
2025-06-04 20:14:20.768419: train_loss -0.7418 
2025-06-04 20:14:20.784367: val_loss -0.6629 
2025-06-04 20:14:20.797572: Pseudo dice [np.float32(0.7218)] 
2025-06-04 20:14:20.811146: Epoch time: 142.43 s 
2025-06-04 20:14:23.378975:  
2025-06-04 20:14:23.406281: Epoch 669 
2025-06-04 20:14:23.421592: Current learning rate: 0.0037 
2025-06-04 20:16:43.932400: train_loss -0.7219 
2025-06-04 20:16:44.068092: val_loss -0.6587 
2025-06-04 20:16:44.169370: Pseudo dice [np.float32(0.7362)] 
2025-06-04 20:16:44.283377: Epoch time: 140.56 s 
2025-06-04 20:16:50.474691:  
2025-06-04 20:16:50.822592: Epoch 670 
2025-06-04 20:16:51.101640: Current learning rate: 0.00369 
2025-06-04 20:19:15.923041: train_loss -0.7179 
2025-06-04 20:19:16.109899: val_loss -0.6689 
2025-06-04 20:19:16.304048: Pseudo dice [np.float32(0.8269)] 
2025-06-04 20:19:16.504628: Epoch time: 145.45 s 
2025-06-04 20:19:21.562059:  
2025-06-04 20:19:21.589479: Epoch 671 
2025-06-04 20:19:21.614274: Current learning rate: 0.00368 
2025-06-04 20:21:28.846332: train_loss -0.7166 
2025-06-04 20:21:29.247736: val_loss -0.6385 
2025-06-04 20:21:29.495244: Pseudo dice [np.float32(0.771)] 
2025-06-04 20:21:29.807012: Epoch time: 127.29 s 
2025-06-04 20:21:38.035621:  
2025-06-04 20:21:38.269891: Epoch 672 
2025-06-04 20:21:38.596101: Current learning rate: 0.00367 
2025-06-04 20:23:37.140808: train_loss -0.7334 
2025-06-04 20:23:37.164907: val_loss -0.6818 
2025-06-04 20:23:37.183768: Pseudo dice [np.float32(0.7522)] 
2025-06-04 20:23:37.198830: Epoch time: 119.11 s 
2025-06-04 20:23:44.236093:  
2025-06-04 20:23:44.536139: Epoch 673 
2025-06-04 20:23:44.552102: Current learning rate: 0.00366 
2025-06-04 20:26:07.607349: train_loss -0.7438 
2025-06-04 20:26:07.914038: val_loss -0.6942 
2025-06-04 20:26:07.931421: Pseudo dice [np.float32(0.7855)] 
2025-06-04 20:26:07.945847: Epoch time: 143.37 s 
2025-06-04 20:26:14.871921:  
2025-06-04 20:26:14.904090: Epoch 674 
2025-06-04 20:26:14.920796: Current learning rate: 0.00365 
2025-06-04 20:28:25.828558: train_loss -0.7456 
2025-06-04 20:28:25.998799: val_loss -0.6986 
2025-06-04 20:28:26.015865: Pseudo dice [np.float32(0.8411)] 
2025-06-04 20:28:26.028785: Epoch time: 130.96 s 
2025-06-04 20:28:31.389780:  
2025-06-04 20:28:31.412234: Epoch 675 
2025-06-04 20:28:31.427155: Current learning rate: 0.00364 
2025-06-04 20:30:49.182582: train_loss -0.722 
2025-06-04 20:30:49.515324: val_loss -0.6202 
2025-06-04 20:30:49.948788: Pseudo dice [np.float32(0.6502)] 
2025-06-04 20:30:49.964063: Epoch time: 137.79 s 
2025-06-04 20:30:57.521630:  
2025-06-04 20:30:57.724347: Epoch 676 
2025-06-04 20:30:57.916433: Current learning rate: 0.00363 
2025-06-04 20:33:19.217908: train_loss -0.6894 
2025-06-04 20:33:19.805486: val_loss -0.6875 
2025-06-04 20:33:20.169368: Pseudo dice [np.float32(0.8368)] 
2025-06-04 20:33:20.540274: Epoch time: 141.7 s 
2025-06-04 20:33:24.629661:  
2025-06-04 20:33:24.862358: Epoch 677 
2025-06-04 20:33:25.138240: Current learning rate: 0.00362 
2025-06-04 20:35:48.542130: train_loss -0.7252 
2025-06-04 20:35:48.743367: val_loss -0.6894 
2025-06-04 20:35:49.190929: Pseudo dice [np.float32(0.8088)] 
2025-06-04 20:35:49.629350: Epoch time: 143.91 s 
2025-06-04 20:35:57.023783:  
2025-06-04 20:35:57.277396: Epoch 678 
2025-06-04 20:35:57.431722: Current learning rate: 0.00361 
2025-06-04 20:38:19.815156: train_loss -0.726 
2025-06-04 20:38:20.153868: val_loss -0.6959 
2025-06-04 20:38:20.170241: Pseudo dice [np.float32(0.794)] 
2025-06-04 20:38:20.185853: Epoch time: 142.79 s 
2025-06-04 20:38:26.027443:  
2025-06-04 20:38:26.335418: Epoch 679 
2025-06-04 20:38:26.573091: Current learning rate: 0.0036 
2025-06-04 20:40:45.534710: train_loss -0.7162 
2025-06-04 20:40:45.557385: val_loss -0.7144 
2025-06-04 20:40:45.571503: Pseudo dice [np.float32(0.8453)] 
2025-06-04 20:40:45.585130: Epoch time: 139.51 s 
2025-06-04 20:40:51.920188:  
2025-06-04 20:40:52.126663: Epoch 680 
2025-06-04 20:40:52.335107: Current learning rate: 0.00359 
2025-06-04 20:43:16.535601: train_loss -0.7352 
2025-06-04 20:43:16.554945: val_loss -0.6886 
2025-06-04 20:43:16.568181: Pseudo dice [np.float32(0.8284)] 
2025-06-04 20:43:16.581011: Epoch time: 144.62 s 
2025-06-04 20:43:22.471685:  
2025-06-04 20:43:22.703477: Epoch 681 
2025-06-04 20:43:22.936523: Current learning rate: 0.00358 
2025-06-04 20:45:46.597642: train_loss -0.704 
2025-06-04 20:45:46.618578: val_loss -0.7062 
2025-06-04 20:45:46.633364: Pseudo dice [np.float32(0.8239)] 
2025-06-04 20:45:46.647613: Epoch time: 144.13 s 
2025-06-04 20:45:53.250161:  
2025-06-04 20:45:53.434245: Epoch 682 
2025-06-04 20:45:53.651274: Current learning rate: 0.00357 
2025-06-04 20:48:15.578027: train_loss -0.7213 
2025-06-04 20:48:15.913522: val_loss -0.6977 
2025-06-04 20:48:16.116526: Pseudo dice [np.float32(0.7808)] 
2025-06-04 20:48:16.132365: Epoch time: 142.33 s 
2025-06-04 20:48:22.039293:  
2025-06-04 20:48:22.287721: Epoch 683 
2025-06-04 20:48:22.734998: Current learning rate: 0.00356 
2025-06-04 20:50:45.660685: train_loss -0.7305 
2025-06-04 20:50:45.680960: val_loss -0.7309 
2025-06-04 20:50:45.694817: Pseudo dice [np.float32(0.7958)] 
2025-06-04 20:50:45.709084: Epoch time: 143.62 s 
2025-06-04 20:50:54.195004:  
2025-06-04 20:50:54.334371: Epoch 684 
2025-06-04 20:50:54.350851: Current learning rate: 0.00355 
2025-06-04 20:53:23.055541: train_loss -0.7218 
2025-06-04 20:53:23.442283: val_loss -0.7249 
2025-06-04 20:53:23.709023: Pseudo dice [np.float32(0.7739)] 
2025-06-04 20:53:24.279238: Epoch time: 148.86 s 
2025-06-04 20:53:31.117953:  
2025-06-04 20:53:31.130559: Epoch 685 
2025-06-04 20:53:31.140267: Current learning rate: 0.00354 
2025-06-04 20:55:49.180032: train_loss -0.7322 
2025-06-04 20:55:49.352643: val_loss -0.6174 
2025-06-04 20:55:49.423936: Pseudo dice [np.float32(0.6778)] 
2025-06-04 20:55:49.473435: Epoch time: 138.06 s 
2025-06-04 20:55:55.610211:  
2025-06-04 20:55:56.030278: Epoch 686 
2025-06-04 20:55:56.416073: Current learning rate: 0.00353 
2025-06-04 20:58:16.375017: train_loss -0.7273 
2025-06-04 20:58:16.395144: val_loss -0.6551 
2025-06-04 20:58:16.410957: Pseudo dice [np.float32(0.8162)] 
2025-06-04 20:58:16.427571: Epoch time: 140.77 s 
2025-06-04 20:58:23.504933:  
2025-06-04 20:58:23.538494: Epoch 687 
2025-06-04 20:58:23.555892: Current learning rate: 0.00352 
2025-06-04 21:00:43.360940: train_loss -0.7099 
2025-06-04 21:00:43.729842: val_loss -0.692 
2025-06-04 21:00:43.899141: Pseudo dice [np.float32(0.7721)] 
2025-06-04 21:00:43.914642: Epoch time: 139.86 s 
2025-06-04 21:00:50.143435:  
2025-06-04 21:00:50.241382: Epoch 688 
2025-06-04 21:00:50.361447: Current learning rate: 0.00351 
2025-06-04 21:03:07.393907: train_loss -0.7196 
2025-06-04 21:03:07.410289: val_loss -0.6808 
2025-06-04 21:03:07.425583: Pseudo dice [np.float32(0.7692)] 
2025-06-04 21:03:07.438382: Epoch time: 137.25 s 
2025-06-04 21:03:13.599159:  
2025-06-04 21:03:13.887528: Epoch 689 
2025-06-04 21:03:14.240246: Current learning rate: 0.0035 
2025-06-04 21:05:36.473249: train_loss -0.7143 
2025-06-04 21:05:36.489384: val_loss -0.7001 
2025-06-04 21:05:36.503704: Pseudo dice [np.float32(0.7975)] 
2025-06-04 21:05:36.516263: Epoch time: 142.88 s 
2025-06-04 21:05:43.852544:  
2025-06-04 21:05:43.871714: Epoch 690 
2025-06-04 21:05:43.888521: Current learning rate: 0.00349 
2025-06-04 21:08:10.220093: train_loss -0.7269 
2025-06-04 21:08:10.553981: val_loss -0.7272 
2025-06-04 21:08:10.921262: Pseudo dice [np.float32(0.7094)] 
2025-06-04 21:08:11.414282: Epoch time: 146.37 s 
2025-06-04 21:08:18.331920:  
2025-06-04 21:08:18.661916: Epoch 691 
2025-06-04 21:08:19.126052: Current learning rate: 0.00348 
2025-06-04 21:10:45.969552: train_loss -0.7228 
2025-06-04 21:10:46.257434: val_loss -0.7435 
2025-06-04 21:10:46.637636: Pseudo dice [np.float32(0.8328)] 
2025-06-04 21:10:47.055884: Epoch time: 147.64 s 
2025-06-04 21:10:54.388106:  
2025-06-04 21:10:54.406402: Epoch 692 
2025-06-04 21:10:54.420074: Current learning rate: 0.00346 
2025-06-04 21:13:18.996906: train_loss -0.7299 
2025-06-04 21:13:19.321918: val_loss -0.707 
2025-06-04 21:13:19.336919: Pseudo dice [np.float32(0.8073)] 
2025-06-04 21:13:19.350386: Epoch time: 144.61 s 
2025-06-04 21:13:29.591411:  
2025-06-04 21:13:29.911333: Epoch 693 
2025-06-04 21:13:30.230055: Current learning rate: 0.00345 
2025-06-04 21:15:50.901567: train_loss -0.7568 
2025-06-04 21:15:51.119677: val_loss -0.6636 
2025-06-04 21:15:51.575149: Pseudo dice [np.float32(0.8023)] 
2025-06-04 21:15:52.065343: Epoch time: 141.31 s 
2025-06-04 21:15:58.866323:  
2025-06-04 21:15:58.957210: Epoch 694 
2025-06-04 21:15:59.143962: Current learning rate: 0.00344 
2025-06-04 21:18:20.948433: train_loss -0.7164 
2025-06-04 21:18:20.975302: val_loss -0.734 
2025-06-04 21:18:20.990877: Pseudo dice [np.float32(0.8069)] 
2025-06-04 21:18:21.005952: Epoch time: 142.09 s 
2025-06-04 21:18:26.813034:  
2025-06-04 21:18:27.222797: Epoch 695 
2025-06-04 21:18:27.528467: Current learning rate: 0.00343 
2025-06-04 21:20:50.513484: train_loss -0.7268 
2025-06-04 21:20:50.853133: val_loss -0.7176 
2025-06-04 21:20:51.180863: Pseudo dice [np.float32(0.8294)] 
2025-06-04 21:20:51.678586: Epoch time: 143.7 s 
2025-06-04 21:20:59.104456:  
2025-06-04 21:20:59.432990: Epoch 696 
2025-06-04 21:20:59.450459: Current learning rate: 0.00342 
2025-06-04 21:23:24.846208: train_loss -0.7387 
2025-06-04 21:23:25.443177: val_loss -0.5795 
2025-06-04 21:23:25.458891: Pseudo dice [np.float32(0.7062)] 
2025-06-04 21:23:25.471668: Epoch time: 145.74 s 
2025-06-04 21:23:33.122532:  
2025-06-04 21:23:33.322782: Epoch 697 
2025-06-04 21:23:33.469204: Current learning rate: 0.00341 
2025-06-04 21:25:58.171923: train_loss -0.729 
2025-06-04 21:25:58.554420: val_loss -0.6728 
2025-06-04 21:25:59.207227: Pseudo dice [np.float32(0.7663)] 
2025-06-04 21:25:59.601288: Epoch time: 145.05 s 
2025-06-04 21:26:05.380230:  
2025-06-04 21:26:05.823278: Epoch 698 
2025-06-04 21:26:05.838724: Current learning rate: 0.0034 
2025-06-04 21:28:25.487379: train_loss -0.7166 
2025-06-04 21:28:25.510648: val_loss -0.7258 
2025-06-04 21:28:25.530196: Pseudo dice [np.float32(0.8396)] 
2025-06-04 21:28:25.543628: Epoch time: 140.11 s 
2025-06-04 21:28:34.100099:  
2025-06-04 21:28:34.353991: Epoch 699 
2025-06-04 21:28:34.371529: Current learning rate: 0.00339 
2025-06-04 21:30:54.431396: train_loss -0.7309 
2025-06-04 21:30:54.931316: val_loss -0.7096 
2025-06-04 21:30:54.947218: Pseudo dice [np.float32(0.7948)] 
2025-06-04 21:30:54.959848: Epoch time: 140.33 s 
2025-06-04 21:31:07.855302:  
2025-06-04 21:31:08.220555: Epoch 700 
2025-06-04 21:31:08.446517: Current learning rate: 0.00338 
2025-06-04 21:33:27.438215: train_loss -0.7363 
2025-06-04 21:33:27.455427: val_loss -0.7349 
2025-06-04 21:33:27.468321: Pseudo dice [np.float32(0.8245)] 
2025-06-04 21:33:27.481155: Epoch time: 139.59 s 
2025-06-04 21:33:30.141032:  
2025-06-04 21:33:30.155997: Epoch 701 
2025-06-04 21:33:30.165922: Current learning rate: 0.00337 
2025-06-04 21:35:49.019353: train_loss -0.7354 
2025-06-04 21:35:49.225361: val_loss -0.6774 
2025-06-04 21:35:49.408803: Pseudo dice [np.float32(0.7843)] 
2025-06-04 21:35:49.424558: Epoch time: 138.88 s 
2025-06-04 21:35:52.258152:  
2025-06-04 21:35:52.277260: Epoch 702 
2025-06-04 21:35:52.292697: Current learning rate: 0.00336 
2025-06-04 21:38:10.116819: train_loss -0.743 
2025-06-04 21:38:10.134618: val_loss -0.7284 
2025-06-04 21:38:10.146845: Pseudo dice [np.float32(0.8418)] 
2025-06-04 21:38:10.159106: Epoch time: 137.86 s 
2025-06-04 21:38:12.909240:  
2025-06-04 21:38:12.950396: Epoch 703 
2025-06-04 21:38:12.966483: Current learning rate: 0.00335 
2025-06-04 21:40:31.705544: train_loss -0.7372 
2025-06-04 21:40:31.843289: val_loss -0.6897 
2025-06-04 21:40:32.036188: Pseudo dice [np.float32(0.7366)] 
2025-06-04 21:40:32.277305: Epoch time: 138.8 s 
2025-06-04 21:40:36.120167:  
2025-06-04 21:40:36.374922: Epoch 704 
2025-06-04 21:40:36.709913: Current learning rate: 0.00334 
2025-06-04 21:42:53.556022: train_loss -0.7328 
2025-06-04 21:42:53.576361: val_loss -0.714 
2025-06-04 21:42:53.594044: Pseudo dice [np.float32(0.8372)] 
2025-06-04 21:42:53.612021: Epoch time: 137.44 s 
2025-06-04 21:42:59.008967:  
2025-06-04 21:42:59.272909: Epoch 705 
2025-06-04 21:42:59.722576: Current learning rate: 0.00333 
2025-06-04 21:45:17.164458: train_loss -0.7467 
2025-06-04 21:45:17.182104: val_loss -0.6592 
2025-06-04 21:45:17.195024: Pseudo dice [np.float32(0.7461)] 
2025-06-04 21:45:17.208076: Epoch time: 138.16 s 
2025-06-04 21:45:24.251978:  
2025-06-04 21:45:24.271340: Epoch 706 
2025-06-04 21:45:24.287510: Current learning rate: 0.00332 
2025-06-04 21:47:39.021842: train_loss -0.75 
2025-06-04 21:47:39.041598: val_loss -0.6743 
2025-06-04 21:47:39.055429: Pseudo dice [np.float32(0.7928)] 
2025-06-04 21:47:39.070775: Epoch time: 134.77 s 
2025-06-04 21:47:48.123270:  
2025-06-04 21:47:48.668513: Epoch 707 
2025-06-04 21:47:49.065527: Current learning rate: 0.00331 
2025-06-04 21:50:07.302605: train_loss -0.7117 
2025-06-04 21:50:07.321400: val_loss -0.7275 
2025-06-04 21:50:07.335614: Pseudo dice [np.float32(0.7852)] 
2025-06-04 21:50:07.349331: Epoch time: 139.18 s 
2025-06-04 21:50:15.547478:  
2025-06-04 21:50:15.882053: Epoch 708 
2025-06-04 21:50:16.141009: Current learning rate: 0.0033 
2025-06-04 21:52:36.514149: train_loss -0.7315 
2025-06-04 21:52:36.531939: val_loss -0.7464 
2025-06-04 21:52:36.545557: Pseudo dice [np.float32(0.8318)] 
2025-06-04 21:52:36.559185: Epoch time: 140.97 s 
2025-06-04 21:52:44.457436:  
2025-06-04 21:52:44.786272: Epoch 709 
2025-06-04 21:52:45.191395: Current learning rate: 0.00329 
2025-06-04 21:55:05.458886: train_loss -0.7026 
2025-06-04 21:55:06.006650: val_loss -0.7119 
2025-06-04 21:55:06.453032: Pseudo dice [np.float32(0.7359)] 
2025-06-04 21:55:06.962113: Epoch time: 141.0 s 
2025-06-04 21:55:13.941818:  
2025-06-04 21:55:14.070814: Epoch 710 
2025-06-04 21:55:14.164919: Current learning rate: 0.00328 
2025-06-04 21:57:36.258601: train_loss -0.7349 
2025-06-04 21:57:36.277728: val_loss -0.6821 
2025-06-04 21:57:36.291017: Pseudo dice [np.float32(0.7703)] 
2025-06-04 21:57:36.304388: Epoch time: 142.32 s 
2025-06-04 21:57:43.066408:  
2025-06-04 21:57:43.213615: Epoch 711 
2025-06-04 21:57:43.327940: Current learning rate: 0.00327 
2025-06-04 22:00:01.033590: train_loss -0.7207 
2025-06-04 22:00:01.440338: val_loss -0.778 
2025-06-04 22:00:01.874655: Pseudo dice [np.float32(0.8226)] 
2025-06-04 22:00:02.186359: Epoch time: 137.97 s 
2025-06-04 22:00:08.568614:  
2025-06-04 22:00:08.588841: Epoch 712 
2025-06-04 22:00:08.651561: Current learning rate: 0.00326 
2025-06-04 22:02:30.001342: train_loss -0.7225 
2025-06-04 22:02:30.026334: val_loss -0.6632 
2025-06-04 22:02:30.370863: Pseudo dice [np.float32(0.7488)] 
2025-06-04 22:02:30.601771: Epoch time: 141.43 s 
2025-06-04 22:02:38.074780:  
2025-06-04 22:02:38.367128: Epoch 713 
2025-06-04 22:02:38.382497: Current learning rate: 0.00325 
2025-06-04 22:04:56.499550: train_loss -0.7445 
2025-06-04 22:04:56.525711: val_loss -0.6517 
2025-06-04 22:04:56.541119: Pseudo dice [np.float32(0.7838)] 
2025-06-04 22:04:56.553962: Epoch time: 138.43 s 
2025-06-04 22:05:03.819482:  
2025-06-04 22:05:03.836961: Epoch 714 
2025-06-04 22:05:03.849678: Current learning rate: 0.00324 
2025-06-04 22:07:20.736590: train_loss -0.7404 
2025-06-04 22:07:21.244482: val_loss -0.6814 
2025-06-04 22:07:21.637801: Pseudo dice [np.float32(0.8371)] 
2025-06-04 22:07:21.654086: Epoch time: 136.92 s 
2025-06-04 22:07:29.041932:  
2025-06-04 22:07:29.239037: Epoch 715 
2025-06-04 22:07:29.484869: Current learning rate: 0.00323 
2025-06-04 22:09:49.099264: train_loss -0.7055 
2025-06-04 22:09:49.236152: val_loss -0.7021 
2025-06-04 22:09:49.513090: Pseudo dice [np.float32(0.7511)] 
2025-06-04 22:09:49.622139: Epoch time: 140.06 s 
2025-06-04 22:09:55.594539:  
2025-06-04 22:09:55.838991: Epoch 716 
2025-06-04 22:09:55.854941: Current learning rate: 0.00322 
2025-06-04 22:12:12.060492: train_loss -0.7446 
2025-06-04 22:12:12.085021: val_loss -0.6691 
2025-06-04 22:12:12.104383: Pseudo dice [np.float32(0.7403)] 
2025-06-04 22:12:12.118995: Epoch time: 136.47 s 
2025-06-04 22:12:17.668246:  
2025-06-04 22:12:17.826588: Epoch 717 
2025-06-04 22:12:17.938532: Current learning rate: 0.00321 
2025-06-04 22:14:35.541448: train_loss -0.7471 
2025-06-04 22:14:35.565138: val_loss -0.7398 
2025-06-04 22:14:35.580490: Pseudo dice [np.float32(0.8461)] 
2025-06-04 22:14:35.594722: Epoch time: 137.87 s 
2025-06-04 22:14:41.686894:  
2025-06-04 22:14:41.705300: Epoch 718 
2025-06-04 22:14:41.722161: Current learning rate: 0.0032 
2025-06-04 22:17:00.450560: train_loss -0.7313 
2025-06-04 22:17:00.476640: val_loss -0.6381 
2025-06-04 22:17:00.491893: Pseudo dice [np.float32(0.6719)] 
2025-06-04 22:17:00.507141: Epoch time: 138.87 s 
2025-06-04 22:17:08.475012:  
2025-06-04 22:17:08.577661: Epoch 719 
2025-06-04 22:17:08.686288: Current learning rate: 0.00319 
2025-06-04 22:19:26.101131: train_loss -0.7257 
2025-06-04 22:19:26.306155: val_loss -0.6858 
2025-06-04 22:19:26.327493: Pseudo dice [np.float32(0.779)] 
2025-06-04 22:19:26.824208: Epoch time: 137.63 s 
2025-06-04 22:19:34.490780:  
2025-06-04 22:19:34.508768: Epoch 720 
2025-06-04 22:19:34.522105: Current learning rate: 0.00318 
2025-06-04 22:21:54.348619: train_loss -0.707 
2025-06-04 22:21:54.614094: val_loss -0.6782 
2025-06-04 22:21:54.992828: Pseudo dice [np.float32(0.7606)] 
2025-06-04 22:21:55.236526: Epoch time: 139.86 s 
2025-06-04 22:22:02.668776:  
2025-06-04 22:22:02.681475: Epoch 721 
2025-06-04 22:22:02.690950: Current learning rate: 0.00317 
2025-06-04 22:24:15.656960: train_loss -0.7385 
2025-06-04 22:24:15.674623: val_loss -0.6992 
2025-06-04 22:24:15.687382: Pseudo dice [np.float32(0.8109)] 
2025-06-04 22:24:15.700357: Epoch time: 132.99 s 
2025-06-04 22:24:17.716613:  
2025-06-04 22:24:17.734460: Epoch 722 
2025-06-04 22:24:17.747720: Current learning rate: 0.00316 
2025-06-04 22:26:29.701787: train_loss -0.7223 
2025-06-04 22:26:29.787650: val_loss -0.7035 
2025-06-04 22:26:29.808240: Pseudo dice [np.float32(0.8101)] 
2025-06-04 22:26:29.827235: Epoch time: 131.99 s 
2025-06-04 22:26:32.077723:  
2025-06-04 22:26:32.133480: Epoch 723 
2025-06-04 22:26:32.190556: Current learning rate: 0.00315 
2025-06-04 22:28:45.467755: train_loss -0.7305 
2025-06-04 22:28:45.540144: val_loss -0.6907 
2025-06-04 22:28:45.577857: Pseudo dice [np.float32(0.8282)] 
2025-06-04 22:28:45.591669: Epoch time: 133.39 s 
2025-06-04 22:28:51.309523:  
2025-06-04 22:28:51.328490: Epoch 724 
2025-06-04 22:28:51.343971: Current learning rate: 0.00314 
2025-06-04 22:31:00.754893: train_loss -0.7382 
2025-06-04 22:31:00.843163: val_loss -0.6786 
2025-06-04 22:31:00.860024: Pseudo dice [np.float32(0.8364)] 
2025-06-04 22:31:00.873701: Epoch time: 129.45 s 
2025-06-04 22:31:06.590528:  
2025-06-04 22:31:06.608984: Epoch 725 
2025-06-04 22:31:06.623518: Current learning rate: 0.00313 
2025-06-04 22:33:11.830203: train_loss -0.7203 
2025-06-04 22:33:12.072649: val_loss -0.7258 
2025-06-04 22:33:12.322963: Pseudo dice [np.float32(0.8351)] 
2025-06-04 22:33:12.586007: Epoch time: 125.24 s 
2025-06-04 22:33:18.338990:  
2025-06-04 22:33:18.428164: Epoch 726 
2025-06-04 22:33:18.564381: Current learning rate: 0.00312 
2025-06-04 22:35:25.360718: train_loss -0.7395 
2025-06-04 22:35:25.537736: val_loss -0.6875 
2025-06-04 22:35:25.553963: Pseudo dice [np.float32(0.7543)] 
2025-06-04 22:35:25.568667: Epoch time: 127.02 s 
2025-06-04 22:35:28.309677:  
2025-06-04 22:35:28.323440: Epoch 727 
2025-06-04 22:35:28.334146: Current learning rate: 0.00311 
2025-06-04 22:37:02.364324: train_loss -0.7451 
2025-06-04 22:37:02.379116: val_loss -0.6562 
2025-06-04 22:37:02.391385: Pseudo dice [np.float32(0.7501)] 
2025-06-04 22:37:02.404223: Epoch time: 94.06 s 
2025-06-04 22:37:05.180340:  
2025-06-04 22:37:05.197259: Epoch 728 
2025-06-04 22:37:05.212945: Current learning rate: 0.0031 
2025-06-04 22:38:36.173611: train_loss -0.7206 
2025-06-04 22:38:36.193724: val_loss -0.6989 
2025-06-04 22:38:36.208037: Pseudo dice [np.float32(0.8008)] 
2025-06-04 22:38:36.220476: Epoch time: 90.99 s 
2025-06-04 22:38:37.830809:  
2025-06-04 22:38:37.842050: Epoch 729 
2025-06-04 22:38:37.852291: Current learning rate: 0.00309 
2025-06-04 22:39:44.649433: train_loss -0.7267 
2025-06-04 22:39:44.745031: val_loss -0.6587 
2025-06-04 22:39:44.758792: Pseudo dice [np.float32(0.7682)] 
2025-06-04 22:39:44.771624: Epoch time: 66.82 s 
2025-06-04 22:39:46.257764:  
2025-06-04 22:39:46.281921: Epoch 730 
2025-06-04 22:39:46.291328: Current learning rate: 0.00308 
2025-06-04 22:40:53.107251: train_loss -0.7342 
2025-06-04 22:40:53.174505: val_loss -0.6986 
2025-06-04 22:40:53.897026: Pseudo dice [np.float32(0.8214)] 
2025-06-04 22:40:53.951471: Epoch time: 66.85 s 
2025-06-04 22:40:55.049327:  
2025-06-04 22:40:55.075523: Epoch 731 
2025-06-04 22:40:55.084548: Current learning rate: 0.00307 
2025-06-04 22:42:01.873598: train_loss -0.753 
2025-06-04 22:42:01.962948: val_loss -0.6933 
2025-06-04 22:42:02.049989: Pseudo dice [np.float32(0.7851)] 
2025-06-04 22:42:02.146194: Epoch time: 66.83 s 
2025-06-04 22:42:03.564198:  
2025-06-04 22:42:03.578926: Epoch 732 
2025-06-04 22:42:03.590668: Current learning rate: 0.00306 
2025-06-04 22:43:10.562213: train_loss -0.7443 
2025-06-04 22:43:10.613618: val_loss -0.719 
2025-06-04 22:43:10.647622: Pseudo dice [np.float32(0.8407)] 
2025-06-04 22:43:10.678401: Epoch time: 67.0 s 
2025-06-04 22:43:11.993666:  
2025-06-04 22:43:12.022127: Epoch 733 
2025-06-04 22:43:12.030751: Current learning rate: 0.00305 
2025-06-04 22:44:18.436979: train_loss -0.7418 
2025-06-04 22:44:18.548584: val_loss -0.6962 
2025-06-04 22:44:18.631305: Pseudo dice [np.float32(0.7526)] 
2025-06-04 22:44:18.646104: Epoch time: 66.44 s 
2025-06-04 22:44:20.046757:  
2025-06-04 22:44:20.065704: Epoch 734 
2025-06-04 22:44:20.074606: Current learning rate: 0.00304 
2025-06-04 22:45:26.680601: train_loss -0.7151 
2025-06-04 22:45:26.699128: val_loss -0.6734 
2025-06-04 22:45:26.712874: Pseudo dice [np.float32(0.8272)] 
2025-06-04 22:45:26.726646: Epoch time: 66.63 s 
2025-06-04 22:45:28.375170:  
2025-06-04 22:45:28.395776: Epoch 735 
2025-06-04 22:45:28.415879: Current learning rate: 0.00303 
2025-06-04 22:46:35.092896: train_loss -0.726 
2025-06-04 22:46:35.110765: val_loss -0.6672 
2025-06-04 22:46:35.124531: Pseudo dice [np.float32(0.7538)] 
2025-06-04 22:46:35.136280: Epoch time: 66.72 s 
2025-06-04 22:46:36.631465:  
2025-06-04 22:46:36.654917: Epoch 736 
2025-06-04 22:46:36.664524: Current learning rate: 0.00302 
2025-06-04 22:47:42.763837: train_loss -0.7355 
2025-06-04 22:47:42.886353: val_loss -0.6837 
2025-06-04 22:47:42.956386: Pseudo dice [np.float32(0.7525)] 
2025-06-04 22:47:42.982270: Epoch time: 66.13 s 
2025-06-04 22:47:44.324681:  
2025-06-04 22:47:44.334776: Epoch 737 
2025-06-04 22:47:44.345218: Current learning rate: 0.00301 
2025-06-04 22:48:51.409537: train_loss -0.7306 
2025-06-04 22:48:51.427142: val_loss -0.6457 
2025-06-04 22:48:51.441228: Pseudo dice [np.float32(0.7256)] 
2025-06-04 22:48:51.454849: Epoch time: 67.09 s 
2025-06-04 22:48:53.195076:  
2025-06-04 22:48:53.206298: Epoch 738 
2025-06-04 22:48:53.224799: Current learning rate: 0.003 
2025-06-04 22:49:59.493453: train_loss -0.7512 
2025-06-04 22:49:59.531738: val_loss -0.6576 
2025-06-04 22:49:59.547867: Pseudo dice [np.float32(0.794)] 
2025-06-04 22:49:59.561981: Epoch time: 66.3 s 
2025-06-04 22:50:01.151672:  
2025-06-04 22:50:01.163980: Epoch 739 
2025-06-04 22:50:01.172622: Current learning rate: 0.00299 
2025-06-04 22:51:07.777917: train_loss -0.7385 
2025-06-04 22:51:07.794937: val_loss -0.7282 
2025-06-04 22:51:07.807781: Pseudo dice [np.float32(0.8507)] 
2025-06-04 22:51:07.820616: Epoch time: 66.63 s 
2025-06-04 22:51:09.252443:  
2025-06-04 22:51:09.269625: Epoch 740 
2025-06-04 22:51:09.279011: Current learning rate: 0.00297 
2025-06-04 22:52:15.532660: train_loss -0.7349 
2025-06-04 22:52:15.636621: val_loss -0.688 
2025-06-04 22:52:15.652948: Pseudo dice [np.float32(0.7107)] 
2025-06-04 22:52:15.666751: Epoch time: 66.28 s 
2025-06-04 22:52:17.044351:  
2025-06-04 22:52:17.056896: Epoch 741 
2025-06-04 22:52:17.067030: Current learning rate: 0.00296 
2025-06-04 22:53:23.685961: train_loss -0.7211 
2025-06-04 22:53:23.700764: val_loss -0.655 
2025-06-04 22:53:23.714476: Pseudo dice [np.float32(0.7458)] 
2025-06-04 22:53:23.727727: Epoch time: 66.64 s 
2025-06-04 22:53:25.529822:  
2025-06-04 22:53:25.551487: Epoch 742 
2025-06-04 22:53:25.560930: Current learning rate: 0.00295 
2025-06-04 22:54:31.925805: train_loss -0.7333 
2025-06-04 22:54:31.945089: val_loss -0.652 
2025-06-04 22:54:31.960826: Pseudo dice [np.float32(0.7809)] 
2025-06-04 22:54:31.974060: Epoch time: 66.4 s 
2025-06-04 22:54:33.493514:  
2025-06-04 22:54:33.526708: Epoch 743 
2025-06-04 22:54:33.537766: Current learning rate: 0.00294 
2025-06-04 22:55:40.213625: train_loss -0.7227 
2025-06-04 22:55:40.232945: val_loss -0.6604 
2025-06-04 22:55:40.246762: Pseudo dice [np.float32(0.7657)] 
2025-06-04 22:55:40.260507: Epoch time: 66.72 s 
2025-06-04 22:55:41.749262:  
2025-06-04 22:55:41.781766: Epoch 744 
2025-06-04 22:55:41.793283: Current learning rate: 0.00293 
2025-06-04 22:56:47.718574: train_loss -0.7436 
2025-06-04 22:56:47.739654: val_loss -0.7186 
2025-06-04 22:56:47.754512: Pseudo dice [np.float32(0.7946)] 
2025-06-04 22:56:47.767753: Epoch time: 65.97 s 
2025-06-04 22:56:49.160631:  
2025-06-04 22:56:49.172863: Epoch 745 
2025-06-04 22:56:49.183171: Current learning rate: 0.00292 
2025-06-04 22:57:55.813068: train_loss -0.7524 
2025-06-04 22:57:55.831932: val_loss -0.6923 
2025-06-04 22:57:55.846140: Pseudo dice [np.float32(0.8007)] 
2025-06-04 22:57:55.858366: Epoch time: 66.65 s 
2025-06-04 22:57:57.329558:  
2025-06-04 22:57:57.353724: Epoch 746 
2025-06-04 22:57:57.362409: Current learning rate: 0.00291 
2025-06-04 22:59:04.022319: train_loss -0.7443 
2025-06-04 22:59:04.039545: val_loss -0.6515 
2025-06-04 22:59:04.053511: Pseudo dice [np.float32(0.7588)] 
2025-06-04 22:59:04.068386: Epoch time: 66.69 s 
2025-06-04 22:59:05.623316:  
2025-06-04 22:59:05.646981: Epoch 747 
2025-06-04 22:59:05.657104: Current learning rate: 0.0029 
2025-06-04 23:00:11.939829: train_loss -0.7405 
2025-06-04 23:00:12.039802: val_loss -0.6482 
2025-06-04 23:00:12.081977: Pseudo dice [np.float32(0.729)] 
2025-06-04 23:00:12.096208: Epoch time: 66.32 s 
2025-06-04 23:00:13.606262:  
2025-06-04 23:00:13.620007: Epoch 748 
2025-06-04 23:00:13.628678: Current learning rate: 0.00289 
2025-06-04 23:01:20.581130: train_loss -0.7268 
2025-06-04 23:01:20.597096: val_loss -0.7002 
2025-06-04 23:01:20.609974: Pseudo dice [np.float32(0.7428)] 
2025-06-04 23:01:20.623866: Epoch time: 66.98 s 
2025-06-04 23:01:22.234946:  
2025-06-04 23:01:22.246768: Epoch 749 
2025-06-04 23:01:22.272259: Current learning rate: 0.00288 
2025-06-04 23:02:28.844650: train_loss -0.7263 
2025-06-04 23:02:28.923649: val_loss -0.6739 
2025-06-04 23:02:29.024710: Pseudo dice [np.float32(0.7451)] 
2025-06-04 23:02:29.065942: Epoch time: 66.61 s 
2025-06-04 23:02:30.780919:  
2025-06-04 23:02:30.804038: Epoch 750 
2025-06-04 23:02:30.812484: Current learning rate: 0.00287 
2025-06-04 23:03:37.513291: train_loss -0.7171 
2025-06-04 23:03:37.531432: val_loss -0.6965 
2025-06-04 23:03:37.545377: Pseudo dice [np.float32(0.7475)] 
2025-06-04 23:03:37.559693: Epoch time: 66.73 s 
2025-06-04 23:03:39.043530:  
2025-06-04 23:03:39.074528: Epoch 751 
2025-06-04 23:03:39.087969: Current learning rate: 0.00286 
2025-06-04 23:04:46.093776: train_loss -0.6983 
2025-06-04 23:04:46.109153: val_loss -0.6709 
2025-06-04 23:04:46.123084: Pseudo dice [np.float32(0.8008)] 
2025-06-04 23:04:46.137987: Epoch time: 67.05 s 
2025-06-04 23:04:47.635313:  
2025-06-04 23:04:47.648202: Epoch 752 
2025-06-04 23:04:47.658153: Current learning rate: 0.00285 
2025-06-04 23:05:54.526196: train_loss -0.7165 
2025-06-04 23:05:54.544803: val_loss -0.6903 
2025-06-04 23:05:54.559707: Pseudo dice [np.float32(0.7767)] 
2025-06-04 23:05:54.575647: Epoch time: 66.89 s 
2025-06-04 23:05:55.955436:  
2025-06-04 23:05:55.966173: Epoch 753 
2025-06-04 23:05:55.975886: Current learning rate: 0.00284 
2025-06-04 23:07:03.072225: train_loss -0.7243 
2025-06-04 23:07:03.191773: val_loss -0.7066 
2025-06-04 23:07:03.246120: Pseudo dice [np.float32(0.8367)] 
2025-06-04 23:07:03.261306: Epoch time: 67.12 s 
2025-06-04 23:07:04.579087:  
2025-06-04 23:07:04.604874: Epoch 754 
2025-06-04 23:07:04.616286: Current learning rate: 0.00283 
2025-06-04 23:08:10.319122: train_loss -0.7297 
2025-06-04 23:08:10.426628: val_loss -0.6993 
2025-06-04 23:08:10.456893: Pseudo dice [np.float32(0.8278)] 
2025-06-04 23:08:10.471806: Epoch time: 65.74 s 
2025-06-04 23:08:11.675993:  
2025-06-04 23:08:11.694947: Epoch 755 
2025-06-04 23:08:11.703047: Current learning rate: 0.00282 
2025-06-04 23:09:16.735133: train_loss -0.746 
2025-06-04 23:09:16.806137: val_loss -0.7193 
2025-06-04 23:09:16.885956: Pseudo dice [np.float32(0.8057)] 
2025-06-04 23:09:16.961386: Epoch time: 65.06 s 
2025-06-04 23:09:18.330071:  
2025-06-04 23:09:18.352580: Epoch 756 
2025-06-04 23:09:18.360512: Current learning rate: 0.00281 
2025-06-04 23:10:23.428952: train_loss -0.7409 
2025-06-04 23:10:23.454674: val_loss -0.732 
2025-06-04 23:10:23.494181: Pseudo dice [np.float32(0.8328)] 
2025-06-04 23:10:23.513564: Epoch time: 65.1 s 
2025-06-04 23:10:24.811163:  
2025-06-04 23:10:24.842623: Epoch 757 
2025-06-04 23:10:24.852681: Current learning rate: 0.0028 
2025-06-04 23:11:29.796395: train_loss -0.7398 
2025-06-04 23:11:29.852596: val_loss -0.7106 
2025-06-04 23:11:29.902930: Pseudo dice [np.float32(0.7965)] 
2025-06-04 23:11:29.921695: Epoch time: 64.99 s 
2025-06-04 23:11:31.136570:  
2025-06-04 23:11:31.161401: Epoch 758 
2025-06-04 23:11:31.169907: Current learning rate: 0.00279 
2025-06-04 23:12:36.263531: train_loss -0.7487 
2025-06-04 23:12:36.325184: val_loss -0.742 
2025-06-04 23:12:36.371283: Pseudo dice [np.float32(0.8116)] 
2025-06-04 23:12:36.411808: Epoch time: 65.13 s 
2025-06-04 23:12:37.675380:  
2025-06-04 23:12:37.687850: Epoch 759 
2025-06-04 23:12:37.696529: Current learning rate: 0.00278 
2025-06-04 23:13:42.756502: train_loss -0.7233 
2025-06-04 23:13:42.825271: val_loss -0.6146 
2025-06-04 23:13:42.897665: Pseudo dice [np.float32(0.6994)] 
2025-06-04 23:13:42.961500: Epoch time: 65.08 s 
2025-06-04 23:13:44.174477:  
2025-06-04 23:13:44.204875: Epoch 760 
2025-06-04 23:13:44.214593: Current learning rate: 0.00277 
2025-06-04 23:14:49.235074: train_loss -0.7192 
2025-06-04 23:14:49.329095: val_loss -0.6653 
2025-06-04 23:14:49.408373: Pseudo dice [np.float32(0.7222)] 
2025-06-04 23:14:49.448231: Epoch time: 65.06 s 
2025-06-04 23:14:50.648751:  
2025-06-04 23:14:50.665503: Epoch 761 
2025-06-04 23:14:50.674161: Current learning rate: 0.00276 
2025-06-04 23:15:55.897214: train_loss -0.7309 
2025-06-04 23:15:55.927179: val_loss -0.7125 
2025-06-04 23:15:56.013055: Pseudo dice [np.float32(0.7619)] 
2025-06-04 23:15:56.074989: Epoch time: 65.25 s 
2025-06-04 23:15:57.202035:  
2025-06-04 23:15:57.229285: Epoch 762 
2025-06-04 23:15:57.238968: Current learning rate: 0.00275 
2025-06-04 23:17:02.457921: train_loss -0.7503 
2025-06-04 23:17:02.481456: val_loss -0.669 
2025-06-04 23:17:02.495242: Pseudo dice [np.float32(0.7313)] 
2025-06-04 23:17:02.510529: Epoch time: 65.26 s 
2025-06-04 23:17:04.016440:  
2025-06-04 23:17:04.041172: Epoch 763 
2025-06-04 23:17:04.049831: Current learning rate: 0.00274 
2025-06-04 23:18:09.227579: train_loss -0.7547 
2025-06-04 23:18:09.267178: val_loss -0.667 
2025-06-04 23:18:09.325010: Pseudo dice [np.float32(0.7272)] 
2025-06-04 23:18:09.371096: Epoch time: 65.21 s 
2025-06-04 23:18:10.605091:  
2025-06-04 23:18:10.637144: Epoch 764 
2025-06-04 23:18:10.645581: Current learning rate: 0.00273 
2025-06-04 23:19:15.612289: train_loss -0.7255 
2025-06-04 23:19:15.635876: val_loss -0.6966 
2025-06-04 23:19:15.656392: Pseudo dice [np.float32(0.7747)] 
2025-06-04 23:19:15.670739: Epoch time: 65.01 s 
2025-06-04 23:19:16.996671:  
2025-06-04 23:19:17.027420: Epoch 765 
2025-06-04 23:19:17.036096: Current learning rate: 0.00272 
2025-06-04 23:20:22.274657: train_loss -0.7335 
2025-06-04 23:20:22.298355: val_loss -0.6758 
2025-06-04 23:20:22.316660: Pseudo dice [np.float32(0.7792)] 
2025-06-04 23:20:22.330365: Epoch time: 65.28 s 
2025-06-04 23:20:23.550627:  
2025-06-04 23:20:23.571977: Epoch 766 
2025-06-04 23:20:23.580809: Current learning rate: 0.00271 
2025-06-04 23:21:28.779330: train_loss -0.7451 
2025-06-04 23:21:28.810827: val_loss -0.6619 
2025-06-04 23:21:28.824633: Pseudo dice [np.float32(0.754)] 
2025-06-04 23:21:28.845280: Epoch time: 65.23 s 
2025-06-04 23:21:30.157498:  
2025-06-04 23:21:30.174996: Epoch 767 
2025-06-04 23:21:30.183234: Current learning rate: 0.0027 
2025-06-04 23:22:35.404061: train_loss -0.7325 
2025-06-04 23:22:35.431118: val_loss -0.7067 
2025-06-04 23:22:35.453828: Pseudo dice [np.float32(0.8163)] 
2025-06-04 23:22:35.468890: Epoch time: 65.25 s 
2025-06-04 23:22:36.817440:  
2025-06-04 23:22:36.834730: Epoch 768 
2025-06-04 23:22:36.843497: Current learning rate: 0.00268 
2025-06-04 23:23:41.948516: train_loss -0.7206 
2025-06-04 23:23:41.990965: val_loss -0.7179 
2025-06-04 23:23:42.013944: Pseudo dice [np.float32(0.8075)] 
2025-06-04 23:23:42.029262: Epoch time: 65.13 s 
2025-06-04 23:23:43.345781:  
2025-06-04 23:23:43.370132: Epoch 769 
2025-06-04 23:23:43.378220: Current learning rate: 0.00267 
2025-06-04 23:24:48.294888: train_loss -0.7137 
2025-06-04 23:24:48.358384: val_loss -0.7021 
2025-06-04 23:24:48.425983: Pseudo dice [np.float32(0.7869)] 
2025-06-04 23:24:48.483654: Epoch time: 64.95 s 
2025-06-04 23:24:49.838547:  
2025-06-04 23:24:49.854683: Epoch 770 
2025-06-04 23:24:49.862789: Current learning rate: 0.00266 
2025-06-04 23:25:54.930884: train_loss -0.734 
2025-06-04 23:25:54.954615: val_loss -0.6835 
2025-06-04 23:25:54.967668: Pseudo dice [np.float32(0.8172)] 
2025-06-04 23:25:54.981255: Epoch time: 65.09 s 
2025-06-04 23:25:56.339658:  
2025-06-04 23:25:56.361080: Epoch 771 
2025-06-04 23:25:56.368695: Current learning rate: 0.00265 
2025-06-04 23:27:01.585607: train_loss -0.7087 
2025-06-04 23:27:01.634141: val_loss -0.6476 
2025-06-04 23:27:01.657965: Pseudo dice [np.float32(0.8156)] 
2025-06-04 23:27:01.672057: Epoch time: 65.25 s 
2025-06-04 23:27:02.929811:  
2025-06-04 23:27:02.958222: Epoch 772 
2025-06-04 23:27:02.966796: Current learning rate: 0.00264 
2025-06-04 23:28:08.060349: train_loss -0.7395 
2025-06-04 23:28:08.116225: val_loss -0.6926 
2025-06-04 23:28:08.150016: Pseudo dice [np.float32(0.7727)] 
2025-06-04 23:28:08.166520: Epoch time: 65.13 s 
2025-06-04 23:28:09.482479:  
2025-06-04 23:28:09.502232: Epoch 773 
2025-06-04 23:28:09.511150: Current learning rate: 0.00263 
2025-06-04 23:29:14.636540: train_loss -0.7217 
2025-06-04 23:29:14.660719: val_loss -0.6394 
2025-06-04 23:29:14.714704: Pseudo dice [np.float32(0.6977)] 
2025-06-04 23:29:14.748460: Epoch time: 65.16 s 
2025-06-04 23:29:16.024482:  
2025-06-04 23:29:16.042959: Epoch 774 
2025-06-04 23:29:16.051890: Current learning rate: 0.00262 
2025-06-04 23:30:21.131937: train_loss -0.7332 
2025-06-04 23:30:21.175824: val_loss -0.7119 
2025-06-04 23:30:21.211472: Pseudo dice [np.float32(0.8855)] 
2025-06-04 23:30:21.253817: Epoch time: 65.11 s 
2025-06-04 23:30:22.556426:  
2025-06-04 23:30:22.567776: Epoch 775 
2025-06-04 23:30:22.576413: Current learning rate: 0.00261 
2025-06-04 23:31:27.697011: train_loss -0.7277 
2025-06-04 23:31:27.798239: val_loss -0.6799 
2025-06-04 23:31:27.834762: Pseudo dice [np.float32(0.7066)] 
2025-06-04 23:31:27.858095: Epoch time: 65.14 s 
2025-06-04 23:31:29.041069:  
2025-06-04 23:31:29.062081: Epoch 776 
2025-06-04 23:31:29.072086: Current learning rate: 0.0026 
2025-06-04 23:32:34.133765: train_loss -0.719 
2025-06-04 23:32:34.222924: val_loss -0.7005 
2025-06-04 23:32:34.270751: Pseudo dice [np.float32(0.7633)] 
2025-06-04 23:32:34.284895: Epoch time: 65.09 s 
2025-06-04 23:32:35.652724:  
2025-06-04 23:32:35.684935: Epoch 777 
2025-06-04 23:32:35.694141: Current learning rate: 0.00259 
2025-06-04 23:33:40.641951: train_loss -0.7549 
2025-06-04 23:33:40.708590: val_loss -0.6975 
2025-06-04 23:33:40.788349: Pseudo dice [np.float32(0.82)] 
2025-06-04 23:33:40.861729: Epoch time: 64.99 s 
2025-06-04 23:33:42.143183:  
2025-06-04 23:33:42.168450: Epoch 778 
2025-06-04 23:33:42.176573: Current learning rate: 0.00258 
2025-06-04 23:34:47.439503: train_loss -0.7235 
2025-06-04 23:34:47.465495: val_loss -0.7183 
2025-06-04 23:34:47.505634: Pseudo dice [np.float32(0.7841)] 
2025-06-04 23:34:47.540792: Epoch time: 65.3 s 
2025-06-04 23:34:48.847826:  
2025-06-04 23:34:48.863938: Epoch 779 
2025-06-04 23:34:48.871868: Current learning rate: 0.00257 
2025-06-04 23:35:54.040110: train_loss -0.7363 
2025-06-04 23:35:54.119279: val_loss -0.7034 
2025-06-04 23:35:54.150850: Pseudo dice [np.float32(0.8215)] 
2025-06-04 23:35:54.195347: Epoch time: 65.19 s 
2025-06-04 23:35:55.356670:  
2025-06-04 23:35:55.374624: Epoch 780 
2025-06-04 23:35:55.384178: Current learning rate: 0.00256 
2025-06-04 23:37:00.222835: train_loss -0.7102 
2025-06-04 23:37:00.248944: val_loss -0.6982 
2025-06-04 23:37:00.277381: Pseudo dice [np.float32(0.7576)] 
2025-06-04 23:37:00.292580: Epoch time: 64.87 s 
2025-06-04 23:37:01.594042:  
2025-06-04 23:37:01.613851: Epoch 781 
2025-06-04 23:37:01.622171: Current learning rate: 0.00255 
2025-06-04 23:38:06.804017: train_loss -0.7256 
2025-06-04 23:38:06.840793: val_loss -0.6899 
2025-06-04 23:38:06.880522: Pseudo dice [np.float32(0.804)] 
2025-06-04 23:38:06.913708: Epoch time: 65.21 s 
2025-06-04 23:38:08.141094:  
2025-06-04 23:38:08.173137: Epoch 782 
2025-06-04 23:38:08.183423: Current learning rate: 0.00254 
2025-06-04 23:39:13.291888: train_loss -0.7276 
2025-06-04 23:39:13.317528: val_loss -0.7301 
2025-06-04 23:39:13.344478: Pseudo dice [np.float32(0.8231)] 
2025-06-04 23:39:13.361042: Epoch time: 65.15 s 
2025-06-04 23:39:14.628979:  
2025-06-04 23:39:14.656528: Epoch 783 
2025-06-04 23:39:14.664625: Current learning rate: 0.00253 
2025-06-04 23:40:19.674910: train_loss -0.7408 
2025-06-04 23:40:19.711556: val_loss -0.6776 
2025-06-04 23:40:19.747300: Pseudo dice [np.float32(0.7528)] 
2025-06-04 23:40:19.761004: Epoch time: 65.05 s 
2025-06-04 23:40:21.227436:  
2025-06-04 23:40:21.256445: Epoch 784 
2025-06-04 23:40:21.264906: Current learning rate: 0.00252 
2025-06-04 23:41:26.421212: train_loss -0.753 
2025-06-04 23:41:26.446301: val_loss -0.6693 
2025-06-04 23:41:26.458472: Pseudo dice [np.float32(0.7434)] 
2025-06-04 23:41:26.473354: Epoch time: 65.19 s 
2025-06-04 23:41:27.747402:  
2025-06-04 23:41:27.770198: Epoch 785 
2025-06-04 23:41:27.778634: Current learning rate: 0.00251 
2025-06-04 23:42:32.822911: train_loss -0.7386 
2025-06-04 23:42:32.869908: val_loss -0.6924 
2025-06-04 23:42:32.921460: Pseudo dice [np.float32(0.7801)] 
2025-06-04 23:42:32.976965: Epoch time: 65.08 s 
2025-06-04 23:42:34.207855:  
2025-06-04 23:42:34.223288: Epoch 786 
2025-06-04 23:42:34.231947: Current learning rate: 0.0025 
2025-06-04 23:43:39.295109: train_loss -0.7402 
2025-06-04 23:43:39.319328: val_loss -0.673 
2025-06-04 23:43:39.338934: Pseudo dice [np.float32(0.8147)] 
2025-06-04 23:43:39.352918: Epoch time: 65.09 s 
2025-06-04 23:43:40.583387:  
2025-06-04 23:43:40.608946: Epoch 787 
2025-06-04 23:43:40.618031: Current learning rate: 0.00249 
2025-06-04 23:44:45.715116: train_loss -0.7326 
2025-06-04 23:44:45.764204: val_loss -0.7606 
2025-06-04 23:44:45.811609: Pseudo dice [np.float32(0.7852)] 
2025-06-04 23:44:45.882662: Epoch time: 65.13 s 
2025-06-04 23:44:47.138272:  
2025-06-04 23:44:47.170833: Epoch 788 
2025-06-04 23:44:47.181037: Current learning rate: 0.00248 
2025-06-04 23:45:52.349261: train_loss -0.7374 
2025-06-04 23:45:52.382892: val_loss -0.6858 
2025-06-04 23:45:52.396451: Pseudo dice [np.float32(0.7793)] 
2025-06-04 23:45:52.409002: Epoch time: 65.21 s 
2025-06-04 23:45:53.739792:  
2025-06-04 23:45:53.771053: Epoch 789 
2025-06-04 23:45:53.796649: Current learning rate: 0.00247 
2025-06-04 23:46:58.873291: train_loss -0.74 
2025-06-04 23:46:58.896999: val_loss -0.7153 
2025-06-04 23:46:58.915531: Pseudo dice [np.float32(0.7536)] 
2025-06-04 23:46:58.930008: Epoch time: 65.13 s 
2025-06-04 23:47:00.415327:  
2025-06-04 23:47:00.438796: Epoch 790 
2025-06-04 23:47:00.447266: Current learning rate: 0.00245 
2025-06-04 23:48:05.547564: train_loss -0.7179 
2025-06-04 23:48:05.607662: val_loss -0.6809 
2025-06-04 23:48:05.653859: Pseudo dice [np.float32(0.7843)] 
2025-06-04 23:48:05.688472: Epoch time: 65.14 s 
2025-06-04 23:48:06.925001:  
2025-06-04 23:48:06.948051: Epoch 791 
2025-06-04 23:48:06.956553: Current learning rate: 0.00244 
2025-06-04 23:49:12.124782: train_loss -0.7467 
2025-06-04 23:49:12.147748: val_loss -0.6792 
2025-06-04 23:49:12.167650: Pseudo dice [np.float32(0.7919)] 
2025-06-04 23:49:12.181432: Epoch time: 65.2 s 
2025-06-04 23:49:13.434092:  
2025-06-04 23:49:13.457609: Epoch 792 
2025-06-04 23:49:13.465739: Current learning rate: 0.00243 
2025-06-04 23:50:18.464996: train_loss -0.7552 
2025-06-04 23:50:18.504183: val_loss -0.6976 
2025-06-04 23:50:18.536414: Pseudo dice [np.float32(0.8011)] 
2025-06-04 23:50:18.550232: Epoch time: 65.04 s 
2025-06-04 23:50:19.856790:  
2025-06-04 23:50:19.879803: Epoch 793 
2025-06-04 23:50:19.888671: Current learning rate: 0.00242 
2025-06-04 23:51:25.092670: train_loss -0.75 
2025-06-04 23:51:25.166636: val_loss -0.7295 
2025-06-04 23:51:25.223182: Pseudo dice [np.float32(0.8051)] 
2025-06-04 23:51:25.268992: Epoch time: 65.24 s 
2025-06-04 23:51:26.437519:  
2025-06-04 23:51:26.452513: Epoch 794 
2025-06-04 23:51:26.460663: Current learning rate: 0.00241 
2025-06-04 23:52:31.642720: train_loss -0.7358 
2025-06-04 23:52:31.740630: val_loss -0.6373 
2025-06-04 23:52:31.786611: Pseudo dice [np.float32(0.7377)] 
2025-06-04 23:52:31.799916: Epoch time: 65.21 s 
2025-06-04 23:52:33.019945:  
2025-06-04 23:52:33.045874: Epoch 795 
2025-06-04 23:52:33.054534: Current learning rate: 0.0024 
2025-06-04 23:53:38.235327: train_loss -0.7438 
2025-06-04 23:53:38.320875: val_loss -0.7731 
2025-06-04 23:53:38.367360: Pseudo dice [np.float32(0.8049)] 
2025-06-04 23:53:38.380266: Epoch time: 65.22 s 
2025-06-04 23:53:39.645888:  
2025-06-04 23:53:39.678814: Epoch 796 
2025-06-04 23:53:39.688808: Current learning rate: 0.00239 
2025-06-04 23:54:44.821135: train_loss -0.7422 
2025-06-04 23:54:44.859597: val_loss -0.7459 
2025-06-04 23:54:44.881056: Pseudo dice [np.float32(0.8274)] 
2025-06-04 23:54:44.896979: Epoch time: 65.18 s 
2025-06-04 23:54:46.373427:  
2025-06-04 23:54:46.397121: Epoch 797 
2025-06-04 23:54:46.405632: Current learning rate: 0.00238 
2025-06-04 23:55:51.607417: train_loss -0.7264 
2025-06-04 23:55:51.632501: val_loss -0.6852 
2025-06-04 23:55:51.652922: Pseudo dice [np.float32(0.8125)] 
2025-06-04 23:55:51.666191: Epoch time: 65.24 s 
2025-06-04 23:55:52.987630:  
2025-06-04 23:55:53.017909: Epoch 798 
2025-06-04 23:55:53.029279: Current learning rate: 0.00237 
2025-06-04 23:56:58.230300: train_loss -0.7351 
2025-06-04 23:56:58.270250: val_loss -0.7059 
2025-06-04 23:56:58.346584: Pseudo dice [np.float32(0.7141)] 
2025-06-04 23:56:58.442272: Epoch time: 65.24 s 
2025-06-04 23:56:59.755858:  
2025-06-04 23:56:59.777467: Epoch 799 
2025-06-04 23:56:59.785019: Current learning rate: 0.00236 
2025-06-04 23:58:04.892402: train_loss -0.7546 
2025-06-04 23:58:04.921349: val_loss -0.6553 
2025-06-04 23:58:04.963460: Pseudo dice [np.float32(0.6867)] 
2025-06-04 23:58:05.021381: Epoch time: 65.14 s 
2025-06-04 23:58:06.656694:  
2025-06-04 23:58:06.678205: Epoch 800 
2025-06-04 23:58:06.686687: Current learning rate: 0.00235 
2025-06-04 23:59:11.942954: train_loss -0.7409 
2025-06-04 23:59:11.979060: val_loss -0.6857 
2025-06-04 23:59:11.996020: Pseudo dice [np.float32(0.7754)] 
2025-06-04 23:59:12.012418: Epoch time: 65.29 s 
2025-06-04 23:59:13.358267:  
2025-06-04 23:59:13.372930: Epoch 801 
2025-06-04 23:59:13.398477: Current learning rate: 0.00234 
2025-06-05 00:00:18.616278: train_loss -0.7173 
2025-06-05 00:00:18.683019: val_loss -0.7636 
2025-06-05 00:00:18.730779: Pseudo dice [np.float32(0.837)] 
2025-06-05 00:00:18.751903: Epoch time: 65.26 s 
2025-06-05 00:00:19.944012:  
2025-06-05 00:00:19.966541: Epoch 802 
2025-06-05 00:00:19.975200: Current learning rate: 0.00233 
2025-06-05 00:01:25.246023: train_loss -0.7447 
2025-06-05 00:01:25.290242: val_loss -0.6452 
2025-06-05 00:01:25.349285: Pseudo dice [np.float32(0.7346)] 
2025-06-05 00:01:25.364598: Epoch time: 65.3 s 
2025-06-05 00:01:26.598703:  
2025-06-05 00:01:26.624788: Epoch 803 
2025-06-05 00:01:26.633279: Current learning rate: 0.00232 
2025-06-05 00:02:31.827870: train_loss -0.7348 
2025-06-05 00:02:31.853575: val_loss -0.7001 
2025-06-05 00:02:31.883451: Pseudo dice [np.float32(0.7918)] 
2025-06-05 00:02:31.915030: Epoch time: 65.23 s 
2025-06-05 00:02:33.352317:  
2025-06-05 00:02:33.375548: Epoch 804 
2025-06-05 00:02:33.383650: Current learning rate: 0.00231 
2025-06-05 00:03:38.507616: train_loss -0.7173 
2025-06-05 00:03:38.562486: val_loss -0.7189 
2025-06-05 00:03:38.598347: Pseudo dice [np.float32(0.766)] 
2025-06-05 00:03:38.637596: Epoch time: 65.16 s 
2025-06-05 00:03:39.964538:  
2025-06-05 00:03:39.995519: Epoch 805 
2025-06-05 00:03:40.004756: Current learning rate: 0.0023 
2025-06-05 00:04:45.207533: train_loss -0.7446 
2025-06-05 00:04:45.280730: val_loss -0.7307 
2025-06-05 00:04:45.316479: Pseudo dice [np.float32(0.8087)] 
2025-06-05 00:04:45.339231: Epoch time: 65.24 s 
2025-06-05 00:04:46.555275:  
2025-06-05 00:04:46.576364: Epoch 806 
2025-06-05 00:04:46.585362: Current learning rate: 0.00229 
2025-06-05 00:05:51.460725: train_loss -0.7314 
2025-06-05 00:05:51.528730: val_loss -0.7196 
2025-06-05 00:05:51.548186: Pseudo dice [np.float32(0.7991)] 
2025-06-05 00:05:51.561015: Epoch time: 64.91 s 
2025-06-05 00:05:52.807662:  
2025-06-05 00:05:52.837930: Epoch 807 
2025-06-05 00:05:52.848793: Current learning rate: 0.00228 
2025-06-05 00:06:57.792301: train_loss -0.7324 
2025-06-05 00:06:57.861218: val_loss -0.7322 
2025-06-05 00:06:57.932739: Pseudo dice [np.float32(0.8322)] 
2025-06-05 00:06:57.973151: Epoch time: 64.99 s 
2025-06-05 00:06:59.245993:  
2025-06-05 00:06:59.266286: Epoch 808 
2025-06-05 00:06:59.275387: Current learning rate: 0.00226 
2025-06-05 00:08:04.434319: train_loss -0.7315 
2025-06-05 00:08:04.486978: val_loss -0.6708 
2025-06-05 00:08:04.531499: Pseudo dice [np.float32(0.7588)] 
2025-06-05 00:08:04.571453: Epoch time: 65.19 s 
2025-06-05 00:08:05.863349:  
2025-06-05 00:08:05.892891: Epoch 809 
2025-06-05 00:08:05.901544: Current learning rate: 0.00225 
2025-06-05 00:09:11.162179: train_loss -0.727 
2025-06-05 00:09:11.187202: val_loss -0.6742 
2025-06-05 00:09:11.211753: Pseudo dice [np.float32(0.7722)] 
2025-06-05 00:09:11.247202: Epoch time: 65.3 s 
2025-06-05 00:09:12.532822:  
2025-06-05 00:09:12.555697: Epoch 810 
2025-06-05 00:09:12.564228: Current learning rate: 0.00224 
2025-06-05 00:10:17.782909: train_loss -0.7096 
2025-06-05 00:10:17.876626: val_loss -0.6905 
2025-06-05 00:10:17.951153: Pseudo dice [np.float32(0.8299)] 
2025-06-05 00:10:17.973848: Epoch time: 65.25 s 
2025-06-05 00:10:19.351603:  
2025-06-05 00:10:19.369719: Epoch 811 
2025-06-05 00:10:19.377851: Current learning rate: 0.00223 
2025-06-05 00:11:25.632543: train_loss -0.7375 
2025-06-05 00:11:25.681727: val_loss -0.6881 
2025-06-05 00:11:25.756174: Pseudo dice [np.float32(0.8039)] 
2025-06-05 00:11:25.802081: Epoch time: 66.28 s 
2025-06-05 00:11:27.218130:  
2025-06-05 00:11:27.241441: Epoch 812 
2025-06-05 00:11:27.255618: Current learning rate: 0.00222 
2025-06-05 00:12:34.039046: train_loss -0.748 
2025-06-05 00:12:34.179404: val_loss -0.6563 
2025-06-05 00:12:34.299305: Pseudo dice [np.float32(0.722)] 
2025-06-05 00:12:34.365125: Epoch time: 66.82 s 
2025-06-05 00:12:35.751434:  
2025-06-05 00:12:35.772238: Epoch 813 
2025-06-05 00:12:35.782405: Current learning rate: 0.00221 
2025-06-05 00:13:42.364984: train_loss -0.7545 
2025-06-05 00:13:42.398516: val_loss -0.6427 
2025-06-05 00:13:42.450648: Pseudo dice [np.float32(0.714)] 
2025-06-05 00:13:42.732452: Epoch time: 66.62 s 
2025-06-05 00:13:44.041713:  
2025-06-05 00:13:44.059581: Epoch 814 
2025-06-05 00:13:44.069748: Current learning rate: 0.0022 
2025-06-05 00:14:51.537632: train_loss -0.7248 
2025-06-05 00:14:51.602017: val_loss -0.7 
2025-06-05 00:14:51.766357: Pseudo dice [np.float32(0.8062)] 
2025-06-05 00:14:51.860042: Epoch time: 67.5 s 
2025-06-05 00:14:53.332916:  
2025-06-05 00:14:53.351734: Epoch 815 
2025-06-05 00:14:53.363315: Current learning rate: 0.00219 
2025-06-05 00:15:59.866218: train_loss -0.7516 
2025-06-05 00:15:59.970964: val_loss -0.71 
2025-06-05 00:16:00.056181: Pseudo dice [np.float32(0.7725)] 
2025-06-05 00:16:00.118354: Epoch time: 66.53 s 
2025-06-05 00:16:01.516204:  
2025-06-05 00:16:01.528903: Epoch 816 
2025-06-05 00:16:01.538545: Current learning rate: 0.00218 
2025-06-05 00:17:08.111056: train_loss -0.7532 
2025-06-05 00:17:08.136037: val_loss -0.7267 
2025-06-05 00:17:08.149915: Pseudo dice [np.float32(0.801)] 
2025-06-05 00:17:08.164755: Epoch time: 66.6 s 
2025-06-05 00:17:09.683937:  
2025-06-05 00:17:09.696377: Epoch 817 
2025-06-05 00:17:09.706719: Current learning rate: 0.00217 
2025-06-05 00:18:17.244691: train_loss -0.7568 
2025-06-05 00:18:17.338737: val_loss -0.695 
2025-06-05 00:18:17.396960: Pseudo dice [np.float32(0.7745)] 
2025-06-05 00:18:17.494023: Epoch time: 67.56 s 
2025-06-05 00:18:19.231057:  
2025-06-05 00:18:19.251315: Epoch 818 
2025-06-05 00:18:19.262767: Current learning rate: 0.00216 
2025-06-05 00:19:26.425304: train_loss -0.7493 
2025-06-05 00:19:26.445775: val_loss -0.6358 
2025-06-05 00:19:26.460898: Pseudo dice [np.float32(0.7234)] 
2025-06-05 00:19:26.475811: Epoch time: 67.2 s 
2025-06-05 00:19:28.201432:  
2025-06-05 00:19:28.220891: Epoch 819 
2025-06-05 00:19:28.242033: Current learning rate: 0.00215 
2025-06-05 00:20:35.416378: train_loss -0.7606 
2025-06-05 00:20:35.437369: val_loss -0.6618 
2025-06-05 00:20:35.452083: Pseudo dice [np.float32(0.7702)] 
2025-06-05 00:20:35.465364: Epoch time: 67.22 s 
2025-06-05 00:20:36.982905:  
2025-06-05 00:20:36.995894: Epoch 820 
2025-06-05 00:20:37.005887: Current learning rate: 0.00214 
2025-06-05 00:21:44.487984: train_loss -0.7574 
2025-06-05 00:21:44.540023: val_loss -0.681 
2025-06-05 00:21:44.555334: Pseudo dice [np.float32(0.7516)] 
2025-06-05 00:21:44.568777: Epoch time: 67.51 s 
2025-06-05 00:21:46.001419:  
2025-06-05 00:21:46.018185: Epoch 821 
2025-06-05 00:21:46.029654: Current learning rate: 0.00213 
2025-06-05 00:22:52.780681: train_loss -0.737 
2025-06-05 00:22:52.801270: val_loss -0.7131 
2025-06-05 00:22:52.815512: Pseudo dice [np.float32(0.7751)] 
2025-06-05 00:22:52.828887: Epoch time: 66.78 s 
2025-06-05 00:22:54.426767:  
2025-06-05 00:22:54.440581: Epoch 822 
2025-06-05 00:22:54.453730: Current learning rate: 0.00212 
2025-06-05 00:24:01.735530: train_loss -0.7534 
2025-06-05 00:24:01.887600: val_loss -0.7174 
2025-06-05 00:24:01.989029: Pseudo dice [np.float32(0.8023)] 
2025-06-05 00:24:02.046046: Epoch time: 67.31 s 
2025-06-05 00:24:03.597399:  
2025-06-05 00:24:03.610260: Epoch 823 
2025-06-05 00:24:03.619916: Current learning rate: 0.0021 
2025-06-05 00:25:10.597274: train_loss -0.7349 
2025-06-05 00:25:10.611760: val_loss -0.6511 
2025-06-05 00:25:10.627292: Pseudo dice [np.float32(0.7033)] 
2025-06-05 00:25:10.673402: Epoch time: 67.0 s 
2025-06-05 00:25:12.354515:  
2025-06-05 00:25:12.371629: Epoch 824 
2025-06-05 00:25:12.381682: Current learning rate: 0.00209 
2025-06-05 00:26:19.427471: train_loss -0.7321 
2025-06-05 00:26:19.530066: val_loss -0.705 
2025-06-05 00:26:19.627748: Pseudo dice [np.float32(0.7171)] 
2025-06-05 00:26:19.690725: Epoch time: 67.07 s 
2025-06-05 00:26:21.332383:  
2025-06-05 00:26:21.344424: Epoch 825 
2025-06-05 00:26:21.353830: Current learning rate: 0.00208 
2025-06-05 00:27:28.113460: train_loss -0.744 
2025-06-05 00:27:28.224900: val_loss -0.6979 
2025-06-05 00:27:28.378470: Pseudo dice [np.float32(0.7785)] 
2025-06-05 00:27:28.426994: Epoch time: 66.78 s 
2025-06-05 00:27:29.931579:  
2025-06-05 00:27:29.943403: Epoch 826 
2025-06-05 00:27:29.960137: Current learning rate: 0.00207 
2025-06-05 00:28:36.642558: train_loss -0.7422 
2025-06-05 00:28:36.664497: val_loss -0.7312 
2025-06-05 00:28:36.680396: Pseudo dice [np.float32(0.8255)] 
2025-06-05 00:28:36.695717: Epoch time: 66.71 s 
2025-06-05 00:28:38.214236:  
2025-06-05 00:28:38.231343: Epoch 827 
2025-06-05 00:28:38.241126: Current learning rate: 0.00206 
2025-06-05 00:29:44.970324: train_loss -0.724 
2025-06-05 00:29:44.997266: val_loss -0.7127 
2025-06-05 00:29:45.012405: Pseudo dice [np.float32(0.8074)] 
2025-06-05 00:29:45.026680: Epoch time: 66.76 s 
2025-06-05 00:29:46.691865:  
2025-06-05 00:29:46.711310: Epoch 828 
2025-06-05 00:29:46.727669: Current learning rate: 0.00205 
2025-06-05 00:30:53.776114: train_loss -0.726 
2025-06-05 00:30:53.856262: val_loss -0.7457 
2025-06-05 00:30:53.895031: Pseudo dice [np.float32(0.7958)] 
2025-06-05 00:30:53.911357: Epoch time: 67.09 s 
2025-06-05 00:30:55.352832:  
2025-06-05 00:30:55.377883: Epoch 829 
2025-06-05 00:30:55.397787: Current learning rate: 0.00204 
2025-06-05 00:32:02.171718: train_loss -0.7255 
2025-06-05 00:32:02.254824: val_loss -0.6739 
2025-06-05 00:32:02.270639: Pseudo dice [np.float32(0.7455)] 
2025-06-05 00:32:02.288734: Epoch time: 66.82 s 
2025-06-05 00:32:03.616638:  
2025-06-05 00:32:03.635839: Epoch 830 
2025-06-05 00:32:03.647358: Current learning rate: 0.00203 
2025-06-05 00:33:10.573162: train_loss -0.729 
2025-06-05 00:33:10.641242: val_loss -0.6779 
2025-06-05 00:33:10.669450: Pseudo dice [np.float32(0.7787)] 
2025-06-05 00:33:10.715488: Epoch time: 66.96 s 
2025-06-05 00:33:12.167429:  
2025-06-05 00:33:12.189271: Epoch 831 
2025-06-05 00:33:12.209435: Current learning rate: 0.00202 
2025-06-05 00:34:19.091121: train_loss -0.7295 
2025-06-05 00:34:19.113595: val_loss -0.6803 
2025-06-05 00:34:19.153296: Pseudo dice [np.float32(0.7361)] 
2025-06-05 00:34:19.228542: Epoch time: 66.92 s 
2025-06-05 00:34:20.861793:  
2025-06-05 00:34:20.889519: Epoch 832 
2025-06-05 00:34:20.899174: Current learning rate: 0.00201 
2025-06-05 00:35:28.035403: train_loss -0.7323 
2025-06-05 00:35:28.054641: val_loss -0.6348 
2025-06-05 00:35:28.069395: Pseudo dice [np.float32(0.751)] 
2025-06-05 00:35:28.083175: Epoch time: 67.17 s 
2025-06-05 00:35:29.610161:  
2025-06-05 00:35:29.630279: Epoch 833 
2025-06-05 00:35:29.646805: Current learning rate: 0.002 
2025-06-05 00:36:36.632862: train_loss -0.754 
2025-06-05 00:36:36.652884: val_loss -0.6906 
2025-06-05 00:36:36.666766: Pseudo dice [np.float32(0.8148)] 
2025-06-05 00:36:36.682122: Epoch time: 67.02 s 
2025-06-05 00:36:38.252297:  
2025-06-05 00:36:38.273721: Epoch 834 
2025-06-05 00:36:38.290132: Current learning rate: 0.00199 
2025-06-05 00:37:45.517309: train_loss -0.7443 
2025-06-05 00:37:45.539349: val_loss -0.7137 
2025-06-05 00:37:45.555494: Pseudo dice [np.float32(0.8249)] 
2025-06-05 00:37:45.569722: Epoch time: 67.27 s 
2025-06-05 00:37:46.937571:  
2025-06-05 00:37:46.957382: Epoch 835 
2025-06-05 00:37:46.967355: Current learning rate: 0.00198 
2025-06-05 00:38:54.147285: train_loss -0.7589 
2025-06-05 00:38:54.283127: val_loss -0.7589 
2025-06-05 00:38:54.352445: Pseudo dice [np.float32(0.8459)] 
2025-06-05 00:38:54.367767: Epoch time: 67.21 s 
2025-06-05 00:38:55.805095:  
2025-06-05 00:38:55.823740: Epoch 836 
2025-06-05 00:38:55.838160: Current learning rate: 0.00196 
2025-06-05 00:40:03.453763: train_loss -0.7322 
2025-06-05 00:40:03.476580: val_loss -0.6521 
2025-06-05 00:40:03.491291: Pseudo dice [np.float32(0.7453)] 
2025-06-05 00:40:03.504674: Epoch time: 67.65 s 
2025-06-05 00:40:05.025933:  
2025-06-05 00:40:05.039002: Epoch 837 
2025-06-05 00:40:05.049296: Current learning rate: 0.00195 
2025-06-05 00:41:12.104637: train_loss -0.7158 
2025-06-05 00:41:12.218795: val_loss -0.6634 
2025-06-05 00:41:12.292276: Pseudo dice [np.float32(0.7034)] 
2025-06-05 00:41:12.325015: Epoch time: 67.08 s 
2025-06-05 00:41:13.915031:  
2025-06-05 00:41:13.933854: Epoch 838 
2025-06-05 00:41:13.950795: Current learning rate: 0.00194 
2025-06-05 00:42:21.299021: train_loss -0.747 
2025-06-05 00:42:21.429929: val_loss -0.7091 
2025-06-05 00:42:21.496789: Pseudo dice [np.float32(0.7854)] 
2025-06-05 00:42:21.542480: Epoch time: 67.39 s 
2025-06-05 00:42:22.987921:  
2025-06-05 00:42:23.005332: Epoch 839 
2025-06-05 00:42:23.018706: Current learning rate: 0.00193 
2025-06-05 00:43:30.556919: train_loss -0.7432 
2025-06-05 00:43:30.577829: val_loss -0.7061 
2025-06-05 00:43:30.593745: Pseudo dice [np.float32(0.7884)] 
2025-06-05 00:43:30.608677: Epoch time: 67.57 s 
2025-06-05 00:43:32.248370:  
2025-06-05 00:43:32.260881: Epoch 840 
2025-06-05 00:43:32.286761: Current learning rate: 0.00192 
2025-06-05 00:44:41.895079: train_loss -0.746 
2025-06-05 00:44:42.006138: val_loss -0.6557 
2025-06-05 00:44:42.024634: Pseudo dice [np.float32(0.7835)] 
2025-06-05 00:44:42.040686: Epoch time: 69.65 s 
2025-06-05 00:44:43.663399:  
2025-06-05 00:44:43.676262: Epoch 841 
2025-06-05 00:44:43.687096: Current learning rate: 0.00191 
2025-06-05 00:45:53.065189: train_loss -0.7408 
2025-06-05 00:45:53.179996: val_loss -0.7436 
2025-06-05 00:45:53.281422: Pseudo dice [np.float32(0.8289)] 
2025-06-05 00:45:53.298792: Epoch time: 69.4 s 
2025-06-05 00:45:54.944873:  
2025-06-05 00:45:54.957135: Epoch 842 
2025-06-05 00:45:54.968043: Current learning rate: 0.0019 
2025-06-05 00:47:04.282317: train_loss -0.7236 
2025-06-05 00:47:04.303126: val_loss -0.6656 
2025-06-05 00:47:04.316857: Pseudo dice [np.float32(0.7219)] 
2025-06-05 00:47:04.332094: Epoch time: 69.34 s 
2025-06-05 00:47:05.939502:  
2025-06-05 00:47:05.951202: Epoch 843 
2025-06-05 00:47:05.960915: Current learning rate: 0.00189 
2025-06-05 00:48:15.782718: train_loss -0.7254 
2025-06-05 00:48:15.885428: val_loss -0.6605 
2025-06-05 00:48:15.954541: Pseudo dice [np.float32(0.7355)] 
2025-06-05 00:48:15.975067: Epoch time: 69.84 s 
2025-06-05 00:48:17.392992:  
2025-06-05 00:48:17.405411: Epoch 844 
2025-06-05 00:48:17.417383: Current learning rate: 0.00188 
2025-06-05 00:49:27.454773: train_loss -0.7633 
2025-06-05 00:49:27.664358: val_loss -0.7279 
2025-06-05 00:49:27.706676: Pseudo dice [np.float32(0.8452)] 
2025-06-05 00:49:27.752732: Epoch time: 70.06 s 
2025-06-05 00:49:29.269918:  
2025-06-05 00:49:29.285230: Epoch 845 
2025-06-05 00:49:29.302145: Current learning rate: 0.00187 
2025-06-05 00:50:39.544050: train_loss -0.7425 
2025-06-05 00:50:39.630326: val_loss -0.7326 
2025-06-05 00:50:39.761248: Pseudo dice [np.float32(0.84)] 
2025-06-05 00:50:39.879027: Epoch time: 70.28 s 
2025-06-05 00:50:41.483372:  
2025-06-05 00:50:41.494108: Epoch 846 
2025-06-05 00:50:41.507046: Current learning rate: 0.00186 
2025-06-05 00:51:51.175110: train_loss -0.7306 
2025-06-05 00:51:51.206078: val_loss -0.7244 
2025-06-05 00:51:51.223361: Pseudo dice [np.float32(0.7775)] 
2025-06-05 00:51:51.237282: Epoch time: 69.69 s 
2025-06-05 00:51:53.080739:  
2025-06-05 00:51:53.102430: Epoch 847 
2025-06-05 00:51:53.116553: Current learning rate: 0.00185 
2025-06-05 00:53:02.128973: train_loss -0.74 
2025-06-05 00:53:02.147283: val_loss -0.6751 
2025-06-05 00:53:02.162578: Pseudo dice [np.float32(0.8399)] 
2025-06-05 00:53:02.178942: Epoch time: 69.05 s 
2025-06-05 00:53:03.967852:  
2025-06-05 00:53:03.979704: Epoch 848 
2025-06-05 00:53:03.990534: Current learning rate: 0.00184 
2025-06-05 00:54:13.751033: train_loss -0.7487 
2025-06-05 00:54:13.883139: val_loss -0.7159 
2025-06-05 00:54:13.937212: Pseudo dice [np.float32(0.7106)] 
2025-06-05 00:54:14.012260: Epoch time: 69.79 s 
2025-06-05 00:54:15.517336:  
2025-06-05 00:54:15.529725: Epoch 849 
2025-06-05 00:54:15.552181: Current learning rate: 0.00182 
2025-06-05 00:55:24.624543: train_loss -0.7532 
2025-06-05 00:55:24.700783: val_loss -0.7179 
2025-06-05 00:55:24.772662: Pseudo dice [np.float32(0.8156)] 
2025-06-05 00:55:24.873463: Epoch time: 69.11 s 
2025-06-05 00:55:26.881023:  
2025-06-05 00:55:26.893562: Epoch 850 
2025-06-05 00:55:26.904294: Current learning rate: 0.00181 
2025-06-05 00:56:36.032012: train_loss -0.7688 
2025-06-05 00:56:36.071862: val_loss -0.7204 
2025-06-05 00:56:36.089862: Pseudo dice [np.float32(0.7663)] 
2025-06-05 00:56:36.106310: Epoch time: 69.15 s 
2025-06-05 00:56:37.881857:  
2025-06-05 00:56:37.893506: Epoch 851 
2025-06-05 00:56:37.904691: Current learning rate: 0.0018 
2025-06-05 00:57:47.511706: train_loss -0.7487 
2025-06-05 00:57:47.581211: val_loss -0.6756 
2025-06-05 00:57:47.629454: Pseudo dice [np.float32(0.7016)] 
2025-06-05 00:57:47.694165: Epoch time: 69.63 s 
2025-06-05 00:57:49.136319:  
2025-06-05 00:57:49.147275: Epoch 852 
2025-06-05 00:57:49.157682: Current learning rate: 0.00179 
2025-06-05 00:58:58.718937: train_loss -0.7553 
2025-06-05 00:58:58.736686: val_loss -0.6543 
2025-06-05 00:58:58.750274: Pseudo dice [np.float32(0.775)] 
2025-06-05 00:58:58.764574: Epoch time: 69.58 s 
2025-06-05 00:59:00.348743:  
2025-06-05 00:59:00.361005: Epoch 853 
2025-06-05 00:59:00.373224: Current learning rate: 0.00178 
2025-06-05 01:00:07.831552: train_loss -0.7326 
2025-06-05 01:00:07.887135: val_loss -0.7055 
2025-06-05 01:00:07.992785: Pseudo dice [np.float32(0.7728)] 
2025-06-05 01:00:08.008144: Epoch time: 67.48 s 
2025-06-05 01:00:09.353697:  
2025-06-05 01:00:09.368955: Epoch 854 
2025-06-05 01:00:09.382264: Current learning rate: 0.00177 
2025-06-05 01:01:15.126218: train_loss -0.7432 
2025-06-05 01:01:15.165390: val_loss -0.7021 
2025-06-05 01:01:15.201436: Pseudo dice [np.float32(0.7567)] 
2025-06-05 01:01:15.248975: Epoch time: 65.77 s 
2025-06-05 01:01:16.779824:  
2025-06-05 01:01:16.807417: Epoch 855 
2025-06-05 01:01:16.815516: Current learning rate: 0.00176 
2025-06-05 01:02:22.161840: train_loss -0.7532 
2025-06-05 01:02:22.211291: val_loss -0.6638 
2025-06-05 01:02:22.278056: Pseudo dice [np.float32(0.7432)] 
2025-06-05 01:02:22.376363: Epoch time: 65.38 s 
2025-06-05 01:02:23.541680:  
2025-06-05 01:02:23.561054: Epoch 856 
2025-06-05 01:02:23.568702: Current learning rate: 0.00175 
2025-06-05 01:03:28.737719: train_loss -0.7402 
2025-06-05 01:03:28.811385: val_loss -0.6842 
2025-06-05 01:03:28.869532: Pseudo dice [np.float32(0.7389)] 
2025-06-05 01:03:28.914671: Epoch time: 65.2 s 
2025-06-05 01:03:30.128472:  
2025-06-05 01:03:30.156475: Epoch 857 
2025-06-05 01:03:30.164253: Current learning rate: 0.00174 
2025-06-05 01:04:35.414087: train_loss -0.7486 
2025-06-05 01:04:35.436977: val_loss -0.6546 
2025-06-05 01:04:35.449769: Pseudo dice [np.float32(0.7583)] 
2025-06-05 01:04:35.461950: Epoch time: 65.29 s 
2025-06-05 01:04:36.704516:  
2025-06-05 01:04:36.715771: Epoch 858 
2025-06-05 01:04:36.724983: Current learning rate: 0.00173 
2025-06-05 01:05:41.888274: train_loss -0.7355 
2025-06-05 01:05:41.936853: val_loss -0.7191 
2025-06-05 01:05:41.983160: Pseudo dice [np.float32(0.8266)] 
2025-06-05 01:05:42.093611: Epoch time: 65.18 s 
2025-06-05 01:05:43.270798:  
2025-06-05 01:05:43.297148: Epoch 859 
2025-06-05 01:05:43.304748: Current learning rate: 0.00172 
2025-06-05 01:06:48.220583: train_loss -0.7551 
2025-06-05 01:06:48.277166: val_loss -0.7066 
2025-06-05 01:06:48.354566: Pseudo dice [np.float32(0.8106)] 
2025-06-05 01:06:48.391215: Epoch time: 64.95 s 
2025-06-05 01:06:49.650833:  
2025-06-05 01:06:49.681147: Epoch 860 
2025-06-05 01:06:49.691977: Current learning rate: 0.0017 
2025-06-05 01:07:54.825695: train_loss -0.7446 
2025-06-05 01:07:54.875216: val_loss -0.7095 
2025-06-05 01:07:54.950240: Pseudo dice [np.float32(0.7401)] 
2025-06-05 01:07:55.018505: Epoch time: 65.18 s 
2025-06-05 01:07:56.219177:  
2025-06-05 01:07:56.233943: Epoch 861 
2025-06-05 01:07:56.241546: Current learning rate: 0.00169 
2025-06-05 01:09:01.335135: train_loss -0.7148 
2025-06-05 01:09:01.359608: val_loss -0.7222 
2025-06-05 01:09:01.378728: Pseudo dice [np.float32(0.7943)] 
2025-06-05 01:09:01.391975: Epoch time: 65.12 s 
2025-06-05 01:09:02.663751:  
2025-06-05 01:09:02.682045: Epoch 862 
2025-06-05 01:09:02.689656: Current learning rate: 0.00168 
2025-06-05 01:10:07.705424: train_loss -0.7416 
2025-06-05 01:10:07.732224: val_loss -0.649 
2025-06-05 01:10:07.756133: Pseudo dice [np.float32(0.7523)] 
2025-06-05 01:10:07.790337: Epoch time: 65.04 s 
2025-06-05 01:10:09.208045:  
2025-06-05 01:10:09.222803: Epoch 863 
2025-06-05 01:10:09.230968: Current learning rate: 0.00167 
2025-06-05 01:11:14.276156: train_loss -0.7525 
2025-06-05 01:11:14.337417: val_loss -0.7547 
2025-06-05 01:11:14.372913: Pseudo dice [np.float32(0.7787)] 
2025-06-05 01:11:14.386757: Epoch time: 65.07 s 
2025-06-05 01:11:15.637176:  
2025-06-05 01:11:15.665758: Epoch 864 
2025-06-05 01:11:15.674929: Current learning rate: 0.00166 
2025-06-05 01:12:20.860135: train_loss -0.7359 
2025-06-05 01:12:20.962874: val_loss -0.683 
2025-06-05 01:12:20.987872: Pseudo dice [np.float32(0.8064)] 
2025-06-05 01:12:21.004785: Epoch time: 65.22 s 
2025-06-05 01:12:22.162639:  
2025-06-05 01:12:22.180451: Epoch 865 
2025-06-05 01:12:22.188066: Current learning rate: 0.00165 
2025-06-05 01:13:27.297337: train_loss -0.7358 
2025-06-05 01:13:27.350218: val_loss -0.7233 
2025-06-05 01:13:27.408028: Pseudo dice [np.float32(0.7698)] 
2025-06-05 01:13:27.462308: Epoch time: 65.14 s 
2025-06-05 01:13:28.648285:  
2025-06-05 01:13:28.670793: Epoch 866 
2025-06-05 01:13:28.688335: Current learning rate: 0.00164 
2025-06-05 01:14:33.699894: train_loss -0.7474 
2025-06-05 01:14:33.723177: val_loss -0.7472 
2025-06-05 01:14:33.742641: Pseudo dice [np.float32(0.8258)] 
2025-06-05 01:14:33.756042: Epoch time: 65.05 s 
2025-06-05 01:14:35.089415:  
2025-06-05 01:14:35.101283: Epoch 867 
2025-06-05 01:14:35.110582: Current learning rate: 0.00163 
2025-06-05 01:15:40.113384: train_loss -0.7375 
2025-06-05 01:15:40.137642: val_loss -0.6523 
2025-06-05 01:15:40.156250: Pseudo dice [np.float32(0.7707)] 
2025-06-05 01:15:40.169194: Epoch time: 65.02 s 
2025-06-05 01:15:41.467667:  
2025-06-05 01:15:41.495430: Epoch 868 
2025-06-05 01:15:41.504134: Current learning rate: 0.00162 
2025-06-05 01:16:46.533469: train_loss -0.7506 
2025-06-05 01:16:46.584118: val_loss -0.6808 
2025-06-05 01:16:46.603326: Pseudo dice [np.float32(0.835)] 
2025-06-05 01:16:46.615689: Epoch time: 65.07 s 
2025-06-05 01:16:47.884939:  
2025-06-05 01:16:47.914954: Epoch 869 
2025-06-05 01:16:47.923563: Current learning rate: 0.00161 
2025-06-05 01:17:53.044267: train_loss -0.7337 
2025-06-05 01:17:53.092505: val_loss -0.7484 
2025-06-05 01:17:53.132359: Pseudo dice [np.float32(0.7677)] 
2025-06-05 01:17:53.163670: Epoch time: 65.16 s 
2025-06-05 01:17:54.664803:  
2025-06-05 01:17:54.694361: Epoch 870 
2025-06-05 01:17:54.701993: Current learning rate: 0.00159 
2025-06-05 01:18:59.729644: train_loss -0.7367 
2025-06-05 01:18:59.759668: val_loss -0.697 
2025-06-05 01:18:59.798700: Pseudo dice [np.float32(0.7892)] 
2025-06-05 01:18:59.813101: Epoch time: 65.07 s 
2025-06-05 01:19:01.057648:  
2025-06-05 01:19:01.085671: Epoch 871 
2025-06-05 01:19:01.093386: Current learning rate: 0.00158 
2025-06-05 01:20:06.090909: train_loss -0.7476 
2025-06-05 01:20:06.141891: val_loss -0.675 
2025-06-05 01:20:06.196122: Pseudo dice [np.float32(0.8202)] 
2025-06-05 01:20:06.276379: Epoch time: 65.03 s 
2025-06-05 01:20:07.428314:  
2025-06-05 01:20:07.449376: Epoch 872 
2025-06-05 01:20:07.457442: Current learning rate: 0.00157 
2025-06-05 01:21:12.509825: train_loss -0.7633 
2025-06-05 01:21:12.533500: val_loss -0.6535 
2025-06-05 01:21:12.564811: Pseudo dice [np.float32(0.7633)] 
2025-06-05 01:21:12.577782: Epoch time: 65.08 s 
2025-06-05 01:21:13.864202:  
2025-06-05 01:21:13.875489: Epoch 873 
2025-06-05 01:21:13.883536: Current learning rate: 0.00156 
2025-06-05 01:22:18.907760: train_loss -0.7483 
2025-06-05 01:22:18.938653: val_loss -0.697 
2025-06-05 01:22:18.959414: Pseudo dice [np.float32(0.8103)] 
2025-06-05 01:22:18.984842: Epoch time: 65.04 s 
2025-06-05 01:22:20.274776:  
2025-06-05 01:22:20.291310: Epoch 874 
2025-06-05 01:22:20.299900: Current learning rate: 0.00155 
2025-06-05 01:23:25.261999: train_loss -0.7556 
2025-06-05 01:23:25.346253: val_loss -0.7036 
2025-06-05 01:23:25.388550: Pseudo dice [np.float32(0.7827)] 
2025-06-05 01:23:25.436857: Epoch time: 64.99 s 
2025-06-05 01:23:26.654624:  
2025-06-05 01:23:26.676657: Epoch 875 
2025-06-05 01:23:26.684738: Current learning rate: 0.00154 
2025-06-05 01:24:31.728178: train_loss -0.7451 
2025-06-05 01:24:31.753230: val_loss -0.6968 
2025-06-05 01:24:31.800118: Pseudo dice [np.float32(0.7495)] 
2025-06-05 01:24:31.839892: Epoch time: 65.07 s 
2025-06-05 01:24:33.066959:  
2025-06-05 01:24:33.094348: Epoch 876 
2025-06-05 01:24:33.102402: Current learning rate: 0.00153 
2025-06-05 01:25:38.103904: train_loss -0.7527 
2025-06-05 01:25:38.183197: val_loss -0.6501 
2025-06-05 01:25:38.222804: Pseudo dice [np.float32(0.7292)] 
2025-06-05 01:25:38.237253: Epoch time: 65.04 s 
2025-06-05 01:25:39.494114:  
2025-06-05 01:25:39.516687: Epoch 877 
2025-06-05 01:25:39.524763: Current learning rate: 0.00152 
2025-06-05 01:26:44.634504: train_loss -0.7243 
2025-06-05 01:26:44.696078: val_loss -0.6711 
2025-06-05 01:26:44.717511: Pseudo dice [np.float32(0.7607)] 
2025-06-05 01:26:44.729919: Epoch time: 65.14 s 
2025-06-05 01:26:46.189265:  
2025-06-05 01:26:46.209018: Epoch 878 
2025-06-05 01:26:46.217067: Current learning rate: 0.00151 
2025-06-05 01:27:51.392759: train_loss -0.7367 
2025-06-05 01:27:51.483275: val_loss -0.6975 
2025-06-05 01:27:51.547520: Pseudo dice [np.float32(0.7666)] 
2025-06-05 01:27:51.567243: Epoch time: 65.2 s 
2025-06-05 01:27:52.762488:  
2025-06-05 01:27:52.780342: Epoch 879 
2025-06-05 01:27:52.787980: Current learning rate: 0.00149 
2025-06-05 01:28:57.912865: train_loss -0.747 
2025-06-05 01:28:57.936509: val_loss -0.7184 
2025-06-05 01:28:57.960165: Pseudo dice [np.float32(0.8179)] 
2025-06-05 01:28:57.975087: Epoch time: 65.15 s 
2025-06-05 01:28:59.222868:  
2025-06-05 01:28:59.234509: Epoch 880 
2025-06-05 01:28:59.243077: Current learning rate: 0.00148 
2025-06-05 01:30:04.259670: train_loss -0.7407 
2025-06-05 01:30:04.284738: val_loss -0.6975 
2025-06-05 01:30:04.303746: Pseudo dice [np.float32(0.7828)] 
2025-06-05 01:30:04.316100: Epoch time: 65.04 s 
2025-06-05 01:30:05.641227:  
2025-06-05 01:30:05.671726: Epoch 881 
2025-06-05 01:30:05.680306: Current learning rate: 0.00147 
2025-06-05 01:31:10.836877: train_loss -0.7345 
2025-06-05 01:31:10.891884: val_loss -0.6629 
2025-06-05 01:31:10.969166: Pseudo dice [np.float32(0.7964)] 
2025-06-05 01:31:11.043648: Epoch time: 65.2 s 
2025-06-05 01:31:12.258139:  
2025-06-05 01:31:12.277467: Epoch 882 
2025-06-05 01:31:12.285552: Current learning rate: 0.00146 
2025-06-05 01:32:17.401727: train_loss -0.7407 
2025-06-05 01:32:17.451492: val_loss -0.7319 
2025-06-05 01:32:17.465314: Pseudo dice [np.float32(0.8101)] 
2025-06-05 01:32:17.482268: Epoch time: 65.14 s 
2025-06-05 01:32:18.727811:  
2025-06-05 01:32:18.754505: Epoch 883 
2025-06-05 01:32:18.762661: Current learning rate: 0.00145 
2025-06-05 01:33:23.811835: train_loss -0.7597 
2025-06-05 01:33:23.848270: val_loss -0.7898 
2025-06-05 01:33:23.885031: Pseudo dice [np.float32(0.8877)] 
2025-06-05 01:33:23.900614: Epoch time: 65.09 s 
2025-06-05 01:33:25.197848:  
2025-06-05 01:33:25.228498: Epoch 884 
2025-06-05 01:33:25.239793: Current learning rate: 0.00144 
2025-06-05 01:34:30.299717: train_loss -0.7395 
2025-06-05 01:34:30.324474: val_loss -0.7023 
2025-06-05 01:34:30.371653: Pseudo dice [np.float32(0.8352)] 
2025-06-05 01:34:30.448337: Epoch time: 65.1 s 
2025-06-05 01:34:30.518049: Yayy! New best EMA pseudo Dice: 0.798799991607666 
2025-06-05 01:34:32.022213:  
2025-06-05 01:34:32.045173: Epoch 885 
2025-06-05 01:34:32.053768: Current learning rate: 0.00143 
2025-06-05 01:35:37.400271: train_loss -0.7581 
2025-06-05 01:35:37.432773: val_loss -0.6941 
2025-06-05 01:35:37.451798: Pseudo dice [np.float32(0.7644)] 
2025-06-05 01:35:37.488873: Epoch time: 65.38 s 
2025-06-05 01:35:38.896763:  
2025-06-05 01:35:38.917680: Epoch 886 
2025-06-05 01:35:38.925763: Current learning rate: 0.00142 
2025-06-05 01:36:44.135311: train_loss -0.7574 
2025-06-05 01:36:44.179444: val_loss -0.6962 
2025-06-05 01:36:44.225586: Pseudo dice [np.float32(0.8088)] 
2025-06-05 01:36:44.312301: Epoch time: 65.24 s 
2025-06-05 01:36:45.524364:  
2025-06-05 01:36:45.545883: Epoch 887 
2025-06-05 01:36:45.553946: Current learning rate: 0.00141 
2025-06-05 01:37:50.723785: train_loss -0.7355 
2025-06-05 01:37:50.795940: val_loss -0.7161 
2025-06-05 01:37:50.850750: Pseudo dice [np.float32(0.8233)] 
2025-06-05 01:37:50.877786: Epoch time: 65.2 s 
2025-06-05 01:37:50.891346: Yayy! New best EMA pseudo Dice: 0.7993999719619751 
2025-06-05 01:37:52.317441:  
2025-06-05 01:37:52.331760: Epoch 888 
2025-06-05 01:37:52.341367: Current learning rate: 0.00139 
2025-06-05 01:38:57.628614: train_loss -0.7496 
2025-06-05 01:38:57.703204: val_loss -0.6813 
2025-06-05 01:38:57.739495: Pseudo dice [np.float32(0.7757)] 
2025-06-05 01:38:57.756493: Epoch time: 65.31 s 
2025-06-05 01:38:58.925725:  
2025-06-05 01:38:58.952838: Epoch 889 
2025-06-05 01:38:58.962232: Current learning rate: 0.00138 
2025-06-05 01:40:04.080142: train_loss -0.7604 
2025-06-05 01:40:04.105757: val_loss -0.6753 
2025-06-05 01:40:04.124149: Pseudo dice [np.float32(0.8109)] 
2025-06-05 01:40:04.139013: Epoch time: 65.16 s 
2025-06-05 01:40:05.399958:  
2025-06-05 01:40:05.429443: Epoch 890 
2025-06-05 01:40:05.438599: Current learning rate: 0.00137 
2025-06-05 01:41:10.525217: train_loss -0.7367 
2025-06-05 01:41:10.580677: val_loss -0.6015 
2025-06-05 01:41:10.619553: Pseudo dice [np.float32(0.6836)] 
2025-06-05 01:41:10.633865: Epoch time: 65.13 s 
2025-06-05 01:41:11.900679:  
2025-06-05 01:41:11.918969: Epoch 891 
2025-06-05 01:41:11.927018: Current learning rate: 0.00136 
2025-06-05 01:42:16.962708: train_loss -0.7611 
2025-06-05 01:42:17.005866: val_loss -0.6666 
2025-06-05 01:42:17.043788: Pseudo dice [np.float32(0.81)] 
2025-06-05 01:42:17.096032: Epoch time: 65.06 s 
2025-06-05 01:42:18.255561:  
2025-06-05 01:42:18.277014: Epoch 892 
2025-06-05 01:42:18.285090: Current learning rate: 0.00135 
2025-06-05 01:43:23.398158: train_loss -0.7542 
2025-06-05 01:43:23.422289: val_loss -0.7169 
2025-06-05 01:43:23.479429: Pseudo dice [np.float32(0.8191)] 
2025-06-05 01:43:23.541999: Epoch time: 65.14 s 
2025-06-05 01:43:24.888261:  
2025-06-05 01:43:24.907480: Epoch 893 
2025-06-05 01:43:24.915065: Current learning rate: 0.00134 
2025-06-05 01:44:29.899238: train_loss -0.7455 
2025-06-05 01:44:29.980578: val_loss -0.7272 
2025-06-05 01:44:30.050210: Pseudo dice [np.float32(0.8638)] 
2025-06-05 01:44:30.097084: Epoch time: 65.01 s 
2025-06-05 01:44:30.158115: Yayy! New best EMA pseudo Dice: 0.7993999719619751 
2025-06-05 01:44:31.555315:  
2025-06-05 01:44:31.570119: Epoch 894 
2025-06-05 01:44:31.593242: Current learning rate: 0.00133 
2025-06-05 01:45:36.704031: train_loss -0.7464 
2025-06-05 01:45:36.728259: val_loss -0.6706 
2025-06-05 01:45:36.768946: Pseudo dice [np.float32(0.7477)] 
2025-06-05 01:45:36.782660: Epoch time: 65.15 s 
2025-06-05 01:45:37.990353:  
2025-06-05 01:45:38.014378: Epoch 895 
2025-06-05 01:45:38.022558: Current learning rate: 0.00132 
2025-06-05 01:46:43.264344: train_loss -0.7468 
2025-06-05 01:46:43.296103: val_loss -0.7258 
2025-06-05 01:46:43.331902: Pseudo dice [np.float32(0.8518)] 
2025-06-05 01:46:43.386851: Epoch time: 65.28 s 
2025-06-05 01:46:43.457465: Yayy! New best EMA pseudo Dice: 0.800000011920929 
2025-06-05 01:46:44.953214:  
2025-06-05 01:46:44.976208: Epoch 896 
2025-06-05 01:46:44.983996: Current learning rate: 0.0013 
2025-06-05 01:47:50.260019: train_loss -0.7217 
2025-06-05 01:47:50.333381: val_loss -0.691 
2025-06-05 01:47:50.409209: Pseudo dice [np.float32(0.7948)] 
2025-06-05 01:47:50.441503: Epoch time: 65.31 s 
2025-06-05 01:47:51.590806:  
2025-06-05 01:47:51.603154: Epoch 897 
2025-06-05 01:47:51.611737: Current learning rate: 0.00129 
2025-06-05 01:48:56.659288: train_loss -0.7375 
2025-06-05 01:48:56.682355: val_loss -0.7165 
2025-06-05 01:48:56.700757: Pseudo dice [np.float32(0.7653)] 
2025-06-05 01:48:56.713405: Epoch time: 65.07 s 
2025-06-05 01:48:58.041256:  
2025-06-05 01:48:58.058551: Epoch 898 
2025-06-05 01:48:58.067192: Current learning rate: 0.00128 
2025-06-05 01:50:03.205575: train_loss -0.7344 
2025-06-05 01:50:03.229138: val_loss -0.7508 
2025-06-05 01:50:03.241922: Pseudo dice [np.float32(0.7844)] 
2025-06-05 01:50:03.256069: Epoch time: 65.17 s 
2025-06-05 01:50:04.491646:  
2025-06-05 01:50:04.508311: Epoch 899 
2025-06-05 01:50:04.516357: Current learning rate: 0.00127 
2025-06-05 01:51:09.603610: train_loss -0.7575 
2025-06-05 01:51:09.630449: val_loss -0.7133 
2025-06-05 01:51:09.704096: Pseudo dice [np.float32(0.8112)] 
2025-06-05 01:51:09.791846: Epoch time: 65.11 s 
2025-06-05 01:51:11.486514:  
2025-06-05 01:51:11.499224: Epoch 900 
2025-06-05 01:51:11.506860: Current learning rate: 0.00126 
2025-06-05 01:52:16.608718: train_loss -0.747 
2025-06-05 01:52:16.653529: val_loss -0.6732 
2025-06-05 01:52:16.695042: Pseudo dice [np.float32(0.7623)] 
2025-06-05 01:52:16.708187: Epoch time: 65.12 s 
2025-06-05 01:52:17.947373:  
2025-06-05 01:52:17.972622: Epoch 901 
2025-06-05 01:52:17.980667: Current learning rate: 0.00125 
2025-06-05 01:53:23.043409: train_loss -0.7454 
2025-06-05 01:53:23.118643: val_loss -0.7196 
2025-06-05 01:53:23.143260: Pseudo dice [np.float32(0.8488)] 
2025-06-05 01:53:23.164367: Epoch time: 65.1 s 
2025-06-05 01:53:24.426158:  
2025-06-05 01:53:24.452820: Epoch 902 
2025-06-05 01:53:24.461049: Current learning rate: 0.00124 
2025-06-05 01:54:29.519995: train_loss -0.7607 
2025-06-05 01:54:29.548002: val_loss -0.6958 
2025-06-05 01:54:29.582479: Pseudo dice [np.float32(0.7592)] 
2025-06-05 01:54:29.626940: Epoch time: 65.09 s 
2025-06-05 01:54:30.891208:  
2025-06-05 01:54:30.907329: Epoch 903 
2025-06-05 01:54:30.914840: Current learning rate: 0.00122 
2025-06-05 01:55:36.006045: train_loss -0.742 
2025-06-05 01:55:36.029651: val_loss -0.7073 
2025-06-05 01:55:36.062878: Pseudo dice [np.float32(0.8403)] 
2025-06-05 01:55:36.079967: Epoch time: 65.12 s 
2025-06-05 01:55:37.301123:  
2025-06-05 01:55:37.324109: Epoch 904 
2025-06-05 01:55:37.332306: Current learning rate: 0.00121 
2025-06-05 01:56:42.444330: train_loss -0.7405 
2025-06-05 01:56:42.523263: val_loss -0.758 
2025-06-05 01:56:42.582048: Pseudo dice [np.float32(0.821)] 
2025-06-05 01:56:42.621456: Epoch time: 65.14 s 
2025-06-05 01:56:42.659805: Yayy! New best EMA pseudo Dice: 0.8014000058174133 
2025-06-05 01:56:44.097003:  
2025-06-05 01:56:44.128208: Epoch 905 
2025-06-05 01:56:44.137051: Current learning rate: 0.0012 
2025-06-05 01:57:49.453362: train_loss -0.7385 
2025-06-05 01:57:49.520848: val_loss -0.706 
2025-06-05 01:57:49.541462: Pseudo dice [np.float32(0.8288)] 
2025-06-05 01:57:49.553803: Epoch time: 65.36 s 
2025-06-05 01:57:49.566385: Yayy! New best EMA pseudo Dice: 0.8041999936103821 
2025-06-05 01:57:51.081742:  
2025-06-05 01:57:51.097017: Epoch 906 
2025-06-05 01:57:51.104664: Current learning rate: 0.00119 
2025-06-05 01:58:56.180961: train_loss -0.745 
2025-06-05 01:58:56.239875: val_loss -0.7387 
2025-06-05 01:58:56.291502: Pseudo dice [np.float32(0.8297)] 
2025-06-05 01:58:56.356578: Epoch time: 65.1 s 
2025-06-05 01:58:56.389718: Yayy! New best EMA pseudo Dice: 0.8066999912261963 
2025-06-05 01:58:57.842819:  
2025-06-05 01:58:57.854072: Epoch 907 
2025-06-05 01:58:57.861733: Current learning rate: 0.00118 
2025-06-05 02:00:02.925721: train_loss -0.7348 
2025-06-05 02:00:02.962199: val_loss -0.7118 
2025-06-05 02:00:02.980732: Pseudo dice [np.float32(0.7586)] 
2025-06-05 02:00:02.993719: Epoch time: 65.08 s 
2025-06-05 02:00:04.482284:  
2025-06-05 02:00:04.504124: Epoch 908 
2025-06-05 02:00:04.512318: Current learning rate: 0.00117 
2025-06-05 02:01:09.614639: train_loss -0.7455 
2025-06-05 02:01:09.636251: val_loss -0.7311 
2025-06-05 02:01:09.696934: Pseudo dice [np.float32(0.8268)] 
2025-06-05 02:01:09.741596: Epoch time: 65.13 s 
2025-06-05 02:01:10.900726:  
2025-06-05 02:01:10.923290: Epoch 909 
2025-06-05 02:01:10.930974: Current learning rate: 0.00116 
2025-06-05 02:02:16.065028: train_loss -0.7594 
2025-06-05 02:02:16.089318: val_loss -0.6345 
2025-06-05 02:02:16.107958: Pseudo dice [np.float32(0.803)] 
2025-06-05 02:02:16.122906: Epoch time: 65.17 s 
2025-06-05 02:02:17.436412:  
2025-06-05 02:02:17.461562: Epoch 910 
2025-06-05 02:02:17.470287: Current learning rate: 0.00115 
2025-06-05 02:03:22.688381: train_loss -0.7469 
2025-06-05 02:03:22.755726: val_loss -0.6693 
2025-06-05 02:03:22.779731: Pseudo dice [np.float32(0.8006)] 
2025-06-05 02:03:22.795263: Epoch time: 65.25 s 
2025-06-05 02:03:24.036006:  
2025-06-05 02:03:24.061899: Epoch 911 
2025-06-05 02:03:24.070653: Current learning rate: 0.00113 
2025-06-05 02:04:28.972458: train_loss -0.7691 
2025-06-05 02:04:29.010686: val_loss -0.7215 
2025-06-05 02:04:29.032223: Pseudo dice [np.float32(0.8281)] 
2025-06-05 02:04:29.045785: Epoch time: 64.94 s 
2025-06-05 02:04:30.260065:  
2025-06-05 02:04:30.276388: Epoch 912 
2025-06-05 02:04:30.284724: Current learning rate: 0.00112 
2025-06-05 02:05:35.088621: train_loss -0.7425 
2025-06-05 02:05:35.147671: val_loss -0.6904 
2025-06-05 02:05:35.187274: Pseudo dice [np.float32(0.7291)] 
2025-06-05 02:05:35.201532: Epoch time: 64.83 s 
2025-06-05 02:05:36.472418:  
2025-06-05 02:05:36.502930: Epoch 913 
2025-06-05 02:05:36.515843: Current learning rate: 0.00111 
2025-06-05 02:06:41.583695: train_loss -0.753 
2025-06-05 02:06:41.630121: val_loss -0.6808 
2025-06-05 02:06:41.642987: Pseudo dice [np.float32(0.7928)] 
2025-06-05 02:06:41.656196: Epoch time: 65.11 s 
2025-06-05 02:06:42.905424:  
2025-06-05 02:06:42.931124: Epoch 914 
2025-06-05 02:06:42.955758: Current learning rate: 0.0011 
2025-06-05 02:07:48.016816: train_loss -0.7507 
2025-06-05 02:07:48.040351: val_loss -0.6364 
2025-06-05 02:07:48.062042: Pseudo dice [np.float32(0.7071)] 
2025-06-05 02:07:48.075369: Epoch time: 65.11 s 
2025-06-05 02:07:49.309442:  
2025-06-05 02:07:49.326097: Epoch 915 
2025-06-05 02:07:49.334186: Current learning rate: 0.00109 
2025-06-05 02:08:54.366517: train_loss -0.7419 
2025-06-05 02:08:54.445533: val_loss -0.6934 
2025-06-05 02:08:54.499300: Pseudo dice [np.float32(0.7997)] 
2025-06-05 02:08:54.535630: Epoch time: 65.06 s 
2025-06-05 02:08:56.028753:  
2025-06-05 02:08:56.046044: Epoch 916 
2025-06-05 02:08:56.054656: Current learning rate: 0.00108 
2025-06-05 02:10:01.231003: train_loss -0.728 
2025-06-05 02:10:01.254065: val_loss -0.7152 
2025-06-05 02:10:01.280476: Pseudo dice [np.float32(0.8189)] 
2025-06-05 02:10:01.328879: Epoch time: 65.2 s 
2025-06-05 02:10:02.627252:  
2025-06-05 02:10:02.638579: Epoch 917 
2025-06-05 02:10:02.646655: Current learning rate: 0.00106 
2025-06-05 02:11:08.018929: train_loss -0.7739 
2025-06-05 02:11:08.121069: val_loss -0.7063 
2025-06-05 02:11:08.188021: Pseudo dice [np.float32(0.7875)] 
2025-06-05 02:11:08.218951: Epoch time: 65.39 s 
2025-06-05 02:11:09.385010:  
2025-06-05 02:11:09.399009: Epoch 918 
2025-06-05 02:11:09.406959: Current learning rate: 0.00105 
2025-06-05 02:12:14.436232: train_loss -0.7588 
2025-06-05 02:12:14.501516: val_loss -0.7097 
2025-06-05 02:12:14.563993: Pseudo dice [np.float32(0.8392)] 
2025-06-05 02:12:14.598021: Epoch time: 65.05 s 
2025-06-05 02:12:15.737341:  
2025-06-05 02:12:15.755546: Epoch 919 
2025-06-05 02:12:15.763075: Current learning rate: 0.00104 
2025-06-05 02:13:20.775615: train_loss -0.7549 
2025-06-05 02:13:20.843025: val_loss -0.7246 
2025-06-05 02:13:20.918119: Pseudo dice [np.float32(0.8244)] 
2025-06-05 02:13:20.941977: Epoch time: 65.04 s 
2025-06-05 02:13:22.102160:  
2025-06-05 02:13:22.116946: Epoch 920 
2025-06-05 02:13:22.125134: Current learning rate: 0.00103 
2025-06-05 02:14:27.048419: train_loss -0.7468 
2025-06-05 02:14:27.090937: val_loss -0.6789 
2025-06-05 02:14:27.112426: Pseudo dice [np.float32(0.7398)] 
2025-06-05 02:14:27.124731: Epoch time: 64.95 s 
2025-06-05 02:14:28.391674:  
2025-06-05 02:14:28.412598: Epoch 921 
2025-06-05 02:14:28.420124: Current learning rate: 0.00102 
2025-06-05 02:15:33.296065: train_loss -0.7492 
2025-06-05 02:15:33.319246: val_loss -0.7209 
2025-06-05 02:15:33.360020: Pseudo dice [np.float32(0.7608)] 
2025-06-05 02:15:33.397385: Epoch time: 64.91 s 
2025-06-05 02:15:34.733015:  
2025-06-05 02:15:34.746764: Epoch 922 
2025-06-05 02:15:34.754394: Current learning rate: 0.00101 
2025-06-05 02:16:39.763619: train_loss -0.7447 
2025-06-05 02:16:39.830080: val_loss -0.7031 
2025-06-05 02:16:39.891584: Pseudo dice [np.float32(0.7617)] 
2025-06-05 02:16:39.926367: Epoch time: 65.03 s 
2025-06-05 02:16:41.085294:  
2025-06-05 02:16:41.103184: Epoch 923 
2025-06-05 02:16:41.113388: Current learning rate: 0.001 
2025-06-05 02:17:46.151502: train_loss -0.7611 
2025-06-05 02:17:46.198607: val_loss -0.6634 
2025-06-05 02:17:46.243771: Pseudo dice [np.float32(0.7911)] 
2025-06-05 02:17:46.323179: Epoch time: 65.07 s 
2025-06-05 02:17:47.772858:  
2025-06-05 02:17:47.792831: Epoch 924 
2025-06-05 02:17:47.799955: Current learning rate: 0.00098 
2025-06-05 02:18:52.896901: train_loss -0.7682 
2025-06-05 02:18:52.943038: val_loss -0.7354 
2025-06-05 02:18:52.981656: Pseudo dice [np.float32(0.7689)] 
2025-06-05 02:18:53.049036: Epoch time: 65.13 s 
2025-06-05 02:18:54.234478:  
2025-06-05 02:18:54.264596: Epoch 925 
2025-06-05 02:18:54.274336: Current learning rate: 0.00097 
2025-06-05 02:19:59.201637: train_loss -0.7503 
2025-06-05 02:19:59.237253: val_loss -0.6618 
2025-06-05 02:19:59.272067: Pseudo dice [np.float32(0.7441)] 
2025-06-05 02:19:59.311288: Epoch time: 64.97 s 
2025-06-05 02:20:00.579184:  
2025-06-05 02:20:00.591630: Epoch 926 
2025-06-05 02:20:00.604703: Current learning rate: 0.00096 
2025-06-05 02:21:05.645473: train_loss -0.7657 
2025-06-05 02:21:05.721931: val_loss -0.6982 
2025-06-05 02:21:05.741377: Pseudo dice [np.float32(0.7405)] 
2025-06-05 02:21:05.755007: Epoch time: 65.07 s 
2025-06-05 02:21:06.968785:  
2025-06-05 02:21:06.991288: Epoch 927 
2025-06-05 02:21:06.999346: Current learning rate: 0.00095 
2025-06-05 02:22:11.873003: train_loss -0.7443 
2025-06-05 02:22:11.899109: val_loss -0.7648 
2025-06-05 02:22:11.954498: Pseudo dice [np.float32(0.8654)] 
2025-06-05 02:22:11.998036: Epoch time: 64.91 s 
2025-06-05 02:22:13.318722:  
2025-06-05 02:22:13.348322: Epoch 928 
2025-06-05 02:22:13.357998: Current learning rate: 0.00094 
2025-06-05 02:23:18.603857: train_loss -0.7578 
2025-06-05 02:23:18.640552: val_loss -0.6838 
2025-06-05 02:23:18.677085: Pseudo dice [np.float32(0.8214)] 
2025-06-05 02:23:18.723487: Epoch time: 65.29 s 
2025-06-05 02:23:19.974292:  
2025-06-05 02:23:20.004471: Epoch 929 
2025-06-05 02:23:20.014167: Current learning rate: 0.00092 
2025-06-05 02:24:24.868319: train_loss -0.7605 
2025-06-05 02:24:24.941984: val_loss -0.7086 
2025-06-05 02:24:24.988901: Pseudo dice [np.float32(0.8319)] 
2025-06-05 02:24:25.055586: Epoch time: 64.9 s 
2025-06-05 02:24:26.236669:  
2025-06-05 02:24:26.254956: Epoch 930 
2025-06-05 02:24:26.262460: Current learning rate: 0.00091 
2025-06-05 02:25:31.291646: train_loss -0.7498 
2025-06-05 02:25:31.326209: val_loss -0.7296 
2025-06-05 02:25:31.359098: Pseudo dice [np.float32(0.8506)] 
2025-06-05 02:25:31.372000: Epoch time: 65.06 s 
2025-06-05 02:25:32.576093:  
2025-06-05 02:25:32.606738: Epoch 931 
2025-06-05 02:25:32.614786: Current learning rate: 0.0009 
2025-06-05 02:26:37.459520: train_loss -0.7662 
2025-06-05 02:26:37.502840: val_loss -0.7354 
2025-06-05 02:26:37.543853: Pseudo dice [np.float32(0.8279)] 
2025-06-05 02:26:37.649188: Epoch time: 64.88 s 
2025-06-05 02:26:39.076638:  
2025-06-05 02:26:39.094043: Epoch 932 
2025-06-05 02:26:39.101699: Current learning rate: 0.00089 
2025-06-05 02:27:44.151152: train_loss -0.7629 
2025-06-05 02:27:44.182403: val_loss -0.7035 
2025-06-05 02:27:44.204514: Pseudo dice [np.float32(0.7819)] 
2025-06-05 02:27:44.219312: Epoch time: 65.08 s 
2025-06-05 02:27:45.486161:  
2025-06-05 02:27:45.510326: Epoch 933 
2025-06-05 02:27:45.518980: Current learning rate: 0.00088 
2025-06-05 02:28:50.412434: train_loss -0.7774 
2025-06-05 02:28:50.460929: val_loss -0.7189 
2025-06-05 02:28:50.500503: Pseudo dice [np.float32(0.83)] 
2025-06-05 02:28:50.542255: Epoch time: 64.93 s 
2025-06-05 02:28:51.712808:  
2025-06-05 02:28:51.726111: Epoch 934 
2025-06-05 02:28:51.733746: Current learning rate: 0.00087 
2025-06-05 02:29:56.757833: train_loss -0.7619 
2025-06-05 02:29:56.787742: val_loss -0.7374 
2025-06-05 02:29:56.820097: Pseudo dice [np.float32(0.792)] 
2025-06-05 02:29:56.835538: Epoch time: 65.05 s 
2025-06-05 02:29:58.061447:  
2025-06-05 02:29:58.082431: Epoch 935 
2025-06-05 02:29:58.090297: Current learning rate: 0.00085 
2025-06-05 02:31:03.124453: train_loss -0.7518 
2025-06-05 02:31:03.164104: val_loss -0.7151 
2025-06-05 02:31:03.182026: Pseudo dice [np.float32(0.7906)] 
2025-06-05 02:31:03.194958: Epoch time: 65.07 s 
2025-06-05 02:31:04.441992:  
2025-06-05 02:31:04.468325: Epoch 936 
2025-06-05 02:31:04.476368: Current learning rate: 0.00084 
2025-06-05 02:32:09.457199: train_loss -0.7633 
2025-06-05 02:32:09.532916: val_loss -0.6612 
2025-06-05 02:32:09.619463: Pseudo dice [np.float32(0.7732)] 
2025-06-05 02:32:09.655931: Epoch time: 65.02 s 
2025-06-05 02:32:10.780622:  
2025-06-05 02:32:10.801296: Epoch 937 
2025-06-05 02:32:10.809129: Current learning rate: 0.00083 
2025-06-05 02:33:15.750020: train_loss -0.7727 
2025-06-05 02:33:15.774656: val_loss -0.6641 
2025-06-05 02:33:15.828296: Pseudo dice [np.float32(0.7571)] 
2025-06-05 02:33:15.873873: Epoch time: 64.97 s 
2025-06-05 02:33:17.031288:  
2025-06-05 02:33:17.044258: Epoch 938 
2025-06-05 02:33:17.052321: Current learning rate: 0.00082 
2025-06-05 02:34:22.049949: train_loss -0.7712 
2025-06-05 02:34:22.128748: val_loss -0.7644 
2025-06-05 02:34:22.151548: Pseudo dice [np.float32(0.7994)] 
2025-06-05 02:34:22.164306: Epoch time: 65.02 s 
2025-06-05 02:34:23.352503:  
2025-06-05 02:34:23.364827: Epoch 939 
2025-06-05 02:34:23.372907: Current learning rate: 0.00081 
2025-06-05 02:35:28.467039: train_loss -0.7548 
2025-06-05 02:35:28.490095: val_loss -0.7176 
2025-06-05 02:35:28.509700: Pseudo dice [np.float32(0.7783)] 
2025-06-05 02:35:28.523027: Epoch time: 65.12 s 
2025-06-05 02:35:29.950926:  
2025-06-05 02:35:29.971386: Epoch 940 
2025-06-05 02:35:29.979549: Current learning rate: 0.00079 
2025-06-05 02:36:34.995461: train_loss -0.7628 
2025-06-05 02:36:35.015056: val_loss -0.7017 
2025-06-05 02:36:35.057424: Pseudo dice [np.float32(0.7813)] 
2025-06-05 02:36:35.102100: Epoch time: 65.05 s 
2025-06-05 02:36:36.366848:  
2025-06-05 02:36:36.389213: Epoch 941 
2025-06-05 02:36:36.396890: Current learning rate: 0.00078 
2025-06-05 02:37:41.401708: train_loss -0.7597 
2025-06-05 02:37:41.479313: val_loss -0.73 
2025-06-05 02:37:41.537016: Pseudo dice [np.float32(0.7517)] 
2025-06-05 02:37:41.568589: Epoch time: 65.04 s 
2025-06-05 02:37:42.721470:  
2025-06-05 02:37:42.748341: Epoch 942 
2025-06-05 02:37:42.756413: Current learning rate: 0.00077 
2025-06-05 02:38:47.705722: train_loss -0.7378 
2025-06-05 02:38:47.730317: val_loss -0.7381 
2025-06-05 02:38:47.749705: Pseudo dice [np.float32(0.7574)] 
2025-06-05 02:38:47.763393: Epoch time: 64.99 s 
2025-06-05 02:38:49.001763:  
2025-06-05 02:38:49.021092: Epoch 943 
2025-06-05 02:38:49.028600: Current learning rate: 0.00076 
2025-06-05 02:39:54.188698: train_loss -0.7573 
2025-06-05 02:39:54.214612: val_loss -0.7234 
2025-06-05 02:39:54.261035: Pseudo dice [np.float32(0.7893)] 
2025-06-05 02:39:54.285979: Epoch time: 65.19 s 
2025-06-05 02:39:55.529342:  
2025-06-05 02:39:55.557334: Epoch 944 
2025-06-05 02:39:55.565400: Current learning rate: 0.00075 
2025-06-05 02:41:00.655344: train_loss -0.7445 
2025-06-05 02:41:00.718935: val_loss -0.7447 
2025-06-05 02:41:00.739556: Pseudo dice [np.float32(0.7778)] 
2025-06-05 02:41:00.754237: Epoch time: 65.13 s 
2025-06-05 02:41:01.933130:  
2025-06-05 02:41:01.951952: Epoch 945 
2025-06-05 02:41:01.960522: Current learning rate: 0.00074 
2025-06-05 02:42:07.022114: train_loss -0.7792 
2025-06-05 02:42:07.106685: val_loss -0.7028 
2025-06-05 02:42:07.156096: Pseudo dice [np.float32(0.8241)] 
2025-06-05 02:42:07.181752: Epoch time: 65.09 s 
2025-06-05 02:42:08.319706:  
2025-06-05 02:42:08.340602: Epoch 946 
2025-06-05 02:42:08.351895: Current learning rate: 0.00072 
2025-06-05 02:43:13.252453: train_loss -0.751 
2025-06-05 02:43:13.306679: val_loss -0.7191 
2025-06-05 02:43:13.344965: Pseudo dice [np.float32(0.8242)] 
2025-06-05 02:43:13.357666: Epoch time: 64.93 s 
2025-06-05 02:43:14.563921:  
2025-06-05 02:43:14.582749: Epoch 947 
2025-06-05 02:43:14.590797: Current learning rate: 0.00071 
2025-06-05 02:44:19.538102: train_loss -0.7425 
2025-06-05 02:44:19.572927: val_loss -0.6967 
2025-06-05 02:44:19.606421: Pseudo dice [np.float32(0.7742)] 
2025-06-05 02:44:19.620575: Epoch time: 64.98 s 
2025-06-05 02:44:21.021678:  
2025-06-05 02:44:21.035566: Epoch 948 
2025-06-05 02:44:21.043097: Current learning rate: 0.0007 
2025-06-05 02:45:26.036212: train_loss -0.7418 
2025-06-05 02:45:26.077114: val_loss -0.6744 
2025-06-05 02:45:26.098332: Pseudo dice [np.float32(0.7859)] 
2025-06-05 02:45:26.112177: Epoch time: 65.02 s 
2025-06-05 02:45:27.336191:  
2025-06-05 02:45:27.358759: Epoch 949 
2025-06-05 02:45:27.366878: Current learning rate: 0.00069 
2025-06-05 02:46:32.263877: train_loss -0.7639 
2025-06-05 02:46:32.330904: val_loss -0.7543 
2025-06-05 02:46:32.403116: Pseudo dice [np.float32(0.8304)] 
2025-06-05 02:46:32.440116: Epoch time: 64.93 s 
2025-06-05 02:46:34.016263:  
2025-06-05 02:46:34.044782: Epoch 950 
2025-06-05 02:46:34.052422: Current learning rate: 0.00067 
2025-06-05 02:47:39.187098: train_loss -0.7766 
2025-06-05 02:47:39.211181: val_loss -0.6942 
2025-06-05 02:47:39.230147: Pseudo dice [np.float32(0.7544)] 
2025-06-05 02:47:39.243773: Epoch time: 65.17 s 
2025-06-05 02:47:40.489253:  
2025-06-05 02:47:40.520602: Epoch 951 
2025-06-05 02:47:40.545120: Current learning rate: 0.00066 
2025-06-05 02:48:45.567052: train_loss -0.7385 
2025-06-05 02:48:45.625460: val_loss -0.7424 
2025-06-05 02:48:45.661932: Pseudo dice [np.float32(0.7998)] 
2025-06-05 02:48:45.692245: Epoch time: 65.08 s 
2025-06-05 02:48:46.806114:  
2025-06-05 02:48:46.828698: Epoch 952 
2025-06-05 02:48:46.853115: Current learning rate: 0.00065 
2025-06-05 02:49:51.805578: train_loss -0.7513 
2025-06-05 02:49:51.830365: val_loss -0.7097 
2025-06-05 02:49:51.859689: Pseudo dice [np.float32(0.7765)] 
2025-06-05 02:49:51.895404: Epoch time: 65.0 s 
2025-06-05 02:49:53.212025:  
2025-06-05 02:49:53.223859: Epoch 953 
2025-06-05 02:49:53.231488: Current learning rate: 0.00064 
2025-06-05 02:50:58.258418: train_loss -0.7722 
2025-06-05 02:50:58.333750: val_loss -0.6774 
2025-06-05 02:50:58.373243: Pseudo dice [np.float32(0.745)] 
2025-06-05 02:50:58.404800: Epoch time: 65.05 s 
2025-06-05 02:50:59.591222:  
2025-06-05 02:50:59.610591: Epoch 954 
2025-06-05 02:50:59.618786: Current learning rate: 0.00063 
2025-06-05 02:52:04.535664: train_loss -0.7561 
2025-06-05 02:52:04.565722: val_loss -0.7169 
2025-06-05 02:52:04.602473: Pseudo dice [np.float32(0.8)] 
2025-06-05 02:52:04.629336: Epoch time: 64.95 s 
2025-06-05 02:52:05.872302:  
2025-06-05 02:52:05.901900: Epoch 955 
2025-06-05 02:52:05.911019: Current learning rate: 0.00061 
2025-06-05 02:53:10.911308: train_loss -0.764 
2025-06-05 02:53:10.962900: val_loss -0.7112 
2025-06-05 02:53:11.000416: Pseudo dice [np.float32(0.7831)] 
2025-06-05 02:53:11.017157: Epoch time: 65.04 s 
2025-06-05 02:53:12.381565:  
2025-06-05 02:53:12.411650: Epoch 956 
2025-06-05 02:53:12.421384: Current learning rate: 0.0006 
2025-06-05 02:54:17.312919: train_loss -0.7276 
2025-06-05 02:54:17.386200: val_loss -0.7535 
2025-06-05 02:54:17.413519: Pseudo dice [np.float32(0.8401)] 
2025-06-05 02:54:17.427262: Epoch time: 64.93 s 
2025-06-05 02:54:18.656626:  
2025-06-05 02:54:18.685619: Epoch 957 
2025-06-05 02:54:18.693112: Current learning rate: 0.00059 
2025-06-05 02:55:23.714688: train_loss -0.7641 
2025-06-05 02:55:23.741976: val_loss -0.6905 
2025-06-05 02:55:23.784357: Pseudo dice [np.float32(0.7808)] 
2025-06-05 02:55:23.812649: Epoch time: 65.06 s 
2025-06-05 02:55:25.077577:  
2025-06-05 02:55:25.105455: Epoch 958 
2025-06-05 02:55:25.113129: Current learning rate: 0.00058 
2025-06-05 02:56:30.001719: train_loss -0.7726 
2025-06-05 02:56:30.047070: val_loss -0.7201 
2025-06-05 02:56:30.090340: Pseudo dice [np.float32(0.7519)] 
2025-06-05 02:56:30.126863: Epoch time: 64.93 s 
2025-06-05 02:56:31.297900:  
2025-06-05 02:56:31.318259: Epoch 959 
2025-06-05 02:56:31.325897: Current learning rate: 0.00056 
2025-06-05 02:57:36.411532: train_loss -0.7582 
2025-06-05 02:57:36.459086: val_loss -0.7008 
2025-06-05 02:57:36.487607: Pseudo dice [np.float32(0.7275)] 
2025-06-05 02:57:36.500362: Epoch time: 65.11 s 
2025-06-05 02:57:37.718563:  
2025-06-05 02:57:37.738911: Epoch 960 
2025-06-05 02:57:37.746823: Current learning rate: 0.00055 
2025-06-05 02:58:42.857711: train_loss -0.7541 
2025-06-05 02:58:42.947295: val_loss -0.694 
2025-06-05 02:58:42.970999: Pseudo dice [np.float32(0.7926)] 
2025-06-05 02:58:42.985200: Epoch time: 65.14 s 
2025-06-05 02:58:44.173292:  
2025-06-05 02:58:44.191074: Epoch 961 
2025-06-05 02:58:44.198599: Current learning rate: 0.00054 
2025-06-05 02:59:49.081506: train_loss -0.7654 
2025-06-05 02:59:49.122870: val_loss -0.6732 
2025-06-05 02:59:49.163796: Pseudo dice [np.float32(0.7334)] 
2025-06-05 02:59:49.214957: Epoch time: 64.91 s 
2025-06-05 02:59:50.408592:  
2025-06-05 02:59:50.428904: Epoch 962 
2025-06-05 02:59:50.436953: Current learning rate: 0.00053 
2025-06-05 03:00:55.504831: train_loss -0.7641 
2025-06-05 03:00:55.555656: val_loss -0.7337 
2025-06-05 03:00:55.619598: Pseudo dice [np.float32(0.8279)] 
2025-06-05 03:00:55.670510: Epoch time: 65.1 s 
2025-06-05 03:00:56.891295:  
2025-06-05 03:00:56.909875: Epoch 963 
2025-06-05 03:00:56.918030: Current learning rate: 0.00051 
2025-06-05 03:02:02.045028: train_loss -0.7803 
2025-06-05 03:02:02.093583: val_loss -0.7098 
2025-06-05 03:02:02.128325: Pseudo dice [np.float32(0.829)] 
2025-06-05 03:02:02.165632: Epoch time: 65.15 s 
2025-06-05 03:02:03.430726:  
2025-06-05 03:02:03.449224: Epoch 964 
2025-06-05 03:02:03.456858: Current learning rate: 0.0005 
2025-06-05 03:03:08.615486: train_loss -0.7475 
2025-06-05 03:03:08.670981: val_loss -0.7036 
2025-06-05 03:03:08.705391: Pseudo dice [np.float32(0.8094)] 
2025-06-05 03:03:08.742792: Epoch time: 65.19 s 
2025-06-05 03:03:09.996362:  
2025-06-05 03:03:10.017817: Epoch 965 
2025-06-05 03:03:10.025885: Current learning rate: 0.00049 
2025-06-05 03:04:14.953970: train_loss -0.7694 
2025-06-05 03:04:14.978065: val_loss -0.6746 
2025-06-05 03:04:14.990793: Pseudo dice [np.float32(0.7868)] 
2025-06-05 03:04:15.005228: Epoch time: 64.96 s 
2025-06-05 03:04:16.242146:  
2025-06-05 03:04:16.260396: Epoch 966 
2025-06-05 03:04:16.268478: Current learning rate: 0.00048 
2025-06-05 03:05:21.151245: train_loss -0.7637 
2025-06-05 03:05:21.174786: val_loss -0.698 
2025-06-05 03:05:21.189026: Pseudo dice [np.float32(0.7595)] 
2025-06-05 03:05:21.201729: Epoch time: 64.91 s 
2025-06-05 03:05:22.451432:  
2025-06-05 03:05:22.469271: Epoch 967 
2025-06-05 03:05:22.476910: Current learning rate: 0.00046 
2025-06-05 03:06:27.325162: train_loss -0.773 
2025-06-05 03:06:27.348366: val_loss -0.6693 
2025-06-05 03:06:27.369192: Pseudo dice [np.float32(0.7272)] 
2025-06-05 03:06:27.382065: Epoch time: 64.87 s 
2025-06-05 03:06:28.670378:  
2025-06-05 03:06:28.700520: Epoch 968 
2025-06-05 03:06:28.709409: Current learning rate: 0.00045 
2025-06-05 03:07:33.832406: train_loss -0.7649 
2025-06-05 03:07:33.895061: val_loss -0.7606 
2025-06-05 03:07:33.922021: Pseudo dice [np.float32(0.821)] 
2025-06-05 03:07:33.944455: Epoch time: 65.16 s 
2025-06-05 03:07:35.196621:  
2025-06-05 03:07:35.217048: Epoch 969 
2025-06-05 03:07:35.225714: Current learning rate: 0.00044 
2025-06-05 03:08:40.213299: train_loss -0.7794 
2025-06-05 03:08:40.269958: val_loss -0.7338 
2025-06-05 03:08:40.313184: Pseudo dice [np.float32(0.7733)] 
2025-06-05 03:08:40.327875: Epoch time: 65.02 s 
2025-06-05 03:08:41.543787:  
2025-06-05 03:08:41.572330: Epoch 970 
2025-06-05 03:08:41.579967: Current learning rate: 0.00043 
2025-06-05 03:09:46.593523: train_loss -0.7717 
2025-06-05 03:09:46.698541: val_loss -0.6908 
2025-06-05 03:09:46.721600: Pseudo dice [np.float32(0.7669)] 
2025-06-05 03:09:46.747014: Epoch time: 65.05 s 
2025-06-05 03:09:48.032674:  
2025-06-05 03:09:48.056282: Epoch 971 
2025-06-05 03:09:48.064335: Current learning rate: 0.00041 
2025-06-05 03:10:53.025659: train_loss -0.7541 
2025-06-05 03:10:53.071986: val_loss -0.6893 
2025-06-05 03:10:53.110306: Pseudo dice [np.float32(0.7331)] 
2025-06-05 03:10:53.152303: Epoch time: 64.99 s 
2025-06-05 03:10:54.391513:  
2025-06-05 03:10:54.415421: Epoch 972 
2025-06-05 03:10:54.439930: Current learning rate: 0.0004 
2025-06-05 03:11:59.506621: train_loss -0.7505 
2025-06-05 03:11:59.531102: val_loss -0.654 
2025-06-05 03:11:59.549132: Pseudo dice [np.float32(0.7847)] 
2025-06-05 03:11:59.562080: Epoch time: 65.12 s 
2025-06-05 03:12:00.919906:  
2025-06-05 03:12:00.946719: Epoch 973 
2025-06-05 03:12:00.958547: Current learning rate: 0.00039 
2025-06-05 03:13:05.979400: train_loss -0.7613 
2025-06-05 03:13:06.023069: val_loss -0.7123 
2025-06-05 03:13:06.076606: Pseudo dice [np.float32(0.8125)] 
2025-06-05 03:13:06.112168: Epoch time: 65.06 s 
2025-06-05 03:13:07.327664:  
2025-06-05 03:13:07.347519: Epoch 974 
2025-06-05 03:13:07.372587: Current learning rate: 0.00037 
2025-06-05 03:14:12.332409: train_loss -0.7427 
2025-06-05 03:14:12.367476: val_loss -0.7245 
2025-06-05 03:14:12.388045: Pseudo dice [np.float32(0.8586)] 
2025-06-05 03:14:12.408215: Epoch time: 65.01 s 
2025-06-05 03:14:13.702900:  
2025-06-05 03:14:13.732894: Epoch 975 
2025-06-05 03:14:13.740766: Current learning rate: 0.00036 
2025-06-05 03:15:18.771085: train_loss -0.7553 
2025-06-05 03:15:18.812253: val_loss -0.7246 
2025-06-05 03:15:18.846847: Pseudo dice [np.float32(0.8086)] 
2025-06-05 03:15:18.878267: Epoch time: 65.07 s 
2025-06-05 03:15:20.158941:  
2025-06-05 03:15:20.184100: Epoch 976 
2025-06-05 03:15:20.192323: Current learning rate: 0.00035 
2025-06-05 03:16:25.052139: train_loss -0.7465 
2025-06-05 03:16:25.112674: val_loss -0.7084 
2025-06-05 03:16:25.161990: Pseudo dice [np.float32(0.756)] 
2025-06-05 03:16:25.197924: Epoch time: 64.89 s 
2025-06-05 03:16:26.380966:  
2025-06-05 03:16:26.398932: Epoch 977 
2025-06-05 03:16:26.405579: Current learning rate: 0.00034 
2025-06-05 03:17:31.418550: train_loss -0.7619 
2025-06-05 03:17:31.443933: val_loss -0.7467 
2025-06-05 03:17:31.455778: Pseudo dice [np.float32(0.8389)] 
2025-06-05 03:17:31.468821: Epoch time: 65.04 s 
2025-06-05 03:17:32.598564:  
2025-06-05 03:17:32.627758: Epoch 978 
2025-06-05 03:17:32.640117: Current learning rate: 0.00032 
2025-06-05 03:18:37.544502: train_loss -0.7531 
2025-06-05 03:18:37.635805: val_loss -0.7641 
2025-06-05 03:18:37.680545: Pseudo dice [np.float32(0.7985)] 
2025-06-05 03:18:37.714447: Epoch time: 64.95 s 
2025-06-05 03:18:39.043809:  
2025-06-05 03:18:39.059537: Epoch 979 
2025-06-05 03:18:39.067199: Current learning rate: 0.00031 
2025-06-05 03:19:43.821791: train_loss -0.7679 
2025-06-05 03:19:43.856382: val_loss -0.737 
2025-06-05 03:19:43.903690: Pseudo dice [np.float32(0.7978)] 
2025-06-05 03:19:43.938697: Epoch time: 64.78 s 
2025-06-05 03:19:45.190074:  
2025-06-05 03:19:45.208415: Epoch 980 
2025-06-05 03:19:45.216045: Current learning rate: 0.0003 
2025-06-05 03:20:50.121826: train_loss -0.7613 
2025-06-05 03:20:50.191261: val_loss -0.7174 
2025-06-05 03:20:50.248016: Pseudo dice [np.float32(0.8157)] 
2025-06-05 03:20:50.296292: Epoch time: 64.93 s 
2025-06-05 03:20:51.491809:  
2025-06-05 03:20:51.508401: Epoch 981 
2025-06-05 03:20:51.516397: Current learning rate: 0.00028 
2025-06-05 03:21:56.572861: train_loss -0.773 
2025-06-05 03:21:56.623111: val_loss -0.7132 
2025-06-05 03:21:56.650611: Pseudo dice [np.float32(0.8316)] 
2025-06-05 03:21:56.676749: Epoch time: 65.08 s 
2025-06-05 03:21:57.926716:  
2025-06-05 03:21:57.937945: Epoch 982 
2025-06-05 03:21:57.945586: Current learning rate: 0.00027 
2025-06-05 03:23:02.842178: train_loss -0.7493 
2025-06-05 03:23:02.865940: val_loss -0.7128 
2025-06-05 03:23:02.884539: Pseudo dice [np.float32(0.8207)] 
2025-06-05 03:23:02.898704: Epoch time: 64.92 s 
2025-06-05 03:23:04.139148:  
2025-06-05 03:23:04.164625: Epoch 983 
2025-06-05 03:23:04.172117: Current learning rate: 0.00026 
2025-06-05 03:24:09.125992: train_loss -0.7724 
2025-06-05 03:24:09.172321: val_loss -0.7344 
2025-06-05 03:24:09.192900: Pseudo dice [np.float32(0.7996)] 
2025-06-05 03:24:09.207013: Epoch time: 64.99 s 
2025-06-05 03:24:10.487733:  
2025-06-05 03:24:10.517777: Epoch 984 
2025-06-05 03:24:10.527989: Current learning rate: 0.00024 
2025-06-05 03:25:15.568453: train_loss -0.769 
2025-06-05 03:25:15.592669: val_loss -0.7014 
2025-06-05 03:25:15.605442: Pseudo dice [np.float32(0.7724)] 
2025-06-05 03:25:15.617837: Epoch time: 65.08 s 
2025-06-05 03:25:16.821746:  
2025-06-05 03:25:16.851306: Epoch 985 
2025-06-05 03:25:16.859814: Current learning rate: 0.00023 
2025-06-05 03:26:21.955366: train_loss -0.7456 
2025-06-05 03:26:21.995389: val_loss -0.6938 
2025-06-05 03:26:22.009007: Pseudo dice [np.float32(0.7452)] 
2025-06-05 03:26:22.022562: Epoch time: 65.13 s 
2025-06-05 03:26:23.342356:  
2025-06-05 03:26:23.363925: Epoch 986 
2025-06-05 03:26:23.371053: Current learning rate: 0.00021 
2025-06-05 03:27:28.357225: train_loss -0.7713 
2025-06-05 03:27:28.383486: val_loss -0.7365 
2025-06-05 03:27:28.396878: Pseudo dice [np.float32(0.8539)] 
2025-06-05 03:27:28.432992: Epoch time: 65.02 s 
2025-06-05 03:27:29.828052:  
2025-06-05 03:27:29.846922: Epoch 987 
2025-06-05 03:27:29.856592: Current learning rate: 0.0002 
2025-06-05 03:28:34.789242: train_loss -0.7658 
2025-06-05 03:28:34.833241: val_loss -0.7477 
2025-06-05 03:28:34.856630: Pseudo dice [np.float32(0.8396)] 
2025-06-05 03:28:34.872694: Epoch time: 64.96 s 
2025-06-05 03:28:36.124152:  
2025-06-05 03:28:36.145136: Epoch 988 
2025-06-05 03:28:36.169257: Current learning rate: 0.00019 
2025-06-05 03:29:41.064485: train_loss -0.7742 
2025-06-05 03:29:41.097926: val_loss -0.7379 
2025-06-05 03:29:41.127146: Pseudo dice [np.float32(0.8758)] 
2025-06-05 03:29:41.160590: Epoch time: 64.94 s 
2025-06-05 03:29:41.175976: Yayy! New best EMA pseudo Dice: 0.8104000091552734 
2025-06-05 03:29:42.683375:  
2025-06-05 03:29:42.711913: Epoch 989 
2025-06-05 03:29:42.719524: Current learning rate: 0.00017 
2025-06-05 03:30:47.884936: train_loss -0.7441 
2025-06-05 03:30:47.936548: val_loss -0.6726 
2025-06-05 03:30:47.985702: Pseudo dice [np.float32(0.7486)] 
2025-06-05 03:30:48.000230: Epoch time: 65.2 s 
2025-06-05 03:30:49.192018:  
2025-06-05 03:30:49.221052: Epoch 990 
2025-06-05 03:30:49.229037: Current learning rate: 0.00016 
2025-06-05 03:31:54.326747: train_loss -0.77 
2025-06-05 03:31:54.372537: val_loss -0.7305 
2025-06-05 03:31:54.435415: Pseudo dice [np.float32(0.7658)] 
2025-06-05 03:31:54.493631: Epoch time: 65.14 s 
2025-06-05 03:31:55.665331:  
2025-06-05 03:31:55.679638: Epoch 991 
2025-06-05 03:31:55.687286: Current learning rate: 0.00014 
2025-06-05 03:33:00.671119: train_loss -0.7832 
2025-06-05 03:33:00.775066: val_loss -0.7087 
2025-06-05 03:33:00.825528: Pseudo dice [np.float32(0.8176)] 
2025-06-05 03:33:00.840937: Epoch time: 65.01 s 
2025-06-05 03:33:02.019336:  
2025-06-05 03:33:02.037735: Epoch 992 
2025-06-05 03:33:02.062244: Current learning rate: 0.00013 
2025-06-05 03:34:07.035310: train_loss -0.7263 
2025-06-05 03:34:07.083995: val_loss -0.7325 
2025-06-05 03:34:07.158124: Pseudo dice [np.float32(0.8451)] 
2025-06-05 03:34:07.180898: Epoch time: 65.02 s 
2025-06-05 03:34:08.336542:  
2025-06-05 03:34:08.362832: Epoch 993 
2025-06-05 03:34:08.387290: Current learning rate: 0.00011 
2025-06-05 03:35:13.445503: train_loss -0.7489 
2025-06-05 03:35:13.488110: val_loss -0.7006 
2025-06-05 03:35:13.522047: Pseudo dice [np.float32(0.7925)] 
2025-06-05 03:35:13.543086: Epoch time: 65.11 s 
2025-06-05 03:35:15.001134:  
2025-06-05 03:35:15.023575: Epoch 994 
2025-06-05 03:35:15.032301: Current learning rate: 0.0001 
2025-06-05 03:36:20.066779: train_loss -0.7683 
2025-06-05 03:36:20.148201: val_loss -0.687 
2025-06-05 03:36:20.222405: Pseudo dice [np.float32(0.7647)] 
2025-06-05 03:36:20.242705: Epoch time: 65.07 s 
2025-06-05 03:36:21.442239:  
2025-06-05 03:36:21.470706: Epoch 995 
2025-06-05 03:36:21.478759: Current learning rate: 8e-05 
2025-06-05 03:37:26.378579: train_loss -0.7416 
2025-06-05 03:37:26.420328: val_loss -0.6903 
2025-06-05 03:37:26.453732: Pseudo dice [np.float32(0.7383)] 
2025-06-05 03:37:26.487697: Epoch time: 64.94 s 
2025-06-05 03:37:27.782136:  
2025-06-05 03:37:27.803451: Epoch 996 
2025-06-05 03:37:27.811104: Current learning rate: 7e-05 
2025-06-05 03:38:32.722328: train_loss -0.7598 
2025-06-05 03:38:32.790545: val_loss -0.7033 
2025-06-05 03:38:32.849593: Pseudo dice [np.float32(0.7758)] 
2025-06-05 03:38:32.909746: Epoch time: 64.94 s 
2025-06-05 03:38:34.106357:  
2025-06-05 03:38:34.132141: Epoch 997 
2025-06-05 03:38:34.140193: Current learning rate: 5e-05 
2025-06-05 03:39:39.263004: train_loss -0.7638 
2025-06-05 03:39:39.365401: val_loss -0.7659 
2025-06-05 03:39:39.408652: Pseudo dice [np.float32(0.8262)] 
2025-06-05 03:39:39.422430: Epoch time: 65.16 s 
2025-06-05 03:39:40.577461:  
2025-06-05 03:39:40.608155: Epoch 998 
2025-06-05 03:39:40.616886: Current learning rate: 4e-05 
2025-06-05 03:40:45.532654: train_loss -0.7738 
2025-06-05 03:40:45.609678: val_loss -0.6889 
2025-06-05 03:40:45.664609: Pseudo dice [np.float32(0.7343)] 
2025-06-05 03:40:45.720932: Epoch time: 64.96 s 
2025-06-05 03:40:46.938730:  
2025-06-05 03:40:46.968475: Epoch 999 
2025-06-05 03:40:46.977477: Current learning rate: 2e-05 
2025-06-05 03:41:51.935038: train_loss -0.7513 
2025-06-05 03:41:52.003392: val_loss -0.7268 
2025-06-05 03:41:52.038638: Pseudo dice [np.float32(0.8154)] 
2025-06-05 03:41:52.054712: Epoch time: 65.0 s 
2025-06-05 03:41:53.722149: Training done. 
2025-06-05 03:41:53.798377: Using splits from existing split file: C:\Users\usuario\Documents\Mama_Mia\nnUNet_preprocessed\Dataset113\splits_final.json 
2025-06-05 03:41:53.814443: The split file contains 5 splits. 
2025-06-05 03:41:53.836307: Desired fold for training: 0 
2025-06-05 03:41:53.847304: This split has 960 training and 240 validation cases. 
2025-06-05 03:41:53.860524: predicting case_000 
2025-06-05 03:41:54.297197: case_000, shape torch.Size([3, 88, 512, 512]), rank 0 
2025-06-05 03:42:17.113281: predicting case_006 
2025-06-05 03:42:17.568010: case_006, shape torch.Size([3, 88, 469, 469]), rank 0 
2025-06-05 03:42:31.251964: predicting case_010 
2025-06-05 03:42:31.848526: case_010, shape torch.Size([3, 84, 498, 498]), rank 0 
2025-06-05 03:42:46.094560: predicting case_017 
2025-06-05 03:42:46.617880: case_017, shape torch.Size([3, 81, 469, 469]), rank 0 
2025-06-05 03:42:55.742789: predicting case_020 
2025-06-05 03:42:57.668239: case_020, shape torch.Size([3, 97, 484, 484]), rank 0 
2025-06-05 03:43:19.199636: predicting case_022 
2025-06-05 03:43:19.675583: case_022, shape torch.Size([3, 88, 484, 484]), rank 0 
2025-06-05 03:43:41.033240: predicting case_025 
2025-06-05 03:43:41.543771: case_025, shape torch.Size([3, 88, 512, 512]), rank 0 
2025-06-05 03:44:02.895505: predicting case_029 
2025-06-05 03:44:03.328923: case_029, shape torch.Size([3, 88, 484, 484]), rank 0 
2025-06-05 03:44:24.636385: predicting case_030 
2025-06-05 03:44:25.123125: case_030, shape torch.Size([3, 100, 484, 484]), rank 0 
2025-06-05 03:44:46.420328: predicting case_033 
2025-06-05 03:44:46.947346: case_033, shape torch.Size([3, 94, 526, 526]), rank 0 
2025-06-05 03:45:08.264170: predicting case_041 
2025-06-05 03:45:08.684029: case_041, shape torch.Size([3, 80, 484, 484]), rank 0 
2025-06-05 03:45:22.903566: predicting case_047 
2025-06-05 03:45:23.367673: case_047, shape torch.Size([3, 83, 498, 498]), rank 0 
2025-06-05 03:45:37.621712: predicting case_052 
2025-06-05 03:45:38.107578: case_052, shape torch.Size([3, 88, 512, 512]), rank 0 
2025-06-05 03:45:59.408704: predicting case_056 
2025-06-05 03:45:59.788341: case_056, shape torch.Size([3, 72, 455, 455]), rank 0 
2025-06-05 03:46:08.944570: predicting case_058 
2025-06-05 03:46:09.641349: case_058, shape torch.Size([3, 88, 512, 512]), rank 0 
2025-06-05 03:46:30.927991: predicting case_059 
2025-06-05 03:46:31.530622: case_059, shape torch.Size([3, 93, 569, 569]), rank 0 
2025-06-05 03:46:52.879585: predicting case_065 
2025-06-05 03:46:53.766833: case_065, shape torch.Size([3, 92, 540, 540]), rank 0 
2025-06-05 03:47:15.039916: predicting case_068 
2025-06-05 03:47:15.410329: case_068, shape torch.Size([3, 80, 427, 427]), rank 0 
2025-06-05 03:47:24.548141: predicting case_070 
2025-06-05 03:47:25.069099: case_070, shape torch.Size([3, 96, 484, 484]), rank 0 
2025-06-05 03:47:46.381539: predicting case_072 
2025-06-05 03:47:46.980753: case_072, shape torch.Size([3, 112, 498, 498]), rank 0 
2025-06-05 03:48:08.308407: predicting case_073 
2025-06-05 03:48:08.767029: case_073, shape torch.Size([3, 88, 512, 512]), rank 0 
2025-06-05 03:48:30.052504: predicting case_076 
2025-06-05 03:48:30.502562: case_076, shape torch.Size([3, 88, 512, 512]), rank 0 
2025-06-05 03:48:51.791910: predicting case_082 
2025-06-05 03:48:52.137860: case_082, shape torch.Size([3, 79, 455, 455]), rank 0 
2025-06-05 03:49:01.305383: predicting case_089 
2025-06-05 03:49:01.862532: case_089, shape torch.Size([3, 104, 498, 498]), rank 0 
2025-06-05 03:49:23.178218: predicting case_090 
2025-06-05 03:49:23.522659: case_090, shape torch.Size([3, 78, 441, 441]), rank 0 
2025-06-05 03:49:32.664285: predicting case_092 
2025-06-05 03:49:33.214364: case_092, shape torch.Size([3, 94, 441, 441]), rank 0 
2025-06-05 03:49:46.860942: predicting case_097 
2025-06-05 03:49:47.364743: case_097, shape torch.Size([3, 100, 512, 512]), rank 0 
2025-06-05 03:50:08.622815: predicting case_1000 
2025-06-05 03:50:08.957896: case_1000, shape torch.Size([3, 80, 427, 427]), rank 0 
2025-06-05 03:50:18.096073: predicting case_1003 
2025-06-05 03:50:18.279046: case_1003, shape torch.Size([3, 80, 213, 213]), rank 0 
2025-06-05 03:50:20.624612: predicting case_1013 
2025-06-05 03:50:20.956647: case_1013, shape torch.Size([3, 90, 320, 320]), rank 0 
2025-06-05 03:50:28.663597: predicting case_1016 
2025-06-05 03:50:29.102782: case_1016, shape torch.Size([3, 80, 427, 427]), rank 0 
2025-06-05 03:50:38.242809: predicting case_1020 
2025-06-05 03:50:38.466102: case_1020, shape torch.Size([3, 80, 256, 256]), rank 0 
2025-06-05 03:50:40.786901: predicting case_1032 
2025-06-05 03:50:41.284999: case_1032, shape torch.Size([3, 97, 512, 512]), rank 0 
2025-06-05 03:51:02.540714: predicting case_1034 
2025-06-05 03:51:02.685144: case_1034, shape torch.Size([3, 79, 220, 220]), rank 0 
2025-06-05 03:51:04.989060: predicting case_1043 
2025-06-05 03:51:05.355071: case_1043, shape torch.Size([3, 80, 455, 455]), rank 0 
2025-06-05 03:51:14.526413: predicting case_1044 
2025-06-05 03:51:14.711358: case_1044, shape torch.Size([3, 80, 243, 243]), rank 0 
2025-06-05 03:51:17.046638: predicting case_1045 
2025-06-05 03:51:17.481348: case_1045, shape torch.Size([3, 80, 512, 512]), rank 0 
2025-06-05 03:51:31.747466: predicting case_1046 
2025-06-05 03:51:31.979117: case_1046, shape torch.Size([3, 80, 270, 270]), rank 0 
2025-06-05 03:51:34.331446: predicting case_1048 
2025-06-05 03:51:35.009232: case_1048, shape torch.Size([3, 86, 512, 512]), rank 0 
2025-06-05 03:51:56.305200: predicting case_1049 
2025-06-05 03:51:56.479137: case_1049, shape torch.Size([3, 80, 235, 235]), rank 0 
2025-06-05 03:51:58.807132: predicting case_1056 
2025-06-05 03:51:59.011479: case_1056, shape torch.Size([3, 79, 256, 256]), rank 0 
2025-06-05 03:52:01.387638: predicting case_1066 
2025-06-05 03:52:01.488243: case_1066, shape torch.Size([3, 79, 192, 192]), rank 0 
2025-06-05 03:52:02.103879: predicting case_1070 
2025-06-05 03:52:02.309140: case_1070, shape torch.Size([3, 80, 263, 263]), rank 0 
2025-06-05 03:52:04.640082: predicting case_1079 
2025-06-05 03:52:04.784453: case_1079, shape torch.Size([3, 80, 206, 206]), rank 0 
2025-06-05 03:52:07.097335: predicting case_1081 
2025-06-05 03:52:07.215483: case_1081, shape torch.Size([3, 80, 221, 221]), rank 0 
2025-06-05 03:52:09.533333: predicting case_1084 
2025-06-05 03:52:09.659955: case_1084, shape torch.Size([3, 80, 209, 209]), rank 0 
2025-06-05 03:52:11.988119: predicting case_1089 
2025-06-05 03:52:12.178178: case_1089, shape torch.Size([3, 80, 256, 256]), rank 0 
2025-06-05 03:52:14.509086: predicting case_1091 
2025-06-05 03:52:14.646992: case_1091, shape torch.Size([3, 80, 213, 213]), rank 0 
2025-06-05 03:52:16.950057: predicting case_1096 
2025-06-05 03:52:17.132874: case_1096, shape torch.Size([3, 79, 256, 256]), rank 0 
2025-06-05 03:52:19.471943: predicting case_1098 
2025-06-05 03:52:19.580979: case_1098, shape torch.Size([3, 80, 206, 206]), rank 0 
2025-06-05 03:52:21.912561: predicting case_1105 
2025-06-05 03:52:22.029132: case_1105, shape torch.Size([3, 80, 213, 213]), rank 0 
2025-06-05 03:52:24.345545: predicting case_111 
2025-06-05 03:52:24.830915: case_111, shape torch.Size([3, 89, 512, 512]), rank 0 
2025-06-05 03:52:46.105860: predicting case_1111 
2025-06-05 03:52:46.246507: case_1111, shape torch.Size([3, 80, 235, 235]), rank 0 
2025-06-05 03:52:48.603847: predicting case_1125 
2025-06-05 03:52:48.715220: case_1125, shape torch.Size([3, 79, 199, 199]), rank 0 
2025-06-05 03:52:51.035698: predicting case_1126 
2025-06-05 03:52:51.195508: case_1126, shape torch.Size([3, 80, 249, 249]), rank 0 
2025-06-05 03:52:53.544600: predicting case_113 
2025-06-05 03:52:54.098028: case_113, shape torch.Size([3, 79, 484, 484]), rank 0 
2025-06-05 03:53:08.328221: predicting case_1136 
2025-06-05 03:53:08.737500: case_1136, shape torch.Size([3, 97, 455, 455]), rank 0 
2025-06-05 03:53:22.422044: predicting case_1139 
2025-06-05 03:53:22.831605: case_1139, shape torch.Size([3, 86, 455, 455]), rank 0 
2025-06-05 03:53:36.484355: predicting case_1149 
2025-06-05 03:53:36.671643: case_1149, shape torch.Size([3, 80, 242, 242]), rank 0 
2025-06-05 03:53:38.988151: predicting case_115 
2025-06-05 03:53:39.444699: case_115, shape torch.Size([3, 80, 498, 498]), rank 0 
2025-06-05 03:53:53.707568: predicting case_1152 
2025-06-05 03:53:53.867483: case_1152, shape torch.Size([3, 79, 206, 206]), rank 0 
2025-06-05 03:53:56.200884: predicting case_1160 
2025-06-05 03:53:56.378207: case_1160, shape torch.Size([3, 60, 284, 284]), rank 0 
2025-06-05 03:53:58.731289: predicting case_1163 
2025-06-05 03:53:58.929937: case_1163, shape torch.Size([3, 60, 256, 256]), rank 0 
2025-06-05 03:54:01.274875: predicting case_1164 
2025-06-05 03:54:01.509597: case_1164, shape torch.Size([3, 69, 256, 256]), rank 0 
2025-06-05 03:54:03.832220: predicting case_1181 
2025-06-05 03:54:04.038354: case_1181, shape torch.Size([3, 60, 256, 256]), rank 0 
2025-06-05 03:54:06.362759: predicting case_1183 
2025-06-05 03:54:06.496231: case_1183, shape torch.Size([3, 70, 256, 256]), rank 0 
2025-06-05 03:54:08.820616: predicting case_1185 
2025-06-05 03:54:09.031259: case_1185, shape torch.Size([3, 60, 256, 256]), rank 0 
2025-06-05 03:54:11.355415: predicting case_1189 
2025-06-05 03:54:11.528538: case_1189, shape torch.Size([3, 66, 313, 313]), rank 0 
2025-06-05 03:54:16.731083: predicting case_1191 
2025-06-05 03:54:17.003285: case_1191, shape torch.Size([3, 60, 256, 256]), rank 0 
2025-06-05 03:54:19.335326: predicting case_122 
2025-06-05 03:54:20.030633: case_122, shape torch.Size([3, 107, 512, 512]), rank 0 
2025-06-05 03:54:41.340986: predicting case_128 
2025-06-05 03:54:41.709623: case_128, shape torch.Size([3, 71, 484, 484]), rank 0 
2025-06-05 03:54:55.936343: predicting case_139 
2025-06-05 03:54:56.427281: case_139, shape torch.Size([3, 88, 498, 498]), rank 0 
2025-06-05 03:55:17.786325: predicting case_143 
2025-06-05 03:55:18.187455: case_143, shape torch.Size([3, 88, 455, 455]), rank 0 
2025-06-05 03:55:31.854049: predicting case_147 
2025-06-05 03:55:32.461604: case_147, shape torch.Size([3, 85, 512, 512]), rank 0 
2025-06-05 03:55:53.753739: predicting case_158 
2025-06-05 03:55:54.216834: case_158, shape torch.Size([3, 88, 484, 484]), rank 0 
2025-06-05 03:56:15.576017: predicting case_159 
2025-06-05 03:56:16.524348: case_159, shape torch.Size([3, 90, 569, 569]), rank 0 
2025-06-05 03:56:37.845121: predicting case_180 
2025-06-05 03:56:38.587976: case_180, shape torch.Size([3, 87, 512, 512]), rank 0 
2025-06-05 03:56:59.885422: predicting case_181 
2025-06-05 03:57:00.349762: case_181, shape torch.Size([3, 88, 484, 484]), rank 0 
2025-06-05 03:57:21.684341: predicting case_190 
2025-06-05 03:57:22.166877: case_190, shape torch.Size([3, 95, 526, 526]), rank 0 
2025-06-05 03:57:43.474652: predicting case_199 
2025-06-05 03:57:44.019017: case_199, shape torch.Size([3, 97, 512, 512]), rank 0 
2025-06-05 03:58:05.347975: predicting case_208 
2025-06-05 03:58:05.512073: case_208, shape torch.Size([3, 63, 313, 313]), rank 0 
2025-06-05 03:58:10.701913: predicting case_211 
2025-06-05 03:58:10.830896: case_211, shape torch.Size([3, 45, 256, 256]), rank 0 
2025-06-05 03:58:12.045301: predicting case_214 
2025-06-05 03:58:12.247627: case_214, shape torch.Size([3, 69, 284, 284]), rank 0 
2025-06-05 03:58:14.588967: predicting case_219 
2025-06-05 03:58:14.785208: case_219, shape torch.Size([3, 60, 284, 284]), rank 0 
2025-06-05 03:58:17.116277: predicting case_223 
2025-06-05 03:58:17.325436: case_223, shape torch.Size([3, 80, 256, 256]), rank 0 
2025-06-05 03:58:19.640198: predicting case_234 
2025-06-05 03:58:19.780352: case_234, shape torch.Size([3, 60, 284, 284]), rank 0 
2025-06-05 03:58:22.086997: predicting case_236 
2025-06-05 03:58:22.277713: case_236, shape torch.Size([3, 70, 256, 256]), rank 0 
2025-06-05 03:58:24.601150: predicting case_249 
2025-06-05 03:58:24.779277: case_249, shape torch.Size([3, 72, 256, 256]), rank 0 
2025-06-05 03:58:27.097162: predicting case_255 
2025-06-05 03:58:27.214821: case_255, shape torch.Size([3, 60, 284, 284]), rank 0 
2025-06-05 03:58:29.548488: predicting case_256 
2025-06-05 03:58:29.728300: case_256, shape torch.Size([3, 60, 284, 284]), rank 0 
2025-06-05 03:58:32.059648: predicting case_268 
2025-06-05 03:58:32.213012: case_268, shape torch.Size([3, 60, 284, 284]), rank 0 
2025-06-05 03:58:34.547853: predicting case_289 
2025-06-05 03:58:34.690288: case_289, shape torch.Size([3, 73, 256, 256]), rank 0 
2025-06-05 03:58:37.010008: predicting case_293 
2025-06-05 03:58:37.129307: case_293, shape torch.Size([3, 60, 284, 284]), rank 0 
2025-06-05 03:58:39.441998: predicting case_299 
2025-06-05 03:58:40.006874: case_299, shape torch.Size([3, 192, 313, 313]), rank 0 
2025-06-05 03:58:55.356422: predicting case_302 
2025-06-05 03:58:55.569104: case_302, shape torch.Size([3, 66, 284, 284]), rank 0 
2025-06-05 03:58:57.899085: predicting case_310 
2025-06-05 03:58:58.026684: case_310, shape torch.Size([3, 80, 228, 228]), rank 0 
2025-06-05 03:59:00.355219: predicting case_311 
2025-06-05 03:59:01.153676: case_311, shape torch.Size([3, 97, 540, 540]), rank 0 
2025-06-05 03:59:22.459521: predicting case_321 
2025-06-05 03:59:22.626386: case_321, shape torch.Size([3, 88, 263, 263]), rank 0 
2025-06-05 03:59:26.099539: predicting case_322 
2025-06-05 03:59:26.388058: case_322, shape torch.Size([3, 80, 329, 329]), rank 0 
2025-06-05 03:59:31.561062: predicting case_330 
2025-06-05 03:59:31.709821: case_330, shape torch.Size([3, 80, 270, 270]), rank 0 
2025-06-05 03:59:34.062061: predicting case_339 
2025-06-05 03:59:34.163567: case_339, shape torch.Size([3, 80, 213, 213]), rank 0 
2025-06-05 03:59:36.504939: predicting case_341 
2025-06-05 03:59:36.698459: case_341, shape torch.Size([3, 80, 328, 328]), rank 0 
2025-06-05 03:59:41.870368: predicting case_345 
2025-06-05 03:59:42.002041: case_345, shape torch.Size([3, 80, 228, 228]), rank 0 
2025-06-05 03:59:44.310497: predicting case_357 
2025-06-05 03:59:44.446222: case_357, shape torch.Size([3, 80, 249, 249]), rank 0 
2025-06-05 03:59:46.783663: predicting case_378 
2025-06-05 03:59:46.934030: case_378, shape torch.Size([3, 80, 242, 242]), rank 0 
2025-06-05 03:59:49.263229: predicting case_387 
2025-06-05 03:59:49.414957: case_387, shape torch.Size([3, 80, 220, 220]), rank 0 
2025-06-05 03:59:51.725337: predicting case_388 
2025-06-05 03:59:51.814222: case_388, shape torch.Size([3, 80, 206, 206]), rank 0 
2025-06-05 03:59:54.119225: predicting case_393 
2025-06-05 03:59:54.524233: case_393, shape torch.Size([3, 86, 469, 469]), rank 0 
2025-06-05 04:00:08.176473: predicting case_396 
2025-06-05 04:00:08.309216: case_396, shape torch.Size([3, 80, 228, 228]), rank 0 
2025-06-05 04:00:10.643822: predicting case_398 
2025-06-05 04:00:10.843821: case_398, shape torch.Size([3, 80, 242, 242]), rank 0 
2025-06-05 04:00:13.197857: predicting case_399 
2025-06-05 04:00:13.378476: case_399, shape torch.Size([3, 80, 242, 242]), rank 0 
2025-06-05 04:00:15.730739: predicting case_404 
2025-06-05 04:00:15.885124: case_404, shape torch.Size([3, 80, 220, 220]), rank 0 
2025-06-05 04:00:18.193741: predicting case_427 
2025-06-05 04:00:18.330258: case_427, shape torch.Size([3, 80, 235, 235]), rank 0 
2025-06-05 04:00:20.656135: predicting case_435 
2025-06-05 04:00:20.843889: case_435, shape torch.Size([3, 80, 256, 256]), rank 0 
2025-06-05 04:00:23.179651: predicting case_437 
2025-06-05 04:00:23.352547: case_437, shape torch.Size([3, 79, 256, 256]), rank 0 
2025-06-05 04:00:25.687662: predicting case_445 
2025-06-05 04:00:25.872656: case_445, shape torch.Size([3, 80, 249, 249]), rank 0 
2025-06-05 04:00:28.204315: predicting case_446 
2025-06-05 04:00:28.313409: case_446, shape torch.Size([3, 79, 206, 206]), rank 0 
2025-06-05 04:00:30.621214: predicting case_448 
2025-06-05 04:00:30.878755: case_448, shape torch.Size([3, 80, 328, 328]), rank 0 
2025-06-05 04:00:36.084344: predicting case_458 
2025-06-05 04:00:36.218002: case_458, shape torch.Size([3, 80, 220, 220]), rank 0 
2025-06-05 04:00:38.541036: predicting case_473 
2025-06-05 04:00:38.647542: case_473, shape torch.Size([3, 80, 199, 199]), rank 0 
2025-06-05 04:00:40.978030: predicting case_476 
2025-06-05 04:00:41.112473: case_476, shape torch.Size([3, 80, 228, 228]), rank 0 
2025-06-05 04:00:43.427978: predicting case_477 
2025-06-05 04:00:43.530931: case_477, shape torch.Size([3, 80, 228, 228]), rank 0 
2025-06-05 04:00:45.874877: predicting case_482 
2025-06-05 04:00:46.013033: case_482, shape torch.Size([3, 79, 256, 256]), rank 0 
2025-06-05 04:00:48.336650: predicting case_486 
2025-06-05 04:00:48.454582: case_486, shape torch.Size([3, 80, 228, 228]), rank 0 
2025-06-05 04:00:50.790443: predicting case_498 
2025-06-05 04:00:50.977978: case_498, shape torch.Size([3, 80, 313, 313]), rank 0 
2025-06-05 04:00:56.148121: predicting case_500 
2025-06-05 04:00:56.303279: case_500, shape torch.Size([3, 80, 213, 213]), rank 0 
2025-06-05 04:00:58.622384: predicting case_503 
2025-06-05 04:00:58.714414: case_503, shape torch.Size([3, 79, 213, 213]), rank 0 
2025-06-05 04:01:01.046324: predicting case_505 
2025-06-05 04:01:01.329759: case_505, shape torch.Size([3, 80, 398, 398]), rank 0 
2025-06-05 04:01:10.438560: predicting case_508 
2025-06-05 04:01:10.611596: case_508, shape torch.Size([3, 79, 256, 256]), rank 0 
2025-06-05 04:01:12.959319: predicting case_515 
2025-06-05 04:01:13.127666: case_515, shape torch.Size([3, 80, 220, 220]), rank 0 
2025-06-05 04:01:15.480871: predicting case_518 
2025-06-05 04:01:16.006768: case_518, shape torch.Size([3, 88, 455, 455]), rank 0 
2025-06-05 04:01:29.642812: predicting case_525 
2025-06-05 04:01:29.794508: case_525, shape torch.Size([3, 80, 235, 235]), rank 0 
2025-06-05 04:01:32.129189: predicting case_526 
2025-06-05 04:01:32.263372: case_526, shape torch.Size([3, 80, 220, 220]), rank 0 
2025-06-05 04:01:34.584039: predicting case_528 
2025-06-05 04:01:35.401594: case_528, shape torch.Size([3, 97, 540, 540]), rank 0 
2025-06-05 04:01:56.722313: predicting case_536 
2025-06-05 04:01:57.204566: case_536, shape torch.Size([3, 86, 512, 512]), rank 0 
2025-06-05 04:02:18.526821: predicting case_538 
2025-06-05 04:02:18.735664: case_538, shape torch.Size([3, 80, 256, 256]), rank 0 
2025-06-05 04:02:21.081456: predicting case_539 
2025-06-05 04:02:21.370798: case_539, shape torch.Size([3, 80, 329, 329]), rank 0 
2025-06-05 04:02:26.573938: predicting case_540 
2025-06-05 04:02:26.805912: case_540, shape torch.Size([3, 90, 329, 329]), rank 0 
2025-06-05 04:02:34.501467: predicting case_556 
2025-06-05 04:02:34.882620: case_556, shape torch.Size([3, 96, 427, 427]), rank 0 
2025-06-05 04:02:48.525053: predicting case_568 
2025-06-05 04:02:48.646182: case_568, shape torch.Size([3, 80, 213, 213]), rank 0 
2025-06-05 04:02:50.980728: predicting case_572 
2025-06-05 04:02:51.160234: case_572, shape torch.Size([3, 80, 256, 256]), rank 0 
2025-06-05 04:02:53.506316: predicting case_577 
2025-06-05 04:02:53.679733: case_577, shape torch.Size([3, 80, 249, 249]), rank 0 
2025-06-05 04:02:56.026922: predicting case_584 
2025-06-05 04:02:56.581896: case_584, shape torch.Size([3, 97, 441, 441]), rank 0 
2025-06-05 04:03:10.222593: predicting case_585 
2025-06-05 04:03:10.653107: case_585, shape torch.Size([3, 97, 455, 455]), rank 0 
2025-06-05 04:03:24.358413: predicting case_587 
2025-06-05 04:03:24.513150: case_587, shape torch.Size([3, 80, 235, 235]), rank 0 
2025-06-05 04:03:26.838632: predicting case_592 
2025-06-05 04:03:27.123365: case_592, shape torch.Size([3, 80, 328, 328]), rank 0 
2025-06-05 04:03:32.320351: predicting case_594 
2025-06-05 04:03:32.469615: case_594, shape torch.Size([3, 91, 231, 231]), rank 0 
2025-06-05 04:03:35.952821: predicting case_595 
2025-06-05 04:03:36.093151: case_595, shape torch.Size([3, 80, 228, 228]), rank 0 
2025-06-05 04:03:38.413877: predicting case_599 
2025-06-05 04:03:38.818524: case_599, shape torch.Size([3, 102, 455, 455]), rank 0 
2025-06-05 04:03:52.459971: predicting case_603 
2025-06-05 04:03:52.821467: case_603, shape torch.Size([3, 88, 427, 427]), rank 0 
2025-06-05 04:04:06.504509: predicting case_604 
2025-06-05 04:04:06.628947: case_604, shape torch.Size([3, 80, 206, 206]), rank 0 
2025-06-05 04:04:08.950518: predicting case_609 
2025-06-05 04:04:09.173720: case_609, shape torch.Size([3, 100, 256, 256]), rank 0 
2025-06-05 04:04:12.632020: predicting case_612 
2025-06-05 04:04:12.794237: case_612, shape torch.Size([3, 80, 284, 284]), rank 0 
2025-06-05 04:04:15.128236: predicting case_614 
2025-06-05 04:04:15.230120: case_614, shape torch.Size([3, 79, 199, 199]), rank 0 
2025-06-05 04:04:17.543662: predicting case_615 
2025-06-05 04:04:17.677748: case_615, shape torch.Size([3, 79, 213, 213]), rank 0 
2025-06-05 04:04:19.981602: predicting case_616 
2025-06-05 04:04:20.161306: case_616, shape torch.Size([3, 80, 256, 256]), rank 0 
2025-06-05 04:04:22.503624: predicting case_621 
2025-06-05 04:04:22.627569: case_621, shape torch.Size([3, 81, 213, 213]), rank 0 
2025-06-05 04:04:24.944871: predicting case_623 
2025-06-05 04:04:25.141945: case_623, shape torch.Size([3, 79, 256, 256]), rank 0 
2025-06-05 04:04:27.491151: predicting case_624 
2025-06-05 04:04:28.069218: case_624, shape torch.Size([3, 100, 512, 512]), rank 0 
2025-06-05 04:04:49.332223: predicting case_636 
2025-06-05 04:04:49.455626: case_636, shape torch.Size([3, 79, 213, 213]), rank 0 
2025-06-05 04:04:51.777236: predicting case_641 
2025-06-05 04:04:51.993798: case_641, shape torch.Size([3, 79, 256, 256]), rank 0 
2025-06-05 04:04:54.333459: predicting case_646 
2025-06-05 04:04:54.418947: case_646, shape torch.Size([3, 79, 185, 185]), rank 0 
2025-06-05 04:04:55.046547: predicting case_648 
2025-06-05 04:04:55.201880: case_648, shape torch.Size([3, 80, 213, 213]), rank 0 
2025-06-05 04:04:57.540405: predicting case_653 
2025-06-05 04:04:57.735777: case_653, shape torch.Size([3, 80, 256, 256]), rank 0 
2025-06-05 04:05:00.050816: predicting case_654 
2025-06-05 04:05:00.181082: case_654, shape torch.Size([3, 80, 242, 242]), rank 0 
2025-06-05 04:05:02.510764: predicting case_657 
2025-06-05 04:05:02.687013: case_657, shape torch.Size([3, 80, 235, 235]), rank 0 
2025-06-05 04:05:05.000227: predicting case_660 
2025-06-05 04:05:05.161303: case_660, shape torch.Size([3, 79, 256, 256]), rank 0 
2025-06-05 04:05:07.486363: predicting case_663 
2025-06-05 04:05:07.703934: case_663, shape torch.Size([3, 80, 256, 256]), rank 0 
2025-06-05 04:05:10.027400: predicting case_667 
2025-06-05 04:05:10.198488: case_667, shape torch.Size([3, 80, 228, 228]), rank 0 
2025-06-05 04:05:12.520079: predicting case_673 
2025-06-05 04:05:12.806055: case_673, shape torch.Size([3, 80, 256, 256]), rank 0 
2025-06-05 04:05:15.160057: predicting case_677 
2025-06-05 04:05:15.867735: case_677, shape torch.Size([3, 90, 512, 512]), rank 0 
2025-06-05 04:05:37.152989: predicting case_678 
2025-06-05 04:05:37.360705: case_678, shape torch.Size([3, 79, 256, 256]), rank 0 
2025-06-05 04:05:39.697339: predicting case_679 
2025-06-05 04:05:39.917246: case_679, shape torch.Size([3, 80, 277, 277]), rank 0 
2025-06-05 04:05:42.254254: predicting case_680 
2025-06-05 04:05:42.556924: case_680, shape torch.Size([3, 80, 256, 256]), rank 0 
2025-06-05 04:05:44.881832: predicting case_681 
2025-06-05 04:05:45.184629: case_681, shape torch.Size([3, 80, 398, 398]), rank 0 
2025-06-05 04:05:54.304506: predicting case_690 
2025-06-05 04:05:54.435203: case_690, shape torch.Size([3, 79, 220, 220]), rank 0 
2025-06-05 04:05:56.740538: predicting case_695 
2025-06-05 04:05:56.912850: case_695, shape torch.Size([3, 77, 302, 302]), rank 0 
2025-06-05 04:06:02.114372: predicting case_698 
2025-06-05 04:06:02.250192: case_698, shape torch.Size([3, 80, 213, 213]), rank 0 
2025-06-05 04:06:04.551807: predicting case_700 
2025-06-05 04:06:04.811265: case_700, shape torch.Size([3, 90, 356, 356]), rank 0 
2025-06-05 04:06:12.544821: predicting case_701 
2025-06-05 04:06:12.703194: case_701, shape torch.Size([3, 80, 256, 256]), rank 0 
2025-06-05 04:06:15.009468: predicting case_707 
2025-06-05 04:06:15.252396: case_707, shape torch.Size([3, 80, 256, 256]), rank 0 
2025-06-05 04:06:17.568630: predicting case_714 
2025-06-05 04:06:17.661840: case_714, shape torch.Size([3, 80, 199, 199]), rank 0 
2025-06-05 04:06:20.002851: predicting case_726 
2025-06-05 04:06:20.148889: case_726, shape torch.Size([3, 80, 220, 220]), rank 0 
2025-06-05 04:06:22.448427: predicting case_728 
2025-06-05 04:06:22.634352: case_728, shape torch.Size([3, 90, 284, 284]), rank 0 
2025-06-05 04:06:26.084736: predicting case_733 
2025-06-05 04:06:26.215499: case_733, shape torch.Size([3, 80, 228, 228]), rank 0 
2025-06-05 04:06:28.523051: predicting case_735 
2025-06-05 04:06:28.725870: case_735, shape torch.Size([3, 79, 256, 256]), rank 0 
2025-06-05 04:06:31.083424: predicting case_738 
2025-06-05 04:06:31.200056: case_738, shape torch.Size([3, 79, 213, 213]), rank 0 
2025-06-05 04:06:33.503364: predicting case_741 
2025-06-05 04:06:33.661891: case_741, shape torch.Size([3, 79, 256, 256]), rank 0 
2025-06-05 04:06:35.979690: predicting case_747 
2025-06-05 04:06:36.586533: case_747, shape torch.Size([3, 86, 569, 569]), rank 0 
2025-06-05 04:06:57.886574: predicting case_758 
2025-06-05 04:06:58.028315: case_758, shape torch.Size([3, 80, 235, 235]), rank 0 
2025-06-05 04:07:00.343029: predicting case_761 
2025-06-05 04:07:00.528251: case_761, shape torch.Size([3, 80, 256, 256]), rank 0 
2025-06-05 04:07:02.880033: predicting case_765 
2025-06-05 04:07:03.029292: case_765, shape torch.Size([3, 80, 243, 243]), rank 0 
2025-06-05 04:07:05.352668: predicting case_766 
2025-06-05 04:07:05.607550: case_766, shape torch.Size([3, 80, 256, 256]), rank 0 
2025-06-05 04:07:07.931547: predicting case_774 
2025-06-05 04:07:08.284503: case_774, shape torch.Size([3, 80, 455, 455]), rank 0 
2025-06-05 04:07:17.412357: predicting case_776 
2025-06-05 04:07:17.882155: case_776, shape torch.Size([3, 88, 512, 512]), rank 0 
2025-06-05 04:07:39.198789: predicting case_783 
2025-06-05 04:07:39.406979: case_783, shape torch.Size([3, 80, 256, 256]), rank 0 
2025-06-05 04:07:41.764914: predicting case_786 
2025-06-05 04:07:41.990317: case_786, shape torch.Size([3, 79, 256, 256]), rank 0 
2025-06-05 04:07:44.321939: predicting case_790 
2025-06-05 04:07:44.429592: case_790, shape torch.Size([3, 79, 228, 228]), rank 0 
2025-06-05 04:07:46.736877: predicting case_792 
2025-06-05 04:07:46.893529: case_792, shape torch.Size([3, 79, 256, 256]), rank 0 
2025-06-05 04:07:49.217094: predicting case_798 
2025-06-05 04:07:49.347058: case_798, shape torch.Size([3, 80, 242, 242]), rank 0 
2025-06-05 04:07:51.642184: predicting case_801 
2025-06-05 04:07:51.777921: case_801, shape torch.Size([3, 79, 213, 213]), rank 0 
2025-06-05 04:07:54.104430: predicting case_803 
2025-06-05 04:07:54.297371: case_803, shape torch.Size([3, 80, 270, 270]), rank 0 
2025-06-05 04:07:56.639261: predicting case_810 
2025-06-05 04:07:56.826772: case_810, shape torch.Size([3, 84, 299, 299]), rank 0 
2025-06-05 04:08:01.993718: predicting case_811 
2025-06-05 04:08:02.190472: case_811, shape torch.Size([3, 80, 256, 256]), rank 0 
2025-06-05 04:08:04.532844: predicting case_812 
2025-06-05 04:08:04.724163: case_812, shape torch.Size([3, 80, 256, 256]), rank 0 
2025-06-05 04:08:07.051388: predicting case_816 
2025-06-05 04:08:07.163377: case_816, shape torch.Size([3, 80, 213, 213]), rank 0 
2025-06-05 04:08:09.468204: predicting case_823 
2025-06-05 04:08:09.848490: case_823, shape torch.Size([3, 96, 455, 455]), rank 0 
2025-06-05 04:08:23.473104: predicting case_830 
2025-06-05 04:08:23.645895: case_830, shape torch.Size([3, 80, 242, 242]), rank 0 
2025-06-05 04:08:25.966946: predicting case_831 
2025-06-05 04:08:26.252213: case_831, shape torch.Size([3, 80, 328, 328]), rank 0 
2025-06-05 04:08:31.435890: predicting case_832 
2025-06-05 04:08:31.600469: case_832, shape torch.Size([3, 81, 213, 213]), rank 0 
2025-06-05 04:08:33.915600: predicting case_836 
2025-06-05 04:08:34.355599: case_836, shape torch.Size([3, 80, 427, 427]), rank 0 
2025-06-05 04:08:43.507484: predicting case_838 
2025-06-05 04:08:43.690798: case_838, shape torch.Size([3, 80, 242, 242]), rank 0 
2025-06-05 04:08:46.002016: predicting case_840 
2025-06-05 04:08:46.163633: case_840, shape torch.Size([3, 80, 249, 249]), rank 0 
2025-06-05 04:08:48.487127: predicting case_846 
2025-06-05 04:08:48.636093: case_846, shape torch.Size([3, 80, 213, 213]), rank 0 
2025-06-05 04:08:50.960614: predicting case_847 
2025-06-05 04:08:51.116188: case_847, shape torch.Size([3, 80, 228, 228]), rank 0 
2025-06-05 04:08:53.426318: predicting case_857 
2025-06-05 04:08:53.592877: case_857, shape torch.Size([3, 80, 242, 242]), rank 0 
2025-06-05 04:08:55.946504: predicting case_858 
2025-06-05 04:08:56.187952: case_858, shape torch.Size([3, 80, 256, 256]), rank 0 
2025-06-05 04:08:58.509803: predicting case_862 
2025-06-05 04:08:58.660535: case_862, shape torch.Size([3, 80, 242, 242]), rank 0 
2025-06-05 04:09:00.997636: predicting case_867 
2025-06-05 04:09:01.213384: case_867, shape torch.Size([3, 90, 320, 320]), rank 0 
2025-06-05 04:09:08.930164: predicting case_868 
2025-06-05 04:09:09.144730: case_868, shape torch.Size([3, 80, 256, 256]), rank 0 
2025-06-05 04:09:11.477102: predicting case_870 
2025-06-05 04:09:11.707196: case_870, shape torch.Size([3, 80, 256, 256]), rank 0 
2025-06-05 04:09:14.041718: predicting case_877 
2025-06-05 04:09:14.241082: case_877, shape torch.Size([3, 79, 235, 235]), rank 0 
2025-06-05 04:09:16.572063: predicting case_878 
2025-06-05 04:09:16.712277: case_878, shape torch.Size([3, 79, 256, 256]), rank 0 
2025-06-05 04:09:19.045436: predicting case_888 
2025-06-05 04:09:19.257738: case_888, shape torch.Size([3, 79, 256, 256]), rank 0 
2025-06-05 04:09:21.587333: predicting case_893 
2025-06-05 04:09:21.758329: case_893, shape torch.Size([3, 80, 270, 270]), rank 0 
2025-06-05 04:09:24.086392: predicting case_899 
2025-06-05 04:09:24.281096: case_899, shape torch.Size([3, 80, 256, 256]), rank 0 
2025-06-05 04:09:26.608371: predicting case_912 
2025-06-05 04:09:26.778698: case_912, shape torch.Size([3, 90, 289, 289]), rank 0 
2025-06-05 04:09:34.496671: predicting case_916 
2025-06-05 04:09:34.781543: case_916, shape torch.Size([3, 80, 398, 398]), rank 0 
2025-06-05 04:09:43.937023: predicting case_929 
2025-06-05 04:09:44.288741: case_929, shape torch.Size([3, 86, 427, 427]), rank 0 
2025-06-05 04:09:57.951770: predicting case_930 
2025-06-05 04:09:58.174858: case_930, shape torch.Size([3, 89, 302, 302]), rank 0 
2025-06-05 04:10:05.888453: predicting case_940 
2025-06-05 04:10:05.996076: case_940, shape torch.Size([3, 80, 213, 213]), rank 0 
2025-06-05 04:10:08.314152: predicting case_943 
2025-06-05 04:10:08.550832: case_943, shape torch.Size([3, 80, 277, 277]), rank 0 
2025-06-05 04:10:10.884837: predicting case_960 
2025-06-05 04:10:10.990552: case_960, shape torch.Size([3, 80, 199, 199]), rank 0 
2025-06-05 04:10:13.314126: predicting case_970 
2025-06-05 04:10:13.479184: case_970, shape torch.Size([3, 80, 242, 242]), rank 0 
2025-06-05 04:10:15.810460: predicting case_976 
2025-06-05 04:10:15.937503: case_976, shape torch.Size([3, 80, 256, 256]), rank 0 
2025-06-05 04:10:18.260478: predicting case_977 
2025-06-05 04:10:18.378214: case_977, shape torch.Size([3, 80, 228, 228]), rank 0 
2025-06-05 04:10:20.694645: predicting case_979 
2025-06-05 04:10:20.907751: case_979, shape torch.Size([3, 90, 258, 258]), rank 0 
2025-06-05 04:10:24.391554: predicting case_985 
2025-06-05 04:10:24.542849: case_985, shape torch.Size([3, 79, 256, 256]), rank 0 
2025-06-05 04:10:26.875571: predicting case_990 
2025-06-05 04:10:27.057886: case_990, shape torch.Size([3, 80, 242, 242]), rank 0 
2025-06-05 04:10:29.404289: predicting case_995 
2025-06-05 04:10:29.560178: case_995, shape torch.Size([3, 80, 235, 235]), rank 0 
2025-06-05 04:10:50.351270: Validation complete 
2025-06-05 04:10:50.381116: Mean Validation Dice:  0.7860999713696868 
