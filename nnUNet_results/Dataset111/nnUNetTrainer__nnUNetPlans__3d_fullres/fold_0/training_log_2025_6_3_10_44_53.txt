
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2025-06-03 10:44:54.865252: do_dummy_2d_data_aug: True 
2025-06-03 10:44:54.903816: Creating new 5-fold cross-validation split... 
2025-06-03 10:44:54.926345: Desired fold for training: 0 
2025-06-03 10:44:54.935360: This split has 960 training and 240 validation cases. 

This is the configuration used by this training:
Configuration name: 3d_fullres
 {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [56, 192, 192], 'median_image_size_in_voxels': [80.0, 256.0, 256.0], 'spacing': [2.0, 0.7031000256538391, 0.7031000256538391], 'normalization_schemes': ['ZScoreNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[1, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [1, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': False} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset111', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [2.0, 0.7031000256538391, 0.7031000256538391], 'original_median_shape_after_transp': [80, 256, 256], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 57.53712844848633, 'mean': 3.6041464805603027, 'median': 2.8339626789093018, 'min': -11.494463920593262, 'percentile_00_5': -1.8308113813400269, 'percentile_99_5': 16.908536911010742, 'std': 3.43110728263855}}} 
 
2025-06-03 10:45:51.222506: Unable to plot network architecture: 
2025-06-03 10:45:51.235826: No module named 'hiddenlayer' 
2025-06-03 10:45:51.396883:  
2025-06-03 10:45:51.411140: Epoch 0 
2025-06-03 10:45:51.423886: Current learning rate: 0.01 
2025-06-03 10:46:59.683993: train_loss -0.2225 
2025-06-03 10:46:59.700366: val_loss -0.3632 
2025-06-03 10:46:59.713213: Pseudo dice [np.float32(0.4328)] 
2025-06-03 10:46:59.725482: Epoch time: 68.29 s 
2025-06-03 10:46:59.738321: Yayy! New best EMA pseudo Dice: 0.4327999949455261 
2025-06-03 10:47:01.198642:  
2025-06-03 10:47:01.223097: Epoch 1 
2025-06-03 10:47:01.235632: Current learning rate: 0.00999 
2025-06-03 10:48:04.566267: train_loss -0.4585 
2025-06-03 10:48:04.581605: val_loss -0.3879 
2025-06-03 10:48:04.593380: Pseudo dice [np.float32(0.3746)] 
2025-06-03 10:48:04.606190: Epoch time: 63.37 s 
2025-06-03 10:48:05.826829:  
2025-06-03 10:48:05.844692: Epoch 2 
2025-06-03 10:48:05.861496: Current learning rate: 0.00998 
2025-06-03 10:49:32.171269: train_loss -0.4591 
2025-06-03 10:49:32.345960: val_loss -0.4123 
2025-06-03 10:49:32.360762: Pseudo dice [np.float32(0.4318)] 
2025-06-03 10:49:32.374047: Epoch time: 86.35 s 
2025-06-03 10:49:34.692185:  
2025-06-03 10:49:34.708121: Epoch 3 
2025-06-03 10:49:34.720716: Current learning rate: 0.00997 
2025-06-03 10:51:12.792909: train_loss -0.4707 
2025-06-03 10:51:13.059914: val_loss -0.4522 
2025-06-03 10:51:13.412378: Pseudo dice [np.float32(0.519)] 
2025-06-03 10:51:13.647958: Epoch time: 98.11 s 
2025-06-03 10:51:13.829515: Yayy! New best EMA pseudo Dice: 0.436599999666214 
2025-06-03 10:51:16.163128:  
2025-06-03 10:51:16.177296: Epoch 4 
2025-06-03 10:51:16.192463: Current learning rate: 0.00996 
2025-06-03 10:52:55.042793: train_loss -0.5227 
2025-06-03 10:52:55.059738: val_loss -0.4678 
2025-06-03 10:52:55.071966: Pseudo dice [np.float32(0.5133)] 
2025-06-03 10:52:55.085202: Epoch time: 98.88 s 
2025-06-03 10:52:55.097432: Yayy! New best EMA pseudo Dice: 0.44429999589920044 
2025-06-03 10:52:58.109396:  
2025-06-03 10:52:58.127748: Epoch 5 
2025-06-03 10:52:58.141516: Current learning rate: 0.00995 
2025-06-03 10:54:37.334743: train_loss -0.5087 
2025-06-03 10:54:37.697511: val_loss -0.5435 
2025-06-03 10:54:38.026585: Pseudo dice [np.float32(0.5741)] 
2025-06-03 10:54:38.317699: Epoch time: 99.23 s 
2025-06-03 10:54:38.526262: Yayy! New best EMA pseudo Dice: 0.45719999074935913 
2025-06-03 10:54:40.312860:  
2025-06-03 10:54:40.330083: Epoch 6 
2025-06-03 10:54:40.340342: Current learning rate: 0.00995 
2025-06-03 10:56:18.371519: train_loss -0.5361 
2025-06-03 10:56:18.387841: val_loss -0.5714 
2025-06-03 10:56:18.400598: Pseudo dice [np.float32(0.6507)] 
2025-06-03 10:56:18.412873: Epoch time: 98.06 s 
2025-06-03 10:56:18.425168: Yayy! New best EMA pseudo Dice: 0.4765999913215637 
2025-06-03 10:56:21.306453:  
2025-06-03 10:56:21.319425: Epoch 7 
2025-06-03 10:56:21.331997: Current learning rate: 0.00994 
2025-06-03 10:57:57.561866: train_loss -0.5323 
2025-06-03 10:57:57.579494: val_loss -0.5179 
2025-06-03 10:57:57.592512: Pseudo dice [np.float32(0.5213)] 
2025-06-03 10:57:57.605292: Epoch time: 96.26 s 
2025-06-03 10:57:57.618075: Yayy! New best EMA pseudo Dice: 0.4810999929904938 
2025-06-03 10:58:00.787339:  
2025-06-03 10:58:00.798228: Epoch 8 
2025-06-03 10:58:00.808057: Current learning rate: 0.00993 
2025-06-03 10:59:40.126436: train_loss -0.5116 
2025-06-03 10:59:40.510458: val_loss -0.5248 
2025-06-03 10:59:40.859223: Pseudo dice [np.float32(0.5611)] 
2025-06-03 10:59:41.203392: Epoch time: 99.34 s 
2025-06-03 10:59:41.475056: Yayy! New best EMA pseudo Dice: 0.48910000920295715 
2025-06-03 10:59:43.746425:  
2025-06-03 10:59:43.765105: Epoch 9 
2025-06-03 10:59:43.777879: Current learning rate: 0.00992 
2025-06-03 11:01:23.144958: train_loss -0.5459 
2025-06-03 11:01:23.163378: val_loss -0.5386 
2025-06-03 11:01:23.176583: Pseudo dice [np.float32(0.5657)] 
2025-06-03 11:01:23.191727: Epoch time: 99.4 s 
2025-06-03 11:01:23.206212: Yayy! New best EMA pseudo Dice: 0.4966999888420105 
2025-06-03 11:01:26.042722:  
2025-06-03 11:01:26.057836: Epoch 10 
2025-06-03 11:01:26.070684: Current learning rate: 0.00991 
2025-06-03 11:03:03.780205: train_loss -0.4979 
2025-06-03 11:03:03.796711: val_loss -0.5671 
2025-06-03 11:03:03.808558: Pseudo dice [np.float32(0.5368)] 
2025-06-03 11:03:03.820760: Epoch time: 97.74 s 
2025-06-03 11:03:03.832803: Yayy! New best EMA pseudo Dice: 0.5006999969482422 
2025-06-03 11:03:07.245042:  
2025-06-03 11:03:07.259717: Epoch 11 
2025-06-03 11:03:07.272587: Current learning rate: 0.0099 
2025-06-03 11:04:43.755084: train_loss -0.5535 
2025-06-03 11:04:43.774036: val_loss -0.543 
2025-06-03 11:04:43.788620: Pseudo dice [np.float32(0.4975)] 
2025-06-03 11:04:43.803869: Epoch time: 96.51 s 
2025-06-03 11:04:46.067136:  
2025-06-03 11:04:46.092395: Epoch 12 
2025-06-03 11:04:46.107497: Current learning rate: 0.00989 
2025-06-03 11:06:22.334954: train_loss -0.5538 
2025-06-03 11:06:22.351863: val_loss -0.5848 
2025-06-03 11:06:22.364700: Pseudo dice [np.float32(0.6691)] 
2025-06-03 11:06:22.376499: Epoch time: 96.27 s 
2025-06-03 11:06:22.389313: Yayy! New best EMA pseudo Dice: 0.517300009727478 
2025-06-03 11:06:25.577094:  
2025-06-03 11:06:25.589558: Epoch 13 
2025-06-03 11:06:25.604562: Current learning rate: 0.00988 
2025-06-03 11:08:06.417774: train_loss -0.5704 
2025-06-03 11:08:06.651722: val_loss -0.5865 
2025-06-03 11:08:06.938622: Pseudo dice [np.float32(0.62)] 
2025-06-03 11:08:07.199598: Epoch time: 100.84 s 
2025-06-03 11:08:07.533088: Yayy! New best EMA pseudo Dice: 0.5274999737739563 
2025-06-03 11:08:09.785270:  
2025-06-03 11:08:09.801095: Epoch 14 
2025-06-03 11:08:09.815009: Current learning rate: 0.00987 
2025-06-03 11:09:47.567250: train_loss -0.5768 
2025-06-03 11:09:47.588692: val_loss -0.6184 
2025-06-03 11:09:47.600910: Pseudo dice [np.float32(0.6693)] 
2025-06-03 11:09:47.612650: Epoch time: 97.78 s 
2025-06-03 11:09:47.624563: Yayy! New best EMA pseudo Dice: 0.541700005531311 
2025-06-03 11:09:51.041427:  
2025-06-03 11:09:51.054664: Epoch 15 
2025-06-03 11:09:51.067378: Current learning rate: 0.00986 
2025-06-03 11:11:29.158168: train_loss -0.5461 
2025-06-03 11:11:29.379055: val_loss -0.5422 
2025-06-03 11:11:29.659821: Pseudo dice [np.float32(0.5425)] 
2025-06-03 11:11:29.925226: Epoch time: 98.12 s 
2025-06-03 11:11:30.191962: Yayy! New best EMA pseudo Dice: 0.5418000221252441 
2025-06-03 11:11:32.298361:  
2025-06-03 11:11:32.311260: Epoch 16 
2025-06-03 11:11:32.322658: Current learning rate: 0.00986 
2025-06-03 11:13:09.060802: train_loss -0.5958 
2025-06-03 11:13:09.333828: val_loss -0.5868 
2025-06-03 11:13:09.622172: Pseudo dice [np.float32(0.6601)] 
2025-06-03 11:13:09.894013: Epoch time: 96.76 s 
2025-06-03 11:13:10.072311: Yayy! New best EMA pseudo Dice: 0.553600013256073 
2025-06-03 11:13:12.502837:  
2025-06-03 11:13:12.517136: Epoch 17 
2025-06-03 11:13:12.530406: Current learning rate: 0.00985 
2025-06-03 11:14:49.965793: train_loss -0.6062 
2025-06-03 11:14:50.292827: val_loss -0.5497 
2025-06-03 11:14:50.799444: Pseudo dice [np.float32(0.5929)] 
2025-06-03 11:14:51.046586: Epoch time: 97.46 s 
2025-06-03 11:14:51.295122: Yayy! New best EMA pseudo Dice: 0.5575000047683716 
2025-06-03 11:14:53.715506:  
2025-06-03 11:14:53.727156: Epoch 18 
2025-06-03 11:14:53.738369: Current learning rate: 0.00984 
2025-06-03 11:16:31.438464: train_loss -0.6065 
2025-06-03 11:16:31.455286: val_loss -0.5456 
2025-06-03 11:16:31.467421: Pseudo dice [np.float32(0.5844)] 
2025-06-03 11:16:31.479093: Epoch time: 97.72 s 
2025-06-03 11:16:31.490897: Yayy! New best EMA pseudo Dice: 0.5601999759674072 
2025-06-03 11:16:35.119850:  
2025-06-03 11:16:35.136011: Epoch 19 
2025-06-03 11:16:35.145922: Current learning rate: 0.00983 
2025-06-03 11:18:09.729527: train_loss -0.5721 
2025-06-03 11:18:09.746689: val_loss -0.6159 
2025-06-03 11:18:09.759502: Pseudo dice [np.float32(0.6867)] 
2025-06-03 11:18:09.772282: Epoch time: 94.61 s 
2025-06-03 11:18:09.785091: Yayy! New best EMA pseudo Dice: 0.5728999972343445 
2025-06-03 11:18:13.100669:  
2025-06-03 11:18:13.116935: Epoch 20 
2025-06-03 11:18:13.131655: Current learning rate: 0.00982 
2025-06-03 11:19:51.773473: train_loss -0.5559 
2025-06-03 11:19:51.791783: val_loss -0.6078 
2025-06-03 11:19:51.803991: Pseudo dice [np.float32(0.6548)] 
2025-06-03 11:19:51.816195: Epoch time: 98.67 s 
2025-06-03 11:19:51.827354: Yayy! New best EMA pseudo Dice: 0.5810999870300293 
2025-06-03 11:19:54.480355:  
2025-06-03 11:19:54.494401: Epoch 21 
2025-06-03 11:19:54.509357: Current learning rate: 0.00981 
2025-06-03 11:21:34.430798: train_loss -0.5882 
2025-06-03 11:21:34.655090: val_loss -0.5301 
2025-06-03 11:21:34.922515: Pseudo dice [np.float32(0.5696)] 
2025-06-03 11:21:35.161602: Epoch time: 99.95 s 
2025-06-03 11:21:36.828146:  
2025-06-03 11:21:36.845196: Epoch 22 
2025-06-03 11:21:36.859139: Current learning rate: 0.0098 
2025-06-03 11:23:14.664390: train_loss -0.604 
2025-06-03 11:23:14.687067: val_loss -0.612 
2025-06-03 11:23:14.705931: Pseudo dice [np.float32(0.599)] 
2025-06-03 11:23:14.719067: Epoch time: 97.84 s 
2025-06-03 11:23:14.731674: Yayy! New best EMA pseudo Dice: 0.5817999839782715 
2025-06-03 11:23:17.806322:  
2025-06-03 11:23:17.818739: Epoch 23 
2025-06-03 11:23:17.832692: Current learning rate: 0.00979 
2025-06-03 11:24:53.982334: train_loss -0.5923 
2025-06-03 11:24:54.000176: val_loss -0.6303 
2025-06-03 11:24:54.013437: Pseudo dice [np.float32(0.6622)] 
2025-06-03 11:24:54.029409: Epoch time: 96.18 s 
2025-06-03 11:24:54.046338: Yayy! New best EMA pseudo Dice: 0.589900016784668 
2025-06-03 11:24:57.519128:  
2025-06-03 11:24:57.538475: Epoch 24 
2025-06-03 11:24:57.553612: Current learning rate: 0.00978 
2025-06-03 11:26:35.824303: train_loss -0.5715 
2025-06-03 11:26:35.954477: val_loss -0.6154 
2025-06-03 11:26:35.968291: Pseudo dice [np.float32(0.6136)] 
2025-06-03 11:26:35.982596: Epoch time: 98.31 s 
2025-06-03 11:26:35.997926: Yayy! New best EMA pseudo Dice: 0.592199981212616 
2025-06-03 11:26:38.608360:  
2025-06-03 11:26:38.621996: Epoch 25 
2025-06-03 11:26:38.631369: Current learning rate: 0.00977 
2025-06-03 11:28:17.760349: train_loss -0.6189 
2025-06-03 11:28:17.777757: val_loss -0.4637 
2025-06-03 11:28:17.792611: Pseudo dice [np.float32(0.3953)] 
2025-06-03 11:28:17.805985: Epoch time: 99.15 s 
2025-06-03 11:28:20.072673:  
2025-06-03 11:28:20.085000: Epoch 26 
2025-06-03 11:28:20.096003: Current learning rate: 0.00977 
2025-06-03 11:29:57.200752: train_loss -0.5982 
2025-06-03 11:29:57.346587: val_loss -0.5777 
2025-06-03 11:29:57.543186: Pseudo dice [np.float32(0.6)] 
2025-06-03 11:29:57.783806: Epoch time: 97.13 s 
2025-06-03 11:29:59.413296:  
2025-06-03 11:29:59.431507: Epoch 27 
2025-06-03 11:29:59.441847: Current learning rate: 0.00976 
2025-06-03 11:31:38.458039: train_loss -0.6163 
2025-06-03 11:31:38.593853: val_loss -0.6207 
2025-06-03 11:31:38.917785: Pseudo dice [np.float32(0.6676)] 
2025-06-03 11:31:39.162394: Epoch time: 99.05 s 
2025-06-03 11:31:40.959261:  
2025-06-03 11:31:40.975357: Epoch 28 
2025-06-03 11:31:40.988328: Current learning rate: 0.00975 
2025-06-03 11:33:18.479094: train_loss -0.6277 
2025-06-03 11:33:18.497153: val_loss -0.5866 
2025-06-03 11:33:18.510046: Pseudo dice [np.float32(0.5676)] 
2025-06-03 11:33:18.522575: Epoch time: 97.52 s 
2025-06-03 11:33:21.061832:  
2025-06-03 11:33:21.075781: Epoch 29 
2025-06-03 11:33:21.088111: Current learning rate: 0.00974 
2025-06-03 11:34:57.041119: train_loss -0.6046 
2025-06-03 11:34:57.057625: val_loss -0.5853 
2025-06-03 11:34:57.070394: Pseudo dice [np.float32(0.6279)] 
2025-06-03 11:34:57.083187: Epoch time: 95.98 s 
2025-06-03 11:34:59.709065:  
2025-06-03 11:34:59.722235: Epoch 30 
2025-06-03 11:34:59.738473: Current learning rate: 0.00973 
2025-06-03 11:36:39.058869: train_loss -0.6218 
2025-06-03 11:36:39.076916: val_loss -0.58 
2025-06-03 11:36:39.089632: Pseudo dice [np.float32(0.6264)] 
2025-06-03 11:36:39.101831: Epoch time: 99.35 s 
2025-06-03 11:36:41.963552:  
2025-06-03 11:36:41.975557: Epoch 31 
2025-06-03 11:36:41.992208: Current learning rate: 0.00972 
2025-06-03 11:38:20.479223: train_loss -0.6085 
2025-06-03 11:38:20.497786: val_loss -0.6534 
2025-06-03 11:38:20.510631: Pseudo dice [np.float32(0.6363)] 
2025-06-03 11:38:20.523993: Epoch time: 98.52 s 
2025-06-03 11:38:20.536855: Yayy! New best EMA pseudo Dice: 0.59579998254776 
2025-06-03 11:38:23.887386:  
2025-06-03 11:38:23.899730: Epoch 32 
2025-06-03 11:38:23.910018: Current learning rate: 0.00971 
2025-06-03 11:40:01.476912: train_loss -0.6179 
2025-06-03 11:40:01.790549: val_loss -0.6436 
2025-06-03 11:40:02.039384: Pseudo dice [np.float32(0.6655)] 
2025-06-03 11:40:02.360075: Epoch time: 97.59 s 
2025-06-03 11:40:02.601075: Yayy! New best EMA pseudo Dice: 0.6026999950408936 
2025-06-03 11:40:04.791958:  
2025-06-03 11:40:04.808647: Epoch 33 
2025-06-03 11:40:04.828310: Current learning rate: 0.0097 
2025-06-03 11:41:43.048448: train_loss -0.6212 
2025-06-03 11:41:43.066308: val_loss -0.5843 
2025-06-03 11:41:43.079065: Pseudo dice [np.float32(0.6454)] 
2025-06-03 11:41:43.090774: Epoch time: 98.26 s 
2025-06-03 11:41:43.102008: Yayy! New best EMA pseudo Dice: 0.6069999933242798 
2025-06-03 11:41:46.547066:  
2025-06-03 11:41:46.565920: Epoch 34 
2025-06-03 11:41:46.579315: Current learning rate: 0.00969 
2025-06-03 11:43:23.662777: train_loss -0.6214 
2025-06-03 11:43:23.681635: val_loss -0.6406 
2025-06-03 11:43:23.695455: Pseudo dice [np.float32(0.6824)] 
2025-06-03 11:43:23.709441: Epoch time: 97.12 s 
2025-06-03 11:43:23.722201: Yayy! New best EMA pseudo Dice: 0.6144999861717224 
2025-06-03 11:43:26.648685:  
2025-06-03 11:43:26.666447: Epoch 35 
2025-06-03 11:43:26.681269: Current learning rate: 0.00968 
2025-06-03 11:45:03.686152: train_loss -0.6253 
2025-06-03 11:45:03.870398: val_loss -0.5955 
2025-06-03 11:45:03.887947: Pseudo dice [np.float32(0.6342)] 
2025-06-03 11:45:03.901691: Epoch time: 97.04 s 
2025-06-03 11:45:03.915494: Yayy! New best EMA pseudo Dice: 0.6165000200271606 
2025-06-03 11:45:06.185810:  
2025-06-03 11:45:06.202672: Epoch 36 
2025-06-03 11:45:06.216386: Current learning rate: 0.00968 
2025-06-03 11:46:44.144313: train_loss -0.5904 
2025-06-03 11:46:44.531098: val_loss -0.601 
2025-06-03 11:46:44.974016: Pseudo dice [np.float32(0.6678)] 
2025-06-03 11:46:45.281177: Epoch time: 97.96 s 
2025-06-03 11:46:45.589172: Yayy! New best EMA pseudo Dice: 0.6215999722480774 
2025-06-03 11:46:47.579082:  
2025-06-03 11:46:47.590675: Epoch 37 
2025-06-03 11:46:47.599736: Current learning rate: 0.00967 
2025-06-03 11:48:24.237337: train_loss -0.6376 
2025-06-03 11:48:24.253997: val_loss -0.5897 
2025-06-03 11:48:24.267293: Pseudo dice [np.float32(0.6537)] 
2025-06-03 11:48:24.279675: Epoch time: 96.66 s 
2025-06-03 11:48:24.292424: Yayy! New best EMA pseudo Dice: 0.6248000264167786 
2025-06-03 11:48:27.018820:  
2025-06-03 11:48:27.032996: Epoch 38 
2025-06-03 11:48:27.044059: Current learning rate: 0.00966 
2025-06-03 11:50:02.336867: train_loss -0.6147 
2025-06-03 11:50:02.613831: val_loss -0.5461 
2025-06-03 11:50:02.886667: Pseudo dice [np.float32(0.5702)] 
2025-06-03 11:50:03.179072: Epoch time: 95.32 s 
2025-06-03 11:50:05.281051:  
2025-06-03 11:50:05.295741: Epoch 39 
2025-06-03 11:50:05.306256: Current learning rate: 0.00965 
2025-06-03 11:51:44.921891: train_loss -0.595 
2025-06-03 11:51:44.937806: val_loss -0.5942 
2025-06-03 11:51:44.950666: Pseudo dice [np.float32(0.6133)] 
2025-06-03 11:51:44.965601: Epoch time: 99.64 s 
2025-06-03 11:51:48.101267:  
2025-06-03 11:51:48.120731: Epoch 40 
2025-06-03 11:51:48.135770: Current learning rate: 0.00964 
2025-06-03 11:53:23.284924: train_loss -0.5754 
2025-06-03 11:53:23.483357: val_loss -0.679 
2025-06-03 11:53:23.686572: Pseudo dice [np.float32(0.6987)] 
2025-06-03 11:53:23.883676: Epoch time: 95.19 s 
2025-06-03 11:53:24.102918: Yayy! New best EMA pseudo Dice: 0.626800000667572 
2025-06-03 11:53:26.121418:  
2025-06-03 11:53:26.134197: Epoch 41 
2025-06-03 11:53:26.144441: Current learning rate: 0.00963 
2025-06-03 11:55:05.038061: train_loss -0.5973 
2025-06-03 11:55:05.512861: val_loss -0.6146 
2025-06-03 11:55:05.750059: Pseudo dice [np.float32(0.6874)] 
2025-06-03 11:55:05.765317: Epoch time: 98.92 s 
2025-06-03 11:55:05.778034: Yayy! New best EMA pseudo Dice: 0.6327999830245972 
2025-06-03 11:55:08.053623:  
2025-06-03 11:55:08.069500: Epoch 42 
2025-06-03 11:55:08.083837: Current learning rate: 0.00962 
2025-06-03 11:56:47.187739: train_loss -0.6331 
2025-06-03 11:56:47.205347: val_loss -0.5616 
2025-06-03 11:56:47.219203: Pseudo dice [np.float32(0.5926)] 
2025-06-03 11:56:47.231993: Epoch time: 99.14 s 
2025-06-03 11:56:49.757010:  
2025-06-03 11:56:49.770475: Epoch 43 
2025-06-03 11:56:49.780298: Current learning rate: 0.00961 
2025-06-03 11:58:26.837333: train_loss -0.6212 
2025-06-03 11:58:27.178442: val_loss -0.5918 
2025-06-03 11:58:27.525186: Pseudo dice [np.float32(0.6885)] 
2025-06-03 11:58:27.846116: Epoch time: 97.08 s 
2025-06-03 11:58:28.080596: Yayy! New best EMA pseudo Dice: 0.6348000168800354 
2025-06-03 11:58:30.420174:  
2025-06-03 11:58:30.438678: Epoch 44 
2025-06-03 11:58:30.450673: Current learning rate: 0.0096 
2025-06-03 12:00:09.546245: train_loss -0.6169 
2025-06-03 12:00:09.920398: val_loss -0.6204 
2025-06-03 12:00:10.302140: Pseudo dice [np.float32(0.7026)] 
2025-06-03 12:00:10.584265: Epoch time: 99.13 s 
2025-06-03 12:00:10.720316: Yayy! New best EMA pseudo Dice: 0.6416000127792358 
2025-06-03 12:00:13.253768:  
2025-06-03 12:00:13.268539: Epoch 45 
2025-06-03 12:00:13.282486: Current learning rate: 0.00959 
2025-06-03 12:01:51.432497: train_loss -0.6385 
2025-06-03 12:01:51.693007: val_loss -0.5174 
2025-06-03 12:01:51.962291: Pseudo dice [np.float32(0.5448)] 
2025-06-03 12:01:52.511105: Epoch time: 98.18 s 
2025-06-03 12:01:54.297648:  
2025-06-03 12:01:54.310491: Epoch 46 
2025-06-03 12:01:54.324763: Current learning rate: 0.00959 
2025-06-03 12:03:31.782449: train_loss -0.6247 
2025-06-03 12:03:32.132869: val_loss -0.555 
2025-06-03 12:03:32.527277: Pseudo dice [np.float32(0.5245)] 
2025-06-03 12:03:32.854585: Epoch time: 97.49 s 
2025-06-03 12:03:34.898702:  
2025-06-03 12:03:34.909969: Epoch 47 
2025-06-03 12:03:34.919659: Current learning rate: 0.00958 
2025-06-03 12:05:11.414468: train_loss -0.659 
2025-06-03 12:05:11.611483: val_loss -0.5839 
2025-06-03 12:05:11.844806: Pseudo dice [np.float32(0.5607)] 
2025-06-03 12:05:12.130911: Epoch time: 96.52 s 
2025-06-03 12:05:13.663250:  
2025-06-03 12:05:13.680133: Epoch 48 
2025-06-03 12:05:13.693522: Current learning rate: 0.00957 
2025-06-03 12:06:51.616571: train_loss -0.6453 
2025-06-03 12:06:51.635371: val_loss -0.5533 
2025-06-03 12:06:51.648187: Pseudo dice [np.float32(0.5611)] 
2025-06-03 12:06:51.660942: Epoch time: 97.95 s 
2025-06-03 12:06:54.048584:  
2025-06-03 12:06:54.067767: Epoch 49 
2025-06-03 12:06:54.083242: Current learning rate: 0.00956 
2025-06-03 12:08:32.407716: train_loss -0.634 
2025-06-03 12:08:32.725895: val_loss -0.6313 
2025-06-03 12:08:33.083347: Pseudo dice [np.float32(0.6368)] 
2025-06-03 12:08:33.098686: Epoch time: 98.36 s 
2025-06-03 12:08:35.701214:  
2025-06-03 12:08:35.711713: Epoch 50 
2025-06-03 12:08:35.722215: Current learning rate: 0.00955 
2025-06-03 12:10:06.068999: train_loss -0.6009 
2025-06-03 12:10:06.118483: val_loss -0.6269 
2025-06-03 12:10:06.152317: Pseudo dice [np.float32(0.6827)] 
2025-06-03 12:10:06.183843: Epoch time: 90.37 s 
2025-06-03 12:10:07.634150:  
2025-06-03 12:10:07.653460: Epoch 51 
2025-06-03 12:10:07.667553: Current learning rate: 0.00954 
2025-06-03 12:11:27.354151: train_loss -0.6147 
2025-06-03 12:11:27.472983: val_loss -0.6234 
2025-06-03 12:11:27.487797: Pseudo dice [np.float32(0.6975)] 
2025-06-03 12:11:27.501119: Epoch time: 79.72 s 
2025-06-03 12:11:29.603364:  
2025-06-03 12:11:29.615686: Epoch 52 
2025-06-03 12:11:29.625455: Current learning rate: 0.00953 
2025-06-03 12:13:07.718867: train_loss -0.6674 
2025-06-03 12:13:07.740346: val_loss -0.6267 
2025-06-03 12:13:07.753129: Pseudo dice [np.float32(0.6836)] 
2025-06-03 12:13:07.766401: Epoch time: 98.12 s 
2025-06-03 12:13:10.822174:  
2025-06-03 12:13:10.840334: Epoch 53 
2025-06-03 12:13:10.855902: Current learning rate: 0.00952 
2025-06-03 12:14:48.641725: train_loss -0.6472 
2025-06-03 12:14:48.659549: val_loss -0.6177 
2025-06-03 12:14:48.672753: Pseudo dice [np.float32(0.6362)] 
2025-06-03 12:14:48.687048: Epoch time: 97.82 s 
2025-06-03 12:14:50.965820:  
2025-06-03 12:14:50.977327: Epoch 54 
2025-06-03 12:14:50.987815: Current learning rate: 0.00951 
2025-06-03 12:16:27.721994: train_loss -0.6603 
2025-06-03 12:16:27.740127: val_loss -0.6141 
2025-06-03 12:16:27.754450: Pseudo dice [np.float32(0.7373)] 
2025-06-03 12:16:27.766761: Epoch time: 96.76 s 
2025-06-03 12:16:27.779120: Yayy! New best EMA pseudo Dice: 0.6435999870300293 
2025-06-03 12:16:30.961424:  
2025-06-03 12:16:30.979821: Epoch 55 
2025-06-03 12:16:30.994629: Current learning rate: 0.0095 
2025-06-03 12:18:03.791242: train_loss -0.6546 
2025-06-03 12:18:03.923704: val_loss -0.6135 
2025-06-03 12:18:03.944191: Pseudo dice [np.float32(0.6989)] 
2025-06-03 12:18:03.957643: Epoch time: 92.83 s 
2025-06-03 12:18:03.970431: Yayy! New best EMA pseudo Dice: 0.6491000056266785 
2025-06-03 12:18:07.308839:  
2025-06-03 12:18:07.327899: Epoch 56 
2025-06-03 12:18:07.342916: Current learning rate: 0.00949 
2025-06-03 12:19:45.682372: train_loss -0.6167 
2025-06-03 12:19:45.942049: val_loss -0.5914 
2025-06-03 12:19:46.159623: Pseudo dice [np.float32(0.6478)] 
2025-06-03 12:19:46.174858: Epoch time: 98.38 s 
2025-06-03 12:19:48.152314:  
2025-06-03 12:19:48.166508: Epoch 57 
2025-06-03 12:19:48.184183: Current learning rate: 0.00949 
2025-06-03 12:21:24.707323: train_loss -0.626 
2025-06-03 12:21:24.726981: val_loss -0.6031 
2025-06-03 12:21:24.743443: Pseudo dice [np.float32(0.6721)] 
2025-06-03 12:21:24.757697: Epoch time: 96.56 s 
2025-06-03 12:21:24.773030: Yayy! New best EMA pseudo Dice: 0.6513000130653381 
2025-06-03 12:21:27.319723:  
2025-06-03 12:21:27.336559: Epoch 58 
2025-06-03 12:21:27.351059: Current learning rate: 0.00948 
2025-06-03 12:23:05.560464: train_loss -0.6021 
2025-06-03 12:23:05.791557: val_loss -0.6129 
2025-06-03 12:23:05.810328: Pseudo dice [np.float32(0.6201)] 
2025-06-03 12:23:05.822925: Epoch time: 98.24 s 
2025-06-03 12:23:07.853725:  
2025-06-03 12:23:07.872841: Epoch 59 
2025-06-03 12:23:07.893714: Current learning rate: 0.00947 
2025-06-03 12:24:44.504734: train_loss -0.6051 
2025-06-03 12:24:44.525563: val_loss -0.6239 
2025-06-03 12:24:44.541800: Pseudo dice [np.float32(0.6687)] 
2025-06-03 12:24:44.554991: Epoch time: 96.65 s 
2025-06-03 12:24:47.350765:  
2025-06-03 12:24:47.370072: Epoch 60 
2025-06-03 12:24:47.384654: Current learning rate: 0.00946 
2025-06-03 12:26:24.924496: train_loss -0.6279 
2025-06-03 12:26:24.947951: val_loss -0.6031 
2025-06-03 12:26:24.968316: Pseudo dice [np.float32(0.5803)] 
2025-06-03 12:26:24.983152: Epoch time: 97.58 s 
2025-06-03 12:26:27.774319:  
2025-06-03 12:26:27.788231: Epoch 61 
2025-06-03 12:26:27.804590: Current learning rate: 0.00945 
2025-06-03 12:28:03.272209: train_loss -0.6413 
2025-06-03 12:28:03.502192: val_loss -0.6226 
2025-06-03 12:28:03.754056: Pseudo dice [np.float32(0.6474)] 
2025-06-03 12:28:04.015307: Epoch time: 95.5 s 
2025-06-03 12:28:06.118545:  
2025-06-03 12:28:06.134207: Epoch 62 
2025-06-03 12:28:06.147360: Current learning rate: 0.00944 
2025-06-03 12:29:42.548259: train_loss -0.6282 
2025-06-03 12:29:42.779274: val_loss -0.6168 
2025-06-03 12:29:42.795230: Pseudo dice [np.float32(0.7018)] 
2025-06-03 12:29:42.812718: Epoch time: 96.43 s 
2025-06-03 12:29:46.217995:  
2025-06-03 12:29:46.237046: Epoch 63 
2025-06-03 12:29:46.254029: Current learning rate: 0.00943 
2025-06-03 12:31:13.065500: train_loss -0.6226 
2025-06-03 12:31:13.103735: val_loss -0.6153 
2025-06-03 12:31:13.118676: Pseudo dice [np.float32(0.6687)] 
2025-06-03 12:31:13.158877: Epoch time: 86.85 s 
2025-06-03 12:31:13.192514: Yayy! New best EMA pseudo Dice: 0.6514000296592712 
2025-06-03 12:31:14.993594:  
2025-06-03 12:31:15.012471: Epoch 64 
2025-06-03 12:31:15.028161: Current learning rate: 0.00942 
2025-06-03 12:32:38.727231: train_loss -0.6438 
2025-06-03 12:32:38.761126: val_loss -0.5936 
2025-06-03 12:32:38.793000: Pseudo dice [np.float32(0.7172)] 
2025-06-03 12:32:38.824554: Epoch time: 83.74 s 
2025-06-03 12:32:38.856165: Yayy! New best EMA pseudo Dice: 0.6579999923706055 
2025-06-03 12:32:40.908489:  
2025-06-03 12:32:40.923104: Epoch 65 
2025-06-03 12:32:40.939591: Current learning rate: 0.00941 
2025-06-03 12:33:59.864769: train_loss -0.6354 
2025-06-03 12:33:59.898758: val_loss -0.6144 
2025-06-03 12:33:59.919762: Pseudo dice [np.float32(0.7122)] 
2025-06-03 12:33:59.958134: Epoch time: 78.96 s 
2025-06-03 12:34:00.001337: Yayy! New best EMA pseudo Dice: 0.6633999943733215 
2025-06-03 12:34:01.922240:  
2025-06-03 12:34:01.937017: Epoch 66 
2025-06-03 12:34:01.954642: Current learning rate: 0.0094 
2025-06-03 12:35:39.682601: train_loss -0.6362 
2025-06-03 12:35:39.923968: val_loss -0.5953 
2025-06-03 12:35:39.940534: Pseudo dice [np.float32(0.645)] 
2025-06-03 12:35:39.958111: Epoch time: 97.76 s 
2025-06-03 12:35:42.385630:  
2025-06-03 12:35:42.404284: Epoch 67 
2025-06-03 12:35:42.420353: Current learning rate: 0.00939 
2025-06-03 12:37:23.306975: train_loss -0.6619 
2025-06-03 12:37:23.327376: val_loss -0.6795 
2025-06-03 12:37:23.342087: Pseudo dice [np.float32(0.6935)] 
2025-06-03 12:37:23.357299: Epoch time: 100.92 s 
2025-06-03 12:37:23.372573: Yayy! New best EMA pseudo Dice: 0.6647999882698059 
2025-06-03 12:37:26.262967:  
2025-06-03 12:37:26.275870: Epoch 68 
2025-06-03 12:37:26.287709: Current learning rate: 0.00939 
2025-06-03 12:39:05.901316: train_loss -0.6178 
2025-06-03 12:39:06.168686: val_loss -0.628 
2025-06-03 12:39:06.190109: Pseudo dice [np.float32(0.6931)] 
2025-06-03 12:39:06.204939: Epoch time: 99.64 s 
2025-06-03 12:39:06.219678: Yayy! New best EMA pseudo Dice: 0.6675999760627747 
2025-06-03 12:39:09.656995:  
2025-06-03 12:39:09.674147: Epoch 69 
2025-06-03 12:39:09.685688: Current learning rate: 0.00938 
2025-06-03 12:40:48.857189: train_loss -0.631 
2025-06-03 12:40:48.891153: val_loss -0.6282 
2025-06-03 12:40:48.906139: Pseudo dice [np.float32(0.7089)] 
2025-06-03 12:40:48.920773: Epoch time: 99.2 s 
2025-06-03 12:40:48.935562: Yayy! New best EMA pseudo Dice: 0.6717000007629395 
2025-06-03 12:40:52.492624:  
2025-06-03 12:40:52.511087: Epoch 70 
2025-06-03 12:40:52.526502: Current learning rate: 0.00937 
2025-06-03 12:42:30.580823: train_loss -0.6421 
2025-06-03 12:42:30.602770: val_loss -0.6324 
2025-06-03 12:42:30.615513: Pseudo dice [np.float32(0.809)] 
2025-06-03 12:42:30.630818: Epoch time: 98.09 s 
2025-06-03 12:42:30.644607: Yayy! New best EMA pseudo Dice: 0.6855000257492065 
2025-06-03 12:42:37.876575:  
2025-06-03 12:42:38.189411: Epoch 71 
2025-06-03 12:42:38.366293: Current learning rate: 0.00936 
2025-06-03 12:44:16.385658: train_loss -0.6542 
2025-06-03 12:44:16.405858: val_loss -0.6323 
2025-06-03 12:44:16.419173: Pseudo dice [np.float32(0.7542)] 
2025-06-03 12:44:16.434045: Epoch time: 98.51 s 
2025-06-03 12:44:16.448419: Yayy! New best EMA pseudo Dice: 0.692300021648407 
2025-06-03 12:44:20.117002:  
2025-06-03 12:44:20.133120: Epoch 72 
2025-06-03 12:44:20.148716: Current learning rate: 0.00935 
2025-06-03 12:45:57.165076: train_loss -0.6327 
2025-06-03 12:45:57.181026: val_loss -0.6414 
2025-06-03 12:45:57.195379: Pseudo dice [np.float32(0.641)] 
2025-06-03 12:45:57.209232: Epoch time: 97.05 s 
2025-06-03 12:45:58.814107:  
2025-06-03 12:45:58.827009: Epoch 73 
2025-06-03 12:45:58.837757: Current learning rate: 0.00934 
2025-06-03 12:47:33.721474: train_loss -0.6594 
2025-06-03 12:47:33.901560: val_loss -0.5958 
2025-06-03 12:47:33.918946: Pseudo dice [np.float32(0.6685)] 
2025-06-03 12:47:33.933859: Epoch time: 94.91 s 
2025-06-03 12:47:36.599857:  
2025-06-03 12:47:36.619101: Epoch 74 
2025-06-03 12:47:36.630960: Current learning rate: 0.00933 
2025-06-03 12:49:13.067387: train_loss -0.6355 
2025-06-03 12:49:13.258240: val_loss -0.5742 
2025-06-03 12:49:13.507680: Pseudo dice [np.float32(0.5817)] 
2025-06-03 12:49:13.524972: Epoch time: 96.47 s 
2025-06-03 12:49:15.242287:  
2025-06-03 12:49:15.257371: Epoch 75 
2025-06-03 12:49:15.274732: Current learning rate: 0.00932 
2025-06-03 12:50:52.600391: train_loss -0.6317 
2025-06-03 12:50:52.707235: val_loss -0.6435 
2025-06-03 12:50:52.931169: Pseudo dice [np.float32(0.72)] 
2025-06-03 12:50:53.100778: Epoch time: 97.36 s 
2025-06-03 12:50:54.584822:  
2025-06-03 12:50:54.600588: Epoch 76 
2025-06-03 12:50:54.613343: Current learning rate: 0.00931 
2025-06-03 12:52:30.624914: train_loss -0.6329 
2025-06-03 12:52:30.641320: val_loss -0.5906 
2025-06-03 12:52:30.657184: Pseudo dice [np.float32(0.6684)] 
2025-06-03 12:52:30.672028: Epoch time: 96.04 s 
2025-06-03 12:52:32.014084:  
2025-06-03 12:52:32.033593: Epoch 77 
2025-06-03 12:52:32.045019: Current learning rate: 0.0093 
2025-06-03 12:54:08.534462: train_loss -0.6269 
2025-06-03 12:54:08.745485: val_loss -0.5996 
2025-06-03 12:54:08.763440: Pseudo dice [np.float32(0.6315)] 
2025-06-03 12:54:08.779434: Epoch time: 96.52 s 
2025-06-03 12:54:10.579523:  
2025-06-03 12:54:10.598662: Epoch 78 
2025-06-03 12:54:10.616289: Current learning rate: 0.0093 
2025-06-03 12:55:46.884712: train_loss -0.6746 
2025-06-03 12:55:46.900547: val_loss -0.5988 
2025-06-03 12:55:46.914354: Pseudo dice [np.float32(0.5888)] 
2025-06-03 12:55:46.926288: Epoch time: 96.31 s 
2025-06-03 12:55:48.413996:  
2025-06-03 12:55:48.433810: Epoch 79 
2025-06-03 12:55:48.445822: Current learning rate: 0.00929 
2025-06-03 12:57:26.678335: train_loss -0.6065 
2025-06-03 12:57:26.815915: val_loss -0.6679 
2025-06-03 12:57:27.079011: Pseudo dice [np.float32(0.7413)] 
2025-06-03 12:57:27.313780: Epoch time: 98.27 s 
2025-06-03 12:57:28.709145:  
2025-06-03 12:57:28.729786: Epoch 80 
2025-06-03 12:57:28.741583: Current learning rate: 0.00928 
2025-06-03 12:59:06.920445: train_loss -0.6515 
2025-06-03 12:59:06.938303: val_loss -0.648 
2025-06-03 12:59:06.951044: Pseudo dice [np.float32(0.6956)] 
2025-06-03 12:59:06.966311: Epoch time: 98.21 s 
2025-06-03 12:59:08.695935:  
2025-06-03 12:59:08.710781: Epoch 81 
2025-06-03 12:59:08.726689: Current learning rate: 0.00927 
2025-06-03 13:00:45.289495: train_loss -0.6378 
2025-06-03 13:00:45.547806: val_loss -0.6468 
2025-06-03 13:00:45.830817: Pseudo dice [np.float32(0.6956)] 
2025-06-03 13:00:46.020842: Epoch time: 96.6 s 
2025-06-03 13:00:47.257944:  
2025-06-03 13:00:47.280195: Epoch 82 
2025-06-03 13:00:47.297750: Current learning rate: 0.00926 
2025-06-03 13:02:24.526083: train_loss -0.635 
2025-06-03 13:02:24.823381: val_loss -0.6427 
2025-06-03 13:02:25.067079: Pseudo dice [np.float32(0.6952)] 
2025-06-03 13:02:25.418500: Epoch time: 97.27 s 
2025-06-03 13:02:27.036561:  
2025-06-03 13:02:27.048647: Epoch 83 
2025-06-03 13:02:27.061320: Current learning rate: 0.00925 
2025-06-03 13:04:02.450325: train_loss -0.6217 
2025-06-03 13:04:02.727625: val_loss -0.6083 
2025-06-03 13:04:03.002949: Pseudo dice [np.float32(0.6935)] 
2025-06-03 13:04:03.270109: Epoch time: 95.42 s 
2025-06-03 13:04:04.909978:  
2025-06-03 13:04:04.923456: Epoch 84 
2025-06-03 13:04:04.935267: Current learning rate: 0.00924 
2025-06-03 13:05:42.836323: train_loss -0.6495 
2025-06-03 13:05:42.852442: val_loss -0.5935 
2025-06-03 13:05:42.867866: Pseudo dice [np.float32(0.6863)] 
2025-06-03 13:05:42.882685: Epoch time: 97.93 s 
2025-06-03 13:05:44.466079:  
2025-06-03 13:05:44.483423: Epoch 85 
2025-06-03 13:05:44.499283: Current learning rate: 0.00923 
2025-06-03 13:07:21.474516: train_loss -0.6424 
2025-06-03 13:07:21.682823: val_loss -0.7139 
2025-06-03 13:07:21.698251: Pseudo dice [np.float32(0.7787)] 
2025-06-03 13:07:21.713701: Epoch time: 97.01 s 
2025-06-03 13:07:23.171401:  
2025-06-03 13:07:23.190596: Epoch 86 
2025-06-03 13:07:23.205767: Current learning rate: 0.00922 
2025-06-03 13:08:59.897002: train_loss -0.636 
2025-06-03 13:09:00.177891: val_loss -0.6514 
2025-06-03 13:09:00.400266: Pseudo dice [np.float32(0.7598)] 
2025-06-03 13:09:00.567734: Epoch time: 96.73 s 
2025-06-03 13:09:00.613014: Yayy! New best EMA pseudo Dice: 0.697700023651123 
2025-06-03 13:09:02.042222:  
2025-06-03 13:09:02.060696: Epoch 87 
2025-06-03 13:09:02.074557: Current learning rate: 0.00921 
2025-06-03 13:10:39.933296: train_loss -0.6384 
2025-06-03 13:10:40.165286: val_loss -0.6769 
2025-06-03 13:10:40.331393: Pseudo dice [np.float32(0.7284)] 
2025-06-03 13:10:40.349416: Epoch time: 97.89 s 
2025-06-03 13:10:40.364829: Yayy! New best EMA pseudo Dice: 0.7006999850273132 
2025-06-03 13:10:42.057467:  
2025-06-03 13:10:42.072628: Epoch 88 
2025-06-03 13:10:42.088668: Current learning rate: 0.0092 
2025-06-03 13:12:18.369016: train_loss -0.6148 
2025-06-03 13:12:18.393749: val_loss -0.6081 
2025-06-03 13:12:18.503393: Pseudo dice [np.float32(0.66)] 
2025-06-03 13:12:18.731116: Epoch time: 96.31 s 
2025-06-03 13:12:20.685040:  
2025-06-03 13:12:20.706252: Epoch 89 
2025-06-03 13:12:20.719267: Current learning rate: 0.0092 
2025-06-03 13:14:00.141648: train_loss -0.6392 
2025-06-03 13:14:00.378793: val_loss -0.5915 
2025-06-03 13:14:00.566036: Pseudo dice [np.float32(0.6817)] 
2025-06-03 13:14:00.583542: Epoch time: 99.46 s 
2025-06-03 13:14:01.909843:  
2025-06-03 13:14:01.926862: Epoch 90 
2025-06-03 13:14:01.941871: Current learning rate: 0.00919 
2025-06-03 13:15:39.179322: train_loss -0.6811 
2025-06-03 13:15:39.198776: val_loss -0.6161 
2025-06-03 13:15:39.212567: Pseudo dice [np.float32(0.6853)] 
2025-06-03 13:15:39.227963: Epoch time: 97.27 s 
2025-06-03 13:15:41.075333:  
2025-06-03 13:15:41.094642: Epoch 91 
2025-06-03 13:15:41.110944: Current learning rate: 0.00918 
2025-06-03 13:17:19.016580: train_loss -0.6822 
2025-06-03 13:17:19.541388: val_loss -0.6622 
2025-06-03 13:17:19.875517: Pseudo dice [np.float32(0.7831)] 
2025-06-03 13:17:19.963165: Epoch time: 97.94 s 
2025-06-03 13:17:20.026082: Yayy! New best EMA pseudo Dice: 0.7031000256538391 
2025-06-03 13:17:21.487007:  
2025-06-03 13:17:21.504664: Epoch 92 
2025-06-03 13:17:21.518865: Current learning rate: 0.00917 
2025-06-03 13:18:59.705526: train_loss -0.6688 
2025-06-03 13:18:59.923734: val_loss -0.6395 
2025-06-03 13:19:00.095219: Pseudo dice [np.float32(0.6593)] 
2025-06-03 13:19:00.264981: Epoch time: 98.22 s 
2025-06-03 13:19:01.415751:  
2025-06-03 13:19:01.429825: Epoch 93 
2025-06-03 13:19:01.447036: Current learning rate: 0.00916 
2025-06-03 13:20:40.465947: train_loss -0.6485 
2025-06-03 13:20:40.652246: val_loss -0.6578 
2025-06-03 13:20:40.834460: Pseudo dice [np.float32(0.7338)] 
2025-06-03 13:20:40.984400: Epoch time: 99.05 s 
2025-06-03 13:20:42.128147:  
2025-06-03 13:20:42.141956: Epoch 94 
2025-06-03 13:20:42.153187: Current learning rate: 0.00915 
2025-06-03 13:22:19.302124: train_loss -0.6491 
2025-06-03 13:22:19.463439: val_loss -0.6447 
2025-06-03 13:22:19.759072: Pseudo dice [np.float32(0.6983)] 
2025-06-03 13:22:19.942687: Epoch time: 97.18 s 
2025-06-03 13:22:21.113982:  
2025-06-03 13:22:21.134129: Epoch 95 
2025-06-03 13:22:21.148674: Current learning rate: 0.00914 
2025-06-03 13:24:01.414661: train_loss -0.6512 
2025-06-03 13:24:01.571302: val_loss -0.6102 
2025-06-03 13:24:01.739589: Pseudo dice [np.float32(0.6944)] 
2025-06-03 13:24:01.928478: Epoch time: 100.3 s 
2025-06-03 13:24:03.167169:  
2025-06-03 13:24:03.185089: Epoch 96 
2025-06-03 13:24:03.199920: Current learning rate: 0.00913 
2025-06-03 13:25:39.352508: train_loss -0.6611 
2025-06-03 13:25:39.370894: val_loss -0.64 
2025-06-03 13:25:39.386742: Pseudo dice [np.float32(0.6614)] 
2025-06-03 13:25:39.423287: Epoch time: 96.19 s 
2025-06-03 13:25:41.537623:  
2025-06-03 13:25:41.550251: Epoch 97 
2025-06-03 13:25:41.561950: Current learning rate: 0.00912 
2025-06-03 13:27:19.789798: train_loss -0.6545 
2025-06-03 13:27:20.067706: val_loss -0.6388 
2025-06-03 13:27:20.528673: Pseudo dice [np.float32(0.681)] 
2025-06-03 13:27:20.545740: Epoch time: 98.25 s 
2025-06-03 13:27:22.143316:  
2025-06-03 13:27:22.154530: Epoch 98 
2025-06-03 13:27:22.166941: Current learning rate: 0.00911 
2025-06-03 13:28:59.347100: train_loss -0.6478 
2025-06-03 13:28:59.593534: val_loss -0.6408 
2025-06-03 13:28:59.739559: Pseudo dice [np.float32(0.6528)] 
2025-06-03 13:28:59.755071: Epoch time: 97.21 s 
2025-06-03 13:29:01.016188:  
2025-06-03 13:29:01.033793: Epoch 99 
2025-06-03 13:29:01.045701: Current learning rate: 0.0091 
2025-06-03 13:30:37.055650: train_loss -0.6376 
2025-06-03 13:30:37.074579: val_loss -0.539 
2025-06-03 13:30:37.090980: Pseudo dice [np.float32(0.5393)] 
2025-06-03 13:30:37.104758: Epoch time: 96.04 s 
2025-06-03 13:30:39.457437:  
2025-06-03 13:30:39.471150: Epoch 100 
2025-06-03 13:30:39.488506: Current learning rate: 0.0091 
2025-06-03 13:32:17.238436: train_loss -0.6203 
2025-06-03 13:32:17.513934: val_loss -0.6041 
2025-06-03 13:32:17.778207: Pseudo dice [np.float32(0.681)] 
2025-06-03 13:32:17.943382: Epoch time: 97.78 s 
2025-06-03 13:32:19.052530:  
2025-06-03 13:32:19.065756: Epoch 101 
2025-06-03 13:32:19.077358: Current learning rate: 0.00909 
2025-06-03 13:33:52.704900: train_loss -0.6501 
2025-06-03 13:33:52.807075: val_loss -0.6047 
2025-06-03 13:33:53.002941: Pseudo dice [np.float32(0.6722)] 
2025-06-03 13:33:53.259506: Epoch time: 93.65 s 
2025-06-03 13:33:57.697627:  
2025-06-03 13:33:57.919318: Epoch 102 
2025-06-03 13:33:58.065530: Current learning rate: 0.00908 
2025-06-03 13:35:34.569200: train_loss -0.6537 
2025-06-03 13:35:34.595753: val_loss -0.6627 
2025-06-03 13:35:34.792959: Pseudo dice [np.float32(0.749)] 
2025-06-03 13:35:35.003960: Epoch time: 96.87 s 
2025-06-03 13:35:37.957783:  
2025-06-03 13:35:37.975059: Epoch 103 
2025-06-03 13:35:37.989886: Current learning rate: 0.00907 
2025-06-03 13:37:15.084016: train_loss -0.659 
2025-06-03 13:37:15.371356: val_loss -0.5792 
2025-06-03 13:37:15.653275: Pseudo dice [np.float32(0.6328)] 
2025-06-03 13:37:15.877463: Epoch time: 97.13 s 
2025-06-03 13:37:17.619408:  
2025-06-03 13:37:17.640617: Epoch 104 
2025-06-03 13:37:17.658060: Current learning rate: 0.00906 
2025-06-03 13:38:55.412285: train_loss -0.6563 
2025-06-03 13:38:55.815568: val_loss -0.6038 
2025-06-03 13:38:56.204222: Pseudo dice [np.float32(0.6647)] 
2025-06-03 13:38:56.363089: Epoch time: 97.79 s 
2025-06-03 13:38:57.429632:  
2025-06-03 13:38:57.443612: Epoch 105 
2025-06-03 13:38:57.459749: Current learning rate: 0.00905 
2025-06-03 13:40:37.171176: train_loss -0.6683 
2025-06-03 13:40:37.190124: val_loss -0.655 
2025-06-03 13:40:37.204443: Pseudo dice [np.float32(0.6738)] 
2025-06-03 13:40:37.219779: Epoch time: 99.74 s 
2025-06-03 13:40:39.149793:  
2025-06-03 13:40:39.163010: Epoch 106 
2025-06-03 13:40:39.174036: Current learning rate: 0.00904 
2025-06-03 13:42:16.393498: train_loss -0.6284 
2025-06-03 13:42:16.556515: val_loss -0.6386 
2025-06-03 13:42:16.751612: Pseudo dice [np.float32(0.6728)] 
2025-06-03 13:42:17.005368: Epoch time: 97.24 s 
2025-06-03 13:42:18.241414:  
2025-06-03 13:42:18.258047: Epoch 107 
2025-06-03 13:42:18.268435: Current learning rate: 0.00903 
2025-06-03 13:43:54.793417: train_loss -0.6808 
2025-06-03 13:43:54.815398: val_loss -0.6279 
2025-06-03 13:43:54.831332: Pseudo dice [np.float32(0.6883)] 
2025-06-03 13:43:54.846990: Epoch time: 96.55 s 
2025-06-03 13:43:57.574113:  
2025-06-03 13:43:57.587710: Epoch 108 
2025-06-03 13:43:57.597768: Current learning rate: 0.00902 
2025-06-03 13:45:34.655925: train_loss -0.6324 
2025-06-03 13:45:34.901380: val_loss -0.7012 
2025-06-03 13:45:35.057586: Pseudo dice [np.float32(0.7642)] 
2025-06-03 13:45:35.375632: Epoch time: 97.08 s 
2025-06-03 13:45:36.826112:  
2025-06-03 13:45:36.839755: Epoch 109 
2025-06-03 13:45:36.852338: Current learning rate: 0.00901 
2025-06-03 13:47:15.660917: train_loss -0.6641 
2025-06-03 13:47:15.678390: val_loss -0.6392 
2025-06-03 13:47:15.693273: Pseudo dice [np.float32(0.6206)] 
2025-06-03 13:47:15.708283: Epoch time: 98.84 s 
2025-06-03 13:47:17.611279:  
2025-06-03 13:47:17.624184: Epoch 110 
2025-06-03 13:47:17.634531: Current learning rate: 0.009 
2025-06-03 13:48:54.717343: train_loss -0.6724 
2025-06-03 13:48:55.011183: val_loss -0.6313 
2025-06-03 13:48:55.260891: Pseudo dice [np.float32(0.7164)] 
2025-06-03 13:48:55.458949: Epoch time: 97.11 s 
2025-06-03 13:48:56.592602:  
2025-06-03 13:48:56.605862: Epoch 111 
2025-06-03 13:48:56.615604: Current learning rate: 0.009 
2025-06-03 13:50:36.876657: train_loss -0.6298 
2025-06-03 13:50:36.965626: val_loss -0.5615 
2025-06-03 13:50:36.983180: Pseudo dice [np.float32(0.5618)] 
2025-06-03 13:50:36.998011: Epoch time: 100.29 s 
2025-06-03 13:50:38.693283:  
2025-06-03 13:50:38.706725: Epoch 112 
2025-06-03 13:50:38.718750: Current learning rate: 0.00899 
2025-06-03 13:52:17.582218: train_loss -0.6618 
2025-06-03 13:52:17.598072: val_loss -0.6421 
2025-06-03 13:52:17.612350: Pseudo dice [np.float32(0.7044)] 
2025-06-03 13:52:17.628641: Epoch time: 98.89 s 
2025-06-03 13:52:19.014063:  
2025-06-03 13:52:19.030505: Epoch 113 
2025-06-03 13:52:19.043555: Current learning rate: 0.00898 
2025-06-03 13:53:56.905012: train_loss -0.6386 
2025-06-03 13:53:56.925985: val_loss -0.6601 
2025-06-03 13:53:56.939289: Pseudo dice [np.float32(0.7383)] 
2025-06-03 13:53:56.951589: Epoch time: 97.89 s 
2025-06-03 13:53:59.029262:  
2025-06-03 13:53:59.074349: Epoch 114 
2025-06-03 13:53:59.085811: Current learning rate: 0.00897 
2025-06-03 13:55:35.806733: train_loss -0.6351 
2025-06-03 13:55:36.163841: val_loss -0.5844 
2025-06-03 13:55:36.399736: Pseudo dice [np.float32(0.6336)] 
2025-06-03 13:55:36.630043: Epoch time: 96.78 s 
2025-06-03 13:55:37.686516:  
2025-06-03 13:55:37.702868: Epoch 115 
2025-06-03 13:55:37.719982: Current learning rate: 0.00896 
2025-06-03 13:57:19.641576: train_loss -0.6314 
2025-06-03 13:57:19.658604: val_loss -0.6032 
2025-06-03 13:57:19.673129: Pseudo dice [np.float32(0.6951)] 
2025-06-03 13:57:19.687595: Epoch time: 101.96 s 
2025-06-03 13:57:21.324256:  
2025-06-03 13:57:21.335753: Epoch 116 
2025-06-03 13:57:21.347768: Current learning rate: 0.00895 
2025-06-03 13:58:58.674756: train_loss -0.6871 
2025-06-03 13:58:59.152153: val_loss -0.676 
2025-06-03 13:58:59.419303: Pseudo dice [np.float32(0.7455)] 
2025-06-03 13:58:59.705859: Epoch time: 97.35 s 
2025-06-03 13:59:00.926326:  
2025-06-03 13:59:00.946505: Epoch 117 
2025-06-03 13:59:00.962310: Current learning rate: 0.00894 
2025-06-03 14:00:40.944489: train_loss -0.6626 
2025-06-03 14:00:40.960960: val_loss -0.6709 
2025-06-03 14:00:40.976380: Pseudo dice [np.float32(0.8325)] 
2025-06-03 14:00:40.991835: Epoch time: 100.02 s 
2025-06-03 14:00:42.707521:  
2025-06-03 14:00:42.720838: Epoch 118 
2025-06-03 14:00:42.738088: Current learning rate: 0.00893 
2025-06-03 14:02:20.429443: train_loss -0.656 
2025-06-03 14:02:20.448968: val_loss -0.6761 
2025-06-03 14:02:20.464812: Pseudo dice [np.float32(0.7416)] 
2025-06-03 14:02:20.480666: Epoch time: 97.72 s 
2025-06-03 14:02:20.495564: Yayy! New best EMA pseudo Dice: 0.7037000060081482 
2025-06-03 14:02:22.583550:  
2025-06-03 14:02:22.596357: Epoch 119 
2025-06-03 14:02:22.608821: Current learning rate: 0.00892 
2025-06-03 14:04:03.663848: train_loss -0.6503 
2025-06-03 14:04:03.838286: val_loss -0.5622 
2025-06-03 14:04:04.036369: Pseudo dice [np.float32(0.6259)] 
2025-06-03 14:04:04.341758: Epoch time: 101.08 s 
2025-06-03 14:04:05.779871:  
2025-06-03 14:04:05.798509: Epoch 120 
2025-06-03 14:04:05.811161: Current learning rate: 0.00891 
2025-06-03 14:05:42.718803: train_loss -0.6438 
2025-06-03 14:05:42.897647: val_loss -0.5957 
2025-06-03 14:05:43.224795: Pseudo dice [np.float32(0.5995)] 
2025-06-03 14:05:43.490199: Epoch time: 96.94 s 
2025-06-03 14:05:45.474016:  
2025-06-03 14:05:45.487383: Epoch 121 
2025-06-03 14:05:45.498367: Current learning rate: 0.0089 
2025-06-03 14:07:21.982738: train_loss -0.6164 
2025-06-03 14:07:22.280653: val_loss -0.652 
2025-06-03 14:07:22.507951: Pseudo dice [np.float32(0.7581)] 
2025-06-03 14:07:22.773373: Epoch time: 96.51 s 
2025-06-03 14:07:24.899261:  
2025-06-03 14:07:24.910899: Epoch 122 
2025-06-03 14:07:24.923450: Current learning rate: 0.00889 
2025-06-03 14:09:01.772559: train_loss -0.6344 
2025-06-03 14:09:02.058929: val_loss -0.6405 
2025-06-03 14:09:02.627535: Pseudo dice [np.float32(0.6988)] 
2025-06-03 14:09:02.852507: Epoch time: 96.87 s 
2025-06-03 14:09:04.066990:  
2025-06-03 14:09:04.083258: Epoch 123 
2025-06-03 14:09:04.094813: Current learning rate: 0.00889 
2025-06-03 14:10:41.063676: train_loss -0.6749 
2025-06-03 14:10:41.150162: val_loss -0.6332 
2025-06-03 14:10:41.168094: Pseudo dice [np.float32(0.6664)] 
2025-06-03 14:10:41.184950: Epoch time: 97.0 s 
2025-06-03 14:10:43.182741:  
2025-06-03 14:10:43.193108: Epoch 124 
2025-06-03 14:10:43.212009: Current learning rate: 0.00888 
2025-06-03 14:12:19.911126: train_loss -0.6455 
2025-06-03 14:12:20.150755: val_loss -0.5877 
2025-06-03 14:12:20.437631: Pseudo dice [np.float32(0.6374)] 
2025-06-03 14:12:20.628130: Epoch time: 96.73 s 
2025-06-03 14:12:21.856155:  
2025-06-03 14:12:21.876504: Epoch 125 
2025-06-03 14:12:21.890728: Current learning rate: 0.00887 
2025-06-03 14:13:58.738622: train_loss -0.667 
2025-06-03 14:13:58.757166: val_loss -0.6391 
2025-06-03 14:13:58.771154: Pseudo dice [np.float32(0.736)] 
2025-06-03 14:13:58.786550: Epoch time: 96.89 s 
2025-06-03 14:14:00.472926:  
2025-06-03 14:14:00.483788: Epoch 126 
2025-06-03 14:14:00.494602: Current learning rate: 0.00886 
2025-06-03 14:15:38.944368: train_loss -0.6653 
2025-06-03 14:15:39.157043: val_loss -0.6665 
2025-06-03 14:15:39.513207: Pseudo dice [np.float32(0.7114)] 
2025-06-03 14:15:39.679499: Epoch time: 98.47 s 
2025-06-03 14:15:41.262358:  
2025-06-03 14:15:41.277483: Epoch 127 
2025-06-03 14:15:41.288496: Current learning rate: 0.00885 
2025-06-03 14:17:16.361888: train_loss -0.6369 
2025-06-03 14:17:16.509894: val_loss -0.6791 
2025-06-03 14:17:16.709223: Pseudo dice [np.float32(0.7654)] 
2025-06-03 14:17:16.816875: Epoch time: 95.1 s 
2025-06-03 14:17:17.927518:  
2025-06-03 14:17:17.944584: Epoch 128 
2025-06-03 14:17:17.958689: Current learning rate: 0.00884 
2025-06-03 14:18:54.212256: train_loss -0.6634 
2025-06-03 14:18:54.508100: val_loss -0.6224 
2025-06-03 14:18:54.807355: Pseudo dice [np.float32(0.65)] 
2025-06-03 14:18:55.063227: Epoch time: 96.29 s 
2025-06-03 14:18:56.760627:  
2025-06-03 14:18:56.776652: Epoch 129 
2025-06-03 14:18:56.790759: Current learning rate: 0.00883 
2025-06-03 14:20:33.922177: train_loss -0.6427 
2025-06-03 14:20:34.016531: val_loss -0.7277 
2025-06-03 14:20:34.168280: Pseudo dice [np.float32(0.7732)] 
2025-06-03 14:20:34.371855: Epoch time: 97.16 s 
2025-06-03 14:20:35.757902:  
2025-06-03 14:20:35.775592: Epoch 130 
2025-06-03 14:20:35.792125: Current learning rate: 0.00882 
2025-06-03 14:22:14.991661: train_loss -0.6684 
2025-06-03 14:22:15.133277: val_loss -0.6506 
2025-06-03 14:22:15.314704: Pseudo dice [np.float32(0.6294)] 
2025-06-03 14:22:15.668675: Epoch time: 99.23 s 
2025-06-03 14:22:16.911269:  
2025-06-03 14:22:16.926865: Epoch 131 
2025-06-03 14:22:16.943904: Current learning rate: 0.00881 
2025-06-03 14:23:52.641923: train_loss -0.6497 
2025-06-03 14:23:52.663408: val_loss -0.6686 
2025-06-03 14:23:52.678702: Pseudo dice [np.float32(0.6836)] 
2025-06-03 14:23:52.694509: Epoch time: 95.73 s 
2025-06-03 14:23:54.657957:  
2025-06-03 14:23:54.674967: Epoch 132 
2025-06-03 14:23:54.686424: Current learning rate: 0.0088 
2025-06-03 14:25:33.534124: train_loss -0.6544 
2025-06-03 14:25:33.762573: val_loss -0.6232 
2025-06-03 14:25:34.069240: Pseudo dice [np.float32(0.6795)] 
2025-06-03 14:25:34.345245: Epoch time: 98.88 s 
2025-06-03 14:25:36.373634:  
2025-06-03 14:25:36.385457: Epoch 133 
2025-06-03 14:25:36.398238: Current learning rate: 0.00879 
2025-06-03 14:27:11.873556: train_loss -0.6706 
2025-06-03 14:27:12.019614: val_loss -0.5385 
2025-06-03 14:27:12.265821: Pseudo dice [np.float32(0.6328)] 
2025-06-03 14:27:12.526104: Epoch time: 95.5 s 
2025-06-03 14:27:13.820089:  
2025-06-03 14:27:13.829818: Epoch 134 
2025-06-03 14:27:13.841151: Current learning rate: 0.00879 
2025-06-03 14:28:49.528620: train_loss -0.647 
2025-06-03 14:28:49.719771: val_loss -0.6756 
2025-06-03 14:28:49.737680: Pseudo dice [np.float32(0.6708)] 
2025-06-03 14:28:49.751971: Epoch time: 95.71 s 
2025-06-03 14:28:51.494837:  
2025-06-03 14:28:51.513288: Epoch 135 
2025-06-03 14:28:51.531831: Current learning rate: 0.00878 
2025-06-03 14:30:30.708290: train_loss -0.6732 
2025-06-03 14:30:30.858322: val_loss -0.6312 
2025-06-03 14:30:31.119935: Pseudo dice [np.float32(0.6449)] 
2025-06-03 14:30:31.312449: Epoch time: 99.22 s 
2025-06-03 14:30:32.436220:  
2025-06-03 14:30:32.456122: Epoch 136 
2025-06-03 14:30:32.473569: Current learning rate: 0.00877 
2025-06-03 14:32:10.666658: train_loss -0.6385 
2025-06-03 14:32:10.687079: val_loss -0.6253 
2025-06-03 14:32:10.702964: Pseudo dice [np.float32(0.7024)] 
2025-06-03 14:32:10.720800: Epoch time: 98.23 s 
2025-06-03 14:32:12.409917:  
2025-06-03 14:32:12.424851: Epoch 137 
2025-06-03 14:32:12.441102: Current learning rate: 0.00876 
2025-06-03 14:33:50.397953: train_loss -0.6595 
2025-06-03 14:33:50.463185: val_loss -0.6384 
2025-06-03 14:33:50.692200: Pseudo dice [np.float32(0.6984)] 
2025-06-03 14:33:50.893524: Epoch time: 97.99 s 
2025-06-03 14:33:52.317949:  
2025-06-03 14:33:52.338650: Epoch 138 
2025-06-03 14:33:52.354150: Current learning rate: 0.00875 
2025-06-03 14:35:26.622121: train_loss -0.6418 
2025-06-03 14:35:26.928035: val_loss -0.5569 
2025-06-03 14:35:27.161597: Pseudo dice [np.float32(0.5856)] 
2025-06-03 14:35:27.375849: Epoch time: 94.3 s 
2025-06-03 14:35:28.682555:  
2025-06-03 14:35:28.696384: Epoch 139 
2025-06-03 14:35:28.706721: Current learning rate: 0.00874 
2025-06-03 14:37:06.464414: train_loss -0.6685 
2025-06-03 14:37:06.564072: val_loss -0.63 
2025-06-03 14:37:06.580083: Pseudo dice [np.float32(0.7704)] 
2025-06-03 14:37:06.596534: Epoch time: 97.78 s 
2025-06-03 14:37:08.216234:  
2025-06-03 14:37:08.237162: Epoch 140 
2025-06-03 14:37:08.255649: Current learning rate: 0.00873 
2025-06-03 14:38:46.980264: train_loss -0.6781 
2025-06-03 14:38:47.267550: val_loss -0.6769 
2025-06-03 14:38:47.522115: Pseudo dice [np.float32(0.7711)] 
2025-06-03 14:38:47.685941: Epoch time: 98.77 s 
2025-06-03 14:38:49.002745:  
2025-06-03 14:38:49.017223: Epoch 141 
2025-06-03 14:38:49.035571: Current learning rate: 0.00872 
2025-06-03 14:40:25.652765: train_loss -0.6655 
2025-06-03 14:40:25.671674: val_loss -0.6359 
2025-06-03 14:40:25.686972: Pseudo dice [np.float32(0.709)] 
2025-06-03 14:40:25.702312: Epoch time: 96.65 s 
2025-06-03 14:40:27.530825:  
2025-06-03 14:40:27.548309: Epoch 142 
2025-06-03 14:40:27.560683: Current learning rate: 0.00871 
2025-06-03 14:42:06.390424: train_loss -0.6654 
2025-06-03 14:42:06.411136: val_loss -0.6866 
2025-06-03 14:42:06.425846: Pseudo dice [np.float32(0.7588)] 
2025-06-03 14:42:06.443969: Epoch time: 98.86 s 
2025-06-03 14:42:07.902595:  
2025-06-03 14:42:07.919860: Epoch 143 
2025-06-03 14:42:07.937930: Current learning rate: 0.0087 
2025-06-03 14:43:47.181843: train_loss -0.6261 
2025-06-03 14:43:47.200337: val_loss -0.6219 
2025-06-03 14:43:47.215739: Pseudo dice [np.float32(0.6015)] 
2025-06-03 14:43:47.233087: Epoch time: 99.28 s 
2025-06-03 14:43:49.114902:  
2025-06-03 14:43:49.130318: Epoch 144 
2025-06-03 14:43:49.147459: Current learning rate: 0.00869 
2025-06-03 14:45:28.581468: train_loss -0.6434 
2025-06-03 14:45:28.736105: val_loss -0.6292 
2025-06-03 14:45:28.890753: Pseudo dice [np.float32(0.6848)] 
2025-06-03 14:45:29.014051: Epoch time: 99.47 s 
2025-06-03 14:45:30.932336:  
2025-06-03 14:45:30.945539: Epoch 145 
2025-06-03 14:45:30.956095: Current learning rate: 0.00868 
2025-06-03 14:47:07.556246: train_loss -0.6607 
2025-06-03 14:47:07.572917: val_loss -0.6181 
2025-06-03 14:47:07.585759: Pseudo dice [np.float32(0.6087)] 
2025-06-03 14:47:07.603104: Epoch time: 96.63 s 
2025-06-03 14:47:09.331704:  
2025-06-03 14:47:09.343441: Epoch 146 
2025-06-03 14:47:09.353639: Current learning rate: 0.00868 
2025-06-03 14:48:46.325765: train_loss -0.6753 
2025-06-03 14:48:46.518996: val_loss -0.6607 
2025-06-03 14:48:46.753776: Pseudo dice [np.float32(0.7326)] 
2025-06-03 14:48:47.014128: Epoch time: 97.0 s 
2025-06-03 14:48:48.429213:  
2025-06-03 14:48:48.444745: Epoch 147 
2025-06-03 14:48:48.464628: Current learning rate: 0.00867 
2025-06-03 14:50:30.052123: train_loss -0.6403 
2025-06-03 14:50:30.216637: val_loss -0.6786 
2025-06-03 14:50:30.386653: Pseudo dice [np.float32(0.7049)] 
2025-06-03 14:50:30.530110: Epoch time: 101.62 s 
2025-06-03 14:50:31.672276:  
2025-06-03 14:50:31.690192: Epoch 148 
2025-06-03 14:50:31.704424: Current learning rate: 0.00866 
2025-06-03 14:52:09.238848: train_loss -0.6846 
2025-06-03 14:52:09.256243: val_loss -0.5892 
2025-06-03 14:52:09.270077: Pseudo dice [np.float32(0.5721)] 
2025-06-03 14:52:09.285451: Epoch time: 97.57 s 
2025-06-03 14:52:11.043434:  
2025-06-03 14:52:11.058275: Epoch 149 
2025-06-03 14:52:11.075644: Current learning rate: 0.00865 
2025-06-03 14:53:48.385775: train_loss -0.6741 
2025-06-03 14:53:48.661362: val_loss -0.6007 
2025-06-03 14:53:49.107157: Pseudo dice [np.float32(0.6343)] 
2025-06-03 14:53:49.303491: Epoch time: 97.34 s 
2025-06-03 14:53:51.140806:  
2025-06-03 14:53:51.156179: Epoch 150 
2025-06-03 14:53:51.173870: Current learning rate: 0.00864 
2025-06-03 14:55:29.139108: train_loss -0.6454 
2025-06-03 14:55:29.156543: val_loss -0.675 
2025-06-03 14:55:29.170463: Pseudo dice [np.float32(0.7094)] 
2025-06-03 14:55:29.184319: Epoch time: 98.0 s 
2025-06-03 14:55:30.679154:  
2025-06-03 14:55:30.692809: Epoch 151 
2025-06-03 14:55:30.706182: Current learning rate: 0.00863 
2025-06-03 14:57:09.390872: train_loss -0.6636 
2025-06-03 14:57:09.577172: val_loss -0.6474 
2025-06-03 14:57:09.596107: Pseudo dice [np.float32(0.7097)] 
2025-06-03 14:57:09.614634: Epoch time: 98.71 s 
2025-06-03 14:57:11.369355:  
2025-06-03 14:57:11.384301: Epoch 152 
2025-06-03 14:57:11.395519: Current learning rate: 0.00862 
2025-06-03 14:58:49.847907: train_loss -0.6734 
2025-06-03 14:58:49.871990: val_loss -0.6251 
2025-06-03 14:58:49.888991: Pseudo dice [np.float32(0.6744)] 
2025-06-03 14:58:49.905181: Epoch time: 98.48 s 
2025-06-03 14:58:51.696599:  
2025-06-03 14:58:51.709568: Epoch 153 
2025-06-03 14:58:51.721569: Current learning rate: 0.00861 
2025-06-03 15:00:28.317363: train_loss -0.6658 
2025-06-03 15:00:28.339319: val_loss -0.6289 
2025-06-03 15:00:28.355654: Pseudo dice [np.float32(0.7691)] 
2025-06-03 15:00:28.372622: Epoch time: 96.62 s 
2025-06-03 15:00:30.888069:  
2025-06-03 15:00:30.906749: Epoch 154 
2025-06-03 15:00:30.919255: Current learning rate: 0.0086 
2025-06-03 15:02:11.063611: train_loss -0.6587 
2025-06-03 15:02:11.334263: val_loss -0.6109 
2025-06-03 15:02:11.570516: Pseudo dice [np.float32(0.6214)] 
2025-06-03 15:02:11.801277: Epoch time: 100.18 s 
2025-06-03 15:02:12.993853:  
2025-06-03 15:02:13.009301: Epoch 155 
2025-06-03 15:02:13.024085: Current learning rate: 0.00859 
2025-06-03 15:03:48.627029: train_loss -0.6684 
2025-06-03 15:03:48.869747: val_loss -0.6737 
2025-06-03 15:03:49.090927: Pseudo dice [np.float32(0.7087)] 
2025-06-03 15:03:49.304832: Epoch time: 95.63 s 
2025-06-03 15:03:50.685532:  
2025-06-03 15:03:50.707890: Epoch 156 
2025-06-03 15:03:50.723448: Current learning rate: 0.00858 
2025-06-03 15:05:29.003634: train_loss -0.6717 
2025-06-03 15:05:29.164221: val_loss -0.6959 
2025-06-03 15:05:29.326871: Pseudo dice [np.float32(0.7188)] 
2025-06-03 15:05:29.491215: Epoch time: 98.32 s 
2025-06-03 15:05:30.638156:  
2025-06-03 15:05:30.655119: Epoch 157 
2025-06-03 15:05:30.667954: Current learning rate: 0.00858 
2025-06-03 15:07:09.890445: train_loss -0.6442 
2025-06-03 15:07:09.910105: val_loss -0.6159 
2025-06-03 15:07:09.927820: Pseudo dice [np.float32(0.7014)] 
2025-06-03 15:07:10.081491: Epoch time: 99.25 s 
2025-06-03 15:07:11.467551:  
2025-06-03 15:07:11.485767: Epoch 158 
2025-06-03 15:07:11.500194: Current learning rate: 0.00857 
2025-06-03 15:08:49.418669: train_loss -0.6684 
2025-06-03 15:08:49.440322: val_loss -0.6481 
2025-06-03 15:08:49.455812: Pseudo dice [np.float32(0.7659)] 
2025-06-03 15:08:49.469236: Epoch time: 97.95 s 
2025-06-03 15:08:51.149917:  
2025-06-03 15:08:51.172977: Epoch 159 
2025-06-03 15:08:51.191347: Current learning rate: 0.00856 
2025-06-03 15:10:28.177557: train_loss -0.6613 
2025-06-03 15:10:28.412776: val_loss -0.6757 
2025-06-03 15:10:28.599119: Pseudo dice [np.float32(0.7231)] 
2025-06-03 15:10:28.704461: Epoch time: 97.03 s 
2025-06-03 15:10:29.910782:  
2025-06-03 15:10:29.925005: Epoch 160 
2025-06-03 15:10:29.948827: Current learning rate: 0.00855 
2025-06-03 15:12:06.300151: train_loss -0.648 
2025-06-03 15:12:06.599391: val_loss -0.6739 
2025-06-03 15:12:06.823498: Pseudo dice [np.float32(0.7881)] 
2025-06-03 15:12:07.084159: Epoch time: 96.39 s 
2025-06-03 15:12:07.286062: Yayy! New best EMA pseudo Dice: 0.7084000110626221 
2025-06-03 15:12:09.661636:  
2025-06-03 15:12:09.673187: Epoch 161 
2025-06-03 15:12:09.685798: Current learning rate: 0.00854 
2025-06-03 15:13:47.994281: train_loss -0.6634 
2025-06-03 15:13:48.144164: val_loss -0.6512 
2025-06-03 15:13:48.361070: Pseudo dice [np.float32(0.6834)] 
2025-06-03 15:13:48.477114: Epoch time: 98.33 s 
2025-06-03 15:13:49.726217:  
2025-06-03 15:13:49.745442: Epoch 162 
2025-06-03 15:13:49.764721: Current learning rate: 0.00853 
2025-06-03 15:15:26.259756: train_loss -0.6488 
2025-06-03 15:15:26.277597: val_loss -0.6765 
2025-06-03 15:15:26.481436: Pseudo dice [np.float32(0.7621)] 
2025-06-03 15:15:26.710629: Epoch time: 96.54 s 
2025-06-03 15:15:26.900758: Yayy! New best EMA pseudo Dice: 0.7114999890327454 
2025-06-03 15:15:28.693436:  
2025-06-03 15:15:28.717536: Epoch 163 
2025-06-03 15:15:28.730992: Current learning rate: 0.00852 
2025-06-03 15:17:07.063303: train_loss -0.6633 
2025-06-03 15:17:07.201736: val_loss -0.6635 
2025-06-03 15:17:07.378232: Pseudo dice [np.float32(0.6712)] 
2025-06-03 15:17:07.512067: Epoch time: 98.37 s 
2025-06-03 15:17:08.870704:  
2025-06-03 15:17:08.889410: Epoch 164 
2025-06-03 15:17:08.909025: Current learning rate: 0.00851 
2025-06-03 15:18:47.499997: train_loss -0.6281 
2025-06-03 15:18:47.691380: val_loss -0.5826 
2025-06-03 15:18:47.870119: Pseudo dice [np.float32(0.6492)] 
2025-06-03 15:18:48.017314: Epoch time: 98.63 s 
2025-06-03 15:18:49.160788:  
2025-06-03 15:18:49.179610: Epoch 165 
2025-06-03 15:18:49.201592: Current learning rate: 0.0085 
2025-06-03 15:20:26.466179: train_loss -0.6693 
2025-06-03 15:20:26.722361: val_loss -0.6508 
2025-06-03 15:20:26.959615: Pseudo dice [np.float32(0.7088)] 
2025-06-03 15:20:27.121171: Epoch time: 97.31 s 
2025-06-03 15:20:28.466905:  
2025-06-03 15:20:28.483995: Epoch 166 
2025-06-03 15:20:28.497386: Current learning rate: 0.00849 
2025-06-03 15:22:05.109355: train_loss -0.6386 
2025-06-03 15:22:05.133504: val_loss -0.638 
2025-06-03 15:22:05.149832: Pseudo dice [np.float32(0.6743)] 
2025-06-03 15:22:05.363249: Epoch time: 96.64 s 
2025-06-03 15:22:07.248233:  
2025-06-03 15:22:07.262644: Epoch 167 
2025-06-03 15:22:07.275042: Current learning rate: 0.00848 
2025-06-03 15:23:42.534941: train_loss -0.6497 
2025-06-03 15:23:42.706410: val_loss -0.6567 
2025-06-03 15:23:42.868703: Pseudo dice [np.float32(0.6897)] 
2025-06-03 15:23:42.886116: Epoch time: 95.29 s 
2025-06-03 15:23:44.667441:  
2025-06-03 15:23:44.684430: Epoch 168 
2025-06-03 15:23:44.695931: Current learning rate: 0.00847 
2025-06-03 15:25:21.605556: train_loss -0.675 
2025-06-03 15:25:21.630791: val_loss -0.639 
2025-06-03 15:25:21.647335: Pseudo dice [np.float32(0.7213)] 
2025-06-03 15:25:21.663919: Epoch time: 96.94 s 
2025-06-03 15:25:24.257843:  
2025-06-03 15:25:24.275722: Epoch 169 
2025-06-03 15:25:24.285935: Current learning rate: 0.00847 
2025-06-03 15:27:04.952669: train_loss -0.664 
2025-06-03 15:27:05.004557: val_loss -0.5785 
2025-06-03 15:27:05.049619: Pseudo dice [np.float32(0.6349)] 
2025-06-03 15:27:05.098998: Epoch time: 100.7 s 
2025-06-03 15:27:06.267479:  
2025-06-03 15:27:06.286884: Epoch 170 
2025-06-03 15:27:06.307683: Current learning rate: 0.00846 
2025-06-03 15:28:41.646573: train_loss -0.6486 
2025-06-03 15:28:41.821778: val_loss -0.6166 
2025-06-03 15:28:42.009387: Pseudo dice [np.float32(0.7194)] 
2025-06-03 15:28:42.134425: Epoch time: 95.38 s 
2025-06-03 15:28:43.397636:  
2025-06-03 15:28:43.414328: Epoch 171 
2025-06-03 15:28:43.429632: Current learning rate: 0.00845 
2025-06-03 15:30:21.291538: train_loss -0.6695 
2025-06-03 15:30:21.309417: val_loss -0.6266 
2025-06-03 15:30:21.323757: Pseudo dice [np.float32(0.7212)] 
2025-06-03 15:30:21.341141: Epoch time: 97.89 s 
2025-06-03 15:30:23.285157:  
2025-06-03 15:30:23.301327: Epoch 172 
2025-06-03 15:30:23.316948: Current learning rate: 0.00844 
2025-06-03 15:32:00.515296: train_loss -0.6666 
2025-06-03 15:32:00.675320: val_loss -0.6444 
2025-06-03 15:32:00.694316: Pseudo dice [np.float32(0.6744)] 
2025-06-03 15:32:00.708730: Epoch time: 97.23 s 
2025-06-03 15:32:02.730545:  
2025-06-03 15:32:02.743719: Epoch 173 
2025-06-03 15:32:02.755150: Current learning rate: 0.00843 
2025-06-03 15:33:39.585177: train_loss -0.6571 
2025-06-03 15:33:39.705581: val_loss -0.6807 
2025-06-03 15:33:39.724498: Pseudo dice [np.float32(0.7544)] 
2025-06-03 15:33:39.740781: Epoch time: 96.86 s 
2025-06-03 15:33:42.266244:  
2025-06-03 15:33:42.281550: Epoch 174 
2025-06-03 15:33:42.294309: Current learning rate: 0.00842 
2025-06-03 15:35:18.630560: train_loss -0.6666 
2025-06-03 15:35:18.781670: val_loss -0.6802 
2025-06-03 15:35:19.069668: Pseudo dice [np.float32(0.8033)] 
2025-06-03 15:35:19.306691: Epoch time: 96.37 s 
2025-06-03 15:35:19.445966: Yayy! New best EMA pseudo Dice: 0.7125999927520752 
2025-06-03 15:35:21.296770:  
2025-06-03 15:35:21.312463: Epoch 175 
2025-06-03 15:35:21.325054: Current learning rate: 0.00841 
2025-06-03 15:36:58.931150: train_loss -0.6394 
2025-06-03 15:36:59.064887: val_loss -0.6897 
2025-06-03 15:36:59.085014: Pseudo dice [np.float32(0.7291)] 
2025-06-03 15:36:59.102112: Epoch time: 97.64 s 
2025-06-03 15:36:59.117033: Yayy! New best EMA pseudo Dice: 0.7142000198364258 
2025-06-03 15:37:01.050761:  
2025-06-03 15:37:01.063645: Epoch 176 
2025-06-03 15:37:01.074425: Current learning rate: 0.0084 
2025-06-03 15:38:36.245634: train_loss -0.6844 
2025-06-03 15:38:36.269620: val_loss -0.6713 
2025-06-03 15:38:36.286594: Pseudo dice [np.float32(0.6912)] 
2025-06-03 15:38:36.304298: Epoch time: 95.2 s 
2025-06-03 15:38:38.556692:  
2025-06-03 15:38:38.569795: Epoch 177 
2025-06-03 15:38:38.580764: Current learning rate: 0.00839 
2025-06-03 15:40:16.465833: train_loss -0.6226 
2025-06-03 15:40:16.646613: val_loss -0.6441 
2025-06-03 15:40:16.746826: Pseudo dice [np.float32(0.7389)] 
2025-06-03 15:40:16.763714: Epoch time: 97.91 s 
2025-06-03 15:40:16.779579: Yayy! New best EMA pseudo Dice: 0.7146000266075134 
2025-06-03 15:40:19.244913:  
2025-06-03 15:40:19.262472: Epoch 178 
2025-06-03 15:40:19.280167: Current learning rate: 0.00838 
2025-06-03 15:41:58.071609: train_loss -0.6611 
2025-06-03 15:41:58.093447: val_loss -0.5961 
2025-06-03 15:41:58.109418: Pseudo dice [np.float32(0.7384)] 
2025-06-03 15:41:58.125607: Epoch time: 98.83 s 
2025-06-03 15:41:58.139077: Yayy! New best EMA pseudo Dice: 0.7170000076293945 
2025-06-03 15:42:00.129310:  
2025-06-03 15:42:00.153297: Epoch 179 
2025-06-03 15:42:00.168215: Current learning rate: 0.00837 
2025-06-03 15:43:39.138941: train_loss -0.6556 
2025-06-03 15:43:39.160777: val_loss -0.6185 
2025-06-03 15:43:39.177212: Pseudo dice [np.float32(0.6266)] 
2025-06-03 15:43:39.194625: Epoch time: 99.01 s 
2025-06-03 15:43:40.762727:  
2025-06-03 15:43:40.780352: Epoch 180 
2025-06-03 15:43:40.796959: Current learning rate: 0.00836 
2025-06-03 15:45:19.534048: train_loss -0.6486 
2025-06-03 15:45:19.760261: val_loss -0.6133 
2025-06-03 15:45:19.916607: Pseudo dice [np.float32(0.7251)] 
2025-06-03 15:45:20.085315: Epoch time: 98.77 s 
2025-06-03 15:45:21.690464:  
2025-06-03 15:45:21.707498: Epoch 181 
2025-06-03 15:45:21.722030: Current learning rate: 0.00836 
2025-06-03 15:46:59.544027: train_loss -0.6543 
2025-06-03 15:46:59.564106: val_loss -0.6716 
2025-06-03 15:46:59.580534: Pseudo dice [np.float32(0.7405)] 
2025-06-03 15:46:59.596385: Epoch time: 97.86 s 
2025-06-03 15:47:01.372615:  
2025-06-03 15:47:01.389882: Epoch 182 
2025-06-03 15:47:01.400658: Current learning rate: 0.00835 
2025-06-03 15:48:39.089170: train_loss -0.6515 
2025-06-03 15:48:39.109179: val_loss -0.6509 
2025-06-03 15:48:39.126923: Pseudo dice [np.float32(0.7405)] 
2025-06-03 15:48:39.143628: Epoch time: 97.72 s 
2025-06-03 15:48:40.614369:  
2025-06-03 15:48:40.628443: Epoch 183 
2025-06-03 15:48:40.641099: Current learning rate: 0.00834 
2025-06-03 15:50:18.300695: train_loss -0.669 
2025-06-03 15:50:18.318150: val_loss -0.634 
2025-06-03 15:50:18.333493: Pseudo dice [np.float32(0.7173)] 
2025-06-03 15:50:18.347115: Epoch time: 97.69 s 
2025-06-03 15:50:19.809855:  
2025-06-03 15:50:19.824055: Epoch 184 
2025-06-03 15:50:19.836856: Current learning rate: 0.00833 
2025-06-03 15:51:58.143915: train_loss -0.6475 
2025-06-03 15:51:58.161439: val_loss -0.6525 
2025-06-03 15:51:58.178339: Pseudo dice [np.float32(0.6437)] 
2025-06-03 15:51:58.189744: Epoch time: 98.33 s 
2025-06-03 15:51:59.711672:  
2025-06-03 15:51:59.725610: Epoch 185 
2025-06-03 15:51:59.745518: Current learning rate: 0.00832 
2025-06-03 15:53:38.311489: train_loss -0.6628 
2025-06-03 15:53:38.558448: val_loss -0.6641 
2025-06-03 15:53:38.838741: Pseudo dice [np.float32(0.7211)] 
2025-06-03 15:53:39.096151: Epoch time: 98.6 s 
2025-06-03 15:53:40.704698:  
2025-06-03 15:53:40.727346: Epoch 186 
2025-06-03 15:53:40.747017: Current learning rate: 0.00831 
2025-06-03 15:55:18.096980: train_loss -0.6467 
2025-06-03 15:55:18.470826: val_loss -0.6491 
2025-06-03 15:55:18.726527: Pseudo dice [np.float32(0.698)] 
2025-06-03 15:55:18.933538: Epoch time: 97.39 s 
2025-06-03 15:55:20.111247:  
2025-06-03 15:55:20.123377: Epoch 187 
2025-06-03 15:55:20.136840: Current learning rate: 0.0083 
2025-06-03 15:56:52.563621: train_loss -0.6576 
2025-06-03 15:56:52.585273: val_loss -0.6405 
2025-06-03 15:56:52.601579: Pseudo dice [np.float32(0.7089)] 
2025-06-03 15:56:52.618559: Epoch time: 92.45 s 
2025-06-03 15:56:54.170755:  
2025-06-03 15:56:54.184969: Epoch 188 
2025-06-03 15:56:54.195257: Current learning rate: 0.00829 
2025-06-03 15:58:24.233204: train_loss -0.6605 
2025-06-03 15:58:24.252911: val_loss -0.6412 
2025-06-03 15:58:24.269116: Pseudo dice [np.float32(0.6637)] 
2025-06-03 15:58:24.286514: Epoch time: 90.06 s 
2025-06-03 15:58:25.563403:  
2025-06-03 15:58:25.596568: Epoch 189 
2025-06-03 15:58:25.609694: Current learning rate: 0.00828 
2025-06-03 15:59:53.861684: train_loss -0.6677 
2025-06-03 15:59:54.029528: val_loss -0.5917 
2025-06-03 15:59:54.217951: Pseudo dice [np.float32(0.6783)] 
2025-06-03 15:59:54.304810: Epoch time: 88.3 s 
2025-06-03 15:59:55.986788:  
2025-06-03 15:59:56.015151: Epoch 190 
2025-06-03 15:59:56.027237: Current learning rate: 0.00827 
2025-06-03 16:01:25.673413: train_loss -0.6781 
2025-06-03 16:01:25.691069: val_loss -0.5784 
2025-06-03 16:01:25.708648: Pseudo dice [np.float32(0.6371)] 
2025-06-03 16:01:25.724600: Epoch time: 89.69 s 
2025-06-03 16:01:27.160236:  
2025-06-03 16:01:27.184146: Epoch 191 
2025-06-03 16:01:27.194328: Current learning rate: 0.00826 
2025-06-03 16:03:00.486513: train_loss -0.6808 
2025-06-03 16:03:00.579603: val_loss -0.602 
2025-06-03 16:03:00.669981: Pseudo dice [np.float32(0.6636)] 
2025-06-03 16:03:00.689163: Epoch time: 93.33 s 
2025-06-03 16:03:01.861486:  
2025-06-03 16:03:01.882358: Epoch 192 
2025-06-03 16:03:01.898548: Current learning rate: 0.00825 
2025-06-03 16:04:30.942692: train_loss -0.6422 
2025-06-03 16:04:31.089388: val_loss -0.6252 
2025-06-03 16:04:31.248703: Pseudo dice [np.float32(0.7194)] 
2025-06-03 16:04:31.392504: Epoch time: 89.08 s 
2025-06-03 16:04:32.565895:  
2025-06-03 16:04:32.584794: Epoch 193 
2025-06-03 16:04:32.602787: Current learning rate: 0.00824 
2025-06-03 16:06:00.423716: train_loss -0.6459 
2025-06-03 16:06:00.596540: val_loss -0.6547 
2025-06-03 16:06:00.810447: Pseudo dice [np.float32(0.7088)] 
2025-06-03 16:06:00.995189: Epoch time: 87.86 s 
2025-06-03 16:06:02.187700:  
2025-06-03 16:06:02.214371: Epoch 194 
2025-06-03 16:06:02.230952: Current learning rate: 0.00824 
2025-06-03 16:07:32.343197: train_loss -0.642 
2025-06-03 16:07:32.441611: val_loss -0.6122 
2025-06-03 16:07:32.459548: Pseudo dice [np.float32(0.7147)] 
2025-06-03 16:07:32.475021: Epoch time: 90.16 s 
2025-06-03 16:07:34.305729:  
2025-06-03 16:07:34.328803: Epoch 195 
2025-06-03 16:07:34.345666: Current learning rate: 0.00823 
2025-06-03 16:09:06.163046: train_loss -0.6519 
2025-06-03 16:09:06.184289: val_loss -0.6412 
2025-06-03 16:09:06.199846: Pseudo dice [np.float32(0.7287)] 
2025-06-03 16:09:06.216600: Epoch time: 91.86 s 
2025-06-03 16:09:08.962441:  
2025-06-03 16:09:08.985164: Epoch 196 
2025-06-03 16:09:08.997605: Current learning rate: 0.00822 
2025-06-03 16:10:38.558424: train_loss -0.6331 
2025-06-03 16:10:38.732004: val_loss -0.6812 
2025-06-03 16:10:38.958658: Pseudo dice [np.float32(0.7136)] 
2025-06-03 16:10:39.176639: Epoch time: 89.6 s 
2025-06-03 16:10:40.321045:  
2025-06-03 16:10:40.344155: Epoch 197 
2025-06-03 16:10:40.356171: Current learning rate: 0.00821 
2025-06-03 16:12:08.796971: train_loss -0.6776 
2025-06-03 16:12:08.922024: val_loss -0.6574 
2025-06-03 16:12:09.087713: Pseudo dice [np.float32(0.647)] 
2025-06-03 16:12:09.188621: Epoch time: 88.48 s 
2025-06-03 16:12:10.738245:  
2025-06-03 16:12:10.771868: Epoch 198 
2025-06-03 16:12:10.787672: Current learning rate: 0.0082 
2025-06-03 16:13:39.473550: train_loss -0.6764 
2025-06-03 16:13:39.638602: val_loss -0.6534 
2025-06-03 16:13:39.773040: Pseudo dice [np.float32(0.7213)] 
2025-06-03 16:13:39.874934: Epoch time: 88.74 s 
2025-06-03 16:13:41.034801:  
2025-06-03 16:13:41.051285: Epoch 199 
2025-06-03 16:13:41.067231: Current learning rate: 0.00819 
2025-06-03 16:15:09.239847: train_loss -0.6506 
2025-06-03 16:15:09.256350: val_loss -0.6754 
2025-06-03 16:15:09.273093: Pseudo dice [np.float32(0.7151)] 
2025-06-03 16:15:09.286599: Epoch time: 88.21 s 
2025-06-03 16:15:11.105316:  
2025-06-03 16:15:11.118332: Epoch 200 
2025-06-03 16:15:11.131426: Current learning rate: 0.00818 
2025-06-03 16:16:39.350677: train_loss -0.6776 
2025-06-03 16:16:39.405730: val_loss -0.6766 
2025-06-03 16:16:39.423333: Pseudo dice [np.float32(0.6153)] 
2025-06-03 16:16:39.437901: Epoch time: 88.25 s 
2025-06-03 16:16:41.647208:  
2025-06-03 16:16:41.671392: Epoch 201 
2025-06-03 16:16:41.683754: Current learning rate: 0.00817 
2025-06-03 16:18:13.739436: train_loss -0.6742 
2025-06-03 16:18:13.759723: val_loss -0.6626 
2025-06-03 16:18:13.774728: Pseudo dice [np.float32(0.7234)] 
2025-06-03 16:18:13.790920: Epoch time: 92.09 s 
2025-06-03 16:18:15.503455:  
2025-06-03 16:18:15.521198: Epoch 202 
2025-06-03 16:18:15.538921: Current learning rate: 0.00816 
2025-06-03 16:19:43.087986: train_loss -0.6765 
2025-06-03 16:19:43.228316: val_loss -0.702 
2025-06-03 16:19:43.432724: Pseudo dice [np.float32(0.7658)] 
2025-06-03 16:19:43.612211: Epoch time: 87.59 s 
2025-06-03 16:19:44.887998:  
2025-06-03 16:19:44.911048: Epoch 203 
2025-06-03 16:19:44.935435: Current learning rate: 0.00815 
2025-06-03 16:21:15.796536: train_loss -0.651 
2025-06-03 16:21:15.923639: val_loss -0.6358 
2025-06-03 16:21:16.120584: Pseudo dice [np.float32(0.6415)] 
2025-06-03 16:21:16.316287: Epoch time: 90.91 s 
2025-06-03 16:21:17.802942:  
2025-06-03 16:21:17.818472: Epoch 204 
2025-06-03 16:21:17.831601: Current learning rate: 0.00814 
2025-06-03 16:22:47.802434: train_loss -0.6637 
2025-06-03 16:22:47.999935: val_loss -0.6437 
2025-06-03 16:22:48.217630: Pseudo dice [np.float32(0.6318)] 
2025-06-03 16:22:48.396841: Epoch time: 90.0 s 
2025-06-03 16:22:49.734919:  
2025-06-03 16:22:49.748244: Epoch 205 
2025-06-03 16:22:49.758654: Current learning rate: 0.00813 
2025-06-03 16:24:21.981515: train_loss -0.6662 
2025-06-03 16:24:22.144927: val_loss -0.6307 
2025-06-03 16:24:22.339810: Pseudo dice [np.float32(0.6777)] 
2025-06-03 16:24:22.428258: Epoch time: 92.25 s 
2025-06-03 16:24:23.486391:  
2025-06-03 16:24:23.515706: Epoch 206 
2025-06-03 16:24:23.542339: Current learning rate: 0.00813 
2025-06-03 16:25:52.925897: train_loss -0.6525 
2025-06-03 16:25:52.944394: val_loss -0.6662 
2025-06-03 16:25:52.959718: Pseudo dice [np.float32(0.6732)] 
2025-06-03 16:25:52.973602: Epoch time: 89.44 s 
2025-06-03 16:25:54.432795:  
2025-06-03 16:25:54.453885: Epoch 207 
2025-06-03 16:25:54.465225: Current learning rate: 0.00812 
2025-06-03 16:27:22.904617: train_loss -0.6436 
2025-06-03 16:27:22.979892: val_loss -0.6839 
2025-06-03 16:27:23.103609: Pseudo dice [np.float32(0.7628)] 
2025-06-03 16:27:23.123013: Epoch time: 88.47 s 
2025-06-03 16:27:24.771151:  
2025-06-03 16:27:24.787777: Epoch 208 
2025-06-03 16:27:24.799551: Current learning rate: 0.00811 
2025-06-03 16:28:55.343561: train_loss -0.6658 
2025-06-03 16:28:55.361184: val_loss -0.6588 
2025-06-03 16:28:55.377621: Pseudo dice [np.float32(0.7581)] 
2025-06-03 16:28:55.392602: Epoch time: 90.58 s 
2025-06-03 16:28:56.625376:  
2025-06-03 16:28:56.638804: Epoch 209 
2025-06-03 16:28:56.653619: Current learning rate: 0.0081 
2025-06-03 16:30:22.127795: train_loss -0.6589 
2025-06-03 16:30:22.234236: val_loss -0.6572 
2025-06-03 16:30:22.337121: Pseudo dice [np.float32(0.691)] 
2025-06-03 16:30:22.394364: Epoch time: 85.5 s 
2025-06-03 16:30:23.659997:  
2025-06-03 16:30:23.675811: Epoch 210 
2025-06-03 16:30:23.688347: Current learning rate: 0.00809 
2025-06-03 16:31:50.094008: train_loss -0.671 
2025-06-03 16:31:50.120326: val_loss -0.6794 
2025-06-03 16:31:50.137978: Pseudo dice [np.float32(0.766)] 
2025-06-03 16:31:50.152010: Epoch time: 86.43 s 
2025-06-03 16:31:51.956642:  
2025-06-03 16:31:51.986798: Epoch 211 
2025-06-03 16:31:51.999124: Current learning rate: 0.00808 
2025-06-03 16:33:20.423737: train_loss -0.6666 
2025-06-03 16:33:20.484663: val_loss -0.6586 
2025-06-03 16:33:20.526924: Pseudo dice [np.float32(0.6979)] 
2025-06-03 16:33:20.557902: Epoch time: 88.47 s 
2025-06-03 16:33:22.869102:  
2025-06-03 16:33:22.883455: Epoch 212 
2025-06-03 16:33:22.897815: Current learning rate: 0.00807 
2025-06-03 16:34:51.347787: train_loss -0.6649 
2025-06-03 16:34:51.371403: val_loss -0.611 
2025-06-03 16:34:51.387529: Pseudo dice [np.float32(0.6759)] 
2025-06-03 16:34:51.400974: Epoch time: 88.48 s 
2025-06-03 16:34:52.856559:  
2025-06-03 16:34:52.881492: Epoch 213 
2025-06-03 16:34:52.908581: Current learning rate: 0.00806 
2025-06-03 16:36:20.739512: train_loss -0.6471 
2025-06-03 16:36:20.993160: val_loss -0.6538 
2025-06-03 16:36:21.010107: Pseudo dice [np.float32(0.7183)] 
2025-06-03 16:36:21.024556: Epoch time: 87.88 s 
2025-06-03 16:36:22.385063:  
2025-06-03 16:36:22.401492: Epoch 214 
2025-06-03 16:36:22.414551: Current learning rate: 0.00805 
2025-06-03 16:37:52.469797: train_loss -0.6664 
2025-06-03 16:37:52.560096: val_loss -0.6258 
2025-06-03 16:37:52.696703: Pseudo dice [np.float32(0.733)] 
2025-06-03 16:37:52.789636: Epoch time: 90.09 s 
2025-06-03 16:37:53.845855:  
2025-06-03 16:37:53.869323: Epoch 215 
2025-06-03 16:37:53.883564: Current learning rate: 0.00804 
2025-06-03 16:39:23.778865: train_loss -0.66 
2025-06-03 16:39:23.796869: val_loss -0.6748 
2025-06-03 16:39:23.812836: Pseudo dice [np.float32(0.6557)] 
2025-06-03 16:39:23.829785: Epoch time: 89.93 s 
2025-06-03 16:39:25.059972:  
2025-06-03 16:39:25.078298: Epoch 216 
2025-06-03 16:39:25.088443: Current learning rate: 0.00803 
2025-06-03 16:40:57.030313: train_loss -0.6503 
2025-06-03 16:40:57.056597: val_loss -0.6793 
2025-06-03 16:40:57.112232: Pseudo dice [np.float32(0.7464)] 
2025-06-03 16:40:57.169052: Epoch time: 91.97 s 
2025-06-03 16:40:58.322536:  
2025-06-03 16:40:58.337118: Epoch 217 
2025-06-03 16:40:58.350254: Current learning rate: 0.00802 
2025-06-03 16:42:27.544698: train_loss -0.6832 
2025-06-03 16:42:27.564763: val_loss -0.5757 
2025-06-03 16:42:27.578631: Pseudo dice [np.float32(0.6607)] 
2025-06-03 16:42:27.596746: Epoch time: 89.22 s 
2025-06-03 16:42:29.037083:  
2025-06-03 16:42:29.055062: Epoch 218 
2025-06-03 16:42:29.065682: Current learning rate: 0.00801 
2025-06-03 16:43:55.706147: train_loss -0.7014 
2025-06-03 16:43:55.727402: val_loss -0.609 
2025-06-03 16:43:55.744408: Pseudo dice [np.float32(0.6369)] 
2025-06-03 16:43:55.760750: Epoch time: 86.67 s 
2025-06-03 16:43:57.294021:  
2025-06-03 16:43:57.323867: Epoch 219 
2025-06-03 16:43:57.336096: Current learning rate: 0.00801 
2025-06-03 16:45:23.683661: train_loss -0.6623 
2025-06-03 16:45:23.699269: val_loss -0.615 
2025-06-03 16:45:23.714569: Pseudo dice [np.float32(0.6278)] 
2025-06-03 16:45:23.728103: Epoch time: 86.39 s 
2025-06-03 16:45:25.114890:  
2025-06-03 16:45:25.138432: Epoch 220 
2025-06-03 16:45:25.160555: Current learning rate: 0.008 
2025-06-03 16:46:53.944142: train_loss -0.6558 
2025-06-03 16:46:54.047429: val_loss -0.6821 
2025-06-03 16:46:54.198296: Pseudo dice [np.float32(0.7169)] 
2025-06-03 16:46:54.410127: Epoch time: 88.83 s 
2025-06-03 16:46:55.641336:  
2025-06-03 16:46:55.654580: Epoch 221 
2025-06-03 16:46:55.664052: Current learning rate: 0.00799 
2025-06-03 16:48:22.907773: train_loss -0.6916 
2025-06-03 16:48:23.029062: val_loss -0.6247 
2025-06-03 16:48:23.155435: Pseudo dice [np.float32(0.7111)] 
2025-06-03 16:48:23.235379: Epoch time: 87.27 s 
2025-06-03 16:48:24.263628:  
2025-06-03 16:48:24.283599: Epoch 222 
2025-06-03 16:48:24.297665: Current learning rate: 0.00798 
2025-06-03 16:49:43.099458: train_loss -0.6727 
2025-06-03 16:49:43.121264: val_loss -0.6127 
2025-06-03 16:49:43.138332: Pseudo dice [np.float32(0.6287)] 
2025-06-03 16:49:43.152621: Epoch time: 78.84 s 
2025-06-03 16:49:45.138275:  
2025-06-03 16:49:45.154216: Epoch 223 
2025-06-03 16:49:45.166643: Current learning rate: 0.00797 
2025-06-03 16:51:08.412045: train_loss -0.67 
2025-06-03 16:51:08.430106: val_loss -0.7068 
2025-06-03 16:51:08.447512: Pseudo dice [np.float32(0.8137)] 
2025-06-03 16:51:08.462520: Epoch time: 83.28 s 
2025-06-03 16:51:10.105890:  
2025-06-03 16:51:10.127490: Epoch 224 
2025-06-03 16:51:10.146088: Current learning rate: 0.00796 
2025-06-03 16:52:31.480196: train_loss -0.671 
2025-06-03 16:52:31.560211: val_loss -0.6779 
2025-06-03 16:52:31.661016: Pseudo dice [np.float32(0.7496)] 
2025-06-03 16:52:31.734772: Epoch time: 81.38 s 
2025-06-03 16:52:32.924614:  
2025-06-03 16:52:32.938227: Epoch 225 
2025-06-03 16:52:32.952126: Current learning rate: 0.00795 
2025-06-03 16:53:47.580017: train_loss -0.6717 
2025-06-03 16:53:47.630151: val_loss -0.5811 
2025-06-03 16:53:47.747225: Pseudo dice [np.float32(0.5675)] 
2025-06-03 16:53:47.765658: Epoch time: 74.66 s 
2025-06-03 16:53:49.493334:  
2025-06-03 16:53:49.509515: Epoch 226 
2025-06-03 16:53:49.519984: Current learning rate: 0.00794 
2025-06-03 16:55:13.930737: train_loss -0.6566 
2025-06-03 16:55:13.948373: val_loss -0.6311 
2025-06-03 16:55:14.017612: Pseudo dice [np.float32(0.683)] 
2025-06-03 16:55:14.091909: Epoch time: 84.44 s 
2025-06-03 16:55:15.195193:  
2025-06-03 16:55:15.213203: Epoch 227 
2025-06-03 16:55:15.226640: Current learning rate: 0.00793 
2025-06-03 16:56:44.932158: train_loss -0.6759 
2025-06-03 16:56:45.032310: val_loss -0.6572 
2025-06-03 16:56:45.083037: Pseudo dice [np.float32(0.6475)] 
2025-06-03 16:56:45.110756: Epoch time: 89.74 s 
2025-06-03 16:56:47.103741:  
2025-06-03 16:56:47.124372: Epoch 228 
2025-06-03 16:56:47.136927: Current learning rate: 0.00792 
2025-06-03 16:58:17.241060: train_loss -0.652 
2025-06-03 16:58:17.424933: val_loss -0.6279 
2025-06-03 16:58:17.687764: Pseudo dice [np.float32(0.6646)] 
2025-06-03 16:58:17.843223: Epoch time: 90.14 s 
2025-06-03 16:58:18.968690:  
2025-06-03 16:58:18.988444: Epoch 229 
2025-06-03 16:58:19.029780: Current learning rate: 0.00791 
2025-06-03 16:59:47.583391: train_loss -0.6546 
2025-06-03 16:59:47.601530: val_loss -0.6267 
2025-06-03 16:59:47.617739: Pseudo dice [np.float32(0.6527)] 
2025-06-03 16:59:47.635975: Epoch time: 88.62 s 
2025-06-03 16:59:48.790631:  
2025-06-03 16:59:48.804453: Epoch 230 
2025-06-03 16:59:48.816260: Current learning rate: 0.0079 
2025-06-03 17:01:18.395641: train_loss -0.6925 
2025-06-03 17:01:18.414775: val_loss -0.6801 
2025-06-03 17:01:18.432458: Pseudo dice [np.float32(0.7533)] 
2025-06-03 17:01:18.549938: Epoch time: 89.61 s 
2025-06-03 17:01:19.977174:  
2025-06-03 17:01:19.993310: Epoch 231 
2025-06-03 17:01:20.007490: Current learning rate: 0.00789 
2025-06-03 17:02:50.911885: train_loss -0.681 
2025-06-03 17:02:51.036466: val_loss -0.6707 
2025-06-03 17:02:51.129832: Pseudo dice [np.float32(0.7127)] 
2025-06-03 17:02:51.438605: Epoch time: 90.94 s 
2025-06-03 17:02:52.684582:  
2025-06-03 17:02:52.698825: Epoch 232 
2025-06-03 17:02:52.711973: Current learning rate: 0.00789 
2025-06-03 17:04:23.416816: train_loss -0.6553 
2025-06-03 17:04:23.441484: val_loss -0.6448 
2025-06-03 17:04:23.455445: Pseudo dice [np.float32(0.7511)] 
2025-06-03 17:04:23.473380: Epoch time: 90.73 s 
2025-06-03 17:04:24.983905:  
2025-06-03 17:04:24.996386: Epoch 233 
2025-06-03 17:04:25.008771: Current learning rate: 0.00788 
2025-06-03 17:05:45.423363: train_loss -0.6635 
2025-06-03 17:05:45.486154: val_loss -0.6526 
2025-06-03 17:05:45.517772: Pseudo dice [np.float32(0.6868)] 
2025-06-03 17:05:45.533935: Epoch time: 80.44 s 
2025-06-03 17:05:47.376368:  
2025-06-03 17:05:47.387495: Epoch 234 
2025-06-03 17:05:47.406102: Current learning rate: 0.00787 
2025-06-03 17:07:13.550514: train_loss -0.6677 
2025-06-03 17:07:13.568995: val_loss -0.6432 
2025-06-03 17:07:13.585391: Pseudo dice [np.float32(0.6788)] 
2025-06-03 17:07:13.602990: Epoch time: 86.17 s 
2025-06-03 17:07:15.108240:  
2025-06-03 17:07:15.133353: Epoch 235 
2025-06-03 17:07:15.143624: Current learning rate: 0.00786 
2025-06-03 17:08:48.234013: train_loss -0.6886 
2025-06-03 17:08:48.353596: val_loss -0.643 
2025-06-03 17:08:48.445044: Pseudo dice [np.float32(0.7243)] 
2025-06-03 17:08:48.566344: Epoch time: 93.13 s 
2025-06-03 17:08:49.756124:  
2025-06-03 17:08:49.772891: Epoch 236 
2025-06-03 17:08:49.791946: Current learning rate: 0.00785 
2025-06-03 17:10:23.564381: train_loss -0.6696 
2025-06-03 17:10:23.607871: val_loss -0.6989 
2025-06-03 17:10:23.726136: Pseudo dice [np.float32(0.7424)] 
2025-06-03 17:10:23.856366: Epoch time: 93.81 s 
2025-06-03 17:10:24.945873:  
2025-06-03 17:10:24.961809: Epoch 237 
2025-06-03 17:10:24.978567: Current learning rate: 0.00784 
2025-06-03 17:11:56.006532: train_loss -0.6871 
2025-06-03 17:11:56.150015: val_loss -0.5981 
2025-06-03 17:11:56.359178: Pseudo dice [np.float32(0.7171)] 
2025-06-03 17:11:56.568799: Epoch time: 91.06 s 
2025-06-03 17:11:57.761533:  
2025-06-03 17:11:57.775254: Epoch 238 
2025-06-03 17:11:57.788921: Current learning rate: 0.00783 
2025-06-03 17:13:28.738020: train_loss -0.6555 
2025-06-03 17:13:28.759049: val_loss -0.6354 
2025-06-03 17:13:28.772090: Pseudo dice [np.float32(0.7095)] 
2025-06-03 17:13:28.789852: Epoch time: 90.98 s 
2025-06-03 17:13:30.368495:  
2025-06-03 17:13:30.382018: Epoch 239 
2025-06-03 17:13:30.394491: Current learning rate: 0.00782 
2025-06-03 17:15:01.955550: train_loss -0.6627 
2025-06-03 17:15:02.203683: val_loss -0.6857 
2025-06-03 17:15:02.886705: Pseudo dice [np.float32(0.7025)] 
2025-06-03 17:15:03.120353: Epoch time: 91.59 s 
2025-06-03 17:15:04.077833:  
2025-06-03 17:15:04.093996: Epoch 240 
2025-06-03 17:15:04.113928: Current learning rate: 0.00781 
2025-06-03 17:16:46.718475: train_loss -0.635 
2025-06-03 17:16:46.882870: val_loss -0.6402 
2025-06-03 17:16:47.092570: Pseudo dice [np.float32(0.786)] 
2025-06-03 17:16:47.242692: Epoch time: 102.64 s 
2025-06-03 17:16:49.783216:  
2025-06-03 17:16:49.800328: Epoch 241 
2025-06-03 17:16:49.814389: Current learning rate: 0.0078 
2025-06-03 17:18:58.310773: train_loss -0.6553 
2025-06-03 17:18:58.724007: val_loss -0.586 
2025-06-03 17:18:59.517948: Pseudo dice [np.float32(0.6824)] 
2025-06-03 17:18:59.692528: Epoch time: 128.53 s 
2025-06-03 17:19:03.826977:  
2025-06-03 17:19:03.853192: Epoch 242 
2025-06-03 17:19:03.869266: Current learning rate: 0.00779 
2025-06-03 17:21:10.082978: train_loss -0.6503 
2025-06-03 17:21:10.287554: val_loss -0.6537 
2025-06-03 17:21:10.533526: Pseudo dice [np.float32(0.7561)] 
2025-06-03 17:21:10.769842: Epoch time: 126.26 s 
2025-06-03 17:21:13.308472:  
2025-06-03 17:21:13.413301: Epoch 243 
2025-06-03 17:21:13.560867: Current learning rate: 0.00778 
2025-06-03 17:23:21.407051: train_loss -0.6682 
2025-06-03 17:23:21.619207: val_loss -0.6914 
2025-06-03 17:23:21.787954: Pseudo dice [np.float32(0.7131)] 
2025-06-03 17:23:21.988194: Epoch time: 128.1 s 
2025-06-03 17:23:24.068332:  
2025-06-03 17:23:24.082941: Epoch 244 
2025-06-03 17:23:24.095357: Current learning rate: 0.00777 
2025-06-03 17:25:32.336794: train_loss -0.6695 
2025-06-03 17:25:32.357198: val_loss -0.7366 
2025-06-03 17:25:32.376593: Pseudo dice [np.float32(0.7944)] 
2025-06-03 17:25:32.394531: Epoch time: 128.27 s 
2025-06-03 17:25:32.408747: Yayy! New best EMA pseudo Dice: 0.7215999960899353 
2025-06-03 17:25:37.065629:  
2025-06-03 17:25:37.322577: Epoch 245 
2025-06-03 17:25:37.586850: Current learning rate: 0.00777 
2025-06-03 17:27:46.316017: train_loss -0.6837 
2025-06-03 17:27:46.334875: val_loss -0.6513 
2025-06-03 17:27:46.350678: Pseudo dice [np.float32(0.6913)] 
2025-06-03 17:27:46.367039: Epoch time: 129.25 s 
2025-06-03 17:27:49.334101:  
2025-06-03 17:27:49.426682: Epoch 246 
2025-06-03 17:27:49.565656: Current learning rate: 0.00776 
2025-06-03 17:30:02.204560: train_loss -0.6706 
2025-06-03 17:30:02.225253: val_loss -0.6577 
2025-06-03 17:30:02.244069: Pseudo dice [np.float32(0.6964)] 
2025-06-03 17:30:02.260956: Epoch time: 132.87 s 
2025-06-03 17:30:05.947381:  
2025-06-03 17:30:06.062121: Epoch 247 
2025-06-03 17:30:06.130928: Current learning rate: 0.00775 
2025-06-03 17:32:17.936001: train_loss -0.6639 
2025-06-03 17:32:18.452569: val_loss -0.6298 
2025-06-03 17:32:18.468552: Pseudo dice [np.float32(0.7191)] 
2025-06-03 17:32:18.486485: Epoch time: 131.99 s 
2025-06-03 17:32:22.185086:  
2025-06-03 17:32:22.315454: Epoch 248 
2025-06-03 17:32:22.362114: Current learning rate: 0.00774 
2025-06-03 17:34:36.642734: train_loss -0.6501 
2025-06-03 17:34:37.173821: val_loss -0.5695 
2025-06-03 17:34:37.724136: Pseudo dice [np.float32(0.635)] 
2025-06-03 17:34:38.136415: Epoch time: 134.46 s 
2025-06-03 17:34:41.083998:  
2025-06-03 17:34:41.105385: Epoch 249 
2025-06-03 17:34:41.135611: Current learning rate: 0.00773 
2025-06-03 17:36:55.901011: train_loss -0.6446 
2025-06-03 17:36:55.922909: val_loss -0.7061 
2025-06-03 17:36:55.938501: Pseudo dice [np.float32(0.7556)] 
2025-06-03 17:36:55.954950: Epoch time: 134.82 s 
2025-06-03 17:37:02.047553:  
2025-06-03 17:37:02.319018: Epoch 250 
2025-06-03 17:37:02.528347: Current learning rate: 0.00772 
2025-06-03 17:39:11.865763: train_loss -0.646 
2025-06-03 17:39:12.289068: val_loss -0.5872 
2025-06-03 17:39:12.648794: Pseudo dice [np.float32(0.5228)] 
2025-06-03 17:39:13.012314: Epoch time: 129.82 s 
2025-06-03 17:39:16.216916:  
2025-06-03 17:39:16.364219: Epoch 251 
2025-06-03 17:39:16.604742: Current learning rate: 0.00771 
2025-06-03 17:41:26.773128: train_loss -0.6603 
2025-06-03 17:41:27.161284: val_loss -0.6481 
2025-06-03 17:41:27.546357: Pseudo dice [np.float32(0.6892)] 
2025-06-03 17:41:27.764971: Epoch time: 130.56 s 
2025-06-03 17:41:30.569290:  
2025-06-03 17:41:30.591612: Epoch 252 
2025-06-03 17:41:30.611356: Current learning rate: 0.0077 
2025-06-03 17:43:41.870224: train_loss -0.6476 
2025-06-03 17:43:41.891068: val_loss -0.6302 
2025-06-03 17:43:41.908100: Pseudo dice [np.float32(0.7081)] 
2025-06-03 17:43:41.924804: Epoch time: 131.3 s 
2025-06-03 17:43:45.973057:  
2025-06-03 17:43:46.045842: Epoch 253 
2025-06-03 17:43:46.088846: Current learning rate: 0.00769 
2025-06-03 17:45:52.891486: train_loss -0.6497 
2025-06-03 17:45:53.237808: val_loss -0.6235 
2025-06-03 17:45:53.772188: Pseudo dice [np.float32(0.7371)] 
2025-06-03 17:45:54.189202: Epoch time: 126.92 s 
2025-06-03 17:45:57.093133:  
2025-06-03 17:45:57.152739: Epoch 254 
2025-06-03 17:45:57.198163: Current learning rate: 0.00768 
2025-06-03 17:48:08.032509: train_loss -0.6685 
2025-06-03 17:48:08.551073: val_loss -0.6621 
2025-06-03 17:48:08.787155: Pseudo dice [np.float32(0.7385)] 
2025-06-03 17:48:08.920401: Epoch time: 130.94 s 
2025-06-03 17:48:12.172136:  
2025-06-03 17:48:12.207833: Epoch 255 
2025-06-03 17:48:12.280111: Current learning rate: 0.00767 
2025-06-03 17:50:21.820083: train_loss -0.6687 
2025-06-03 17:50:22.150286: val_loss -0.693 
2025-06-03 17:50:22.589919: Pseudo dice [np.float32(0.7824)] 
2025-06-03 17:50:22.988867: Epoch time: 129.65 s 
2025-06-03 17:50:26.147776:  
2025-06-03 17:50:26.249867: Epoch 256 
2025-06-03 17:50:26.396993: Current learning rate: 0.00766 
2025-06-03 17:52:36.800023: train_loss -0.6625 
2025-06-03 17:52:36.821963: val_loss -0.709 
2025-06-03 17:52:36.846228: Pseudo dice [np.float32(0.7055)] 
2025-06-03 17:52:37.036162: Epoch time: 130.65 s 
2025-06-03 17:52:40.160688:  
2025-06-03 17:52:40.181163: Epoch 257 
2025-06-03 17:52:40.197720: Current learning rate: 0.00765 
2025-06-03 17:54:50.305035: train_loss -0.6292 
2025-06-03 17:54:50.326413: val_loss -0.7065 
2025-06-03 17:54:50.343873: Pseudo dice [np.float32(0.7451)] 
2025-06-03 17:54:50.359980: Epoch time: 130.15 s 
2025-06-03 17:54:53.519021:  
2025-06-03 17:54:53.546000: Epoch 258 
2025-06-03 17:54:53.569137: Current learning rate: 0.00764 
2025-06-03 17:57:02.726132: train_loss -0.6734 
2025-06-03 17:57:02.746896: val_loss -0.6646 
2025-06-03 17:57:02.767203: Pseudo dice [np.float32(0.7144)] 
2025-06-03 17:57:02.786519: Epoch time: 129.21 s 
2025-06-03 17:57:06.017024:  
2025-06-03 17:57:06.064930: Epoch 259 
2025-06-03 17:57:06.091271: Current learning rate: 0.00764 
2025-06-03 17:59:14.430521: train_loss -0.6918 
2025-06-03 17:59:14.452412: val_loss -0.6283 
2025-06-03 17:59:14.469066: Pseudo dice [np.float32(0.6785)] 
2025-06-03 17:59:14.486172: Epoch time: 128.42 s 
2025-06-03 17:59:18.120981:  
2025-06-03 17:59:18.168991: Epoch 260 
2025-06-03 17:59:18.197356: Current learning rate: 0.00763 
2025-06-03 18:01:26.001834: train_loss -0.6839 
2025-06-03 18:01:26.024258: val_loss -0.6764 
2025-06-03 18:01:26.042138: Pseudo dice [np.float32(0.7145)] 
2025-06-03 18:01:26.058707: Epoch time: 127.88 s 
2025-06-03 18:01:30.465367:  
2025-06-03 18:01:30.482233: Epoch 261 
2025-06-03 18:01:30.504837: Current learning rate: 0.00762 
2025-06-03 18:03:42.622016: train_loss -0.6881 
2025-06-03 18:03:42.636692: val_loss -0.6376 
2025-06-03 18:03:42.654342: Pseudo dice [np.float32(0.7325)] 
2025-06-03 18:03:42.670090: Epoch time: 132.16 s 
2025-06-03 18:03:46.403064:  
2025-06-03 18:03:46.427277: Epoch 262 
2025-06-03 18:03:46.445492: Current learning rate: 0.00761 
2025-06-03 18:05:53.090361: train_loss -0.6793 
2025-06-03 18:05:53.111915: val_loss -0.6156 
2025-06-03 18:05:53.127789: Pseudo dice [np.float32(0.6922)] 
2025-06-03 18:05:53.146543: Epoch time: 126.69 s 
2025-06-03 18:05:56.709640:  
2025-06-03 18:05:56.759175: Epoch 263 
2025-06-03 18:05:56.793745: Current learning rate: 0.0076 
2025-06-03 18:08:03.703791: train_loss -0.684 
2025-06-03 18:08:03.776118: val_loss -0.5579 
2025-06-03 18:08:03.895247: Pseudo dice [np.float32(0.6076)] 
2025-06-03 18:08:03.963654: Epoch time: 127.0 s 
2025-06-03 18:08:05.356257:  
2025-06-03 18:08:05.375081: Epoch 264 
2025-06-03 18:08:05.390037: Current learning rate: 0.00759 
2025-06-03 18:10:16.441334: train_loss -0.6524 
2025-06-03 18:10:16.523797: val_loss -0.6428 
2025-06-03 18:10:16.779007: Pseudo dice [np.float32(0.6358)] 
2025-06-03 18:10:17.007962: Epoch time: 131.09 s 
2025-06-03 18:10:19.287047:  
2025-06-03 18:10:19.317143: Epoch 265 
2025-06-03 18:10:19.455321: Current learning rate: 0.00758 
2025-06-03 18:12:30.608490: train_loss -0.684 
2025-06-03 18:12:30.914959: val_loss -0.6618 
2025-06-03 18:12:31.278574: Pseudo dice [np.float32(0.7139)] 
2025-06-03 18:12:31.627484: Epoch time: 131.32 s 
2025-06-03 18:12:34.760283:  
2025-06-03 18:12:34.967837: Epoch 266 
2025-06-03 18:12:35.170195: Current learning rate: 0.00757 
2025-06-03 18:14:46.728971: train_loss -0.6969 
2025-06-03 18:14:47.072547: val_loss -0.6542 
2025-06-03 18:14:47.446854: Pseudo dice [np.float32(0.6979)] 
2025-06-03 18:14:47.639116: Epoch time: 131.97 s 
2025-06-03 18:14:50.027323:  
2025-06-03 18:14:50.135419: Epoch 267 
2025-06-03 18:14:50.188111: Current learning rate: 0.00756 
2025-06-03 18:17:02.247248: train_loss -0.6686 
2025-06-03 18:17:02.265892: val_loss -0.6804 
2025-06-03 18:17:02.282752: Pseudo dice [np.float32(0.7224)] 
2025-06-03 18:17:02.296274: Epoch time: 132.22 s 
2025-06-03 18:17:05.618695:  
2025-06-03 18:17:05.637766: Epoch 268 
2025-06-03 18:17:05.654333: Current learning rate: 0.00755 
2025-06-03 18:19:16.249934: train_loss -0.6771 
2025-06-03 18:19:16.271482: val_loss -0.6452 
2025-06-03 18:19:16.289268: Pseudo dice [np.float32(0.7522)] 
2025-06-03 18:19:16.310360: Epoch time: 130.63 s 
2025-06-03 18:19:18.901598:  
2025-06-03 18:19:18.925453: Epoch 269 
2025-06-03 18:19:18.954748: Current learning rate: 0.00754 
2025-06-03 18:21:31.115630: train_loss -0.657 
2025-06-03 18:21:31.519750: val_loss -0.6646 
2025-06-03 18:21:32.035594: Pseudo dice [np.float32(0.6209)] 
2025-06-03 18:21:32.433380: Epoch time: 132.22 s 
2025-06-03 18:21:36.190670:  
2025-06-03 18:21:36.378090: Epoch 270 
2025-06-03 18:21:36.582980: Current learning rate: 0.00753 
2025-06-03 18:23:46.904076: train_loss -0.6723 
2025-06-03 18:23:47.125982: val_loss -0.6253 
2025-06-03 18:23:47.509437: Pseudo dice [np.float32(0.7543)] 
2025-06-03 18:23:47.892889: Epoch time: 130.72 s 
2025-06-03 18:23:51.689993:  
2025-06-03 18:23:51.884562: Epoch 271 
2025-06-03 18:23:51.981480: Current learning rate: 0.00752 
2025-06-03 18:26:04.147361: train_loss -0.6776 
2025-06-03 18:26:04.169647: val_loss -0.6724 
2025-06-03 18:26:04.274509: Pseudo dice [np.float32(0.7575)] 
2025-06-03 18:26:04.295874: Epoch time: 132.46 s 
2025-06-03 18:26:10.352215:  
2025-06-03 18:26:10.591743: Epoch 272 
2025-06-03 18:26:10.850704: Current learning rate: 0.00751 
2025-06-03 18:28:17.859133: train_loss -0.6809 
2025-06-03 18:28:18.308596: val_loss -0.6155 
2025-06-03 18:28:18.328477: Pseudo dice [np.float32(0.6436)] 
2025-06-03 18:28:18.344189: Epoch time: 127.51 s 
2025-06-03 18:28:23.196755:  
2025-06-03 18:28:23.330122: Epoch 273 
2025-06-03 18:28:23.347768: Current learning rate: 0.00751 
2025-06-03 18:30:34.592313: train_loss -0.6754 
2025-06-03 18:30:34.867539: val_loss -0.6338 
2025-06-03 18:30:35.195009: Pseudo dice [np.float32(0.6734)] 
2025-06-03 18:30:35.215856: Epoch time: 131.4 s 
2025-06-03 18:30:38.826603:  
2025-06-03 18:30:39.137083: Epoch 274 
2025-06-03 18:30:39.423239: Current learning rate: 0.0075 
2025-06-03 18:32:48.060284: train_loss -0.6562 
2025-06-03 18:32:48.218677: val_loss -0.6445 
2025-06-03 18:32:48.235809: Pseudo dice [np.float32(0.7117)] 
2025-06-03 18:32:48.250355: Epoch time: 129.24 s 
2025-06-03 18:32:51.419960:  
2025-06-03 18:32:51.660269: Epoch 275 
2025-06-03 18:32:51.842727: Current learning rate: 0.00749 
2025-06-03 18:35:06.434312: train_loss -0.6694 
2025-06-03 18:35:06.452821: val_loss -0.5741 
2025-06-03 18:35:06.470682: Pseudo dice [np.float32(0.6362)] 
2025-06-03 18:35:06.485184: Epoch time: 135.02 s 
2025-06-03 18:35:10.924100:  
2025-06-03 18:35:10.946569: Epoch 276 
2025-06-03 18:35:10.965174: Current learning rate: 0.00748 
2025-06-03 18:37:23.908119: train_loss -0.6715 
2025-06-03 18:37:24.251986: val_loss -0.6556 
2025-06-03 18:37:24.475880: Pseudo dice [np.float32(0.7294)] 
2025-06-03 18:37:24.492881: Epoch time: 132.99 s 
2025-06-03 18:37:28.464346:  
2025-06-03 18:37:28.555629: Epoch 277 
2025-06-03 18:37:28.573709: Current learning rate: 0.00747 
2025-06-03 18:39:41.249009: train_loss -0.6786 
2025-06-03 18:39:41.709814: val_loss -0.6782 
2025-06-03 18:39:42.067026: Pseudo dice [np.float32(0.7081)] 
2025-06-03 18:39:42.086766: Epoch time: 132.79 s 
2025-06-03 18:39:44.981413:  
2025-06-03 18:39:45.000411: Epoch 278 
2025-06-03 18:39:45.024535: Current learning rate: 0.00746 
2025-06-03 18:41:55.322393: train_loss -0.6379 
2025-06-03 18:41:55.399463: val_loss -0.5814 
2025-06-03 18:41:55.644588: Pseudo dice [np.float32(0.6331)] 
2025-06-03 18:41:56.003306: Epoch time: 130.34 s 
2025-06-03 18:41:58.755696:  
2025-06-03 18:41:59.162580: Epoch 279 
2025-06-03 18:41:59.312503: Current learning rate: 0.00745 
2025-06-03 18:44:08.868365: train_loss -0.6456 
2025-06-03 18:44:09.131492: val_loss -0.6656 
2025-06-03 18:44:09.579925: Pseudo dice [np.float32(0.6489)] 
2025-06-03 18:44:10.060946: Epoch time: 130.11 s 
2025-06-03 18:44:13.157878:  
2025-06-03 18:44:13.180698: Epoch 280 
2025-06-03 18:44:13.196440: Current learning rate: 0.00744 
2025-06-03 18:46:21.766237: train_loss -0.6834 
2025-06-03 18:46:22.135375: val_loss -0.6496 
2025-06-03 18:46:22.393051: Pseudo dice [np.float32(0.7515)] 
2025-06-03 18:46:22.810324: Epoch time: 128.61 s 
2025-06-03 18:46:26.226604:  
2025-06-03 18:46:26.325184: Epoch 281 
2025-06-03 18:46:26.342834: Current learning rate: 0.00743 
2025-06-03 18:48:31.098573: train_loss -0.6823 
2025-06-03 18:48:31.352407: val_loss -0.6903 
2025-06-03 18:48:32.116231: Pseudo dice [np.float32(0.6789)] 
2025-06-03 18:48:32.628900: Epoch time: 124.87 s 
2025-06-03 18:48:35.277937:  
2025-06-03 18:48:35.349861: Epoch 282 
2025-06-03 18:48:35.392116: Current learning rate: 0.00742 
2025-06-03 18:50:42.835666: train_loss -0.6784 
2025-06-03 18:50:43.019154: val_loss -0.6907 
2025-06-03 18:50:43.142329: Pseudo dice [np.float32(0.7804)] 
2025-06-03 18:50:43.507463: Epoch time: 127.56 s 
2025-06-03 18:50:45.693345:  
2025-06-03 18:50:45.710325: Epoch 283 
2025-06-03 18:50:45.723287: Current learning rate: 0.00741 
2025-06-03 18:52:55.596048: train_loss -0.684 
2025-06-03 18:52:55.822295: val_loss -0.6563 
2025-06-03 18:52:56.131609: Pseudo dice [np.float32(0.7489)] 
2025-06-03 18:52:56.506045: Epoch time: 129.9 s 
2025-06-03 18:52:59.695324:  
2025-06-03 18:52:59.825022: Epoch 284 
2025-06-03 18:52:59.989672: Current learning rate: 0.0074 
2025-06-03 18:55:09.623874: train_loss -0.6831 
2025-06-03 18:55:09.641616: val_loss -0.6316 
2025-06-03 18:55:09.658040: Pseudo dice [np.float32(0.7104)] 
2025-06-03 18:55:09.674182: Epoch time: 129.93 s 
2025-06-03 18:55:11.972492:  
2025-06-03 18:55:12.066315: Epoch 285 
2025-06-03 18:55:12.157693: Current learning rate: 0.00739 
2025-06-03 18:57:21.607084: train_loss -0.6911 
2025-06-03 18:57:21.921811: val_loss -0.6356 
2025-06-03 18:57:22.234580: Pseudo dice [np.float32(0.6418)] 
2025-06-03 18:57:22.569950: Epoch time: 129.64 s 
2025-06-03 18:57:25.908531:  
2025-06-03 18:57:25.930407: Epoch 286 
2025-06-03 18:57:26.053031: Current learning rate: 0.00738 
2025-06-03 18:59:38.882875: train_loss -0.6994 
2025-06-03 18:59:39.319245: val_loss -0.6618 
2025-06-03 18:59:39.761361: Pseudo dice [np.float32(0.7096)] 
2025-06-03 18:59:40.145352: Epoch time: 132.99 s 
2025-06-03 18:59:43.629261:  
2025-06-03 18:59:43.684581: Epoch 287 
2025-06-03 18:59:43.755810: Current learning rate: 0.00738 
2025-06-03 19:01:53.008653: train_loss -0.6925 
2025-06-03 19:01:53.431413: val_loss -0.6652 
2025-06-03 19:01:53.738116: Pseudo dice [np.float32(0.7169)] 
2025-06-03 19:01:53.756348: Epoch time: 129.38 s 
2025-06-03 19:01:56.432554:  
2025-06-03 19:01:56.491477: Epoch 288 
2025-06-03 19:01:56.566165: Current learning rate: 0.00737 
2025-06-03 19:04:06.572912: train_loss -0.7071 
2025-06-03 19:04:06.877676: val_loss -0.6197 
2025-06-03 19:04:06.896312: Pseudo dice [np.float32(0.7209)] 
2025-06-03 19:04:06.915016: Epoch time: 130.14 s 
2025-06-03 19:04:12.344886:  
2025-06-03 19:04:12.363556: Epoch 289 
2025-06-03 19:04:12.380686: Current learning rate: 0.00736 
2025-06-03 19:06:20.888182: train_loss -0.6997 
2025-06-03 19:06:20.906900: val_loss -0.6979 
2025-06-03 19:06:20.924807: Pseudo dice [np.float32(0.7818)] 
2025-06-03 19:06:20.938804: Epoch time: 128.55 s 
2025-06-03 19:06:25.199084:  
2025-06-03 19:06:25.480364: Epoch 290 
2025-06-03 19:06:25.506249: Current learning rate: 0.00735 
2025-06-03 19:08:35.220984: train_loss -0.655 
2025-06-03 19:08:35.594405: val_loss -0.6384 
2025-06-03 19:08:35.722317: Pseudo dice [np.float32(0.7572)] 
2025-06-03 19:08:35.842257: Epoch time: 130.02 s 
2025-06-03 19:08:39.045765:  
2025-06-03 19:08:39.126073: Epoch 291 
2025-06-03 19:08:39.151485: Current learning rate: 0.00734 
2025-06-03 19:10:51.342576: train_loss -0.6826 
2025-06-03 19:10:51.792637: val_loss -0.6244 
2025-06-03 19:10:52.295132: Pseudo dice [np.float32(0.7385)] 
2025-06-03 19:10:52.312114: Epoch time: 132.3 s 
2025-06-03 19:10:55.962286:  
2025-06-03 19:10:56.042877: Epoch 292 
2025-06-03 19:10:56.063453: Current learning rate: 0.00733 
2025-06-03 19:13:01.808279: train_loss -0.6648 
2025-06-03 19:13:01.834428: val_loss -0.6351 
2025-06-03 19:13:01.849076: Pseudo dice [np.float32(0.7583)] 
2025-06-03 19:13:01.867173: Epoch time: 125.85 s 
2025-06-03 19:13:01.880584: Yayy! New best EMA pseudo Dice: 0.7226999998092651 
2025-06-03 19:13:08.990530:  
2025-06-03 19:13:09.013685: Epoch 293 
2025-06-03 19:13:09.040890: Current learning rate: 0.00732 
2025-06-03 19:15:15.148180: train_loss -0.6591 
2025-06-03 19:15:15.411515: val_loss -0.6572 
2025-06-03 19:15:15.727092: Pseudo dice [np.float32(0.6565)] 
2025-06-03 19:15:15.890105: Epoch time: 126.16 s 
2025-06-03 19:15:21.565238:  
2025-06-03 19:15:21.853018: Epoch 294 
2025-06-03 19:15:22.089501: Current learning rate: 0.00731 
2025-06-03 19:17:34.659013: train_loss -0.6662 
2025-06-03 19:17:34.679658: val_loss -0.6175 
2025-06-03 19:17:34.697130: Pseudo dice [np.float32(0.7323)] 
2025-06-03 19:17:34.713155: Epoch time: 133.1 s 
2025-06-03 19:17:39.202389:  
2025-06-03 19:17:39.329269: Epoch 295 
2025-06-03 19:17:39.550223: Current learning rate: 0.0073 
2025-06-03 19:19:47.653911: train_loss -0.6304 
2025-06-03 19:19:47.702944: val_loss -0.6142 
2025-06-03 19:19:47.724799: Pseudo dice [np.float32(0.6498)] 
2025-06-03 19:19:47.740371: Epoch time: 128.45 s 
2025-06-03 19:19:53.256630:  
2025-06-03 19:19:53.277621: Epoch 296 
2025-06-03 19:19:53.294338: Current learning rate: 0.00729 
2025-06-03 19:22:04.329880: train_loss -0.6496 
2025-06-03 19:22:04.347765: val_loss -0.6118 
2025-06-03 19:22:04.366265: Pseudo dice [np.float32(0.6264)] 
2025-06-03 19:22:04.383565: Epoch time: 131.08 s 
2025-06-03 19:22:07.704777:  
2025-06-03 19:22:07.729554: Epoch 297 
2025-06-03 19:22:07.760666: Current learning rate: 0.00728 
2025-06-03 19:24:17.921496: train_loss -0.6677 
2025-06-03 19:24:17.947290: val_loss -0.616 
2025-06-03 19:24:17.964507: Pseudo dice [np.float32(0.6308)] 
2025-06-03 19:24:17.986957: Epoch time: 130.22 s 
2025-06-03 19:24:20.821576:  
2025-06-03 19:24:20.886237: Epoch 298 
2025-06-03 19:24:20.916467: Current learning rate: 0.00727 
2025-06-03 19:26:30.194906: train_loss -0.6825 
2025-06-03 19:26:30.357503: val_loss -0.5769 
2025-06-03 19:26:30.632340: Pseudo dice [np.float32(0.6242)] 
2025-06-03 19:26:30.649179: Epoch time: 129.38 s 
2025-06-03 19:26:34.833368:  
2025-06-03 19:26:34.855487: Epoch 299 
2025-06-03 19:26:34.873969: Current learning rate: 0.00726 
2025-06-03 19:28:44.469426: train_loss -0.6564 
2025-06-03 19:28:44.963483: val_loss -0.6309 
2025-06-03 19:28:45.438998: Pseudo dice [np.float32(0.727)] 
2025-06-03 19:28:45.751207: Epoch time: 129.64 s 
2025-06-03 19:28:50.391021:  
2025-06-03 19:28:50.523572: Epoch 300 
2025-06-03 19:28:50.778484: Current learning rate: 0.00725 
2025-06-03 19:30:56.713513: train_loss -0.6723 
2025-06-03 19:30:57.098566: val_loss -0.6627 
2025-06-03 19:30:57.495459: Pseudo dice [np.float32(0.7148)] 
2025-06-03 19:30:58.323951: Epoch time: 126.32 s 
2025-06-03 19:31:01.406125:  
2025-06-03 19:31:01.458655: Epoch 301 
2025-06-03 19:31:01.506879: Current learning rate: 0.00724 
2025-06-03 19:33:07.054805: train_loss -0.6683 
2025-06-03 19:33:07.076747: val_loss -0.699 
2025-06-03 19:33:07.095525: Pseudo dice [np.float32(0.7783)] 
2025-06-03 19:33:07.108802: Epoch time: 125.65 s 
2025-06-03 19:33:08.829521:  
2025-06-03 19:33:08.853492: Epoch 302 
2025-06-03 19:33:08.872164: Current learning rate: 0.00724 
2025-06-03 19:35:17.622900: train_loss -0.6698 
2025-06-03 19:35:17.882409: val_loss -0.6904 
2025-06-03 19:35:18.011248: Pseudo dice [np.float32(0.7451)] 
2025-06-03 19:35:18.205735: Epoch time: 128.79 s 
2025-06-03 19:35:20.268649:  
2025-06-03 19:35:20.283465: Epoch 303 
2025-06-03 19:35:20.293947: Current learning rate: 0.00723 
2025-06-03 19:37:30.561732: train_loss -0.6848 
2025-06-03 19:37:30.824919: val_loss -0.6402 
2025-06-03 19:37:31.045458: Pseudo dice [np.float32(0.7419)] 
2025-06-03 19:37:31.242434: Epoch time: 130.29 s 
2025-06-03 19:37:34.368995:  
2025-06-03 19:37:34.384455: Epoch 304 
2025-06-03 19:37:34.396716: Current learning rate: 0.00722 
2025-06-03 19:39:43.404064: train_loss -0.6743 
2025-06-03 19:39:43.619069: val_loss -0.6631 
2025-06-03 19:39:43.944975: Pseudo dice [np.float32(0.7524)] 
2025-06-03 19:39:43.964259: Epoch time: 129.04 s 
2025-06-03 19:39:47.156570:  
2025-06-03 19:39:47.233877: Epoch 305 
2025-06-03 19:39:47.359583: Current learning rate: 0.00721 
2025-06-03 19:41:58.135834: train_loss -0.6751 
2025-06-03 19:41:58.153094: val_loss -0.6558 
2025-06-03 19:41:58.168246: Pseudo dice [np.float32(0.7157)] 
2025-06-03 19:41:58.183081: Epoch time: 130.98 s 
2025-06-03 19:42:01.042594:  
2025-06-03 19:42:01.069069: Epoch 306 
2025-06-03 19:42:01.084509: Current learning rate: 0.0072 
2025-06-03 19:44:12.077305: train_loss -0.7044 
2025-06-03 19:44:12.353299: val_loss -0.6203 
2025-06-03 19:44:12.370885: Pseudo dice [np.float32(0.7034)] 
2025-06-03 19:44:12.384726: Epoch time: 131.04 s 
2025-06-03 19:44:15.838282:  
2025-06-03 19:44:15.939774: Epoch 307 
2025-06-03 19:44:15.978642: Current learning rate: 0.00719 
2025-06-03 19:46:30.558175: train_loss -0.6672 
2025-06-03 19:46:30.871020: val_loss -0.6352 
2025-06-03 19:46:30.887269: Pseudo dice [np.float32(0.6689)] 
2025-06-03 19:46:30.902458: Epoch time: 134.72 s 
2025-06-03 19:46:35.322112:  
2025-06-03 19:46:35.363619: Epoch 308 
2025-06-03 19:46:35.508678: Current learning rate: 0.00718 
2025-06-03 19:48:49.261852: train_loss -0.6809 
2025-06-03 19:48:49.288065: val_loss -0.6772 
2025-06-03 19:48:49.311187: Pseudo dice [np.float32(0.7787)] 
2025-06-03 19:48:49.325629: Epoch time: 133.94 s 
2025-06-03 19:48:54.188644:  
2025-06-03 19:48:54.249395: Epoch 309 
2025-06-03 19:48:54.285356: Current learning rate: 0.00717 
2025-06-03 19:51:08.319950: train_loss -0.6763 
2025-06-03 19:51:08.543773: val_loss -0.6691 
2025-06-03 19:51:08.642787: Pseudo dice [np.float32(0.7482)] 
2025-06-03 19:51:08.855537: Epoch time: 134.13 s 
2025-06-03 19:51:11.653649:  
2025-06-03 19:51:11.725677: Epoch 310 
2025-06-03 19:51:11.859587: Current learning rate: 0.00716 
2025-06-03 19:53:22.094695: train_loss -0.689 
2025-06-03 19:53:22.655955: val_loss -0.667 
2025-06-03 19:53:23.146487: Pseudo dice [np.float32(0.7794)] 
2025-06-03 19:53:23.638660: Epoch time: 130.44 s 
2025-06-03 19:53:23.659440: Yayy! New best EMA pseudo Dice: 0.7253000140190125 
2025-06-03 19:53:28.052335:  
2025-06-03 19:53:28.146951: Epoch 311 
2025-06-03 19:53:28.325523: Current learning rate: 0.00715 
2025-06-03 19:55:41.686487: train_loss -0.6904 
2025-06-03 19:55:42.491707: val_loss -0.6849 
2025-06-03 19:55:42.929077: Pseudo dice [np.float32(0.6985)] 
2025-06-03 19:55:42.950962: Epoch time: 133.64 s 
2025-06-03 19:55:47.001173:  
2025-06-03 19:55:47.095677: Epoch 312 
2025-06-03 19:55:47.215972: Current learning rate: 0.00714 
2025-06-03 19:57:57.925936: train_loss -0.6667 
2025-06-03 19:57:58.507858: val_loss -0.7035 
2025-06-03 19:57:59.103727: Pseudo dice [np.float32(0.8009)] 
2025-06-03 19:57:59.546176: Epoch time: 130.93 s 
2025-06-03 19:57:59.910904: Yayy! New best EMA pseudo Dice: 0.7304999828338623 
2025-06-03 19:58:03.313623:  
2025-06-03 19:58:03.576071: Epoch 313 
2025-06-03 19:58:03.745496: Current learning rate: 0.00713 
2025-06-03 20:00:17.529586: train_loss -0.684 
2025-06-03 20:00:17.550363: val_loss -0.6089 
2025-06-03 20:00:17.566773: Pseudo dice [np.float32(0.6295)] 
2025-06-03 20:00:17.583825: Epoch time: 134.22 s 
2025-06-03 20:00:20.990164:  
2025-06-03 20:00:21.125108: Epoch 314 
2025-06-03 20:00:21.165279: Current learning rate: 0.00712 
2025-06-03 20:02:30.553835: train_loss -0.6659 
2025-06-03 20:02:30.882340: val_loss -0.6304 
2025-06-03 20:02:31.229045: Pseudo dice [np.float32(0.6757)] 
2025-06-03 20:02:31.248642: Epoch time: 129.57 s 
2025-06-03 20:02:35.749164:  
2025-06-03 20:02:35.792471: Epoch 315 
2025-06-03 20:02:35.884895: Current learning rate: 0.00711 
2025-06-03 20:04:44.651732: train_loss -0.6938 
2025-06-03 20:04:45.156864: val_loss -0.6176 
2025-06-03 20:04:45.656578: Pseudo dice [np.float32(0.7104)] 
2025-06-03 20:04:45.982050: Epoch time: 128.9 s 
2025-06-03 20:04:50.091251:  
2025-06-03 20:04:50.160933: Epoch 316 
2025-06-03 20:04:50.270731: Current learning rate: 0.0071 
2025-06-03 20:06:59.293343: train_loss -0.7146 
2025-06-03 20:06:59.693739: val_loss -0.7146 
2025-06-03 20:06:59.710977: Pseudo dice [np.float32(0.7607)] 
2025-06-03 20:06:59.724059: Epoch time: 129.22 s 
2025-06-03 20:07:05.166464:  
2025-06-03 20:07:05.187844: Epoch 317 
2025-06-03 20:07:05.255158: Current learning rate: 0.0071 
2025-06-03 20:09:15.144308: train_loss -0.6807 
2025-06-03 20:09:15.585329: val_loss -0.6999 
2025-06-03 20:09:16.024529: Pseudo dice [np.float32(0.8097)] 
2025-06-03 20:09:16.547625: Epoch time: 129.98 s 
2025-06-03 20:09:20.622293:  
2025-06-03 20:09:20.717081: Epoch 318 
2025-06-03 20:09:20.827771: Current learning rate: 0.00709 
2025-06-03 20:11:26.003250: train_loss -0.671 
2025-06-03 20:11:26.029523: val_loss -0.6602 
2025-06-03 20:11:26.047987: Pseudo dice [np.float32(0.7127)] 
2025-06-03 20:11:26.063992: Epoch time: 125.38 s 
2025-06-03 20:11:33.029952:  
2025-06-03 20:11:33.111655: Epoch 319 
2025-06-03 20:11:33.157552: Current learning rate: 0.00708 
2025-06-03 20:13:43.389350: train_loss -0.6556 
2025-06-03 20:13:43.897489: val_loss -0.7061 
2025-06-03 20:13:44.390728: Pseudo dice [np.float32(0.7693)] 
2025-06-03 20:13:44.665516: Epoch time: 130.36 s 
2025-06-03 20:13:44.687208: Yayy! New best EMA pseudo Dice: 0.7315000295639038 
2025-06-03 20:13:48.854032:  
2025-06-03 20:13:49.082817: Epoch 320 
2025-06-03 20:13:49.297224: Current learning rate: 0.00707 
2025-06-03 20:15:55.913706: train_loss -0.6436 
2025-06-03 20:15:55.934547: val_loss -0.6579 
2025-06-03 20:15:55.952546: Pseudo dice [np.float32(0.8227)] 
2025-06-03 20:15:55.970230: Epoch time: 127.06 s 
2025-06-03 20:15:55.986575: Yayy! New best EMA pseudo Dice: 0.7405999898910522 
2025-06-03 20:16:00.551102:  
2025-06-03 20:16:00.570616: Epoch 321 
2025-06-03 20:16:00.587558: Current learning rate: 0.00706 
2025-06-03 20:18:09.160084: train_loss -0.6264 
2025-06-03 20:18:09.179696: val_loss -0.6701 
2025-06-03 20:18:09.195117: Pseudo dice [np.float32(0.7269)] 
2025-06-03 20:18:09.208349: Epoch time: 128.61 s 
2025-06-03 20:18:12.630497:  
2025-06-03 20:18:12.813346: Epoch 322 
2025-06-03 20:18:13.023647: Current learning rate: 0.00705 
2025-06-03 20:20:20.251764: train_loss -0.6784 
2025-06-03 20:20:20.627154: val_loss -0.6738 
2025-06-03 20:20:21.076805: Pseudo dice [np.float32(0.7148)] 
2025-06-03 20:20:21.618259: Epoch time: 127.62 s 
2025-06-03 20:20:25.631963:  
2025-06-03 20:20:25.723315: Epoch 323 
2025-06-03 20:20:25.743379: Current learning rate: 0.00704 
2025-06-03 20:22:37.055541: train_loss -0.6649 
2025-06-03 20:22:37.072913: val_loss -0.6511 
2025-06-03 20:22:37.087914: Pseudo dice [np.float32(0.728)] 
2025-06-03 20:22:37.104223: Epoch time: 131.43 s 
2025-06-03 20:22:40.961128:  
2025-06-03 20:22:40.977694: Epoch 324 
2025-06-03 20:22:40.993415: Current learning rate: 0.00703 
2025-06-03 20:24:47.218648: train_loss -0.6773 
2025-06-03 20:24:47.234813: val_loss -0.6502 
2025-06-03 20:24:47.248910: Pseudo dice [np.float32(0.7583)] 
2025-06-03 20:24:47.263293: Epoch time: 126.26 s 
2025-06-03 20:24:51.018712:  
2025-06-03 20:24:51.101797: Epoch 325 
2025-06-03 20:24:51.123394: Current learning rate: 0.00702 
2025-06-03 20:26:58.989254: train_loss -0.6826 
2025-06-03 20:26:59.014758: val_loss -0.6628 
2025-06-03 20:26:59.356116: Pseudo dice [np.float32(0.7861)] 
2025-06-03 20:26:59.860413: Epoch time: 127.97 s 
2025-06-03 20:27:00.255524: Yayy! New best EMA pseudo Dice: 0.742900013923645 
2025-06-03 20:27:05.482090:  
2025-06-03 20:27:05.575599: Epoch 326 
2025-06-03 20:27:05.732860: Current learning rate: 0.00701 
2025-06-03 20:29:17.571588: train_loss -0.6779 
2025-06-03 20:29:17.592867: val_loss -0.6685 
2025-06-03 20:29:17.609563: Pseudo dice [np.float32(0.7976)] 
2025-06-03 20:29:17.771104: Epoch time: 132.09 s 
2025-06-03 20:29:18.162751: Yayy! New best EMA pseudo Dice: 0.7483999729156494 
2025-06-03 20:29:23.045700:  
2025-06-03 20:29:23.335657: Epoch 327 
2025-06-03 20:29:23.360160: Current learning rate: 0.007 
2025-06-03 20:31:32.248542: train_loss -0.6921 
2025-06-03 20:31:32.681496: val_loss -0.6532 
2025-06-03 20:31:32.994820: Pseudo dice [np.float32(0.7481)] 
2025-06-03 20:31:33.014098: Epoch time: 129.2 s 
2025-06-03 20:31:37.105946:  
2025-06-03 20:31:37.692079: Epoch 328 
2025-06-03 20:31:37.904900: Current learning rate: 0.00699 
2025-06-03 20:33:45.181908: train_loss -0.7059 
2025-06-03 20:33:45.909624: val_loss -0.619 
2025-06-03 20:33:46.328511: Pseudo dice [np.float32(0.7527)] 
2025-06-03 20:33:46.678424: Epoch time: 128.08 s 
2025-06-03 20:33:46.960699: Yayy! New best EMA pseudo Dice: 0.7487999796867371 
2025-06-03 20:33:52.663418:  
2025-06-03 20:33:52.793912: Epoch 329 
2025-06-03 20:33:53.078748: Current learning rate: 0.00698 
2025-06-03 20:36:04.709033: train_loss -0.6791 
2025-06-03 20:36:04.986842: val_loss -0.6053 
2025-06-03 20:36:05.424342: Pseudo dice [np.float32(0.7211)] 
2025-06-03 20:36:05.713668: Epoch time: 132.05 s 
2025-06-03 20:36:09.770112:  
2025-06-03 20:36:10.120904: Epoch 330 
2025-06-03 20:36:10.141886: Current learning rate: 0.00697 
2025-06-03 20:38:18.581749: train_loss -0.6655 
2025-06-03 20:38:18.599172: val_loss -0.6721 
2025-06-03 20:38:18.614563: Pseudo dice [np.float32(0.7153)] 
2025-06-03 20:38:18.630121: Epoch time: 128.81 s 
2025-06-03 20:38:20.520247:  
2025-06-03 20:38:20.533936: Epoch 331 
2025-06-03 20:38:20.546107: Current learning rate: 0.00696 
2025-06-03 20:40:32.023928: train_loss -0.6802 
2025-06-03 20:40:32.044639: val_loss -0.5545 
2025-06-03 20:40:32.058681: Pseudo dice [np.float32(0.6254)] 
2025-06-03 20:40:32.073641: Epoch time: 131.5 s 
2025-06-03 20:40:34.559544:  
2025-06-03 20:40:34.626920: Epoch 332 
2025-06-03 20:40:34.684508: Current learning rate: 0.00696 
2025-06-03 20:42:46.499437: train_loss -0.6646 
2025-06-03 20:42:46.520361: val_loss -0.7013 
2025-06-03 20:42:46.537745: Pseudo dice [np.float32(0.8118)] 
2025-06-03 20:42:46.554385: Epoch time: 131.94 s 
2025-06-03 20:42:49.578384:  
2025-06-03 20:42:49.608959: Epoch 333 
2025-06-03 20:42:49.624861: Current learning rate: 0.00695 
2025-06-03 20:44:53.764532: train_loss -0.6687 
2025-06-03 20:44:53.790643: val_loss -0.6782 
2025-06-03 20:44:53.808030: Pseudo dice [np.float32(0.7501)] 
2025-06-03 20:44:53.825030: Epoch time: 124.19 s 
2025-06-03 20:44:57.823812:  
2025-06-03 20:44:57.946366: Epoch 334 
2025-06-03 20:44:58.204874: Current learning rate: 0.00694 
2025-06-03 20:47:11.186862: train_loss -0.671 
2025-06-03 20:47:11.414989: val_loss -0.6264 
2025-06-03 20:47:11.659998: Pseudo dice [np.float32(0.6999)] 
2025-06-03 20:47:11.921489: Epoch time: 133.37 s 
2025-06-03 20:47:14.471546:  
2025-06-03 20:47:14.529279: Epoch 335 
2025-06-03 20:47:14.706302: Current learning rate: 0.00693 
2025-06-03 20:49:30.153940: train_loss -0.6782 
2025-06-03 20:49:30.317679: val_loss -0.6678 
2025-06-03 20:49:30.610652: Pseudo dice [np.float32(0.7067)] 
2025-06-03 20:49:30.726547: Epoch time: 135.69 s 
2025-06-03 20:49:33.934079:  
2025-06-03 20:49:34.123886: Epoch 336 
2025-06-03 20:49:34.171858: Current learning rate: 0.00692 
2025-06-03 20:51:45.069856: train_loss -0.6613 
2025-06-03 20:51:45.421000: val_loss -0.6674 
2025-06-03 20:51:45.622627: Pseudo dice [np.float32(0.7737)] 
2025-06-03 20:51:45.908028: Epoch time: 131.14 s 
2025-06-03 20:51:48.687065:  
2025-06-03 20:51:48.812365: Epoch 337 
2025-06-03 20:51:48.960522: Current learning rate: 0.00691 
2025-06-03 20:54:00.769420: train_loss -0.697 
2025-06-03 20:54:00.791341: val_loss -0.664 
2025-06-03 20:54:00.806976: Pseudo dice [np.float32(0.7338)] 
2025-06-03 20:54:00.821987: Epoch time: 132.09 s 
2025-06-03 20:54:04.078679:  
2025-06-03 20:54:04.097565: Epoch 338 
2025-06-03 20:54:04.115430: Current learning rate: 0.0069 
2025-06-03 20:56:16.995507: train_loss -0.6804 
2025-06-03 20:56:17.238701: val_loss -0.6155 
2025-06-03 20:56:17.512656: Pseudo dice [np.float32(0.6767)] 
2025-06-03 20:56:17.533112: Epoch time: 132.92 s 
2025-06-03 20:56:20.464616:  
2025-06-03 20:56:20.481007: Epoch 339 
2025-06-03 20:56:20.495207: Current learning rate: 0.00689 
2025-06-03 20:58:35.337599: train_loss -0.687 
2025-06-03 20:58:35.352223: val_loss -0.6131 
2025-06-03 20:58:35.369410: Pseudo dice [np.float32(0.6359)] 
2025-06-03 20:58:35.385069: Epoch time: 134.87 s 
2025-06-03 20:58:39.545686:  
2025-06-03 20:58:39.699183: Epoch 340 
2025-06-03 20:58:39.777364: Current learning rate: 0.00688 
2025-06-03 21:00:52.501878: train_loss -0.678 
2025-06-03 21:00:52.837385: val_loss -0.6793 
2025-06-03 21:00:53.476446: Pseudo dice [np.float32(0.7214)] 
2025-06-03 21:00:53.632696: Epoch time: 132.96 s 
2025-06-03 21:00:57.361496:  
2025-06-03 21:00:57.406791: Epoch 341 
2025-06-03 21:00:57.452937: Current learning rate: 0.00687 
2025-06-03 21:03:06.413981: train_loss -0.6845 
2025-06-03 21:03:06.433703: val_loss -0.6213 
2025-06-03 21:03:06.450296: Pseudo dice [np.float32(0.6769)] 
2025-06-03 21:03:06.623425: Epoch time: 129.05 s 
2025-06-03 21:03:09.717389:  
2025-06-03 21:03:09.739393: Epoch 342 
2025-06-03 21:03:09.757075: Current learning rate: 0.00686 
2025-06-03 21:05:22.352404: train_loss -0.6776 
2025-06-03 21:05:22.372154: val_loss -0.6248 
2025-06-03 21:05:22.389422: Pseudo dice [np.float32(0.7036)] 
2025-06-03 21:05:22.407551: Epoch time: 132.64 s 
2025-06-03 21:05:26.329207:  
2025-06-03 21:05:26.383451: Epoch 343 
2025-06-03 21:05:26.404220: Current learning rate: 0.00685 
2025-06-03 21:07:33.779231: train_loss -0.6546 
2025-06-03 21:07:33.802950: val_loss -0.6616 
2025-06-03 21:07:33.819340: Pseudo dice [np.float32(0.6892)] 
2025-06-03 21:07:33.835387: Epoch time: 127.45 s 
2025-06-03 21:07:39.115641:  
2025-06-03 21:07:39.346503: Epoch 344 
2025-06-03 21:07:39.530209: Current learning rate: 0.00684 
2025-06-03 21:09:49.976280: train_loss -0.6716 
2025-06-03 21:09:50.529609: val_loss -0.63 
2025-06-03 21:09:51.035222: Pseudo dice [np.float32(0.7474)] 
2025-06-03 21:09:51.545650: Epoch time: 130.86 s 
2025-06-03 21:09:56.294832:  
2025-06-03 21:09:56.447826: Epoch 345 
2025-06-03 21:09:56.645880: Current learning rate: 0.00683 
2025-06-03 21:12:08.135076: train_loss -0.6666 
2025-06-03 21:12:08.567353: val_loss -0.6866 
2025-06-03 21:12:08.951259: Pseudo dice [np.float32(0.7172)] 
2025-06-03 21:12:09.342206: Epoch time: 131.84 s 
2025-06-03 21:12:14.050357:  
2025-06-03 21:12:14.076132: Epoch 346 
2025-06-03 21:12:14.123072: Current learning rate: 0.00682 
2025-06-03 21:14:19.532364: train_loss -0.6796 
2025-06-03 21:14:19.559299: val_loss -0.6664 
2025-06-03 21:14:19.586924: Pseudo dice [np.float32(0.7805)] 
2025-06-03 21:14:19.614856: Epoch time: 125.48 s 
2025-06-03 21:14:24.313575:  
2025-06-03 21:14:24.537905: Epoch 347 
2025-06-03 21:14:24.607726: Current learning rate: 0.00681 
2025-06-03 21:16:31.644760: train_loss -0.6752 
2025-06-03 21:16:31.668434: val_loss -0.6067 
2025-06-03 21:16:31.683838: Pseudo dice [np.float32(0.5792)] 
2025-06-03 21:16:31.701978: Epoch time: 127.33 s 
2025-06-03 21:16:37.362975:  
2025-06-03 21:16:37.422024: Epoch 348 
2025-06-03 21:16:37.441119: Current learning rate: 0.0068 
2025-06-03 21:18:45.935947: train_loss -0.6842 
2025-06-03 21:18:45.961049: val_loss -0.6803 
2025-06-03 21:18:46.248059: Pseudo dice [np.float32(0.7854)] 
2025-06-03 21:18:46.726365: Epoch time: 128.58 s 
2025-06-03 21:18:51.045990:  
2025-06-03 21:18:51.065196: Epoch 349 
2025-06-03 21:18:51.082585: Current learning rate: 0.0068 
2025-06-03 21:21:01.916705: train_loss -0.685 
2025-06-03 21:21:02.181747: val_loss -0.6286 
2025-06-03 21:21:02.475399: Pseudo dice [np.float32(0.6465)] 
2025-06-03 21:21:02.776770: Epoch time: 130.87 s 
2025-06-03 21:21:06.248174:  
2025-06-03 21:21:06.277228: Epoch 350 
2025-06-03 21:21:06.305988: Current learning rate: 0.00679 
2025-06-03 21:23:13.937046: train_loss -0.693 
2025-06-03 21:23:13.960304: val_loss -0.6101 
2025-06-03 21:23:13.976333: Pseudo dice [np.float32(0.6929)] 
2025-06-03 21:23:13.992555: Epoch time: 127.69 s 
2025-06-03 21:23:18.053036:  
2025-06-03 21:23:18.078710: Epoch 351 
2025-06-03 21:23:18.101714: Current learning rate: 0.00678 
2025-06-03 21:25:25.978140: train_loss -0.6782 
2025-06-03 21:25:26.003083: val_loss -0.6841 
2025-06-03 21:25:26.025898: Pseudo dice [np.float32(0.7473)] 
2025-06-03 21:25:26.042544: Epoch time: 127.93 s 
2025-06-03 21:25:30.164471:  
2025-06-03 21:25:30.186170: Epoch 352 
2025-06-03 21:25:30.204466: Current learning rate: 0.00677 
2025-06-03 21:27:39.334666: train_loss -0.6603 
2025-06-03 21:27:39.354317: val_loss -0.6679 
2025-06-03 21:27:39.372367: Pseudo dice [np.float32(0.7343)] 
2025-06-03 21:27:39.390461: Epoch time: 129.17 s 
2025-06-03 21:27:46.679494:  
2025-06-03 21:27:46.698961: Epoch 353 
2025-06-03 21:27:46.716046: Current learning rate: 0.00676 
2025-06-03 21:29:56.603483: train_loss -0.6602 
2025-06-03 21:29:56.625884: val_loss -0.6456 
2025-06-03 21:29:56.646216: Pseudo dice [np.float32(0.6721)] 
2025-06-03 21:29:56.663346: Epoch time: 129.93 s 
2025-06-03 21:30:02.567852:  
2025-06-03 21:30:02.587625: Epoch 354 
2025-06-03 21:30:02.651051: Current learning rate: 0.00675 
2025-06-03 21:32:14.414369: train_loss -0.6852 
2025-06-03 21:32:14.943111: val_loss -0.731 
2025-06-03 21:32:15.501151: Pseudo dice [np.float32(0.8008)] 
2025-06-03 21:32:15.879568: Epoch time: 131.86 s 
2025-06-03 21:32:19.419790:  
2025-06-03 21:32:19.433443: Epoch 355 
2025-06-03 21:32:19.447455: Current learning rate: 0.00674 
2025-06-03 21:34:25.552373: train_loss -0.6842 
2025-06-03 21:34:25.568536: val_loss -0.685 
2025-06-03 21:34:25.584717: Pseudo dice [np.float32(0.7333)] 
2025-06-03 21:34:25.598301: Epoch time: 126.14 s 
2025-06-03 21:34:29.709648:  
2025-06-03 21:34:29.728266: Epoch 356 
2025-06-03 21:34:29.765691: Current learning rate: 0.00673 
2025-06-03 21:36:37.160630: train_loss -0.6424 
2025-06-03 21:36:37.178435: val_loss -0.6137 
2025-06-03 21:36:37.196461: Pseudo dice [np.float32(0.682)] 
2025-06-03 21:36:37.212654: Epoch time: 127.45 s 
2025-06-03 21:36:39.142318:  
2025-06-03 21:36:39.158231: Epoch 357 
2025-06-03 21:36:39.173871: Current learning rate: 0.00672 
2025-06-03 21:38:48.541893: train_loss -0.707 
2025-06-03 21:38:48.753389: val_loss -0.6608 
2025-06-03 21:38:48.983788: Pseudo dice [np.float32(0.7326)] 
2025-06-03 21:38:49.178613: Epoch time: 129.4 s 
2025-06-03 21:38:51.886505:  
2025-06-03 21:38:51.903076: Epoch 358 
2025-06-03 21:38:51.919149: Current learning rate: 0.00671 
2025-06-03 21:41:03.941046: train_loss -0.7018 
2025-06-03 21:41:04.173230: val_loss -0.6825 
2025-06-03 21:41:04.325116: Pseudo dice [np.float32(0.8051)] 
2025-06-03 21:41:04.348418: Epoch time: 132.06 s 
2025-06-03 21:41:07.302796:  
2025-06-03 21:41:07.525257: Epoch 359 
2025-06-03 21:41:07.720868: Current learning rate: 0.0067 
2025-06-03 21:43:19.030617: train_loss -0.6798 
2025-06-03 21:43:19.053689: val_loss -0.6335 
2025-06-03 21:43:19.069588: Pseudo dice [np.float32(0.6434)] 
2025-06-03 21:43:19.084631: Epoch time: 131.73 s 
2025-06-03 21:43:21.854621:  
2025-06-03 21:43:21.922062: Epoch 360 
2025-06-03 21:43:21.940503: Current learning rate: 0.00669 
2025-06-03 21:45:33.483591: train_loss -0.6571 
2025-06-03 21:45:33.746425: val_loss -0.6551 
2025-06-03 21:45:33.761976: Pseudo dice [np.float32(0.6608)] 
2025-06-03 21:45:33.780145: Epoch time: 131.63 s 
2025-06-03 21:45:37.417638:  
2025-06-03 21:45:37.440801: Epoch 361 
2025-06-03 21:45:37.459232: Current learning rate: 0.00668 
2025-06-03 21:47:48.327045: train_loss -0.6759 
2025-06-03 21:47:48.846886: val_loss -0.698 
2025-06-03 21:47:49.267740: Pseudo dice [np.float32(0.7743)] 
2025-06-03 21:47:49.682007: Epoch time: 130.91 s 
2025-06-03 21:47:52.765536:  
2025-06-03 21:47:52.789246: Epoch 362 
2025-06-03 21:47:52.862164: Current learning rate: 0.00667 
2025-06-03 21:50:08.603196: train_loss -0.6899 
2025-06-03 21:50:08.630900: val_loss -0.6774 
2025-06-03 21:50:08.649177: Pseudo dice [np.float32(0.7615)] 
2025-06-03 21:50:08.998677: Epoch time: 135.84 s 
2025-06-03 21:50:14.548074:  
2025-06-03 21:50:14.604513: Epoch 363 
2025-06-03 21:50:14.765040: Current learning rate: 0.00666 
2025-06-03 21:52:27.888145: train_loss -0.6662 
2025-06-03 21:52:28.500152: val_loss -0.6246 
2025-06-03 21:52:28.965032: Pseudo dice [np.float32(0.6563)] 
2025-06-03 21:52:28.984667: Epoch time: 133.35 s 
2025-06-03 21:52:33.613368:  
2025-06-03 21:52:33.682496: Epoch 364 
2025-06-03 21:52:33.809640: Current learning rate: 0.00665 
2025-06-03 21:54:45.836013: train_loss -0.6822 
2025-06-03 21:54:46.386085: val_loss -0.6654 
2025-06-03 21:54:46.826098: Pseudo dice [np.float32(0.7551)] 
2025-06-03 21:54:47.231590: Epoch time: 132.22 s 
2025-06-03 21:54:52.188198:  
2025-06-03 21:54:52.330600: Epoch 365 
2025-06-03 21:54:52.492926: Current learning rate: 0.00665 
2025-06-03 21:57:04.781477: train_loss -0.669 
2025-06-03 21:57:05.071522: val_loss -0.6291 
2025-06-03 21:57:05.416588: Pseudo dice [np.float32(0.6814)] 
2025-06-03 21:57:05.435804: Epoch time: 132.6 s 
2025-06-03 21:57:10.513869:  
2025-06-03 21:57:10.576855: Epoch 366 
2025-06-03 21:57:10.594592: Current learning rate: 0.00664 
2025-06-03 21:59:24.510879: train_loss -0.6742 
2025-06-03 21:59:24.914868: val_loss -0.628 
2025-06-03 21:59:24.939561: Pseudo dice [np.float32(0.6142)] 
2025-06-03 21:59:24.955789: Epoch time: 134.0 s 
2025-06-03 21:59:27.533143:  
2025-06-03 21:59:27.553439: Epoch 367 
2025-06-03 21:59:27.574296: Current learning rate: 0.00663 
2025-06-03 22:01:39.260427: train_loss -0.6682 
2025-06-03 22:01:39.284595: val_loss -0.6661 
2025-06-03 22:01:39.451582: Pseudo dice [np.float32(0.7066)] 
2025-06-03 22:01:39.640050: Epoch time: 131.73 s 
2025-06-03 22:01:42.833107:  
2025-06-03 22:01:42.860919: Epoch 368 
2025-06-03 22:01:42.907372: Current learning rate: 0.00662 
2025-06-03 22:03:53.194748: train_loss -0.621 
2025-06-03 22:03:53.663887: val_loss -0.6819 
2025-06-03 22:03:54.466719: Pseudo dice [np.float32(0.6892)] 
2025-06-03 22:03:54.770316: Epoch time: 130.36 s 
2025-06-03 22:03:57.986576:  
2025-06-03 22:03:58.007065: Epoch 369 
2025-06-03 22:03:58.025237: Current learning rate: 0.00661 
2025-06-03 22:06:08.339931: train_loss -0.6424 
2025-06-03 22:06:08.940234: val_loss -0.6232 
2025-06-03 22:06:09.383902: Pseudo dice [np.float32(0.7261)] 
2025-06-03 22:06:09.543984: Epoch time: 130.36 s 
2025-06-03 22:06:12.810365:  
2025-06-03 22:06:12.833184: Epoch 370 
2025-06-03 22:06:12.852504: Current learning rate: 0.0066 
2025-06-03 22:08:26.242949: train_loss -0.6664 
2025-06-03 22:08:26.266650: val_loss -0.6236 
2025-06-03 22:08:26.281886: Pseudo dice [np.float32(0.7026)] 
2025-06-03 22:08:26.297954: Epoch time: 133.43 s 
2025-06-03 22:08:29.137033:  
2025-06-03 22:08:29.293239: Epoch 371 
2025-06-03 22:08:29.572338: Current learning rate: 0.00659 
2025-06-03 22:10:37.117669: train_loss -0.6851 
2025-06-03 22:10:37.139440: val_loss -0.6227 
2025-06-03 22:10:37.156981: Pseudo dice [np.float32(0.684)] 
2025-06-03 22:10:37.173490: Epoch time: 127.98 s 
2025-06-03 22:10:41.012657:  
2025-06-03 22:10:41.045804: Epoch 372 
2025-06-03 22:10:41.138016: Current learning rate: 0.00658 
2025-06-03 22:12:52.999839: train_loss -0.6663 
2025-06-03 22:12:53.016439: val_loss -0.6573 
2025-06-03 22:12:53.034048: Pseudo dice [np.float32(0.7719)] 
2025-06-03 22:12:53.052463: Epoch time: 131.99 s 
2025-06-03 22:12:57.085854:  
2025-06-03 22:12:57.187814: Epoch 373 
2025-06-03 22:12:57.293238: Current learning rate: 0.00657 
2025-06-03 22:15:12.882866: train_loss -0.6613 
2025-06-03 22:15:12.904593: val_loss -0.6594 
2025-06-03 22:15:12.922129: Pseudo dice [np.float32(0.7639)] 
2025-06-03 22:15:12.938200: Epoch time: 135.8 s 
2025-06-03 22:15:16.725007:  
2025-06-03 22:15:16.742289: Epoch 374 
2025-06-03 22:15:16.756781: Current learning rate: 0.00656 
2025-06-03 22:17:27.310560: train_loss -0.6869 
2025-06-03 22:17:27.328991: val_loss -0.7165 
2025-06-03 22:17:27.347034: Pseudo dice [np.float32(0.8323)] 
2025-06-03 22:17:27.364970: Epoch time: 130.59 s 
2025-06-03 22:17:30.600435:  
2025-06-03 22:17:30.663863: Epoch 375 
2025-06-03 22:17:30.692533: Current learning rate: 0.00655 
2025-06-03 22:19:42.823840: train_loss -0.693 
2025-06-03 22:19:43.158348: val_loss -0.6446 
2025-06-03 22:19:43.517850: Pseudo dice [np.float32(0.7597)] 
2025-06-03 22:19:43.927356: Epoch time: 132.23 s 
2025-06-03 22:19:47.557871:  
2025-06-03 22:19:47.659835: Epoch 376 
2025-06-03 22:19:47.798752: Current learning rate: 0.00654 
2025-06-03 22:21:56.681518: train_loss -0.6721 
2025-06-03 22:21:56.984199: val_loss -0.5846 
2025-06-03 22:21:57.003181: Pseudo dice [np.float32(0.5827)] 
2025-06-03 22:21:57.021710: Epoch time: 129.13 s 
2025-06-03 22:22:02.192590:  
2025-06-03 22:22:02.344401: Epoch 377 
2025-06-03 22:22:02.627680: Current learning rate: 0.00653 
2025-06-03 22:24:13.147247: train_loss -0.6747 
2025-06-03 22:24:13.166033: val_loss -0.6916 
2025-06-03 22:24:13.184314: Pseudo dice [np.float32(0.7818)] 
2025-06-03 22:24:13.200531: Epoch time: 130.96 s 
2025-06-03 22:24:17.834803:  
2025-06-03 22:24:17.935814: Epoch 378 
2025-06-03 22:24:18.207335: Current learning rate: 0.00652 
2025-06-03 22:26:26.141599: train_loss -0.6812 
2025-06-03 22:26:26.308529: val_loss -0.6766 
2025-06-03 22:26:26.589828: Pseudo dice [np.float32(0.8051)] 
2025-06-03 22:26:26.908186: Epoch time: 128.31 s 
2025-06-03 22:26:29.651315:  
2025-06-03 22:26:29.682887: Epoch 379 
2025-06-03 22:26:29.704140: Current learning rate: 0.00651 
2025-06-03 22:28:37.489885: train_loss -0.6858 
2025-06-03 22:28:37.508354: val_loss -0.7045 
2025-06-03 22:28:37.526911: Pseudo dice [np.float32(0.7333)] 
2025-06-03 22:28:37.544105: Epoch time: 127.84 s 
2025-06-03 22:28:39.341642:  
2025-06-03 22:28:39.366992: Epoch 380 
2025-06-03 22:28:39.389396: Current learning rate: 0.0065 
2025-06-03 22:30:50.933666: train_loss -0.6854 
2025-06-03 22:30:51.312026: val_loss -0.6702 
2025-06-03 22:30:51.507277: Pseudo dice [np.float32(0.7515)] 
2025-06-03 22:30:51.528981: Epoch time: 131.59 s 
2025-06-03 22:30:54.089059:  
2025-06-03 22:30:54.103001: Epoch 381 
2025-06-03 22:30:54.114964: Current learning rate: 0.00649 
2025-06-03 22:33:03.036006: train_loss -0.7092 
2025-06-03 22:33:03.253247: val_loss -0.6524 
2025-06-03 22:33:03.474566: Pseudo dice [np.float32(0.6682)] 
2025-06-03 22:33:03.669626: Epoch time: 128.95 s 
2025-06-03 22:33:06.240753:  
2025-06-03 22:33:06.302692: Epoch 382 
2025-06-03 22:33:06.321617: Current learning rate: 0.00648 
2025-06-03 22:35:14.470234: train_loss -0.6808 
2025-06-03 22:35:14.729508: val_loss -0.6775 
2025-06-03 22:35:14.983344: Pseudo dice [np.float32(0.7162)] 
2025-06-03 22:35:15.190596: Epoch time: 128.23 s 
2025-06-03 22:35:18.318546:  
2025-06-03 22:35:18.343326: Epoch 383 
2025-06-03 22:35:18.360262: Current learning rate: 0.00648 
2025-06-03 22:37:27.605852: train_loss -0.6785 
2025-06-03 22:37:27.829752: val_loss -0.7235 
2025-06-03 22:37:28.217511: Pseudo dice [np.float32(0.8226)] 
2025-06-03 22:37:28.586079: Epoch time: 129.29 s 
2025-06-03 22:37:32.121295:  
2025-06-03 22:37:32.144664: Epoch 384 
2025-06-03 22:37:32.163483: Current learning rate: 0.00647 
2025-06-03 22:39:45.183996: train_loss -0.7074 
2025-06-03 22:39:45.475720: val_loss -0.6653 
2025-06-03 22:39:45.862877: Pseudo dice [np.float32(0.7236)] 
2025-06-03 22:39:46.183765: Epoch time: 133.08 s 
2025-06-03 22:39:50.098065:  
2025-06-03 22:39:50.121132: Epoch 385 
2025-06-03 22:39:50.139601: Current learning rate: 0.00646 
2025-06-03 22:42:01.848045: train_loss -0.6835 
2025-06-03 22:42:01.868718: val_loss -0.6959 
2025-06-03 22:42:01.885986: Pseudo dice [np.float32(0.7597)] 
2025-06-03 22:42:01.903678: Epoch time: 131.75 s 
2025-06-03 22:42:05.435178:  
2025-06-03 22:42:05.548996: Epoch 386 
2025-06-03 22:42:05.882002: Current learning rate: 0.00645 
2025-06-03 22:44:19.109798: train_loss -0.6856 
2025-06-03 22:44:19.232579: val_loss -0.6738 
2025-06-03 22:44:19.250963: Pseudo dice [np.float32(0.8486)] 
2025-06-03 22:44:19.268832: Epoch time: 133.68 s 
2025-06-03 22:44:21.998587:  
2025-06-03 22:44:22.040725: Epoch 387 
2025-06-03 22:44:22.085289: Current learning rate: 0.00644 
2025-06-03 22:46:35.998901: train_loss -0.6514 
2025-06-03 22:46:36.016391: val_loss -0.7039 
2025-06-03 22:46:36.034092: Pseudo dice [np.float32(0.7599)] 
2025-06-03 22:46:36.322070: Epoch time: 134.0 s 
2025-06-03 22:46:36.761003: Yayy! New best EMA pseudo Dice: 0.7491000294685364 
2025-06-03 22:46:42.797053:  
2025-06-03 22:46:43.046292: Epoch 388 
2025-06-03 22:46:43.276543: Current learning rate: 0.00643 
2025-06-03 22:48:56.798181: train_loss -0.6729 
2025-06-03 22:48:56.927693: val_loss -0.6278 
2025-06-03 22:48:57.191173: Pseudo dice [np.float32(0.6955)] 
2025-06-03 22:48:57.502922: Epoch time: 134.0 s 
2025-06-03 22:49:00.772055:  
2025-06-03 22:49:01.006380: Epoch 389 
2025-06-03 22:49:01.256471: Current learning rate: 0.00642 
2025-06-03 22:51:17.379634: train_loss -0.6675 
2025-06-03 22:51:17.401153: val_loss -0.645 
2025-06-03 22:51:17.416520: Pseudo dice [np.float32(0.7813)] 
2025-06-03 22:51:17.433289: Epoch time: 136.61 s 
2025-06-03 22:51:20.259501:  
2025-06-03 22:51:20.322194: Epoch 390 
2025-06-03 22:51:20.393953: Current learning rate: 0.00641 
2025-06-03 22:53:30.233516: train_loss -0.6835 
2025-06-03 22:53:30.249953: val_loss -0.6532 
2025-06-03 22:53:30.267653: Pseudo dice [np.float32(0.6988)] 
2025-06-03 22:53:30.494011: Epoch time: 129.98 s 
2025-06-03 22:53:33.638175:  
2025-06-03 22:53:33.723583: Epoch 391 
2025-06-03 22:53:33.915115: Current learning rate: 0.0064 
2025-06-03 22:55:43.278860: train_loss -0.6706 
2025-06-03 22:55:43.662636: val_loss -0.589 
2025-06-03 22:55:44.215022: Pseudo dice [np.float32(0.713)] 
2025-06-03 22:55:44.661481: Epoch time: 129.64 s 
2025-06-03 22:55:49.306754:  
2025-06-03 22:55:49.452215: Epoch 392 
2025-06-03 22:55:49.827845: Current learning rate: 0.00639 
2025-06-03 22:58:00.565151: train_loss -0.6802 
2025-06-03 22:58:01.065001: val_loss -0.6261 
2025-06-03 22:58:01.597871: Pseudo dice [np.float32(0.7101)] 
2025-06-03 22:58:02.070863: Epoch time: 131.26 s 
2025-06-03 22:58:05.963509:  
2025-06-03 22:58:06.141108: Epoch 393 
2025-06-03 22:58:06.202946: Current learning rate: 0.00638 
2025-06-03 23:00:15.086763: train_loss -0.6828 
2025-06-03 23:00:15.106745: val_loss -0.6227 
2025-06-03 23:00:15.126150: Pseudo dice [np.float32(0.6875)] 
2025-06-03 23:00:15.142678: Epoch time: 129.13 s 
2025-06-03 23:00:19.961503:  
2025-06-03 23:00:20.165316: Epoch 394 
2025-06-03 23:00:20.421592: Current learning rate: 0.00637 
2025-06-03 23:02:28.206686: train_loss -0.6408 
2025-06-03 23:02:28.383936: val_loss -0.6965 
2025-06-03 23:02:28.409707: Pseudo dice [np.float32(0.7553)] 
2025-06-03 23:02:28.431558: Epoch time: 128.25 s 
2025-06-03 23:02:31.604457:  
2025-06-03 23:02:31.630653: Epoch 395 
2025-06-03 23:02:31.650967: Current learning rate: 0.00636 
2025-06-03 23:04:41.208050: train_loss -0.7243 
2025-06-03 23:04:41.230634: val_loss -0.644 
2025-06-03 23:04:41.248649: Pseudo dice [np.float32(0.772)] 
2025-06-03 23:04:41.402572: Epoch time: 129.61 s 
2025-06-03 23:04:45.046237:  
2025-06-03 23:04:45.229769: Epoch 396 
2025-06-03 23:04:45.401981: Current learning rate: 0.00635 
2025-06-03 23:06:58.657554: train_loss -0.7008 
2025-06-03 23:06:59.043273: val_loss -0.657 
2025-06-03 23:06:59.385871: Pseudo dice [np.float32(0.7598)] 
2025-06-03 23:06:59.624036: Epoch time: 133.61 s 
2025-06-03 23:07:03.270988:  
2025-06-03 23:07:03.305211: Epoch 397 
2025-06-03 23:07:03.411095: Current learning rate: 0.00634 
2025-06-03 23:09:10.630614: train_loss -0.6811 
2025-06-03 23:09:11.061368: val_loss -0.7008 
2025-06-03 23:09:11.532377: Pseudo dice [np.float32(0.7254)] 
2025-06-03 23:09:11.894114: Epoch time: 127.36 s 
2025-06-03 23:09:15.515343:  
2025-06-03 23:09:15.578590: Epoch 398 
2025-06-03 23:09:15.682920: Current learning rate: 0.00633 
2025-06-03 23:11:26.184961: train_loss -0.698 
2025-06-03 23:11:26.340379: val_loss -0.7094 
2025-06-03 23:11:26.358436: Pseudo dice [np.float32(0.7692)] 
2025-06-03 23:11:26.373035: Epoch time: 130.67 s 
2025-06-03 23:11:30.464995:  
2025-06-03 23:11:30.597430: Epoch 399 
2025-06-03 23:11:30.787789: Current learning rate: 0.00632 
2025-06-03 23:13:42.914099: train_loss -0.6954 
2025-06-03 23:13:42.935014: val_loss -0.6496 
2025-06-03 23:13:42.951955: Pseudo dice [np.float32(0.7664)] 
2025-06-03 23:13:42.968390: Epoch time: 132.45 s 
2025-06-03 23:13:46.653064:  
2025-06-03 23:13:46.876215: Epoch 400 
2025-06-03 23:13:47.032365: Current learning rate: 0.00631 
2025-06-03 23:15:57.834982: train_loss -0.6827 
2025-06-03 23:15:58.126719: val_loss -0.6497 
2025-06-03 23:15:58.729806: Pseudo dice [np.float32(0.741)] 
2025-06-03 23:15:59.368176: Epoch time: 131.18 s 
2025-06-03 23:16:03.262592:  
2025-06-03 23:16:03.384467: Epoch 401 
2025-06-03 23:16:03.443465: Current learning rate: 0.0063 
2025-06-03 23:18:14.492810: train_loss -0.6916 
2025-06-03 23:18:14.513892: val_loss -0.6001 
2025-06-03 23:18:14.883226: Pseudo dice [np.float32(0.6972)] 
2025-06-03 23:18:15.223252: Epoch time: 131.23 s 
2025-06-03 23:18:18.173900:  
2025-06-03 23:18:18.205746: Epoch 402 
2025-06-03 23:18:18.221392: Current learning rate: 0.0063 
2025-06-03 23:20:28.546728: train_loss -0.6816 
2025-06-03 23:20:28.963932: val_loss -0.6547 
2025-06-03 23:20:28.981765: Pseudo dice [np.float32(0.6811)] 
2025-06-03 23:20:29.168286: Epoch time: 130.37 s 
2025-06-03 23:20:34.074058:  
2025-06-03 23:20:34.131343: Epoch 403 
2025-06-03 23:20:34.148573: Current learning rate: 0.00629 
2025-06-03 23:22:45.227316: train_loss -0.6621 
2025-06-03 23:22:45.690180: val_loss -0.7161 
2025-06-03 23:22:46.210387: Pseudo dice [np.float32(0.7607)] 
2025-06-03 23:22:46.719642: Epoch time: 131.16 s 
2025-06-03 23:22:52.514000:  
2025-06-03 23:22:52.732658: Epoch 404 
2025-06-03 23:22:52.771016: Current learning rate: 0.00628 
2025-06-03 23:24:58.783545: train_loss -0.687 
2025-06-03 23:24:58.805578: val_loss -0.6926 
2025-06-03 23:24:58.823545: Pseudo dice [np.float32(0.7078)] 
2025-06-03 23:24:58.839420: Epoch time: 126.27 s 
2025-06-03 23:25:04.178896:  
2025-06-03 23:25:04.547524: Epoch 405 
2025-06-03 23:25:04.676255: Current learning rate: 0.00627 
2025-06-03 23:27:11.231765: train_loss -0.6702 
2025-06-03 23:27:11.251701: val_loss -0.6765 
2025-06-03 23:27:11.267526: Pseudo dice [np.float32(0.7798)] 
2025-06-03 23:27:11.283319: Epoch time: 127.06 s 
2025-06-03 23:27:18.450757:  
2025-06-03 23:27:18.471895: Epoch 406 
2025-06-03 23:27:18.494080: Current learning rate: 0.00626 
2025-06-03 23:29:24.834368: train_loss -0.6641 
2025-06-03 23:29:24.856611: val_loss -0.6863 
2025-06-03 23:29:24.871455: Pseudo dice [np.float32(0.7818)] 
2025-06-03 23:29:24.886913: Epoch time: 126.38 s 
2025-06-03 23:29:26.602224:  
2025-06-03 23:29:26.707866: Epoch 407 
2025-06-03 23:29:26.748940: Current learning rate: 0.00625 
2025-06-03 23:31:33.677664: train_loss -0.6934 
2025-06-03 23:31:33.839518: val_loss -0.6773 
2025-06-03 23:31:34.112588: Pseudo dice [np.float32(0.7603)] 
2025-06-03 23:31:34.427781: Epoch time: 127.08 s 
2025-06-03 23:31:40.486543:  
2025-06-03 23:31:40.557860: Epoch 408 
2025-06-03 23:31:40.577266: Current learning rate: 0.00624 
2025-06-03 23:33:52.122919: train_loss -0.674 
2025-06-03 23:33:52.142267: val_loss -0.6612 
2025-06-03 23:33:52.160055: Pseudo dice [np.float32(0.8155)] 
2025-06-03 23:33:52.176367: Epoch time: 131.64 s 
2025-06-03 23:33:52.189676: Yayy! New best EMA pseudo Dice: 0.7512999773025513 
2025-06-03 23:33:56.746414:  
2025-06-03 23:33:56.766841: Epoch 409 
2025-06-03 23:33:56.787008: Current learning rate: 0.00623 
2025-06-03 23:36:06.598869: train_loss -0.6844 
2025-06-03 23:36:06.847258: val_loss -0.6743 
2025-06-03 23:36:07.053756: Pseudo dice [np.float32(0.818)] 
2025-06-03 23:36:07.408996: Epoch time: 129.85 s 
2025-06-03 23:36:07.602037: Yayy! New best EMA pseudo Dice: 0.7578999996185303 
2025-06-03 23:36:11.284262:  
2025-06-03 23:36:11.353531: Epoch 410 
2025-06-03 23:36:11.389445: Current learning rate: 0.00622 
2025-06-03 23:38:19.473383: train_loss -0.6786 
2025-06-03 23:38:19.492267: val_loss -0.6621 
2025-06-03 23:38:19.509075: Pseudo dice [np.float32(0.6956)] 
2025-06-03 23:38:19.525895: Epoch time: 128.19 s 
2025-06-03 23:38:22.364941:  
2025-06-03 23:38:22.417967: Epoch 411 
2025-06-03 23:38:22.441726: Current learning rate: 0.00621 
2025-06-03 23:40:33.682341: train_loss -0.6667 
2025-06-03 23:40:34.035645: val_loss -0.6605 
2025-06-03 23:40:34.386781: Pseudo dice [np.float32(0.7534)] 
2025-06-03 23:40:34.686491: Epoch time: 131.32 s 
2025-06-03 23:40:38.448206:  
2025-06-03 23:40:38.537168: Epoch 412 
2025-06-03 23:40:38.597489: Current learning rate: 0.0062 
2025-06-03 23:42:50.013021: train_loss -0.6702 
2025-06-03 23:42:50.343571: val_loss -0.6679 
2025-06-03 23:42:50.723482: Pseudo dice [np.float32(0.6681)] 
2025-06-03 23:42:51.089778: Epoch time: 131.57 s 
2025-06-03 23:42:55.437628:  
2025-06-03 23:42:55.647151: Epoch 413 
2025-06-03 23:42:55.865619: Current learning rate: 0.00619 
2025-06-03 23:45:10.043629: train_loss -0.69 
2025-06-03 23:45:10.370993: val_loss -0.6953 
2025-06-03 23:45:10.392948: Pseudo dice [np.float32(0.771)] 
2025-06-03 23:45:10.524287: Epoch time: 134.61 s 
2025-06-03 23:45:13.176969:  
2025-06-03 23:45:13.240144: Epoch 414 
2025-06-03 23:45:13.309186: Current learning rate: 0.00618 
2025-06-03 23:47:24.454478: train_loss -0.6819 
2025-06-03 23:47:24.602027: val_loss -0.6569 
2025-06-03 23:47:24.617504: Pseudo dice [np.float32(0.6718)] 
2025-06-03 23:47:24.635402: Epoch time: 131.28 s 
2025-06-03 23:47:29.151323:  
2025-06-03 23:47:29.221266: Epoch 415 
2025-06-03 23:47:29.269812: Current learning rate: 0.00617 
2025-06-03 23:49:46.139574: train_loss -0.6657 
2025-06-03 23:49:46.896106: val_loss -0.6358 
2025-06-03 23:49:47.195185: Pseudo dice [np.float32(0.6481)] 
2025-06-03 23:49:47.215814: Epoch time: 136.99 s 
2025-06-03 23:49:49.830297:  
2025-06-03 23:49:49.850454: Epoch 416 
2025-06-03 23:49:49.868558: Current learning rate: 0.00616 
2025-06-03 23:52:02.658872: train_loss -0.6741 
2025-06-03 23:52:02.680571: val_loss -0.6519 
2025-06-03 23:52:02.956555: Pseudo dice [np.float32(0.7382)] 
2025-06-03 23:52:03.282398: Epoch time: 132.83 s 
2025-06-03 23:52:07.136140:  
2025-06-03 23:52:07.220368: Epoch 417 
2025-06-03 23:52:07.239399: Current learning rate: 0.00615 
2025-06-03 23:54:21.691584: train_loss -0.6797 
2025-06-03 23:54:22.267013: val_loss -0.6339 
2025-06-03 23:54:22.400396: Pseudo dice [np.float32(0.6927)] 
2025-06-03 23:54:22.417518: Epoch time: 134.56 s 
2025-06-03 23:54:26.909275:  
2025-06-03 23:54:26.929381: Epoch 418 
2025-06-03 23:54:26.949309: Current learning rate: 0.00614 
2025-06-03 23:56:38.254977: train_loss -0.6783 
2025-06-03 23:56:38.276019: val_loss -0.6035 
2025-06-03 23:56:38.371155: Pseudo dice [np.float32(0.6186)] 
2025-06-03 23:56:38.568129: Epoch time: 131.35 s 
2025-06-03 23:56:42.157690:  
2025-06-03 23:56:42.181962: Epoch 419 
2025-06-03 23:56:42.204841: Current learning rate: 0.00613 
2025-06-03 23:58:52.271482: train_loss -0.6494 
2025-06-03 23:58:52.753016: val_loss -0.648 
2025-06-03 23:58:53.394784: Pseudo dice [np.float32(0.7294)] 
2025-06-03 23:58:53.914236: Epoch time: 130.12 s 
2025-06-03 23:58:56.707951:  
2025-06-03 23:58:56.728336: Epoch 420 
2025-06-03 23:58:56.747620: Current learning rate: 0.00612 
2025-06-04 00:01:07.243297: train_loss -0.6959 
2025-06-04 00:01:07.536022: val_loss -0.5998 
2025-06-04 00:01:07.998800: Pseudo dice [np.float32(0.6438)] 
2025-06-04 00:01:08.819309: Epoch time: 130.54 s 
2025-06-04 00:01:12.206125:  
2025-06-04 00:01:12.224396: Epoch 421 
2025-06-04 00:01:12.242978: Current learning rate: 0.00612 
2025-06-04 00:03:23.529149: train_loss -0.6702 
2025-06-04 00:03:23.556539: val_loss -0.6884 
2025-06-04 00:03:23.573683: Pseudo dice [np.float32(0.7334)] 
2025-06-04 00:03:23.591153: Epoch time: 131.32 s 
2025-06-04 00:03:28.062915:  
2025-06-04 00:03:28.156747: Epoch 422 
2025-06-04 00:03:28.176827: Current learning rate: 0.00611 
2025-06-04 00:05:40.045573: train_loss -0.6804 
2025-06-04 00:05:40.068046: val_loss -0.7113 
2025-06-04 00:05:40.083871: Pseudo dice [np.float32(0.78)] 
2025-06-04 00:05:40.100774: Epoch time: 131.98 s 
2025-06-04 00:05:44.695324:  
2025-06-04 00:05:44.720922: Epoch 423 
2025-06-04 00:05:44.809151: Current learning rate: 0.0061 
2025-06-04 00:07:56.578034: train_loss -0.6867 
2025-06-04 00:07:56.986531: val_loss -0.6799 
2025-06-04 00:07:57.415142: Pseudo dice [np.float32(0.7271)] 
2025-06-04 00:07:57.842616: Epoch time: 131.88 s 
2025-06-04 00:08:00.994567:  
2025-06-04 00:08:01.066860: Epoch 424 
2025-06-04 00:08:01.163537: Current learning rate: 0.00609 
2025-06-04 00:10:10.271564: train_loss -0.6681 
2025-06-04 00:10:10.406552: val_loss -0.6805 
2025-06-04 00:10:10.427583: Pseudo dice [np.float32(0.8005)] 
2025-06-04 00:10:10.456151: Epoch time: 129.28 s 
2025-06-04 00:10:16.683140:  
2025-06-04 00:10:16.699614: Epoch 425 
2025-06-04 00:10:16.717086: Current learning rate: 0.00608 
2025-06-04 00:12:28.379109: train_loss -0.6819 
2025-06-04 00:12:28.733807: val_loss -0.6396 
2025-06-04 00:12:29.004109: Pseudo dice [np.float32(0.6204)] 
2025-06-04 00:12:29.025286: Epoch time: 131.81 s 
2025-06-04 00:12:33.676318:  
2025-06-04 00:12:33.854563: Epoch 426 
2025-06-04 00:12:33.890495: Current learning rate: 0.00607 
2025-06-04 00:14:46.634428: train_loss -0.6827 
2025-06-04 00:14:46.656885: val_loss -0.7051 
2025-06-04 00:14:46.673729: Pseudo dice [np.float32(0.6906)] 
2025-06-04 00:14:46.691269: Epoch time: 132.96 s 
2025-06-04 00:14:51.377582:  
2025-06-04 00:14:51.398877: Epoch 427 
2025-06-04 00:14:51.612779: Current learning rate: 0.00606 
2025-06-04 00:16:57.797376: train_loss -0.6932 
2025-06-04 00:16:58.200963: val_loss -0.6458 
2025-06-04 00:16:58.622529: Pseudo dice [np.float32(0.645)] 
2025-06-04 00:16:58.641831: Epoch time: 126.42 s 
2025-06-04 00:17:03.321687:  
2025-06-04 00:17:03.382098: Epoch 428 
2025-06-04 00:17:03.404506: Current learning rate: 0.00605 
2025-06-04 00:19:07.531791: train_loss -0.6618 
2025-06-04 00:19:07.559806: val_loss -0.6431 
2025-06-04 00:19:07.578458: Pseudo dice [np.float32(0.7471)] 
2025-06-04 00:19:07.593379: Epoch time: 124.21 s 
2025-06-04 00:19:12.675203:  
2025-06-04 00:19:12.836331: Epoch 429 
2025-06-04 00:19:12.906040: Current learning rate: 0.00604 
2025-06-04 00:21:16.528095: train_loss -0.679 
2025-06-04 00:21:16.735956: val_loss -0.6559 
2025-06-04 00:21:16.946773: Pseudo dice [np.float32(0.7113)] 
2025-06-04 00:21:17.143092: Epoch time: 123.85 s 
2025-06-04 00:21:19.854787:  
2025-06-04 00:21:19.873396: Epoch 430 
2025-06-04 00:21:19.890071: Current learning rate: 0.00603 
2025-06-04 00:23:32.706157: train_loss -0.6914 
2025-06-04 00:23:32.725422: val_loss -0.6528 
2025-06-04 00:23:32.741993: Pseudo dice [np.float32(0.7997)] 
2025-06-04 00:23:32.757310: Epoch time: 132.85 s 
2025-06-04 00:23:34.895106:  
2025-06-04 00:23:34.923387: Epoch 431 
2025-06-04 00:23:34.936381: Current learning rate: 0.00602 
2025-06-04 00:25:46.386581: train_loss -0.6753 
2025-06-04 00:25:46.407617: val_loss -0.6559 
2025-06-04 00:25:46.426037: Pseudo dice [np.float32(0.7389)] 
2025-06-04 00:25:46.444315: Epoch time: 131.49 s 
2025-06-04 00:25:49.795003:  
2025-06-04 00:25:49.818388: Epoch 432 
2025-06-04 00:25:49.839647: Current learning rate: 0.00601 
2025-06-04 00:27:57.665418: train_loss -0.6784 
2025-06-04 00:27:57.681855: val_loss -0.6576 
2025-06-04 00:27:57.699795: Pseudo dice [np.float32(0.6888)] 
2025-06-04 00:27:57.715314: Epoch time: 127.87 s 
2025-06-04 00:28:00.558372:  
2025-06-04 00:28:00.578404: Epoch 433 
2025-06-04 00:28:00.595706: Current learning rate: 0.006 
2025-06-04 00:30:04.549662: train_loss -0.6766 
2025-06-04 00:30:04.914046: val_loss -0.6499 
2025-06-04 00:30:05.922305: Pseudo dice [np.float32(0.7543)] 
2025-06-04 00:30:06.033104: Epoch time: 123.99 s 
2025-06-04 00:30:09.158237:  
2025-06-04 00:30:09.200149: Epoch 434 
2025-06-04 00:30:09.234046: Current learning rate: 0.00599 
2025-06-04 00:32:20.357939: train_loss -0.6679 
2025-06-04 00:32:20.588801: val_loss -0.604 
2025-06-04 00:32:20.606634: Pseudo dice [np.float32(0.6369)] 
2025-06-04 00:32:20.624340: Epoch time: 131.2 s 
2025-06-04 00:32:23.891159:  
2025-06-04 00:32:23.911367: Epoch 435 
2025-06-04 00:32:23.933120: Current learning rate: 0.00598 
2025-06-04 00:34:36.535595: train_loss -0.6719 
2025-06-04 00:34:36.891114: val_loss -0.6733 
2025-06-04 00:34:37.092847: Pseudo dice [np.float32(0.6978)] 
2025-06-04 00:34:37.355297: Epoch time: 132.65 s 
2025-06-04 00:34:40.412981:  
2025-06-04 00:34:40.711094: Epoch 436 
2025-06-04 00:34:40.979976: Current learning rate: 0.00597 
2025-06-04 00:36:49.884073: train_loss -0.6743 
2025-06-04 00:36:50.063733: val_loss -0.6573 
2025-06-04 00:36:50.271419: Pseudo dice [np.float32(0.7699)] 
2025-06-04 00:36:50.739977: Epoch time: 129.47 s 
2025-06-04 00:36:52.906864:  
2025-06-04 00:36:52.927771: Epoch 437 
2025-06-04 00:36:52.942725: Current learning rate: 0.00596 
2025-06-04 00:39:05.369416: train_loss -0.6698 
2025-06-04 00:39:05.645399: val_loss -0.6387 
2025-06-04 00:39:05.852424: Pseudo dice [np.float32(0.7852)] 
2025-06-04 00:39:05.871073: Epoch time: 132.46 s 
2025-06-04 00:39:08.664569:  
2025-06-04 00:39:08.680925: Epoch 438 
2025-06-04 00:39:08.696141: Current learning rate: 0.00595 
2025-06-04 00:41:25.470329: train_loss -0.6678 
2025-06-04 00:41:25.491353: val_loss -0.6543 
2025-06-04 00:41:25.508885: Pseudo dice [np.float32(0.7644)] 
2025-06-04 00:41:25.526158: Epoch time: 136.81 s 
2025-06-04 00:41:28.525635:  
2025-06-04 00:41:28.546932: Epoch 439 
2025-06-04 00:41:28.564465: Current learning rate: 0.00594 
2025-06-04 00:43:42.476822: train_loss -0.6665 
2025-06-04 00:43:42.850731: val_loss -0.6372 
2025-06-04 00:43:43.387501: Pseudo dice [np.float32(0.7343)] 
2025-06-04 00:43:43.781488: Epoch time: 133.95 s 
2025-06-04 00:43:46.435954:  
2025-06-04 00:43:46.455451: Epoch 440 
2025-06-04 00:43:46.470259: Current learning rate: 0.00593 
2025-06-04 00:45:56.166972: train_loss -0.6523 
2025-06-04 00:45:56.188563: val_loss -0.649 
2025-06-04 00:45:56.204670: Pseudo dice [np.float32(0.6959)] 
2025-06-04 00:45:56.222586: Epoch time: 129.73 s 
2025-06-04 00:46:00.234594:  
2025-06-04 00:46:00.258412: Epoch 441 
2025-06-04 00:46:00.301710: Current learning rate: 0.00592 
2025-06-04 00:48:15.178133: train_loss -0.6628 
2025-06-04 00:48:15.381520: val_loss -0.6476 
2025-06-04 00:48:15.398986: Pseudo dice [np.float32(0.7743)] 
2025-06-04 00:48:15.417146: Epoch time: 134.95 s 
2025-06-04 00:48:19.254149:  
2025-06-04 00:48:19.343948: Epoch 442 
2025-06-04 00:48:19.551569: Current learning rate: 0.00592 
2025-06-04 00:50:35.892264: train_loss -0.6955 
2025-06-04 00:50:35.913210: val_loss -0.699 
2025-06-04 00:50:35.928329: Pseudo dice [np.float32(0.7797)] 
2025-06-04 00:50:35.945838: Epoch time: 136.64 s 
2025-06-04 00:50:39.437623:  
2025-06-04 00:50:39.600897: Epoch 443 
2025-06-04 00:50:39.676280: Current learning rate: 0.00591 
2025-06-04 00:52:48.387406: train_loss -0.6493 
2025-06-04 00:52:48.410453: val_loss -0.6709 
2025-06-04 00:52:48.688627: Pseudo dice [np.float32(0.7555)] 
2025-06-04 00:52:48.710686: Epoch time: 128.95 s 
2025-06-04 00:52:54.646631:  
2025-06-04 00:52:54.698966: Epoch 444 
2025-06-04 00:52:54.748051: Current learning rate: 0.0059 
2025-06-04 00:55:06.438001: train_loss -0.6605 
2025-06-04 00:55:06.814941: val_loss -0.6704 
2025-06-04 00:55:07.383883: Pseudo dice [np.float32(0.6889)] 
2025-06-04 00:55:07.619139: Epoch time: 131.79 s 
2025-06-04 00:55:11.476619:  
2025-06-04 00:55:11.797975: Epoch 445 
2025-06-04 00:55:11.868597: Current learning rate: 0.00589 
2025-06-04 00:57:21.973722: train_loss -0.6738 
2025-06-04 00:57:21.993182: val_loss -0.668 
2025-06-04 00:57:22.008970: Pseudo dice [np.float32(0.6894)] 
2025-06-04 00:57:22.025996: Epoch time: 130.5 s 
2025-06-04 00:57:26.002677:  
2025-06-04 00:57:26.065815: Epoch 446 
2025-06-04 00:57:26.093100: Current learning rate: 0.00588 
2025-06-04 00:59:35.237759: train_loss -0.6619 
2025-06-04 00:59:35.536066: val_loss -0.6608 
2025-06-04 00:59:36.054764: Pseudo dice [np.float32(0.7143)] 
2025-06-04 00:59:36.601825: Epoch time: 129.24 s 
2025-06-04 00:59:40.114102:  
2025-06-04 00:59:40.223912: Epoch 447 
2025-06-04 00:59:40.276356: Current learning rate: 0.00587 
2025-06-04 01:01:50.423827: train_loss -0.6779 
2025-06-04 01:01:50.797913: val_loss -0.6106 
2025-06-04 01:01:51.329268: Pseudo dice [np.float32(0.7133)] 
2025-06-04 01:01:51.926256: Epoch time: 130.31 s 
2025-06-04 01:01:55.183725:  
2025-06-04 01:01:55.334294: Epoch 448 
2025-06-04 01:01:55.411084: Current learning rate: 0.00586 
2025-06-04 01:04:07.852808: train_loss -0.6974 
2025-06-04 01:04:07.877649: val_loss -0.6072 
2025-06-04 01:04:08.078694: Pseudo dice [np.float32(0.7511)] 
2025-06-04 01:04:08.262225: Epoch time: 132.67 s 
2025-06-04 01:04:11.914665:  
2025-06-04 01:04:11.937485: Epoch 449 
2025-06-04 01:04:11.959438: Current learning rate: 0.00585 
2025-06-04 01:06:24.873083: train_loss -0.6996 
2025-06-04 01:06:25.127631: val_loss -0.6855 
2025-06-04 01:06:25.586343: Pseudo dice [np.float32(0.6933)] 
2025-06-04 01:06:25.958598: Epoch time: 132.96 s 
2025-06-04 01:06:29.334902:  
2025-06-04 01:06:29.605008: Epoch 450 
2025-06-04 01:06:29.780236: Current learning rate: 0.00584 
2025-06-04 01:08:41.370660: train_loss -0.6989 
2025-06-04 01:08:41.654066: val_loss -0.6418 
2025-06-04 01:08:41.826975: Pseudo dice [np.float32(0.6979)] 
2025-06-04 01:08:41.885631: Epoch time: 132.04 s 
2025-06-04 01:08:44.376085:  
2025-06-04 01:08:44.632956: Epoch 451 
2025-06-04 01:08:44.862435: Current learning rate: 0.00583 
2025-06-04 01:10:58.020955: train_loss -0.6913 
2025-06-04 01:10:58.041910: val_loss -0.6362 
2025-06-04 01:10:58.063643: Pseudo dice [np.float32(0.7398)] 
2025-06-04 01:10:58.083450: Epoch time: 133.65 s 
2025-06-04 01:11:01.278656:  
2025-06-04 01:11:01.369433: Epoch 452 
2025-06-04 01:11:01.530236: Current learning rate: 0.00582 
2025-06-04 01:13:08.120560: train_loss -0.7037 
2025-06-04 01:13:08.689173: val_loss -0.6648 
2025-06-04 01:13:09.044793: Pseudo dice [np.float32(0.7946)] 
2025-06-04 01:13:09.063138: Epoch time: 126.84 s 
2025-06-04 01:13:13.064973:  
2025-06-04 01:13:13.088149: Epoch 453 
2025-06-04 01:13:13.113266: Current learning rate: 0.00581 
2025-06-04 01:15:22.558680: train_loss -0.691 
2025-06-04 01:15:22.875019: val_loss -0.6647 
2025-06-04 01:15:23.323899: Pseudo dice [np.float32(0.6689)] 
2025-06-04 01:15:23.775867: Epoch time: 129.5 s 
2025-06-04 01:15:27.135774:  
2025-06-04 01:15:27.169575: Epoch 454 
2025-06-04 01:15:27.202211: Current learning rate: 0.0058 
2025-06-04 01:17:36.656940: train_loss -0.6811 
2025-06-04 01:17:36.678062: val_loss -0.7177 
2025-06-04 01:17:36.743202: Pseudo dice [np.float32(0.8066)] 
2025-06-04 01:17:36.759234: Epoch time: 129.52 s 
2025-06-04 01:17:41.649454:  
2025-06-04 01:17:41.676878: Epoch 455 
2025-06-04 01:17:41.699640: Current learning rate: 0.00579 
2025-06-04 01:19:54.692901: train_loss -0.6838 
2025-06-04 01:19:55.166513: val_loss -0.7007 
2025-06-04 01:19:55.602749: Pseudo dice [np.float32(0.7689)] 
2025-06-04 01:19:56.004927: Epoch time: 133.05 s 
2025-06-04 01:19:59.196154:  
2025-06-04 01:19:59.217065: Epoch 456 
2025-06-04 01:19:59.254918: Current learning rate: 0.00578 
2025-06-04 01:22:04.400274: train_loss -0.6998 
2025-06-04 01:22:04.568712: val_loss -0.6943 
2025-06-04 01:22:04.898703: Pseudo dice [np.float32(0.7775)] 
2025-06-04 01:22:04.918011: Epoch time: 125.25 s 
2025-06-04 01:22:08.722363:  
2025-06-04 01:22:08.746366: Epoch 457 
2025-06-04 01:22:08.768542: Current learning rate: 0.00577 
2025-06-04 01:24:18.310477: train_loss -0.7 
2025-06-04 01:24:18.643906: val_loss -0.6387 
2025-06-04 01:24:18.963826: Pseudo dice [np.float32(0.7347)] 
2025-06-04 01:24:19.290651: Epoch time: 129.59 s 
2025-06-04 01:24:21.321943:  
2025-06-04 01:24:21.340905: Epoch 458 
2025-06-04 01:24:21.363356: Current learning rate: 0.00576 
2025-06-04 01:26:31.284068: train_loss -0.6738 
2025-06-04 01:26:31.306722: val_loss -0.6841 
2025-06-04 01:26:31.321220: Pseudo dice [np.float32(0.7149)] 
2025-06-04 01:26:31.336675: Epoch time: 129.96 s 
2025-06-04 01:26:35.348441:  
2025-06-04 01:26:35.367455: Epoch 459 
2025-06-04 01:26:35.382313: Current learning rate: 0.00575 
2025-06-04 01:28:45.283667: train_loss -0.6838 
2025-06-04 01:28:45.666755: val_loss -0.7245 
2025-06-04 01:28:45.874933: Pseudo dice [np.float32(0.7398)] 
2025-06-04 01:28:45.894540: Epoch time: 129.94 s 
2025-06-04 01:28:48.864146:  
2025-06-04 01:28:48.944404: Epoch 460 
2025-06-04 01:28:49.046690: Current learning rate: 0.00574 
2025-06-04 01:30:56.676108: train_loss -0.6827 
2025-06-04 01:30:57.063074: val_loss -0.6674 
2025-06-04 01:30:57.387453: Pseudo dice [np.float32(0.7741)] 
2025-06-04 01:30:57.600677: Epoch time: 127.81 s 
2025-06-04 01:31:01.834871:  
2025-06-04 01:31:01.869749: Epoch 461 
2025-06-04 01:31:01.948502: Current learning rate: 0.00573 
2025-06-04 01:33:14.504872: train_loss -0.6986 
2025-06-04 01:33:14.936713: val_loss -0.6743 
2025-06-04 01:33:15.265790: Pseudo dice [np.float32(0.7674)] 
2025-06-04 01:33:15.527225: Epoch time: 132.67 s 
2025-06-04 01:33:18.564070:  
2025-06-04 01:33:18.651954: Epoch 462 
2025-06-04 01:33:18.686283: Current learning rate: 0.00572 
2025-06-04 01:35:30.806235: train_loss -0.6998 
2025-06-04 01:35:31.037423: val_loss -0.6744 
2025-06-04 01:35:31.056523: Pseudo dice [np.float32(0.7211)] 
2025-06-04 01:35:31.073977: Epoch time: 132.24 s 
2025-06-04 01:35:33.918376:  
2025-06-04 01:35:33.971061: Epoch 463 
2025-06-04 01:35:33.989421: Current learning rate: 0.00571 
2025-06-04 01:37:49.795047: train_loss -0.7107 
2025-06-04 01:37:50.147914: val_loss -0.6526 
2025-06-04 01:37:50.166758: Pseudo dice [np.float32(0.7651)] 
2025-06-04 01:37:50.180591: Epoch time: 135.88 s 
2025-06-04 01:37:52.767214:  
2025-06-04 01:37:52.926262: Epoch 464 
2025-06-04 01:37:53.050415: Current learning rate: 0.0057 
2025-06-04 01:40:05.119448: train_loss -0.7043 
2025-06-04 01:40:05.147659: val_loss -0.649 
2025-06-04 01:40:05.165123: Pseudo dice [np.float32(0.7489)] 
2025-06-04 01:40:05.181331: Epoch time: 132.35 s 
2025-06-04 01:40:09.320472:  
2025-06-04 01:40:09.410858: Epoch 465 
2025-06-04 01:40:09.555015: Current learning rate: 0.0057 
2025-06-04 01:42:22.691571: train_loss -0.703 
2025-06-04 01:42:22.865885: val_loss -0.7177 
2025-06-04 01:42:22.885228: Pseudo dice [np.float32(0.7475)] 
2025-06-04 01:42:22.901061: Epoch time: 133.37 s 
2025-06-04 01:42:27.047083:  
2025-06-04 01:42:27.063702: Epoch 466 
2025-06-04 01:42:27.086130: Current learning rate: 0.00569 
2025-06-04 01:44:36.076419: train_loss -0.6875 
2025-06-04 01:44:36.214837: val_loss -0.6258 
2025-06-04 01:44:36.231723: Pseudo dice [np.float32(0.7092)] 
2025-06-04 01:44:36.586378: Epoch time: 129.03 s 
2025-06-04 01:44:41.575561:  
2025-06-04 01:44:41.720755: Epoch 467 
2025-06-04 01:44:41.807716: Current learning rate: 0.00568 
2025-06-04 01:46:49.926226: train_loss -0.6834 
2025-06-04 01:46:49.952491: val_loss -0.6391 
2025-06-04 01:46:49.970962: Pseudo dice [np.float32(0.7008)] 
2025-06-04 01:46:49.987918: Epoch time: 128.35 s 
2025-06-04 01:46:54.791306:  
2025-06-04 01:46:54.811945: Epoch 468 
2025-06-04 01:46:54.832364: Current learning rate: 0.00567 
2025-06-04 01:49:04.847984: train_loss -0.685 
2025-06-04 01:49:05.282837: val_loss -0.6864 
2025-06-04 01:49:05.799264: Pseudo dice [np.float32(0.6899)] 
2025-06-04 01:49:06.262659: Epoch time: 130.06 s 
2025-06-04 01:49:09.839516:  
2025-06-04 01:49:10.015968: Epoch 469 
2025-06-04 01:49:10.039736: Current learning rate: 0.00566 
2025-06-04 01:51:20.132061: train_loss -0.6968 
2025-06-04 01:51:20.158925: val_loss -0.7022 
2025-06-04 01:51:20.176210: Pseudo dice [np.float32(0.7436)] 
2025-06-04 01:51:20.193607: Epoch time: 130.3 s 
2025-06-04 01:51:25.842648:  
2025-06-04 01:51:25.932634: Epoch 470 
2025-06-04 01:51:25.953413: Current learning rate: 0.00565 
2025-06-04 01:53:35.467797: train_loss -0.7025 
2025-06-04 01:53:35.700489: val_loss -0.6313 
2025-06-04 01:53:36.121300: Pseudo dice [np.float32(0.7049)] 
2025-06-04 01:53:36.653444: Epoch time: 129.63 s 
2025-06-04 01:53:42.951349:  
2025-06-04 01:53:43.240601: Epoch 471 
2025-06-04 01:53:43.310550: Current learning rate: 0.00564 
2025-06-04 01:55:53.721383: train_loss -0.6526 
2025-06-04 01:55:54.044239: val_loss -0.5914 
2025-06-04 01:55:54.065264: Pseudo dice [np.float32(0.6006)] 
2025-06-04 01:55:54.453614: Epoch time: 130.77 s 
2025-06-04 01:55:59.919151:  
2025-06-04 01:55:59.963515: Epoch 472 
2025-06-04 01:55:59.981699: Current learning rate: 0.00563 
2025-06-04 01:58:13.338801: train_loss -0.6606 
2025-06-04 01:58:13.514005: val_loss -0.6301 
2025-06-04 01:58:13.537631: Pseudo dice [np.float32(0.6787)] 
2025-06-04 01:58:13.554895: Epoch time: 133.42 s 
2025-06-04 01:58:18.554572:  
2025-06-04 01:58:18.655908: Epoch 473 
2025-06-04 01:58:18.775842: Current learning rate: 0.00562 
2025-06-04 02:00:30.606187: train_loss -0.6721 
2025-06-04 02:00:31.125939: val_loss -0.6008 
2025-06-04 02:00:31.714046: Pseudo dice [np.float32(0.596)] 
2025-06-04 02:00:31.890118: Epoch time: 132.05 s 
2025-06-04 02:00:35.887493:  
2025-06-04 02:00:35.910268: Epoch 474 
2025-06-04 02:00:35.928354: Current learning rate: 0.00561 
2025-06-04 02:02:49.146469: train_loss -0.6882 
2025-06-04 02:02:49.176343: val_loss -0.5891 
2025-06-04 02:02:49.523617: Pseudo dice [np.float32(0.6494)] 
2025-06-04 02:02:49.970469: Epoch time: 133.26 s 
2025-06-04 02:02:55.803586:  
2025-06-04 02:02:56.058661: Epoch 475 
2025-06-04 02:02:56.336343: Current learning rate: 0.0056 
2025-06-04 02:05:06.474139: train_loss -0.6843 
2025-06-04 02:05:06.498090: val_loss -0.6867 
2025-06-04 02:05:06.516390: Pseudo dice [np.float32(0.7415)] 
2025-06-04 02:05:06.532695: Epoch time: 130.67 s 
2025-06-04 02:05:09.816687:  
2025-06-04 02:05:09.837506: Epoch 476 
2025-06-04 02:05:09.855439: Current learning rate: 0.00559 
2025-06-04 02:07:19.953104: train_loss -0.6735 
2025-06-04 02:07:20.362321: val_loss -0.6485 
2025-06-04 02:07:20.702313: Pseudo dice [np.float32(0.6921)] 
2025-06-04 02:07:20.720229: Epoch time: 130.14 s 
2025-06-04 02:07:24.807547:  
2025-06-04 02:07:24.829612: Epoch 477 
2025-06-04 02:07:24.848482: Current learning rate: 0.00558 
2025-06-04 02:09:30.886004: train_loss -0.6596 
2025-06-04 02:09:30.911679: val_loss -0.6914 
2025-06-04 02:09:30.928761: Pseudo dice [np.float32(0.7819)] 
2025-06-04 02:09:30.947603: Epoch time: 126.08 s 
2025-06-04 02:09:35.538285:  
2025-06-04 02:09:35.565900: Epoch 478 
2025-06-04 02:09:35.587519: Current learning rate: 0.00557 
2025-06-04 02:11:44.583196: train_loss -0.6986 
2025-06-04 02:11:44.606653: val_loss -0.6984 
2025-06-04 02:11:44.623638: Pseudo dice [np.float32(0.8056)] 
2025-06-04 02:11:44.638832: Epoch time: 129.05 s 
2025-06-04 02:11:47.629232:  
2025-06-04 02:11:47.648032: Epoch 479 
2025-06-04 02:11:47.671276: Current learning rate: 0.00556 
2025-06-04 02:13:58.099722: train_loss -0.684 
2025-06-04 02:13:58.118469: val_loss -0.6461 
2025-06-04 02:13:58.135219: Pseudo dice [np.float32(0.7517)] 
2025-06-04 02:13:58.151467: Epoch time: 130.47 s 
2025-06-04 02:14:00.457633:  
2025-06-04 02:14:00.478323: Epoch 480 
2025-06-04 02:14:00.490836: Current learning rate: 0.00555 
2025-06-04 02:16:10.263555: train_loss -0.6779 
2025-06-04 02:16:10.525081: val_loss -0.6381 
2025-06-04 02:16:10.777370: Pseudo dice [np.float32(0.6907)] 
2025-06-04 02:16:11.091479: Epoch time: 129.81 s 
2025-06-04 02:16:13.687000:  
2025-06-04 02:16:13.739453: Epoch 481 
2025-06-04 02:16:13.859241: Current learning rate: 0.00554 
2025-06-04 02:18:25.511780: train_loss -0.7131 
2025-06-04 02:18:25.859117: val_loss -0.6309 
2025-06-04 02:18:26.159844: Pseudo dice [np.float32(0.747)] 
2025-06-04 02:18:26.447478: Epoch time: 131.83 s 
2025-06-04 02:18:28.708224:  
2025-06-04 02:18:28.796170: Epoch 482 
2025-06-04 02:18:28.987465: Current learning rate: 0.00553 
2025-06-04 02:20:38.115232: train_loss -0.7089 
2025-06-04 02:20:38.141320: val_loss -0.6611 
2025-06-04 02:20:38.308005: Pseudo dice [np.float32(0.7731)] 
2025-06-04 02:20:38.516044: Epoch time: 129.41 s 
2025-06-04 02:20:44.620720:  
2025-06-04 02:20:44.640992: Epoch 483 
2025-06-04 02:20:44.657465: Current learning rate: 0.00552 
2025-06-04 02:22:52.731465: train_loss -0.6731 
2025-06-04 02:22:52.899986: val_loss -0.6213 
2025-06-04 02:22:53.142379: Pseudo dice [np.float32(0.748)] 
2025-06-04 02:22:53.340008: Epoch time: 128.11 s 
2025-06-04 02:22:55.480790:  
2025-06-04 02:22:55.601577: Epoch 484 
2025-06-04 02:22:55.693601: Current learning rate: 0.00551 
2025-06-04 02:25:08.819108: train_loss -0.6883 
2025-06-04 02:25:09.352412: val_loss -0.637 
2025-06-04 02:25:09.662079: Pseudo dice [np.float32(0.7269)] 
2025-06-04 02:25:10.100855: Epoch time: 133.34 s 
2025-06-04 02:25:12.797337:  
2025-06-04 02:25:12.836529: Epoch 485 
2025-06-04 02:25:12.861433: Current learning rate: 0.0055 
2025-06-04 02:27:27.605518: train_loss -0.6819 
2025-06-04 02:27:27.626133: val_loss -0.6825 
2025-06-04 02:27:27.644739: Pseudo dice [np.float32(0.7739)] 
2025-06-04 02:27:27.662709: Epoch time: 134.81 s 
2025-06-04 02:27:30.865852:  
2025-06-04 02:27:30.884574: Epoch 486 
2025-06-04 02:27:30.901466: Current learning rate: 0.00549 
2025-06-04 02:29:40.022038: train_loss -0.6966 
2025-06-04 02:29:40.047508: val_loss -0.6174 
2025-06-04 02:29:40.069392: Pseudo dice [np.float32(0.7146)] 
2025-06-04 02:29:40.083300: Epoch time: 129.16 s 
2025-06-04 02:29:44.671428:  
2025-06-04 02:29:44.780150: Epoch 487 
2025-06-04 02:29:44.912290: Current learning rate: 0.00548 
2025-06-04 02:31:55.778773: train_loss -0.6717 
2025-06-04 02:31:56.125892: val_loss -0.67 
2025-06-04 02:31:56.504070: Pseudo dice [np.float32(0.8157)] 
2025-06-04 02:31:56.767916: Epoch time: 131.11 s 
2025-06-04 02:31:59.539725:  
2025-06-04 02:31:59.646128: Epoch 488 
2025-06-04 02:31:59.691459: Current learning rate: 0.00547 
2025-06-04 02:34:10.955028: train_loss -0.6891 
2025-06-04 02:34:10.987318: val_loss -0.6857 
2025-06-04 02:34:11.008416: Pseudo dice [np.float32(0.7903)] 
2025-06-04 02:34:11.250674: Epoch time: 131.42 s 
2025-06-04 02:34:13.995922:  
2025-06-04 02:34:14.065929: Epoch 489 
2025-06-04 02:34:14.102300: Current learning rate: 0.00546 
2025-06-04 02:36:23.822699: train_loss -0.6914 
2025-06-04 02:36:24.215902: val_loss -0.6437 
2025-06-04 02:36:24.235044: Pseudo dice [np.float32(0.6719)] 
2025-06-04 02:36:24.252526: Epoch time: 129.83 s 
2025-06-04 02:36:27.945860:  
2025-06-04 02:36:27.967854: Epoch 490 
2025-06-04 02:36:27.984284: Current learning rate: 0.00546 
2025-06-04 02:38:38.147317: train_loss -0.6661 
2025-06-04 02:38:38.176678: val_loss -0.6822 
2025-06-04 02:38:38.200375: Pseudo dice [np.float32(0.7773)] 
2025-06-04 02:38:38.218462: Epoch time: 130.2 s 
2025-06-04 02:38:43.996872:  
2025-06-04 02:38:44.120602: Epoch 491 
2025-06-04 02:38:44.383429: Current learning rate: 0.00545 
2025-06-04 02:40:52.908746: train_loss -0.674 
2025-06-04 02:40:53.400799: val_loss -0.6778 
2025-06-04 02:40:53.874215: Pseudo dice [np.float32(0.7463)] 
2025-06-04 02:40:54.054639: Epoch time: 128.91 s 
2025-06-04 02:40:58.827839:  
2025-06-04 02:40:58.852940: Epoch 492 
2025-06-04 02:40:58.875955: Current learning rate: 0.00544 
2025-06-04 02:43:10.617814: train_loss -0.6742 
2025-06-04 02:43:10.640272: val_loss -0.6516 
2025-06-04 02:43:10.660202: Pseudo dice [np.float32(0.7523)] 
2025-06-04 02:43:10.676079: Epoch time: 131.79 s 
2025-06-04 02:43:13.937678:  
2025-06-04 02:43:13.962015: Epoch 493 
2025-06-04 02:43:13.982275: Current learning rate: 0.00543 
2025-06-04 02:45:24.276337: train_loss -0.6962 
2025-06-04 02:45:24.534393: val_loss -0.6241 
2025-06-04 02:45:24.890975: Pseudo dice [np.float32(0.6393)] 
2025-06-04 02:45:25.091126: Epoch time: 130.34 s 
2025-06-04 02:45:28.211490:  
2025-06-04 02:45:28.233058: Epoch 494 
2025-06-04 02:45:28.292574: Current learning rate: 0.00542 
2025-06-04 02:47:37.146785: train_loss -0.6933 
2025-06-04 02:47:37.168279: val_loss -0.6828 
2025-06-04 02:47:37.372879: Pseudo dice [np.float32(0.707)] 
2025-06-04 02:47:37.727596: Epoch time: 128.94 s 
2025-06-04 02:47:40.439349:  
2025-06-04 02:47:40.461661: Epoch 495 
2025-06-04 02:47:40.480261: Current learning rate: 0.00541 
2025-06-04 02:49:51.675175: train_loss -0.6567 
2025-06-04 02:49:51.698263: val_loss -0.6347 
2025-06-04 02:49:51.937743: Pseudo dice [np.float32(0.7698)] 
2025-06-04 02:49:52.329422: Epoch time: 131.24 s 
2025-06-04 02:49:55.154556:  
2025-06-04 02:49:55.176291: Epoch 496 
2025-06-04 02:49:55.195195: Current learning rate: 0.0054 
2025-06-04 02:52:07.048936: train_loss -0.6746 
2025-06-04 02:52:07.071585: val_loss -0.6234 
2025-06-04 02:52:07.086492: Pseudo dice [np.float32(0.7134)] 
2025-06-04 02:52:07.102479: Epoch time: 131.9 s 
2025-06-04 02:52:10.272467:  
2025-06-04 02:52:10.298697: Epoch 497 
2025-06-04 02:52:10.321218: Current learning rate: 0.00539 
2025-06-04 02:54:22.598246: train_loss -0.6818 
2025-06-04 02:54:23.224004: val_loss -0.5942 
2025-06-04 02:54:23.242482: Pseudo dice [np.float32(0.6527)] 
2025-06-04 02:54:23.257648: Epoch time: 132.33 s 
2025-06-04 02:54:27.877410:  
2025-06-04 02:54:28.385212: Epoch 498 
2025-06-04 02:54:28.493585: Current learning rate: 0.00538 
2025-06-04 02:56:35.423955: train_loss -0.6729 
2025-06-04 02:56:35.744845: val_loss -0.6258 
2025-06-04 02:56:36.250489: Pseudo dice [np.float32(0.6763)] 
2025-06-04 02:56:36.443480: Epoch time: 127.55 s 
2025-06-04 02:56:39.890294:  
2025-06-04 02:56:39.914991: Epoch 499 
2025-06-04 02:56:39.938456: Current learning rate: 0.00537 
2025-06-04 02:58:48.180291: train_loss -0.6925 
2025-06-04 02:58:48.320106: val_loss -0.6749 
2025-06-04 02:58:48.460876: Pseudo dice [np.float32(0.7463)] 
2025-06-04 02:58:48.594782: Epoch time: 128.29 s 
2025-06-04 02:58:50.528024:  
2025-06-04 02:58:50.550044: Epoch 500 
2025-06-04 02:58:50.569687: Current learning rate: 0.00536 
2025-06-04 03:01:05.580976: train_loss -0.6559 
2025-06-04 03:01:05.819954: val_loss -0.6785 
2025-06-04 03:01:06.040818: Pseudo dice [np.float32(0.7717)] 
2025-06-04 03:01:06.229578: Epoch time: 135.06 s 
2025-06-04 03:01:08.237512:  
2025-06-04 03:01:08.250850: Epoch 501 
2025-06-04 03:01:08.270449: Current learning rate: 0.00535 
2025-06-04 03:03:20.843960: train_loss -0.6853 
2025-06-04 03:03:20.865543: val_loss -0.6377 
2025-06-04 03:03:20.930851: Pseudo dice [np.float32(0.6872)] 
2025-06-04 03:03:21.005132: Epoch time: 132.61 s 
2025-06-04 03:03:23.787328:  
2025-06-04 03:03:23.847579: Epoch 502 
2025-06-04 03:03:23.910759: Current learning rate: 0.00534 
2025-06-04 03:05:33.569500: train_loss -0.6562 
2025-06-04 03:05:33.789774: val_loss -0.6326 
2025-06-04 03:05:34.221163: Pseudo dice [np.float32(0.7359)] 
2025-06-04 03:05:34.693606: Epoch time: 129.78 s 
2025-06-04 03:05:37.752861:  
2025-06-04 03:05:37.901479: Epoch 503 
2025-06-04 03:05:38.049264: Current learning rate: 0.00533 
2025-06-04 03:07:53.127703: train_loss -0.6753 
2025-06-04 03:07:53.148281: val_loss -0.6789 
2025-06-04 03:07:53.164580: Pseudo dice [np.float32(0.7709)] 
2025-06-04 03:07:53.180034: Epoch time: 135.38 s 
2025-06-04 03:07:56.262486:  
2025-06-04 03:07:56.345764: Epoch 504 
2025-06-04 03:07:56.508863: Current learning rate: 0.00532 
2025-06-04 03:10:10.333498: train_loss -0.6949 
2025-06-04 03:10:10.351583: val_loss -0.6253 
2025-06-04 03:10:10.477493: Pseudo dice [np.float32(0.7242)] 
2025-06-04 03:10:10.706111: Epoch time: 134.07 s 
2025-06-04 03:10:13.909113:  
2025-06-04 03:10:13.928475: Epoch 505 
2025-06-04 03:10:13.946860: Current learning rate: 0.00531 
2025-06-04 03:12:29.894437: train_loss -0.688 
2025-06-04 03:12:29.917637: val_loss -0.7139 
2025-06-04 03:12:29.935024: Pseudo dice [np.float32(0.8083)] 
2025-06-04 03:12:29.949847: Epoch time: 135.99 s 
2025-06-04 03:12:34.973822:  
2025-06-04 03:12:35.164970: Epoch 506 
2025-06-04 03:12:35.216146: Current learning rate: 0.0053 
2025-06-04 03:14:51.497609: train_loss -0.6733 
2025-06-04 03:14:51.517849: val_loss -0.6868 
2025-06-04 03:14:51.535142: Pseudo dice [np.float32(0.7821)] 
2025-06-04 03:14:51.549758: Epoch time: 136.53 s 
2025-06-04 03:14:56.244952:  
2025-06-04 03:14:56.401646: Epoch 507 
2025-06-04 03:14:56.475393: Current learning rate: 0.00529 
2025-06-04 03:17:12.203063: train_loss -0.6763 
2025-06-04 03:17:12.224271: val_loss -0.662 
2025-06-04 03:17:12.241796: Pseudo dice [np.float32(0.7142)] 
2025-06-04 03:17:12.496710: Epoch time: 135.96 s 
2025-06-04 03:17:16.824534:  
2025-06-04 03:17:17.073969: Epoch 508 
2025-06-04 03:17:17.223918: Current learning rate: 0.00528 
2025-06-04 03:19:26.664894: train_loss -0.6862 
2025-06-04 03:19:26.683899: val_loss -0.6389 
2025-06-04 03:19:26.701812: Pseudo dice [np.float32(0.7962)] 
2025-06-04 03:19:26.719359: Epoch time: 129.84 s 
2025-06-04 03:19:30.195530:  
2025-06-04 03:19:30.384470: Epoch 509 
2025-06-04 03:19:30.585662: Current learning rate: 0.00527 
2025-06-04 03:21:43.035059: train_loss -0.6672 
2025-06-04 03:21:43.054878: val_loss -0.7364 
2025-06-04 03:21:43.070631: Pseudo dice [np.float32(0.8054)] 
2025-06-04 03:21:43.086264: Epoch time: 132.84 s 
2025-06-04 03:21:46.800732:  
2025-06-04 03:21:46.820236: Epoch 510 
2025-06-04 03:21:46.834300: Current learning rate: 0.00526 
2025-06-04 03:23:57.308156: train_loss -0.704 
2025-06-04 03:23:57.330560: val_loss -0.6712 
2025-06-04 03:23:57.348861: Pseudo dice [np.float32(0.6874)] 
2025-06-04 03:23:57.641588: Epoch time: 130.51 s 
2025-06-04 03:24:01.072536:  
2025-06-04 03:24:01.139106: Epoch 511 
2025-06-04 03:24:01.157562: Current learning rate: 0.00525 
2025-06-04 03:26:12.668778: train_loss -0.6812 
2025-06-04 03:26:12.686416: val_loss -0.6983 
2025-06-04 03:26:12.706825: Pseudo dice [np.float32(0.8)] 
2025-06-04 03:26:12.725582: Epoch time: 131.6 s 
2025-06-04 03:26:16.256692:  
2025-06-04 03:26:16.278454: Epoch 512 
2025-06-04 03:26:16.297982: Current learning rate: 0.00524 
2025-06-04 03:28:28.162295: train_loss -0.6806 
2025-06-04 03:28:28.438092: val_loss -0.6575 
2025-06-04 03:28:28.456943: Pseudo dice [np.float32(0.7928)] 
2025-06-04 03:28:28.472368: Epoch time: 131.91 s 
2025-06-04 03:28:31.893638:  
2025-06-04 03:28:31.971878: Epoch 513 
2025-06-04 03:28:32.021949: Current learning rate: 0.00523 
2025-06-04 03:30:42.792302: train_loss -0.6667 
2025-06-04 03:30:42.958308: val_loss -0.6688 
2025-06-04 03:30:43.685976: Pseudo dice [np.float32(0.775)] 
2025-06-04 03:30:44.220912: Epoch time: 130.9 s 
2025-06-04 03:30:48.800388:  
2025-06-04 03:30:48.893534: Epoch 514 
2025-06-04 03:30:49.018976: Current learning rate: 0.00522 
2025-06-04 03:33:00.309619: train_loss -0.6901 
2025-06-04 03:33:00.971792: val_loss -0.6646 
2025-06-04 03:33:01.158455: Pseudo dice [np.float32(0.6728)] 
2025-06-04 03:33:01.173657: Epoch time: 131.51 s 
2025-06-04 03:33:04.351354:  
2025-06-04 03:33:04.457035: Epoch 515 
2025-06-04 03:33:04.479068: Current learning rate: 0.00521 
2025-06-04 03:35:13.087869: train_loss -0.6808 
2025-06-04 03:35:13.437514: val_loss -0.6939 
2025-06-04 03:35:13.458937: Pseudo dice [np.float32(0.7793)] 
2025-06-04 03:35:13.476017: Epoch time: 128.74 s 
2025-06-04 03:35:18.563661:  
2025-06-04 03:35:18.667524: Epoch 516 
2025-06-04 03:35:18.792097: Current learning rate: 0.0052 
2025-06-04 03:37:30.887712: train_loss -0.6994 
2025-06-04 03:37:31.233540: val_loss -0.728 
2025-06-04 03:37:31.700662: Pseudo dice [np.float32(0.8225)] 
2025-06-04 03:37:32.217557: Epoch time: 132.33 s 
2025-06-04 03:37:32.741904: Yayy! New best EMA pseudo Dice: 0.7580000162124634 
2025-06-04 03:37:38.605145:  
2025-06-04 03:37:38.866874: Epoch 517 
2025-06-04 03:37:39.042966: Current learning rate: 0.00519 
2025-06-04 03:39:51.734973: train_loss -0.6816 
2025-06-04 03:39:51.754859: val_loss -0.6962 
2025-06-04 03:39:51.771083: Pseudo dice [np.float32(0.7668)] 
2025-06-04 03:39:51.788803: Epoch time: 133.13 s 
2025-06-04 03:39:51.808725: Yayy! New best EMA pseudo Dice: 0.758899986743927 
2025-06-04 03:39:55.681205:  
2025-06-04 03:39:55.898567: Epoch 518 
2025-06-04 03:39:56.105346: Current learning rate: 0.00518 
2025-06-04 03:42:03.636497: train_loss -0.6877 
2025-06-04 03:42:03.896294: val_loss -0.667 
2025-06-04 03:42:03.916779: Pseudo dice [np.float32(0.7289)] 
2025-06-04 03:42:03.932145: Epoch time: 127.96 s 
2025-06-04 03:42:07.183032:  
2025-06-04 03:42:07.310685: Epoch 519 
2025-06-04 03:42:07.379018: Current learning rate: 0.00518 
2025-06-04 03:44:14.636977: train_loss -0.6821 
2025-06-04 03:44:14.655846: val_loss -0.6976 
2025-06-04 03:44:14.671007: Pseudo dice [np.float32(0.8197)] 
2025-06-04 03:44:14.688495: Epoch time: 127.46 s 
2025-06-04 03:44:14.706784: Yayy! New best EMA pseudo Dice: 0.7623000144958496 
2025-06-04 03:44:17.167364:  
2025-06-04 03:44:17.186637: Epoch 520 
2025-06-04 03:44:17.205606: Current learning rate: 0.00517 
2025-06-04 03:46:27.865486: train_loss -0.6792 
2025-06-04 03:46:28.149519: val_loss -0.5913 
2025-06-04 03:46:28.482442: Pseudo dice [np.float32(0.7396)] 
2025-06-04 03:46:28.729401: Epoch time: 130.7 s 
2025-06-04 03:46:30.409854:  
2025-06-04 03:46:30.431014: Epoch 521 
2025-06-04 03:46:30.447012: Current learning rate: 0.00516 
2025-06-04 03:48:40.876328: train_loss -0.6888 
2025-06-04 03:48:41.091791: val_loss -0.6502 
2025-06-04 03:48:41.111600: Pseudo dice [np.float32(0.6766)] 
2025-06-04 03:48:41.279045: Epoch time: 130.47 s 
2025-06-04 03:48:45.717291:  
2025-06-04 03:48:45.914943: Epoch 522 
2025-06-04 03:48:46.213939: Current learning rate: 0.00515 
2025-06-04 03:50:57.771929: train_loss -0.6915 
2025-06-04 03:50:58.017487: val_loss -0.6301 
2025-06-04 03:50:58.242834: Pseudo dice [np.float32(0.7071)] 
2025-06-04 03:50:58.527817: Epoch time: 132.06 s 
2025-06-04 03:51:00.772902:  
2025-06-04 03:51:00.888180: Epoch 523 
2025-06-04 03:51:00.990489: Current learning rate: 0.00514 
2025-06-04 03:53:17.796152: train_loss -0.6975 
2025-06-04 03:53:17.996292: val_loss -0.6523 
2025-06-04 03:53:18.252524: Pseudo dice [np.float32(0.7049)] 
2025-06-04 03:53:18.524329: Epoch time: 137.03 s 
2025-06-04 03:53:20.857948:  
2025-06-04 03:53:20.923579: Epoch 524 
2025-06-04 03:53:21.014632: Current learning rate: 0.00513 
2025-06-04 03:55:31.749427: train_loss -0.7055 
2025-06-04 03:55:32.131903: val_loss -0.6241 
2025-06-04 03:55:32.525801: Pseudo dice [np.float32(0.7279)] 
2025-06-04 03:55:32.861026: Epoch time: 130.89 s 
2025-06-04 03:55:35.268371:  
2025-06-04 03:55:35.386705: Epoch 525 
2025-06-04 03:55:35.516034: Current learning rate: 0.00512 
2025-06-04 03:57:47.066059: train_loss -0.7143 
2025-06-04 03:57:47.090560: val_loss -0.6998 
2025-06-04 03:57:47.106203: Pseudo dice [np.float32(0.7517)] 
2025-06-04 03:57:47.122973: Epoch time: 131.8 s 
2025-06-04 03:57:51.896234:  
2025-06-04 03:57:51.976483: Epoch 526 
2025-06-04 03:57:52.091082: Current learning rate: 0.00511 
2025-06-04 04:00:03.753442: train_loss -0.6704 
2025-06-04 04:00:03.775493: val_loss -0.6285 
2025-06-04 04:00:03.920215: Pseudo dice [np.float32(0.6998)] 
2025-06-04 04:00:04.149992: Epoch time: 131.86 s 
2025-06-04 04:00:07.311328:  
2025-06-04 04:00:07.503215: Epoch 527 
2025-06-04 04:00:07.719019: Current learning rate: 0.0051 
2025-06-04 04:02:21.969696: train_loss -0.6661 
2025-06-04 04:02:22.359598: val_loss -0.6775 
2025-06-04 04:02:22.671050: Pseudo dice [np.float32(0.7747)] 
2025-06-04 04:02:22.979282: Epoch time: 134.66 s 
2025-06-04 04:02:26.986415:  
2025-06-04 04:02:27.049686: Epoch 528 
2025-06-04 04:02:27.227260: Current learning rate: 0.00509 
2025-06-04 04:04:39.214668: train_loss -0.7083 
2025-06-04 04:04:39.357409: val_loss -0.5853 
2025-06-04 04:04:39.797737: Pseudo dice [np.float32(0.7677)] 
2025-06-04 04:04:40.249257: Epoch time: 132.23 s 
2025-06-04 04:04:45.854936:  
2025-06-04 04:04:45.878004: Epoch 529 
2025-06-04 04:04:45.895222: Current learning rate: 0.00508 
2025-06-04 04:06:58.557695: train_loss -0.6768 
2025-06-04 04:06:58.844561: val_loss -0.6744 
2025-06-04 04:06:59.145315: Pseudo dice [np.float32(0.7469)] 
2025-06-04 04:06:59.451833: Epoch time: 132.77 s 
2025-06-04 04:07:03.258202:  
2025-06-04 04:07:03.423777: Epoch 530 
2025-06-04 04:07:03.642352: Current learning rate: 0.00507 
2025-06-04 04:09:14.404821: train_loss -0.7007 
2025-06-04 04:09:14.739131: val_loss -0.692 
2025-06-04 04:09:15.173143: Pseudo dice [np.float32(0.726)] 
2025-06-04 04:09:15.193048: Epoch time: 131.15 s 
2025-06-04 04:09:18.873391:  
2025-06-04 04:09:19.076600: Epoch 531 
2025-06-04 04:09:19.229350: Current learning rate: 0.00506 
2025-06-04 04:11:31.417465: train_loss -0.711 
2025-06-04 04:11:31.548302: val_loss -0.6851 
2025-06-04 04:11:31.680842: Pseudo dice [np.float32(0.7645)] 
2025-06-04 04:11:31.997846: Epoch time: 132.55 s 
2025-06-04 04:11:34.711107:  
2025-06-04 04:11:34.809648: Epoch 532 
2025-06-04 04:11:34.832944: Current learning rate: 0.00505 
2025-06-04 04:13:44.582044: train_loss -0.6772 
2025-06-04 04:13:44.604002: val_loss -0.664 
2025-06-04 04:13:44.621237: Pseudo dice [np.float32(0.6894)] 
2025-06-04 04:13:44.797918: Epoch time: 129.87 s 
2025-06-04 04:13:48.239881:  
2025-06-04 04:13:48.259879: Epoch 533 
2025-06-04 04:13:48.437627: Current learning rate: 0.00504 
2025-06-04 04:15:57.239413: train_loss -0.7128 
2025-06-04 04:15:57.264680: val_loss -0.6236 
2025-06-04 04:15:57.280741: Pseudo dice [np.float32(0.6418)] 
2025-06-04 04:15:57.624782: Epoch time: 129.0 s 
2025-06-04 04:16:02.977365:  
2025-06-04 04:16:03.000829: Epoch 534 
2025-06-04 04:16:03.020640: Current learning rate: 0.00503 
2025-06-04 04:18:13.561422: train_loss -0.7041 
2025-06-04 04:18:14.195871: val_loss -0.6353 
2025-06-04 04:18:14.758313: Pseudo dice [np.float32(0.7405)] 
2025-06-04 04:18:15.040597: Epoch time: 130.59 s 
2025-06-04 04:18:17.411372:  
2025-06-04 04:18:17.434771: Epoch 535 
2025-06-04 04:18:17.471240: Current learning rate: 0.00502 
2025-06-04 04:20:29.750560: train_loss -0.6803 
2025-06-04 04:20:30.027378: val_loss -0.6504 
2025-06-04 04:20:30.337636: Pseudo dice [np.float32(0.7285)] 
2025-06-04 04:20:30.633919: Epoch time: 132.34 s 
2025-06-04 04:20:33.306549:  
2025-06-04 04:20:33.331676: Epoch 536 
2025-06-04 04:20:33.353545: Current learning rate: 0.00501 
2025-06-04 04:22:48.393592: train_loss -0.674 
2025-06-04 04:22:48.428002: val_loss -0.674 
2025-06-04 04:22:48.446139: Pseudo dice [np.float32(0.7049)] 
2025-06-04 04:22:48.461438: Epoch time: 135.09 s 
2025-06-04 04:22:54.098572:  
2025-06-04 04:22:54.122764: Epoch 537 
2025-06-04 04:22:54.147148: Current learning rate: 0.005 
2025-06-04 04:25:03.288098: train_loss -0.6746 
2025-06-04 04:25:03.310100: val_loss -0.6584 
2025-06-04 04:25:03.441270: Pseudo dice [np.float32(0.5764)] 
2025-06-04 04:25:03.463469: Epoch time: 129.19 s 
2025-06-04 04:25:06.236560:  
2025-06-04 04:25:06.258098: Epoch 538 
2025-06-04 04:25:06.276184: Current learning rate: 0.00499 
2025-06-04 04:27:17.701338: train_loss -0.7009 
2025-06-04 04:27:17.954466: val_loss -0.6518 
2025-06-04 04:27:18.359626: Pseudo dice [np.float32(0.776)] 
2025-06-04 04:27:18.638888: Epoch time: 131.47 s 
2025-06-04 04:27:21.514424:  
2025-06-04 04:27:21.600548: Epoch 539 
2025-06-04 04:27:21.752869: Current learning rate: 0.00498 
2025-06-04 04:29:31.732653: train_loss -0.6898 
2025-06-04 04:29:31.901067: val_loss -0.6844 
2025-06-04 04:29:31.918924: Pseudo dice [np.float32(0.7423)] 
2025-06-04 04:29:31.935320: Epoch time: 130.22 s 
2025-06-04 04:29:37.232822:  
2025-06-04 04:29:37.397067: Epoch 540 
2025-06-04 04:29:37.529927: Current learning rate: 0.00497 
2025-06-04 04:31:48.347499: train_loss -0.7002 
2025-06-04 04:31:48.722847: val_loss -0.6579 
2025-06-04 04:31:49.247348: Pseudo dice [np.float32(0.7122)] 
2025-06-04 04:31:49.684102: Epoch time: 131.12 s 
2025-06-04 04:31:53.511091:  
2025-06-04 04:31:53.708343: Epoch 541 
2025-06-04 04:31:53.972142: Current learning rate: 0.00496 
2025-06-04 04:34:01.922606: train_loss -0.7046 
2025-06-04 04:34:01.944118: val_loss -0.6637 
2025-06-04 04:34:01.966685: Pseudo dice [np.float32(0.6243)] 
2025-06-04 04:34:01.984271: Epoch time: 128.41 s 
2025-06-04 04:34:05.036709:  
2025-06-04 04:34:05.066864: Epoch 542 
2025-06-04 04:34:05.100218: Current learning rate: 0.00495 
2025-06-04 04:36:08.831146: train_loss -0.6785 
2025-06-04 04:36:09.043185: val_loss -0.6232 
2025-06-04 04:36:09.337971: Pseudo dice [np.float32(0.6884)] 
2025-06-04 04:36:09.510472: Epoch time: 123.8 s 
2025-06-04 04:36:11.016616:  
2025-06-04 04:36:11.034102: Epoch 543 
2025-06-04 04:36:11.059291: Current learning rate: 0.00494 
2025-06-04 04:38:19.095428: train_loss -0.7015 
2025-06-04 04:38:19.115894: val_loss -0.6948 
2025-06-04 04:38:19.133158: Pseudo dice [np.float32(0.7103)] 
2025-06-04 04:38:19.346743: Epoch time: 128.08 s 
2025-06-04 04:38:22.165257:  
2025-06-04 04:38:22.245860: Epoch 544 
2025-06-04 04:38:22.269598: Current learning rate: 0.00493 
2025-06-04 04:40:30.831026: train_loss -0.6841 
2025-06-04 04:40:31.071960: val_loss -0.6918 
2025-06-04 04:40:31.319645: Pseudo dice [np.float32(0.7999)] 
2025-06-04 04:40:31.648951: Epoch time: 128.67 s 
2025-06-04 04:40:36.417892:  
2025-06-04 04:40:36.517413: Epoch 545 
2025-06-04 04:40:36.645593: Current learning rate: 0.00492 
2025-06-04 04:42:45.422769: train_loss -0.6819 
2025-06-04 04:42:45.442641: val_loss -0.6543 
2025-06-04 04:42:45.460763: Pseudo dice [np.float32(0.7384)] 
2025-06-04 04:42:45.478335: Epoch time: 129.01 s 
2025-06-04 04:42:48.959159:  
2025-06-04 04:42:49.067224: Epoch 546 
2025-06-04 04:42:49.164766: Current learning rate: 0.00491 
2025-06-04 04:44:56.713146: train_loss -0.6758 
2025-06-04 04:44:56.963125: val_loss -0.6767 
2025-06-04 04:44:57.175016: Pseudo dice [np.float32(0.742)] 
2025-06-04 04:44:57.551862: Epoch time: 127.76 s 
2025-06-04 04:45:00.586372:  
2025-06-04 04:45:00.683071: Epoch 547 
2025-06-04 04:45:00.701661: Current learning rate: 0.0049 
2025-06-04 04:47:15.385910: train_loss -0.6745 
2025-06-04 04:47:15.654950: val_loss -0.6431 
2025-06-04 04:47:16.019976: Pseudo dice [np.float32(0.7203)] 
2025-06-04 04:47:16.428082: Epoch time: 134.8 s 
2025-06-04 04:47:19.807437:  
2025-06-04 04:47:19.876705: Epoch 548 
2025-06-04 04:47:19.985487: Current learning rate: 0.00489 
2025-06-04 04:49:33.643452: train_loss -0.6973 
2025-06-04 04:49:33.935255: val_loss -0.6542 
2025-06-04 04:49:34.334466: Pseudo dice [np.float32(0.7405)] 
2025-06-04 04:49:34.618479: Epoch time: 133.84 s 
2025-06-04 04:49:37.152168:  
2025-06-04 04:49:37.359314: Epoch 549 
2025-06-04 04:49:37.596328: Current learning rate: 0.00488 
2025-06-04 04:51:53.386876: train_loss -0.6771 
2025-06-04 04:51:53.705376: val_loss -0.6078 
2025-06-04 04:51:53.840003: Pseudo dice [np.float32(0.6522)] 
2025-06-04 04:51:53.858787: Epoch time: 136.24 s 
2025-06-04 04:51:57.650671:  
2025-06-04 04:51:57.676137: Epoch 550 
2025-06-04 04:51:57.697764: Current learning rate: 0.00487 
2025-06-04 04:54:08.179583: train_loss -0.6985 
2025-06-04 04:54:08.449385: val_loss -0.6633 
2025-06-04 04:54:08.656192: Pseudo dice [np.float32(0.791)] 
2025-06-04 04:54:08.676562: Epoch time: 130.53 s 
2025-06-04 04:54:12.577345:  
2025-06-04 04:54:12.830854: Epoch 551 
2025-06-04 04:54:13.087205: Current learning rate: 0.00486 
2025-06-04 04:56:23.963103: train_loss -0.6549 
2025-06-04 04:56:24.217223: val_loss -0.6264 
2025-06-04 04:56:24.431964: Pseudo dice [np.float32(0.7818)] 
2025-06-04 04:56:24.682599: Epoch time: 131.39 s 
2025-06-04 04:56:27.809545:  
2025-06-04 04:56:27.906503: Epoch 552 
2025-06-04 04:56:27.962559: Current learning rate: 0.00485 
2025-06-04 04:58:40.121114: train_loss -0.6772 
2025-06-04 04:58:40.418815: val_loss -0.6151 
2025-06-04 04:58:40.710304: Pseudo dice [np.float32(0.6634)] 
2025-06-04 04:58:41.002281: Epoch time: 132.31 s 
2025-06-04 04:58:43.443355:  
2025-06-04 04:58:43.547731: Epoch 553 
2025-06-04 04:58:43.702419: Current learning rate: 0.00484 
2025-06-04 05:00:54.716358: train_loss -0.6572 
2025-06-04 05:00:55.055357: val_loss -0.6645 
2025-06-04 05:00:55.389852: Pseudo dice [np.float32(0.7562)] 
2025-06-04 05:00:55.674264: Epoch time: 131.27 s 
2025-06-04 05:00:58.280343:  
2025-06-04 05:00:58.430344: Epoch 554 
2025-06-04 05:00:58.591999: Current learning rate: 0.00484 
2025-06-04 05:03:07.144556: train_loss -0.701 
2025-06-04 05:03:07.351353: val_loss -0.6177 
2025-06-04 05:03:07.583297: Pseudo dice [np.float32(0.7127)] 
2025-06-04 05:03:07.933537: Epoch time: 128.87 s 
2025-06-04 05:03:12.603399:  
2025-06-04 05:03:12.664498: Epoch 555 
2025-06-04 05:03:12.720178: Current learning rate: 0.00483 
2025-06-04 05:05:19.791730: train_loss -0.6804 
2025-06-04 05:05:19.817559: val_loss -0.6744 
2025-06-04 05:05:20.118704: Pseudo dice [np.float32(0.7928)] 
2025-06-04 05:05:20.491855: Epoch time: 127.19 s 
2025-06-04 05:05:24.296216:  
2025-06-04 05:05:24.402109: Epoch 556 
2025-06-04 05:05:24.421747: Current learning rate: 0.00482 
2025-06-04 05:07:37.141537: train_loss -0.7113 
2025-06-04 05:07:37.485424: val_loss -0.6087 
2025-06-04 05:07:37.509418: Pseudo dice [np.float32(0.7199)] 
2025-06-04 05:07:37.575895: Epoch time: 132.85 s 
2025-06-04 05:07:42.738612:  
2025-06-04 05:07:42.761635: Epoch 557 
2025-06-04 05:07:42.779447: Current learning rate: 0.00481 
2025-06-04 05:09:57.634891: train_loss -0.6895 
2025-06-04 05:09:58.089299: val_loss -0.5954 
2025-06-04 05:09:58.505683: Pseudo dice [np.float32(0.6409)] 
2025-06-04 05:09:58.878448: Epoch time: 134.9 s 
2025-06-04 05:10:04.161328:  
2025-06-04 05:10:04.257483: Epoch 558 
2025-06-04 05:10:04.347767: Current learning rate: 0.0048 
2025-06-04 05:12:14.179801: train_loss -0.7002 
2025-06-04 05:12:14.500022: val_loss -0.6748 
2025-06-04 05:12:14.780397: Pseudo dice [np.float32(0.7209)] 
2025-06-04 05:12:15.166092: Epoch time: 130.02 s 
2025-06-04 05:12:20.173748:  
2025-06-04 05:12:20.238316: Epoch 559 
2025-06-04 05:12:20.494035: Current learning rate: 0.00479 
2025-06-04 05:14:32.984381: train_loss -0.6844 
2025-06-04 05:14:33.006127: val_loss -0.6744 
2025-06-04 05:14:33.023422: Pseudo dice [np.float32(0.73)] 
2025-06-04 05:14:33.041392: Epoch time: 132.81 s 
2025-06-04 05:14:36.983699:  
2025-06-04 05:14:37.018168: Epoch 560 
2025-06-04 05:14:37.128792: Current learning rate: 0.00478 
2025-06-04 05:16:46.404053: train_loss -0.6789 
2025-06-04 05:16:46.722595: val_loss -0.7022 
2025-06-04 05:16:47.000812: Pseudo dice [np.float32(0.8329)] 
2025-06-04 05:16:47.133915: Epoch time: 129.42 s 
2025-06-04 05:16:50.080451:  
2025-06-04 05:16:50.171149: Epoch 561 
2025-06-04 05:16:50.360148: Current learning rate: 0.00477 
2025-06-04 05:19:02.399444: train_loss -0.6725 
2025-06-04 05:19:02.421655: val_loss -0.6573 
2025-06-04 05:19:02.439570: Pseudo dice [np.float32(0.6883)] 
2025-06-04 05:19:02.457992: Epoch time: 132.32 s 
2025-06-04 05:19:06.399338:  
2025-06-04 05:19:06.559058: Epoch 562 
2025-06-04 05:19:06.681377: Current learning rate: 0.00476 
2025-06-04 05:21:19.864547: train_loss -0.6584 
2025-06-04 05:21:20.135608: val_loss -0.6736 
2025-06-04 05:21:20.500424: Pseudo dice [np.float32(0.7525)] 
2025-06-04 05:21:20.645734: Epoch time: 133.47 s 
2025-06-04 05:21:24.389238:  
2025-06-04 05:21:24.410861: Epoch 563 
2025-06-04 05:21:24.426677: Current learning rate: 0.00475 
2025-06-04 05:23:35.479010: train_loss -0.6782 
2025-06-04 05:23:35.498101: val_loss -0.6221 
2025-06-04 05:23:35.517601: Pseudo dice [np.float32(0.7021)] 
2025-06-04 05:23:35.535569: Epoch time: 131.09 s 
2025-06-04 05:23:39.307043:  
2025-06-04 05:23:39.326607: Epoch 564 
2025-06-04 05:23:39.342447: Current learning rate: 0.00474 
2025-06-04 05:25:50.350981: train_loss -0.6793 
2025-06-04 05:25:50.713880: val_loss -0.618 
2025-06-04 05:25:50.735882: Pseudo dice [np.float32(0.7755)] 
2025-06-04 05:25:50.753265: Epoch time: 131.05 s 
2025-06-04 05:25:54.961521:  
2025-06-04 05:25:54.984991: Epoch 565 
2025-06-04 05:25:55.005965: Current learning rate: 0.00473 
2025-06-04 05:28:05.989474: train_loss -0.6996 
2025-06-04 05:28:06.011683: val_loss -0.6611 
2025-06-04 05:28:06.030421: Pseudo dice [np.float32(0.7371)] 
2025-06-04 05:28:06.045765: Epoch time: 131.03 s 
2025-06-04 05:28:10.763487:  
2025-06-04 05:28:10.861660: Epoch 566 
2025-06-04 05:28:10.881394: Current learning rate: 0.00472 
2025-06-04 05:30:24.124490: train_loss -0.6805 
2025-06-04 05:30:24.316091: val_loss -0.673 
2025-06-04 05:30:24.453431: Pseudo dice [np.float32(0.736)] 
2025-06-04 05:30:24.472827: Epoch time: 133.36 s 
2025-06-04 05:30:28.229793:  
2025-06-04 05:30:28.405550: Epoch 567 
2025-06-04 05:30:28.478974: Current learning rate: 0.00471 
2025-06-04 05:32:36.661626: train_loss -0.6986 
2025-06-04 05:32:36.989572: val_loss -0.7085 
2025-06-04 05:32:37.507665: Pseudo dice [np.float32(0.8054)] 
2025-06-04 05:32:37.921965: Epoch time: 128.43 s 
2025-06-04 05:32:42.634235:  
2025-06-04 05:32:42.702472: Epoch 568 
2025-06-04 05:32:42.738685: Current learning rate: 0.0047 
2025-06-04 05:34:52.697993: train_loss -0.6793 
2025-06-04 05:34:53.238826: val_loss -0.6554 
2025-06-04 05:34:53.772056: Pseudo dice [np.float32(0.7522)] 
2025-06-04 05:34:54.236200: Epoch time: 130.07 s 
2025-06-04 05:34:56.752310:  
2025-06-04 05:34:56.784092: Epoch 569 
2025-06-04 05:34:56.806008: Current learning rate: 0.00469 
2025-06-04 05:37:06.020964: train_loss -0.695 
2025-06-04 05:37:06.043440: val_loss -0.7277 
2025-06-04 05:37:06.062194: Pseudo dice [np.float32(0.8079)] 
2025-06-04 05:37:06.082347: Epoch time: 129.27 s 
2025-06-04 05:37:08.890354:  
2025-06-04 05:37:08.919158: Epoch 570 
2025-06-04 05:37:08.962849: Current learning rate: 0.00468 
2025-06-04 05:39:16.643605: train_loss -0.6642 
2025-06-04 05:39:16.955840: val_loss -0.6638 
2025-06-04 05:39:17.235528: Pseudo dice [np.float32(0.7764)] 
2025-06-04 05:39:17.496437: Epoch time: 127.76 s 
2025-06-04 05:39:19.302828:  
2025-06-04 05:39:19.320064: Epoch 571 
2025-06-04 05:39:19.334628: Current learning rate: 0.00467 
2025-06-04 05:41:30.956720: train_loss -0.7042 
2025-06-04 05:41:31.303777: val_loss -0.666 
2025-06-04 05:41:31.373779: Pseudo dice [np.float32(0.7461)] 
2025-06-04 05:41:31.440481: Epoch time: 131.66 s 
2025-06-04 05:41:33.968070:  
2025-06-04 05:41:34.080174: Epoch 572 
2025-06-04 05:41:34.165261: Current learning rate: 0.00466 
2025-06-04 05:43:48.147286: train_loss -0.6857 
2025-06-04 05:43:48.628343: val_loss -0.6435 
2025-06-04 05:43:48.752769: Pseudo dice [np.float32(0.7312)] 
2025-06-04 05:43:48.771263: Epoch time: 134.18 s 
2025-06-04 05:43:51.963876:  
2025-06-04 05:43:51.982412: Epoch 573 
2025-06-04 05:43:51.999278: Current learning rate: 0.00465 
2025-06-04 05:46:06.026825: train_loss -0.6843 
2025-06-04 05:46:06.173026: val_loss -0.7092 
2025-06-04 05:46:06.190672: Pseudo dice [np.float32(0.7562)] 
2025-06-04 05:46:06.210102: Epoch time: 134.06 s 
2025-06-04 05:46:08.444163:  
2025-06-04 05:46:08.532137: Epoch 574 
2025-06-04 05:46:08.547525: Current learning rate: 0.00464 
2025-06-04 05:48:19.063703: train_loss -0.6929 
2025-06-04 05:48:19.365275: val_loss -0.7403 
2025-06-04 05:48:19.786843: Pseudo dice [np.float32(0.8277)] 
2025-06-04 05:48:20.352767: Epoch time: 130.62 s 
2025-06-04 05:48:24.193847:  
2025-06-04 05:48:24.296882: Epoch 575 
2025-06-04 05:48:24.315364: Current learning rate: 0.00463 
2025-06-04 05:50:36.036148: train_loss -0.6875 
2025-06-04 05:50:36.466402: val_loss -0.6149 
2025-06-04 05:50:36.805624: Pseudo dice [np.float32(0.745)] 
2025-06-04 05:50:37.099366: Epoch time: 131.84 s 
2025-06-04 05:50:41.256148:  
2025-06-04 05:50:41.413995: Epoch 576 
2025-06-04 05:50:41.468837: Current learning rate: 0.00462 
2025-06-04 05:52:52.914065: train_loss -0.6667 
2025-06-04 05:52:53.240820: val_loss -0.6387 
2025-06-04 05:52:53.371571: Pseudo dice [np.float32(0.7117)] 
2025-06-04 05:52:53.743440: Epoch time: 131.66 s 
2025-06-04 05:52:56.160742:  
2025-06-04 05:52:56.224956: Epoch 577 
2025-06-04 05:52:56.368642: Current learning rate: 0.00461 
2025-06-04 05:55:09.822544: train_loss -0.7141 
2025-06-04 05:55:09.906870: val_loss -0.6862 
2025-06-04 05:55:10.064141: Pseudo dice [np.float32(0.7537)] 
2025-06-04 05:55:10.174130: Epoch time: 133.66 s 
2025-06-04 05:55:14.943554:  
2025-06-04 05:55:15.038631: Epoch 578 
2025-06-04 05:55:15.135903: Current learning rate: 0.0046 
2025-06-04 05:57:26.464408: train_loss -0.6902 
2025-06-04 05:57:26.943957: val_loss -0.6945 
2025-06-04 05:57:27.407735: Pseudo dice [np.float32(0.6509)] 
2025-06-04 05:57:27.888794: Epoch time: 131.52 s 
2025-06-04 05:57:31.553103:  
2025-06-04 05:57:31.598355: Epoch 579 
2025-06-04 05:57:31.732271: Current learning rate: 0.00459 
2025-06-04 05:59:43.913325: train_loss -0.6945 
2025-06-04 05:59:44.465274: val_loss -0.6735 
2025-06-04 05:59:45.094228: Pseudo dice [np.float32(0.7766)] 
2025-06-04 05:59:45.269782: Epoch time: 132.36 s 
2025-06-04 05:59:49.424248:  
2025-06-04 05:59:49.494038: Epoch 580 
2025-06-04 05:59:49.572678: Current learning rate: 0.00458 
2025-06-04 06:02:00.831994: train_loss -0.6884 
2025-06-04 06:02:00.860206: val_loss -0.7047 
2025-06-04 06:02:00.877932: Pseudo dice [np.float32(0.8049)] 
2025-06-04 06:02:01.098589: Epoch time: 131.41 s 
2025-06-04 06:02:06.644521:  
2025-06-04 06:02:06.736908: Epoch 581 
2025-06-04 06:02:06.780094: Current learning rate: 0.00457 
2025-06-04 06:04:22.984485: train_loss -0.6888 
2025-06-04 06:04:23.264316: val_loss -0.6919 
2025-06-04 06:04:23.796162: Pseudo dice [np.float32(0.7811)] 
2025-06-04 06:04:24.458603: Epoch time: 136.34 s 
2025-06-04 06:04:28.495553:  
2025-06-04 06:04:28.656909: Epoch 582 
2025-06-04 06:04:28.744427: Current learning rate: 0.00456 
2025-06-04 06:06:40.275713: train_loss -0.7071 
2025-06-04 06:06:40.611837: val_loss -0.639 
2025-06-04 06:06:41.160908: Pseudo dice [np.float32(0.7784)] 
2025-06-04 06:06:41.598778: Epoch time: 131.78 s 
2025-06-04 06:06:45.951672:  
2025-06-04 06:06:46.051217: Epoch 583 
2025-06-04 06:06:46.173620: Current learning rate: 0.00455 
2025-06-04 06:08:56.103631: train_loss -0.6982 
2025-06-04 06:08:56.448362: val_loss -0.6905 
2025-06-04 06:08:56.466353: Pseudo dice [np.float32(0.7811)] 
2025-06-04 06:08:56.484117: Epoch time: 130.15 s 
2025-06-04 06:09:00.777538:  
2025-06-04 06:09:00.856859: Epoch 584 
2025-06-04 06:09:00.887515: Current learning rate: 0.00454 
2025-06-04 06:11:15.258261: train_loss -0.706 
2025-06-04 06:11:15.455425: val_loss -0.5991 
2025-06-04 06:11:15.474788: Pseudo dice [np.float32(0.6949)] 
2025-06-04 06:11:15.493031: Epoch time: 134.48 s 
2025-06-04 06:11:21.138736:  
2025-06-04 06:11:21.256009: Epoch 585 
2025-06-04 06:11:21.390929: Current learning rate: 0.00453 
2025-06-04 06:13:28.408582: train_loss -0.6842 
2025-06-04 06:13:28.866431: val_loss -0.639 
2025-06-04 06:13:29.364323: Pseudo dice [np.float32(0.7965)] 
2025-06-04 06:13:29.734467: Epoch time: 127.27 s 
2025-06-04 06:13:33.134335:  
2025-06-04 06:13:33.156537: Epoch 586 
2025-06-04 06:13:33.179932: Current learning rate: 0.00452 
2025-06-04 06:15:44.141796: train_loss -0.7057 
2025-06-04 06:15:44.519951: val_loss -0.6847 
2025-06-04 06:15:44.888680: Pseudo dice [np.float32(0.7756)] 
2025-06-04 06:15:45.315543: Epoch time: 131.01 s 
2025-06-04 06:15:48.592835:  
2025-06-04 06:15:48.611310: Epoch 587 
2025-06-04 06:15:48.630424: Current learning rate: 0.00451 
2025-06-04 06:18:01.191813: train_loss -0.7104 
2025-06-04 06:18:01.215615: val_loss -0.7309 
2025-06-04 06:18:01.235027: Pseudo dice [np.float32(0.7978)] 
2025-06-04 06:18:01.463735: Epoch time: 132.6 s 
2025-06-04 06:18:01.849401: Yayy! New best EMA pseudo Dice: 0.7627999782562256 
2025-06-04 06:18:07.090224:  
2025-06-04 06:18:07.248125: Epoch 588 
2025-06-04 06:18:07.345952: Current learning rate: 0.0045 
2025-06-04 06:20:18.043112: train_loss -0.7007 
2025-06-04 06:20:18.414873: val_loss -0.6643 
2025-06-04 06:20:18.910512: Pseudo dice [np.float32(0.6989)] 
2025-06-04 06:20:19.168438: Epoch time: 130.96 s 
2025-06-04 06:20:22.013004:  
2025-06-04 06:20:22.075662: Epoch 589 
2025-06-04 06:20:22.095151: Current learning rate: 0.00449 
2025-06-04 06:22:29.800052: train_loss -0.6772 
2025-06-04 06:22:30.375370: val_loss -0.664 
2025-06-04 06:22:30.829960: Pseudo dice [np.float32(0.8063)] 
2025-06-04 06:22:31.323412: Epoch time: 127.79 s 
2025-06-04 06:22:36.202747:  
2025-06-04 06:22:36.428105: Epoch 590 
2025-06-04 06:22:36.591859: Current learning rate: 0.00448 
2025-06-04 06:24:46.689777: train_loss -0.6835 
2025-06-04 06:24:46.712157: val_loss -0.6535 
2025-06-04 06:24:46.731128: Pseudo dice [np.float32(0.7714)] 
2025-06-04 06:24:46.749863: Epoch time: 130.49 s 
2025-06-04 06:24:50.712991:  
2025-06-04 06:24:50.733945: Epoch 591 
2025-06-04 06:24:50.780493: Current learning rate: 0.00447 
2025-06-04 06:27:00.419796: train_loss -0.6989 
2025-06-04 06:27:01.012977: val_loss -0.5997 
2025-06-04 06:27:01.410182: Pseudo dice [np.float32(0.6742)] 
2025-06-04 06:27:01.635026: Epoch time: 129.71 s 
2025-06-04 06:27:04.941691:  
2025-06-04 06:27:04.967237: Epoch 592 
2025-06-04 06:27:04.998208: Current learning rate: 0.00446 
2025-06-04 06:29:15.553757: train_loss -0.6814 
2025-06-04 06:29:16.031066: val_loss -0.6705 
2025-06-04 06:29:16.417302: Pseudo dice [np.float32(0.7729)] 
2025-06-04 06:29:16.596141: Epoch time: 130.61 s 
2025-06-04 06:29:20.660231:  
2025-06-04 06:29:20.817966: Epoch 593 
2025-06-04 06:29:21.010841: Current learning rate: 0.00445 
2025-06-04 06:31:25.745944: train_loss -0.7219 
2025-06-04 06:31:25.766238: val_loss -0.6309 
2025-06-04 06:31:25.782403: Pseudo dice [np.float32(0.7629)] 
2025-06-04 06:31:25.801158: Epoch time: 125.09 s 
2025-06-04 06:31:31.562485:  
2025-06-04 06:31:31.595636: Epoch 594 
2025-06-04 06:31:31.624135: Current learning rate: 0.00444 
2025-06-04 06:33:40.984510: train_loss -0.7039 
2025-06-04 06:33:41.539812: val_loss -0.6411 
2025-06-04 06:33:41.883681: Pseudo dice [np.float32(0.6995)] 
2025-06-04 06:33:42.720921: Epoch time: 129.42 s 
2025-06-04 06:33:47.048088:  
2025-06-04 06:33:47.082098: Epoch 595 
2025-06-04 06:33:47.148752: Current learning rate: 0.00443 
2025-06-04 06:36:00.626897: train_loss -0.6773 
2025-06-04 06:36:00.967216: val_loss -0.721 
2025-06-04 06:36:01.351836: Pseudo dice [np.float32(0.8372)] 
2025-06-04 06:36:01.890730: Epoch time: 133.58 s 
2025-06-04 06:36:06.198618:  
2025-06-04 06:36:06.219426: Epoch 596 
2025-06-04 06:36:06.237379: Current learning rate: 0.00442 
2025-06-04 06:38:10.895731: train_loss -0.6991 
2025-06-04 06:38:10.918319: val_loss -0.6765 
2025-06-04 06:38:10.933110: Pseudo dice [np.float32(0.7839)] 
2025-06-04 06:38:10.950495: Epoch time: 124.7 s 
2025-06-04 06:38:17.117576:  
2025-06-04 06:38:17.141217: Epoch 597 
2025-06-04 06:38:17.163637: Current learning rate: 0.00441 
2025-06-04 06:40:26.161942: train_loss -0.6869 
2025-06-04 06:40:26.324908: val_loss -0.6338 
2025-06-04 06:40:26.473343: Pseudo dice [np.float32(0.6987)] 
2025-06-04 06:40:26.721431: Epoch time: 129.05 s 
2025-06-04 06:40:28.736277:  
2025-06-04 06:40:28.784384: Epoch 598 
2025-06-04 06:40:28.809000: Current learning rate: 0.0044 
2025-06-04 06:42:37.817995: train_loss -0.6844 
2025-06-04 06:42:37.841624: val_loss -0.6691 
2025-06-04 06:42:37.856554: Pseudo dice [np.float32(0.7138)] 
2025-06-04 06:42:37.872906: Epoch time: 129.08 s 
2025-06-04 06:42:40.704664:  
2025-06-04 06:42:40.729196: Epoch 599 
2025-06-04 06:42:40.746818: Current learning rate: 0.00439 
2025-06-04 06:44:47.541552: train_loss -0.6957 
2025-06-04 06:44:47.813042: val_loss -0.6976 
2025-06-04 06:44:48.177741: Pseudo dice [np.float32(0.7605)] 
2025-06-04 06:44:48.540863: Epoch time: 126.84 s 
2025-06-04 06:44:52.018961:  
2025-06-04 06:44:52.035203: Epoch 600 
2025-06-04 06:44:52.049731: Current learning rate: 0.00438 
2025-06-04 06:47:03.472023: train_loss -0.6834 
2025-06-04 06:47:03.802168: val_loss -0.6699 
2025-06-04 06:47:03.935228: Pseudo dice [np.float32(0.7945)] 
2025-06-04 06:47:04.120108: Epoch time: 131.45 s 
2025-06-04 06:47:06.900115:  
2025-06-04 06:47:06.933942: Epoch 601 
2025-06-04 06:47:06.958446: Current learning rate: 0.00437 
2025-06-04 06:49:14.274400: train_loss -0.7153 
2025-06-04 06:49:14.296542: val_loss -0.6742 
2025-06-04 06:49:14.309989: Pseudo dice [np.float32(0.723)] 
2025-06-04 06:49:14.414893: Epoch time: 127.38 s 
2025-06-04 06:49:17.518761:  
2025-06-04 06:49:17.611059: Epoch 602 
2025-06-04 06:49:17.654322: Current learning rate: 0.00436 
2025-06-04 06:51:30.629160: train_loss -0.7157 
2025-06-04 06:51:31.010748: val_loss -0.6688 
2025-06-04 06:51:31.385865: Pseudo dice [np.float32(0.7745)] 
2025-06-04 06:51:31.760685: Epoch time: 133.11 s 
2025-06-04 06:51:35.191279:  
2025-06-04 06:51:35.267968: Epoch 603 
2025-06-04 06:51:35.309837: Current learning rate: 0.00435 
2025-06-04 06:53:48.220647: train_loss -0.6944 
2025-06-04 06:53:48.665380: val_loss -0.6923 
2025-06-04 06:53:49.042756: Pseudo dice [np.float32(0.7114)] 
2025-06-04 06:53:49.346838: Epoch time: 133.03 s 
2025-06-04 06:53:52.383798:  
2025-06-04 06:53:52.405263: Epoch 604 
2025-06-04 06:53:52.423641: Current learning rate: 0.00434 
2025-06-04 06:56:04.413783: train_loss -0.6976 
2025-06-04 06:56:04.574948: val_loss -0.6728 
2025-06-04 06:56:04.837002: Pseudo dice [np.float32(0.7514)] 
2025-06-04 06:56:05.029067: Epoch time: 132.03 s 
2025-06-04 06:56:09.964030:  
2025-06-04 06:56:10.113667: Epoch 605 
2025-06-04 06:56:10.344823: Current learning rate: 0.00433 
2025-06-04 06:58:17.713631: train_loss -0.6876 
2025-06-04 06:58:17.953054: val_loss -0.6508 
2025-06-04 06:58:18.116094: Pseudo dice [np.float32(0.6886)] 
2025-06-04 06:58:18.233576: Epoch time: 127.75 s 
2025-06-04 06:58:20.801968:  
2025-06-04 06:58:20.900020: Epoch 606 
2025-06-04 06:58:20.972193: Current learning rate: 0.00432 
2025-06-04 07:00:33.586016: train_loss -0.7047 
2025-06-04 07:00:33.605495: val_loss -0.6675 
2025-06-04 07:00:33.622202: Pseudo dice [np.float32(0.7396)] 
2025-06-04 07:00:33.636867: Epoch time: 132.79 s 
2025-06-04 07:00:36.535356:  
2025-06-04 07:00:36.691313: Epoch 607 
2025-06-04 07:00:36.729897: Current learning rate: 0.00431 
2025-06-04 07:02:49.598625: train_loss -0.7155 
2025-06-04 07:02:49.618543: val_loss -0.6847 
2025-06-04 07:02:49.637896: Pseudo dice [np.float32(0.7739)] 
2025-06-04 07:02:50.088075: Epoch time: 133.07 s 
2025-06-04 07:02:56.134507:  
2025-06-04 07:02:56.203433: Epoch 608 
2025-06-04 07:02:56.248130: Current learning rate: 0.0043 
2025-06-04 07:05:05.431681: train_loss -0.6705 
2025-06-04 07:05:05.693918: val_loss -0.7113 
2025-06-04 07:05:05.845662: Pseudo dice [np.float32(0.8247)] 
2025-06-04 07:05:05.860998: Epoch time: 129.3 s 
2025-06-04 07:05:09.746825:  
2025-06-04 07:05:09.914943: Epoch 609 
2025-06-04 07:05:10.103209: Current learning rate: 0.00429 
2025-06-04 07:07:19.641659: train_loss -0.7021 
2025-06-04 07:07:20.145388: val_loss -0.6364 
2025-06-04 07:07:20.691444: Pseudo dice [np.float32(0.6935)] 
2025-06-04 07:07:20.873062: Epoch time: 129.9 s 
2025-06-04 07:07:23.981347:  
2025-06-04 07:07:24.006023: Epoch 610 
2025-06-04 07:07:24.031062: Current learning rate: 0.00429 
2025-06-04 07:09:35.371346: train_loss -0.7178 
2025-06-04 07:09:35.750382: val_loss -0.6695 
2025-06-04 07:09:36.091980: Pseudo dice [np.float32(0.7326)] 
2025-06-04 07:09:36.109974: Epoch time: 131.39 s 
2025-06-04 07:09:40.147354:  
2025-06-04 07:09:40.167809: Epoch 611 
2025-06-04 07:09:40.300410: Current learning rate: 0.00428 
2025-06-04 07:11:53.993470: train_loss -0.697 
2025-06-04 07:11:54.400466: val_loss -0.6446 
2025-06-04 07:11:54.791279: Pseudo dice [np.float32(0.7324)] 
2025-06-04 07:11:55.211300: Epoch time: 133.85 s 
2025-06-04 07:11:58.790826:  
2025-06-04 07:11:58.888587: Epoch 612 
2025-06-04 07:11:58.946386: Current learning rate: 0.00427 
2025-06-04 07:14:07.221771: train_loss -0.7172 
2025-06-04 07:14:07.240297: val_loss -0.6884 
2025-06-04 07:14:07.527906: Pseudo dice [np.float32(0.7457)] 
2025-06-04 07:14:07.949008: Epoch time: 128.43 s 
2025-06-04 07:14:10.435880:  
2025-06-04 07:14:10.511006: Epoch 613 
2025-06-04 07:14:10.603589: Current learning rate: 0.00426 
2025-06-04 07:16:20.237069: train_loss -0.6976 
2025-06-04 07:16:20.648471: val_loss -0.6372 
2025-06-04 07:16:21.134549: Pseudo dice [np.float32(0.7467)] 
2025-06-04 07:16:21.448136: Epoch time: 129.8 s 
2025-06-04 07:16:25.889360:  
2025-06-04 07:16:25.980753: Epoch 614 
2025-06-04 07:16:26.101819: Current learning rate: 0.00425 
2025-06-04 07:18:33.728159: train_loss -0.7117 
2025-06-04 07:18:34.385020: val_loss -0.6709 
2025-06-04 07:18:34.850753: Pseudo dice [np.float32(0.7553)] 
2025-06-04 07:18:35.271141: Epoch time: 127.84 s 
2025-06-04 07:18:38.653335:  
2025-06-04 07:18:38.676113: Epoch 615 
2025-06-04 07:18:38.694729: Current learning rate: 0.00424 
2025-06-04 07:20:50.532142: train_loss -0.6921 
2025-06-04 07:20:50.558069: val_loss -0.6533 
2025-06-04 07:20:50.576310: Pseudo dice [np.float32(0.7801)] 
2025-06-04 07:20:50.603846: Epoch time: 131.88 s 
2025-06-04 07:20:53.969975:  
2025-06-04 07:20:53.995624: Epoch 616 
2025-06-04 07:20:54.019684: Current learning rate: 0.00423 
2025-06-04 07:23:08.177709: train_loss -0.7184 
2025-06-04 07:23:08.516001: val_loss -0.6509 
2025-06-04 07:23:08.973051: Pseudo dice [np.float32(0.7454)] 
2025-06-04 07:23:09.301502: Epoch time: 134.21 s 
2025-06-04 07:23:12.050667:  
2025-06-04 07:23:12.079873: Epoch 617 
2025-06-04 07:23:12.099045: Current learning rate: 0.00422 
2025-06-04 07:25:23.894009: train_loss -0.7061 
2025-06-04 07:25:23.931186: val_loss -0.6841 
2025-06-04 07:25:23.948622: Pseudo dice [np.float32(0.7934)] 
2025-06-04 07:25:23.962965: Epoch time: 131.85 s 
2025-06-04 07:25:27.967278:  
2025-06-04 07:25:27.998476: Epoch 618 
2025-06-04 07:25:28.032883: Current learning rate: 0.00421 
2025-06-04 07:27:37.402563: train_loss -0.7266 
2025-06-04 07:27:37.430597: val_loss -0.6989 
2025-06-04 07:27:37.748080: Pseudo dice [np.float32(0.8126)] 
2025-06-04 07:27:38.227719: Epoch time: 129.44 s 
2025-06-04 07:27:44.568522:  
2025-06-04 07:27:44.601444: Epoch 619 
2025-06-04 07:27:44.640433: Current learning rate: 0.0042 
2025-06-04 07:29:55.444500: train_loss -0.6918 
2025-06-04 07:29:55.664768: val_loss -0.6714 
2025-06-04 07:29:55.884801: Pseudo dice [np.float32(0.7232)] 
2025-06-04 07:29:56.241665: Epoch time: 130.88 s 
2025-06-04 07:30:01.716468:  
2025-06-04 07:30:02.130608: Epoch 620 
2025-06-04 07:30:02.149707: Current learning rate: 0.00419 
2025-06-04 07:32:08.328016: train_loss -0.7032 
2025-06-04 07:32:08.349993: val_loss -0.6579 
2025-06-04 07:32:08.365962: Pseudo dice [np.float32(0.7607)] 
2025-06-04 07:32:08.591216: Epoch time: 126.61 s 
2025-06-04 07:32:11.310502:  
2025-06-04 07:32:11.329588: Epoch 621 
2025-06-04 07:32:11.354482: Current learning rate: 0.00418 
2025-06-04 07:34:19.390467: train_loss -0.6887 
2025-06-04 07:34:19.419670: val_loss -0.6588 
2025-06-04 07:34:19.442739: Pseudo dice [np.float32(0.6789)] 
2025-06-04 07:34:19.456975: Epoch time: 128.08 s 
2025-06-04 07:34:24.034569:  
2025-06-04 07:34:24.061145: Epoch 622 
2025-06-04 07:34:24.084336: Current learning rate: 0.00417 
2025-06-04 07:36:30.073454: train_loss -0.6934 
2025-06-04 07:36:30.249255: val_loss -0.6567 
2025-06-04 07:36:30.523793: Pseudo dice [np.float32(0.6687)] 
2025-06-04 07:36:30.764683: Epoch time: 126.04 s 
2025-06-04 07:36:33.852624:  
2025-06-04 07:36:33.869730: Epoch 623 
2025-06-04 07:36:33.893569: Current learning rate: 0.00416 
2025-06-04 07:38:44.931083: train_loss -0.7085 
2025-06-04 07:38:45.157638: val_loss -0.6764 
2025-06-04 07:38:45.353086: Pseudo dice [np.float32(0.73)] 
2025-06-04 07:38:45.569577: Epoch time: 131.08 s 
2025-06-04 07:38:47.452210:  
2025-06-04 07:38:47.479952: Epoch 624 
2025-06-04 07:38:47.494577: Current learning rate: 0.00415 
2025-06-04 07:40:58.697879: train_loss -0.7044 
2025-06-04 07:40:58.719485: val_loss -0.69 
2025-06-04 07:40:58.736397: Pseudo dice [np.float32(0.7633)] 
2025-06-04 07:40:58.754631: Epoch time: 131.25 s 
2025-06-04 07:41:01.395988:  
2025-06-04 07:41:01.478991: Epoch 625 
2025-06-04 07:41:01.560883: Current learning rate: 0.00414 
2025-06-04 07:43:11.086164: train_loss -0.7004 
2025-06-04 07:43:11.394910: val_loss -0.6757 
2025-06-04 07:43:11.700970: Pseudo dice [np.float32(0.7088)] 
2025-06-04 07:43:11.989135: Epoch time: 129.69 s 
2025-06-04 07:43:16.885323:  
2025-06-04 07:43:16.975342: Epoch 626 
2025-06-04 07:43:17.126506: Current learning rate: 0.00413 
2025-06-04 07:45:27.774742: train_loss -0.7081 
2025-06-04 07:45:27.979519: val_loss -0.6847 
2025-06-04 07:45:28.282095: Pseudo dice [np.float32(0.7346)] 
2025-06-04 07:45:28.608836: Epoch time: 130.89 s 
2025-06-04 07:45:33.055964:  
2025-06-04 07:45:33.134924: Epoch 627 
2025-06-04 07:45:33.174173: Current learning rate: 0.00412 
2025-06-04 07:47:43.491137: train_loss -0.7055 
2025-06-04 07:47:43.860672: val_loss -0.6466 
2025-06-04 07:47:44.241055: Pseudo dice [np.float32(0.7099)] 
2025-06-04 07:47:44.581781: Epoch time: 130.44 s 
2025-06-04 07:47:47.660358:  
2025-06-04 07:47:47.841995: Epoch 628 
2025-06-04 07:47:47.975392: Current learning rate: 0.00411 
2025-06-04 07:50:06.263215: train_loss -0.6949 
2025-06-04 07:50:06.283739: val_loss -0.6316 
2025-06-04 07:50:06.302585: Pseudo dice [np.float32(0.712)] 
2025-06-04 07:50:06.433163: Epoch time: 138.6 s 
2025-06-04 07:50:09.184998:  
2025-06-04 07:50:09.314382: Epoch 629 
2025-06-04 07:50:09.558799: Current learning rate: 0.0041 
2025-06-04 07:52:23.080880: train_loss -0.6848 
2025-06-04 07:52:23.739545: val_loss -0.6538 
2025-06-04 07:52:24.322356: Pseudo dice [np.float32(0.7062)] 
2025-06-04 07:52:24.666009: Epoch time: 133.9 s 
2025-06-04 07:52:27.643259:  
2025-06-04 07:52:27.723725: Epoch 630 
2025-06-04 07:52:27.819987: Current learning rate: 0.00409 
2025-06-04 07:54:41.823139: train_loss -0.7023 
2025-06-04 07:54:41.852222: val_loss -0.6997 
2025-06-04 07:54:41.921674: Pseudo dice [np.float32(0.7964)] 
2025-06-04 07:54:42.254279: Epoch time: 134.18 s 
2025-06-04 07:54:45.932364:  
2025-06-04 07:54:46.006975: Epoch 631 
2025-06-04 07:54:46.031372: Current learning rate: 0.00408 
2025-06-04 07:56:57.594543: train_loss -0.718 
2025-06-04 07:56:57.848334: val_loss -0.6943 
2025-06-04 07:56:58.037057: Pseudo dice [np.float32(0.7899)] 
2025-06-04 07:56:58.377760: Epoch time: 131.66 s 
2025-06-04 07:57:01.751145:  
2025-06-04 07:57:01.888853: Epoch 632 
2025-06-04 07:57:02.034255: Current learning rate: 0.00407 
2025-06-04 07:59:14.488296: train_loss -0.728 
2025-06-04 07:59:14.508106: val_loss -0.6632 
2025-06-04 07:59:14.527780: Pseudo dice [np.float32(0.7512)] 
2025-06-04 07:59:14.546630: Epoch time: 132.74 s 
2025-06-04 07:59:18.313507:  
2025-06-04 07:59:18.403619: Epoch 633 
2025-06-04 07:59:18.521549: Current learning rate: 0.00406 
2025-06-04 08:01:31.288808: train_loss -0.6991 
2025-06-04 08:01:31.312137: val_loss -0.6909 
2025-06-04 08:01:31.329941: Pseudo dice [np.float32(0.8171)] 
2025-06-04 08:01:31.346698: Epoch time: 132.98 s 
2025-06-04 08:01:35.522504:  
2025-06-04 08:01:35.543404: Epoch 634 
2025-06-04 08:01:35.564765: Current learning rate: 0.00405 
2025-06-04 08:03:44.818738: train_loss -0.7062 
2025-06-04 08:03:44.862181: val_loss -0.7067 
2025-06-04 08:03:44.952104: Pseudo dice [np.float32(0.8051)] 
2025-06-04 08:03:45.028872: Epoch time: 129.3 s 
2025-06-04 08:03:47.302482:  
2025-06-04 08:03:47.343929: Epoch 635 
2025-06-04 08:03:47.463513: Current learning rate: 0.00404 
2025-06-04 08:06:02.054029: train_loss -0.7152 
2025-06-04 08:06:02.391680: val_loss -0.6566 
2025-06-04 08:06:02.775006: Pseudo dice [np.float32(0.713)] 
2025-06-04 08:06:03.215258: Epoch time: 134.75 s 
2025-06-04 08:06:06.449914:  
2025-06-04 08:06:06.474485: Epoch 636 
2025-06-04 08:06:06.514373: Current learning rate: 0.00403 
2025-06-04 08:08:16.770335: train_loss -0.6952 
2025-06-04 08:08:16.957400: val_loss -0.6397 
2025-06-04 08:08:17.046143: Pseudo dice [np.float32(0.6933)] 
2025-06-04 08:08:17.161581: Epoch time: 130.32 s 
2025-06-04 08:08:20.253878:  
2025-06-04 08:08:20.289620: Epoch 637 
2025-06-04 08:08:20.309200: Current learning rate: 0.00402 
2025-06-04 08:10:31.470697: train_loss -0.7288 
2025-06-04 08:10:31.499589: val_loss -0.6534 
2025-06-04 08:10:32.040612: Pseudo dice [np.float32(0.7858)] 
2025-06-04 08:10:32.553205: Epoch time: 131.22 s 
2025-06-04 08:10:35.933319:  
2025-06-04 08:10:36.127611: Epoch 638 
2025-06-04 08:10:36.211354: Current learning rate: 0.00401 
2025-06-04 08:12:44.499796: train_loss -0.6782 
2025-06-04 08:12:44.832050: val_loss -0.7243 
2025-06-04 08:12:45.241740: Pseudo dice [np.float32(0.7723)] 
2025-06-04 08:12:45.525045: Epoch time: 128.57 s 
2025-06-04 08:12:48.992567:  
2025-06-04 08:12:49.019694: Epoch 639 
2025-06-04 08:12:49.048355: Current learning rate: 0.004 
2025-06-04 08:14:59.510841: train_loss -0.6919 
2025-06-04 08:14:59.986343: val_loss -0.6454 
2025-06-04 08:15:00.568408: Pseudo dice [np.float32(0.744)] 
2025-06-04 08:15:00.787859: Epoch time: 130.52 s 
2025-06-04 08:15:04.547920:  
2025-06-04 08:15:04.653335: Epoch 640 
2025-06-04 08:15:04.783089: Current learning rate: 0.00399 
2025-06-04 08:17:09.900605: train_loss -0.7041 
2025-06-04 08:17:09.919914: val_loss -0.6499 
2025-06-04 08:17:09.937389: Pseudo dice [np.float32(0.7995)] 
2025-06-04 08:17:09.957861: Epoch time: 125.36 s 
2025-06-04 08:17:14.468912:  
2025-06-04 08:17:14.579777: Epoch 641 
2025-06-04 08:17:14.626939: Current learning rate: 0.00398 
2025-06-04 08:19:22.424035: train_loss -0.6818 
2025-06-04 08:19:23.306777: val_loss -0.698 
2025-06-04 08:19:23.325053: Pseudo dice [np.float32(0.6925)] 
2025-06-04 08:19:23.344572: Epoch time: 127.96 s 
2025-06-04 08:19:28.036450:  
2025-06-04 08:19:28.063851: Epoch 642 
2025-06-04 08:19:28.087365: Current learning rate: 0.00397 
2025-06-04 08:21:39.374793: train_loss -0.7045 
2025-06-04 08:21:39.775199: val_loss -0.6623 
2025-06-04 08:21:39.799860: Pseudo dice [np.float32(0.7919)] 
2025-06-04 08:21:39.817117: Epoch time: 131.34 s 
2025-06-04 08:21:42.696742:  
2025-06-04 08:21:42.831798: Epoch 643 
2025-06-04 08:21:42.907158: Current learning rate: 0.00396 
2025-06-04 08:23:51.277561: train_loss -0.6905 
2025-06-04 08:23:51.623244: val_loss -0.6932 
2025-06-04 08:23:51.978372: Pseudo dice [np.float32(0.8413)] 
2025-06-04 08:23:51.997935: Epoch time: 128.58 s 
2025-06-04 08:23:56.007417:  
2025-06-04 08:23:56.200528: Epoch 644 
2025-06-04 08:23:56.463509: Current learning rate: 0.00395 
2025-06-04 08:26:04.188159: train_loss -0.6956 
2025-06-04 08:26:04.282088: val_loss -0.6806 
2025-06-04 08:26:04.447297: Pseudo dice [np.float32(0.7421)] 
2025-06-04 08:26:04.535666: Epoch time: 128.18 s 
2025-06-04 08:26:06.120281:  
2025-06-04 08:26:06.140173: Epoch 645 
2025-06-04 08:26:06.167289: Current learning rate: 0.00394 
2025-06-04 08:28:18.111689: train_loss -0.7207 
2025-06-04 08:28:18.410645: val_loss -0.6682 
2025-06-04 08:28:18.867182: Pseudo dice [np.float32(0.6549)] 
2025-06-04 08:28:19.146616: Epoch time: 131.99 s 
2025-06-04 08:28:21.804858:  
2025-06-04 08:28:21.820418: Epoch 646 
2025-06-04 08:28:21.832813: Current learning rate: 0.00393 
2025-06-04 08:30:28.019426: train_loss -0.6924 
2025-06-04 08:30:28.038534: val_loss -0.6477 
2025-06-04 08:30:28.064089: Pseudo dice [np.float32(0.7359)] 
2025-06-04 08:30:28.079428: Epoch time: 126.21 s 
2025-06-04 08:30:31.605176:  
2025-06-04 08:30:31.635611: Epoch 647 
2025-06-04 08:30:31.695820: Current learning rate: 0.00392 
2025-06-04 08:32:41.322453: train_loss -0.6981 
2025-06-04 08:32:41.657815: val_loss -0.6849 
2025-06-04 08:32:42.049744: Pseudo dice [np.float32(0.7552)] 
2025-06-04 08:32:42.387801: Epoch time: 129.72 s 
2025-06-04 08:32:46.457702:  
2025-06-04 08:32:46.508346: Epoch 648 
2025-06-04 08:32:46.556246: Current learning rate: 0.00391 
2025-06-04 08:35:02.060785: train_loss -0.6772 
2025-06-04 08:35:02.354535: val_loss -0.6605 
2025-06-04 08:35:02.573121: Pseudo dice [np.float32(0.709)] 
2025-06-04 08:35:02.996934: Epoch time: 135.61 s 
2025-06-04 08:35:07.385556:  
2025-06-04 08:35:07.472968: Epoch 649 
2025-06-04 08:35:07.566438: Current learning rate: 0.0039 
2025-06-04 08:37:16.891411: train_loss -0.691 
2025-06-04 08:37:17.221732: val_loss -0.6737 
2025-06-04 08:37:17.454139: Pseudo dice [np.float32(0.7016)] 
2025-06-04 08:37:17.971397: Epoch time: 129.51 s 
2025-06-04 08:37:24.593358:  
2025-06-04 08:37:24.616359: Epoch 650 
2025-06-04 08:37:24.637626: Current learning rate: 0.00389 
2025-06-04 08:39:34.665660: train_loss -0.7111 
2025-06-04 08:39:35.038416: val_loss -0.601 
2025-06-04 08:39:35.372496: Pseudo dice [np.float32(0.6727)] 
2025-06-04 08:39:35.736939: Epoch time: 130.07 s 
2025-06-04 08:39:40.081753:  
2025-06-04 08:39:40.234718: Epoch 651 
2025-06-04 08:39:40.384700: Current learning rate: 0.00388 
2025-06-04 08:41:51.327668: train_loss -0.6808 
2025-06-04 08:41:51.786971: val_loss -0.6888 
2025-06-04 08:41:52.124488: Pseudo dice [np.float32(0.7482)] 
2025-06-04 08:41:52.486730: Epoch time: 131.25 s 
2025-06-04 08:41:55.388920:  
2025-06-04 08:41:55.549159: Epoch 652 
2025-06-04 08:41:55.620729: Current learning rate: 0.00387 
2025-06-04 08:44:05.232673: train_loss -0.6867 
2025-06-04 08:44:05.394703: val_loss -0.6259 
2025-06-04 08:44:05.633829: Pseudo dice [np.float32(0.5942)] 
2025-06-04 08:44:05.650701: Epoch time: 129.85 s 
2025-06-04 08:44:09.897996:  
2025-06-04 08:44:10.021713: Epoch 653 
2025-06-04 08:44:10.195589: Current learning rate: 0.00386 
2025-06-04 08:46:22.272750: train_loss -0.6741 
2025-06-04 08:46:22.900796: val_loss -0.6812 
2025-06-04 08:46:23.325293: Pseudo dice [np.float32(0.7554)] 
2025-06-04 08:46:23.718795: Epoch time: 132.38 s 
2025-06-04 08:46:27.187270:  
2025-06-04 08:46:27.405716: Epoch 654 
2025-06-04 08:46:27.646019: Current learning rate: 0.00385 
2025-06-04 08:48:40.137175: train_loss -0.7052 
2025-06-04 08:48:40.387112: val_loss -0.6489 
2025-06-04 08:48:40.802422: Pseudo dice [np.float32(0.7508)] 
2025-06-04 08:48:41.185970: Epoch time: 132.95 s 
2025-06-04 08:48:44.834125:  
2025-06-04 08:48:44.858414: Epoch 655 
2025-06-04 08:48:44.949603: Current learning rate: 0.00384 
2025-06-04 08:50:56.769020: train_loss -0.6858 
2025-06-04 08:50:57.060860: val_loss -0.7043 
2025-06-04 08:50:57.184129: Pseudo dice [np.float32(0.6929)] 
2025-06-04 08:50:57.455271: Epoch time: 131.94 s 
2025-06-04 08:51:00.463056:  
2025-06-04 08:51:00.514618: Epoch 656 
2025-06-04 08:51:00.558088: Current learning rate: 0.00383 
2025-06-04 08:53:12.531332: train_loss -0.6966 
2025-06-04 08:53:13.162385: val_loss -0.7222 
2025-06-04 08:53:13.179514: Pseudo dice [np.float32(0.772)] 
2025-06-04 08:53:13.198015: Epoch time: 132.07 s 
2025-06-04 08:53:16.324522:  
2025-06-04 08:53:16.340751: Epoch 657 
2025-06-04 08:53:16.354338: Current learning rate: 0.00382 
2025-06-04 08:55:23.364025: train_loss -0.6987 
2025-06-04 08:55:23.936952: val_loss -0.6843 
2025-06-04 08:55:24.430766: Pseudo dice [np.float32(0.8011)] 
2025-06-04 08:55:24.881725: Epoch time: 127.04 s 
2025-06-04 08:55:28.130989:  
2025-06-04 08:55:28.159868: Epoch 658 
2025-06-04 08:55:28.202806: Current learning rate: 0.00381 
2025-06-04 08:57:37.645928: train_loss -0.6902 
2025-06-04 08:57:37.668837: val_loss -0.675 
2025-06-04 08:57:37.926588: Pseudo dice [np.float32(0.8074)] 
2025-06-04 08:57:38.271404: Epoch time: 129.52 s 
2025-06-04 08:57:42.609354:  
2025-06-04 08:57:42.824094: Epoch 659 
2025-06-04 08:57:42.972902: Current learning rate: 0.0038 
2025-06-04 08:59:55.689112: train_loss -0.6862 
2025-06-04 08:59:55.986602: val_loss -0.6622 
2025-06-04 08:59:56.272749: Pseudo dice [np.float32(0.7503)] 
2025-06-04 08:59:56.291097: Epoch time: 133.08 s 
2025-06-04 09:00:00.775491:  
2025-06-04 09:00:00.915074: Epoch 660 
2025-06-04 09:00:00.971137: Current learning rate: 0.00379 
2025-06-04 09:02:10.067577: train_loss -0.7072 
2025-06-04 09:02:10.231223: val_loss -0.6711 
2025-06-04 09:02:10.292823: Pseudo dice [np.float32(0.7709)] 
2025-06-04 09:02:10.310654: Epoch time: 129.29 s 
2025-06-04 09:02:12.898767:  
2025-06-04 09:02:13.058769: Epoch 661 
2025-06-04 09:02:13.079012: Current learning rate: 0.00378 
2025-06-04 09:04:20.039135: train_loss -0.6947 
2025-06-04 09:04:20.409065: val_loss -0.6883 
2025-06-04 09:04:20.781223: Pseudo dice [np.float32(0.7505)] 
2025-06-04 09:04:20.801388: Epoch time: 127.14 s 
2025-06-04 09:04:23.948746:  
2025-06-04 09:04:23.971845: Epoch 662 
2025-06-04 09:04:23.994554: Current learning rate: 0.00377 
2025-06-04 09:06:33.664127: train_loss -0.6957 
2025-06-04 09:06:33.893898: val_loss -0.6169 
2025-06-04 09:06:34.162183: Pseudo dice [np.float32(0.6711)] 
2025-06-04 09:06:34.264629: Epoch time: 129.72 s 
2025-06-04 09:06:39.038749:  
2025-06-04 09:06:39.406318: Epoch 663 
2025-06-04 09:06:39.712653: Current learning rate: 0.00376 
2025-06-04 09:08:43.754534: train_loss -0.7035 
2025-06-04 09:08:44.054085: val_loss -0.6744 
2025-06-04 09:08:44.440052: Pseudo dice [np.float32(0.7202)] 
2025-06-04 09:08:44.710128: Epoch time: 124.72 s 
2025-06-04 09:08:47.696018:  
2025-06-04 09:08:47.767294: Epoch 664 
2025-06-04 09:08:47.879325: Current learning rate: 0.00375 
2025-06-04 09:10:58.128299: train_loss -0.6988 
2025-06-04 09:10:58.253625: val_loss -0.7084 
2025-06-04 09:10:58.349881: Pseudo dice [np.float32(0.7789)] 
2025-06-04 09:10:58.368209: Epoch time: 130.43 s 
2025-06-04 09:10:59.815784:  
2025-06-04 09:10:59.827891: Epoch 665 
2025-06-04 09:10:59.861856: Current learning rate: 0.00374 
2025-06-04 09:13:13.015829: train_loss -0.7052 
2025-06-04 09:13:13.034476: val_loss -0.6696 
2025-06-04 09:13:13.050105: Pseudo dice [np.float32(0.7924)] 
2025-06-04 09:13:13.068668: Epoch time: 133.2 s 
2025-06-04 09:13:17.414859:  
2025-06-04 09:13:17.439223: Epoch 666 
2025-06-04 09:13:17.475410: Current learning rate: 0.00373 
2025-06-04 09:15:29.311968: train_loss -0.7166 
2025-06-04 09:15:29.334759: val_loss -0.6814 
2025-06-04 09:15:29.349732: Pseudo dice [np.float32(0.7451)] 
2025-06-04 09:15:29.559084: Epoch time: 131.9 s 
2025-06-04 09:15:33.270690:  
2025-06-04 09:15:33.332848: Epoch 667 
2025-06-04 09:15:33.418226: Current learning rate: 0.00372 
2025-06-04 09:17:43.201495: train_loss -0.7228 
2025-06-04 09:17:43.481817: val_loss -0.656 
2025-06-04 09:17:43.786986: Pseudo dice [np.float32(0.6548)] 
2025-06-04 09:17:44.089275: Epoch time: 129.93 s 
2025-06-04 09:17:47.632108:  
2025-06-04 09:17:47.823276: Epoch 668 
2025-06-04 09:17:47.991156: Current learning rate: 0.00371 
2025-06-04 09:20:00.313425: train_loss -0.6874 
2025-06-04 09:20:00.583195: val_loss -0.6872 
2025-06-04 09:20:00.604237: Pseudo dice [np.float32(0.7744)] 
2025-06-04 09:20:00.621299: Epoch time: 132.68 s 
2025-06-04 09:20:03.639869:  
2025-06-04 09:20:03.693296: Epoch 669 
2025-06-04 09:20:03.710760: Current learning rate: 0.0037 
2025-06-04 09:22:18.348112: train_loss -0.69 
2025-06-04 09:22:18.694993: val_loss -0.6659 
2025-06-04 09:22:19.015286: Pseudo dice [np.float32(0.6974)] 
2025-06-04 09:22:19.259251: Epoch time: 134.71 s 
2025-06-04 09:22:21.814672:  
2025-06-04 09:22:21.868631: Epoch 670 
2025-06-04 09:22:22.005146: Current learning rate: 0.00369 
2025-06-04 09:24:35.036686: train_loss -0.6601 
2025-06-04 09:24:35.242079: val_loss -0.6663 
2025-06-04 09:24:35.569915: Pseudo dice [np.float32(0.7349)] 
2025-06-04 09:24:35.971700: Epoch time: 133.22 s 
2025-06-04 09:24:41.079081:  
2025-06-04 09:24:41.337529: Epoch 671 
2025-06-04 09:24:41.387588: Current learning rate: 0.00368 
2025-06-04 09:26:50.489126: train_loss -0.7016 
2025-06-04 09:26:50.695358: val_loss -0.6986 
2025-06-04 09:26:50.975398: Pseudo dice [np.float32(0.7541)] 
2025-06-04 09:26:51.211519: Epoch time: 129.41 s 
2025-06-04 09:26:53.905054:  
2025-06-04 09:26:54.043996: Epoch 672 
2025-06-04 09:26:54.243014: Current learning rate: 0.00367 
2025-06-04 09:29:06.170088: train_loss -0.7019 
2025-06-04 09:29:06.343134: val_loss -0.6783 
2025-06-04 09:29:06.606831: Pseudo dice [np.float32(0.7462)] 
2025-06-04 09:29:06.741967: Epoch time: 132.27 s 
2025-06-04 09:29:09.897841:  
2025-06-04 09:29:09.925046: Epoch 673 
2025-06-04 09:29:10.040525: Current learning rate: 0.00366 
2025-06-04 09:31:24.963223: train_loss -0.6967 
2025-06-04 09:31:24.983268: val_loss -0.6573 
2025-06-04 09:31:25.002350: Pseudo dice [np.float32(0.7322)] 
2025-06-04 09:31:25.016704: Epoch time: 135.07 s 
2025-06-04 09:31:28.580854:  
2025-06-04 09:31:28.676631: Epoch 674 
2025-06-04 09:31:28.831830: Current learning rate: 0.00365 
2025-06-04 09:33:40.693023: train_loss -0.7083 
2025-06-04 09:33:40.714752: val_loss -0.6396 
2025-06-04 09:33:40.732085: Pseudo dice [np.float32(0.7867)] 
2025-06-04 09:33:40.749334: Epoch time: 132.11 s 
2025-06-04 09:33:43.455062:  
2025-06-04 09:33:43.594047: Epoch 675 
2025-06-04 09:33:43.672851: Current learning rate: 0.00364 
2025-06-04 09:35:57.242629: train_loss -0.7185 
2025-06-04 09:35:57.262392: val_loss -0.6368 
2025-06-04 09:35:57.513037: Pseudo dice [np.float32(0.6329)] 
2025-06-04 09:35:57.796324: Epoch time: 133.79 s 
2025-06-04 09:36:01.272443:  
2025-06-04 09:36:01.395472: Epoch 676 
2025-06-04 09:36:01.431327: Current learning rate: 0.00363 
2025-06-04 09:38:12.897284: train_loss -0.7045 
2025-06-04 09:38:12.919038: val_loss -0.6246 
2025-06-04 09:38:12.957654: Pseudo dice [np.float32(0.7464)] 
2025-06-04 09:38:12.978230: Epoch time: 131.63 s 
2025-06-04 09:38:16.752325:  
2025-06-04 09:38:16.811497: Epoch 677 
2025-06-04 09:38:16.890365: Current learning rate: 0.00362 
2025-06-04 09:40:29.020399: train_loss -0.7173 
2025-06-04 09:40:29.387702: val_loss -0.6876 
2025-06-04 09:40:29.406088: Pseudo dice [np.float32(0.7586)] 
2025-06-04 09:40:29.425016: Epoch time: 132.27 s 
2025-06-04 09:40:34.217877:  
2025-06-04 09:40:34.328817: Epoch 678 
2025-06-04 09:40:34.473567: Current learning rate: 0.00361 
2025-06-04 09:42:46.337271: train_loss -0.6975 
2025-06-04 09:42:46.487909: val_loss -0.6814 
2025-06-04 09:42:46.505194: Pseudo dice [np.float32(0.7556)] 
2025-06-04 09:42:46.519910: Epoch time: 132.12 s 
2025-06-04 09:42:50.127177:  
2025-06-04 09:42:50.308072: Epoch 679 
2025-06-04 09:42:50.328825: Current learning rate: 0.0036 
2025-06-04 09:45:00.827220: train_loss -0.6848 
2025-06-04 09:45:01.304402: val_loss -0.692 
2025-06-04 09:45:01.458785: Pseudo dice [np.float32(0.6972)] 
2025-06-04 09:45:01.605825: Epoch time: 130.7 s 
2025-06-04 09:45:04.213998:  
2025-06-04 09:45:04.262766: Epoch 680 
2025-06-04 09:45:04.313162: Current learning rate: 0.00359 
2025-06-04 09:47:18.565032: train_loss -0.7218 
2025-06-04 09:47:18.792800: val_loss -0.6285 
2025-06-04 09:47:18.882577: Pseudo dice [np.float32(0.7334)] 
2025-06-04 09:47:18.972265: Epoch time: 134.35 s 
2025-06-04 09:47:22.346123:  
2025-06-04 09:47:22.369542: Epoch 681 
2025-06-04 09:47:22.388188: Current learning rate: 0.00358 
2025-06-04 09:49:32.412247: train_loss -0.7157 
2025-06-04 09:49:33.150442: val_loss -0.6536 
2025-06-04 09:49:33.336717: Pseudo dice [np.float32(0.7219)] 
2025-06-04 09:49:33.356124: Epoch time: 130.07 s 
2025-06-04 09:49:36.523239:  
2025-06-04 09:49:36.550397: Epoch 682 
2025-06-04 09:49:36.576143: Current learning rate: 0.00357 
2025-06-04 09:51:51.885211: train_loss -0.6972 
2025-06-04 09:51:52.057316: val_loss -0.6364 
2025-06-04 09:51:52.074835: Pseudo dice [np.float32(0.7008)] 
2025-06-04 09:51:52.088697: Epoch time: 135.36 s 
2025-06-04 09:51:55.292825:  
2025-06-04 09:51:55.312721: Epoch 683 
2025-06-04 09:51:55.333053: Current learning rate: 0.00356 
2025-06-04 09:54:06.869112: train_loss -0.7186 
2025-06-04 09:54:07.054896: val_loss -0.7019 
2025-06-04 09:54:07.315274: Pseudo dice [np.float32(0.8004)] 
2025-06-04 09:54:07.579883: Epoch time: 131.58 s 
2025-06-04 09:54:11.214393:  
2025-06-04 09:54:11.238396: Epoch 684 
2025-06-04 09:54:11.259954: Current learning rate: 0.00355 
2025-06-04 09:56:23.999325: train_loss -0.7022 
2025-06-04 09:56:24.022314: val_loss -0.6494 
2025-06-04 09:56:24.040695: Pseudo dice [np.float32(0.7435)] 
2025-06-04 09:56:24.200011: Epoch time: 132.79 s 
2025-06-04 09:56:29.358420:  
2025-06-04 09:56:29.390732: Epoch 685 
2025-06-04 09:56:29.485225: Current learning rate: 0.00354 
2025-06-04 09:58:37.089411: train_loss -0.7147 
2025-06-04 09:58:37.658396: val_loss -0.682 
2025-06-04 09:58:38.215869: Pseudo dice [np.float32(0.8151)] 
2025-06-04 09:58:38.764870: Epoch time: 127.73 s 
2025-06-04 09:58:41.973975:  
2025-06-04 09:58:41.994618: Epoch 686 
2025-06-04 09:58:42.006541: Current learning rate: 0.00353 
2025-06-04 10:00:49.946682: train_loss -0.7236 
2025-06-04 10:00:50.128067: val_loss -0.6429 
2025-06-04 10:00:50.148434: Pseudo dice [np.float32(0.583)] 
2025-06-04 10:00:50.164215: Epoch time: 127.97 s 
2025-06-04 10:00:54.792454:  
2025-06-04 10:00:54.876378: Epoch 687 
2025-06-04 10:00:54.968060: Current learning rate: 0.00352 
2025-06-04 10:03:01.813596: train_loss -0.6795 
2025-06-04 10:03:01.829479: val_loss -0.674 
2025-06-04 10:03:01.847419: Pseudo dice [np.float32(0.6718)] 
2025-06-04 10:03:01.866193: Epoch time: 127.02 s 
2025-06-04 10:03:05.184493:  
2025-06-04 10:03:05.205691: Epoch 688 
2025-06-04 10:03:05.245260: Current learning rate: 0.00351 
2025-06-04 10:05:17.627504: train_loss -0.713 
2025-06-04 10:05:18.103929: val_loss -0.6453 
2025-06-04 10:05:18.124629: Pseudo dice [np.float32(0.7332)] 
2025-06-04 10:05:18.546412: Epoch time: 132.45 s 
2025-06-04 10:05:21.458200:  
2025-06-04 10:05:21.479941: Epoch 689 
2025-06-04 10:05:21.508860: Current learning rate: 0.0035 
2025-06-04 10:07:33.317445: train_loss -0.7072 
2025-06-04 10:07:33.655362: val_loss -0.6851 
2025-06-04 10:07:33.813205: Pseudo dice [np.float32(0.7857)] 
2025-06-04 10:07:33.830515: Epoch time: 131.86 s 
2025-06-04 10:07:36.700377:  
2025-06-04 10:07:36.862508: Epoch 690 
2025-06-04 10:07:37.035224: Current learning rate: 0.00349 
2025-06-04 10:09:45.456832: train_loss -0.7055 
2025-06-04 10:09:45.477035: val_loss -0.7034 
2025-06-04 10:09:45.660143: Pseudo dice [np.float32(0.7789)] 
2025-06-04 10:09:45.853709: Epoch time: 128.76 s 
2025-06-04 10:09:47.934717:  
2025-06-04 10:09:47.959228: Epoch 691 
2025-06-04 10:09:47.981233: Current learning rate: 0.00348 
2025-06-04 10:11:54.197748: train_loss -0.684 
2025-06-04 10:11:54.223259: val_loss -0.6679 
2025-06-04 10:11:54.239279: Pseudo dice [np.float32(0.737)] 
2025-06-04 10:11:54.298243: Epoch time: 126.27 s 
2025-06-04 10:11:58.122390:  
2025-06-04 10:11:58.142985: Epoch 692 
2025-06-04 10:11:58.156440: Current learning rate: 0.00346 
2025-06-04 10:14:06.524678: train_loss -0.731 
2025-06-04 10:14:06.768083: val_loss -0.7342 
2025-06-04 10:14:06.990237: Pseudo dice [np.float32(0.8367)] 
2025-06-04 10:14:07.273723: Epoch time: 128.4 s 
2025-06-04 10:14:10.727866:  
2025-06-04 10:14:10.752007: Epoch 693 
2025-06-04 10:14:10.772759: Current learning rate: 0.00345 
2025-06-04 10:16:20.465929: train_loss -0.7248 
2025-06-04 10:16:20.737715: val_loss -0.6976 
2025-06-04 10:16:20.990486: Pseudo dice [np.float32(0.8137)] 
2025-06-04 10:16:21.188137: Epoch time: 129.74 s 
2025-06-04 10:16:24.193903:  
2025-06-04 10:16:24.403901: Epoch 694 
2025-06-04 10:16:24.497939: Current learning rate: 0.00344 
2025-06-04 10:18:37.601374: train_loss -0.6773 
2025-06-04 10:18:37.621160: val_loss -0.6113 
2025-06-04 10:18:37.639462: Pseudo dice [np.float32(0.6527)] 
2025-06-04 10:18:37.655699: Epoch time: 133.41 s 
2025-06-04 10:18:40.467506:  
2025-06-04 10:18:40.489623: Epoch 695 
2025-06-04 10:18:40.590446: Current learning rate: 0.00343 
2025-06-04 10:20:52.362661: train_loss -0.7124 
2025-06-04 10:20:52.630852: val_loss -0.634 
2025-06-04 10:20:52.656991: Pseudo dice [np.float32(0.7897)] 
2025-06-04 10:20:52.674184: Epoch time: 131.9 s 
2025-06-04 10:20:57.165311:  
2025-06-04 10:20:57.357425: Epoch 696 
2025-06-04 10:20:57.598569: Current learning rate: 0.00342 
2025-06-04 10:23:16.762723: train_loss -0.7039 
2025-06-04 10:23:16.791093: val_loss -0.7106 
2025-06-04 10:23:16.807537: Pseudo dice [np.float32(0.8018)] 
2025-06-04 10:23:16.827639: Epoch time: 139.6 s 
2025-06-04 10:23:21.719342:  
2025-06-04 10:23:21.740690: Epoch 697 
2025-06-04 10:23:21.763582: Current learning rate: 0.00341 
2025-06-04 10:25:42.076220: train_loss -0.7074 
2025-06-04 10:25:42.098176: val_loss -0.6758 
2025-06-04 10:25:42.113114: Pseudo dice [np.float32(0.7642)] 
2025-06-04 10:25:42.129595: Epoch time: 140.36 s 
2025-06-04 10:25:46.936160:  
2025-06-04 10:25:47.227510: Epoch 698 
2025-06-04 10:25:47.255691: Current learning rate: 0.0034 
2025-06-04 10:28:03.571437: train_loss -0.723 
2025-06-04 10:28:04.175717: val_loss -0.6337 
2025-06-04 10:28:04.715844: Pseudo dice [np.float32(0.7629)] 
2025-06-04 10:28:04.860421: Epoch time: 136.64 s 
2025-06-04 10:28:13.160089:  
2025-06-04 10:28:13.186320: Epoch 699 
2025-06-04 10:28:13.206212: Current learning rate: 0.00339 
2025-06-04 10:30:31.298077: train_loss -0.6985 
2025-06-04 10:30:31.646019: val_loss -0.6985 
2025-06-04 10:30:32.236498: Pseudo dice [np.float32(0.7934)] 
2025-06-04 10:30:32.680026: Epoch time: 138.14 s 
2025-06-04 10:30:42.960404:  
2025-06-04 10:30:42.981487: Epoch 700 
2025-06-04 10:30:43.000967: Current learning rate: 0.00338 
2025-06-04 10:33:01.903593: train_loss -0.7094 
2025-06-04 10:33:01.930912: val_loss -0.6777 
2025-06-04 10:33:01.948086: Pseudo dice [np.float32(0.8011)] 
2025-06-04 10:33:01.965018: Epoch time: 138.95 s 
2025-06-04 10:33:05.883927:  
2025-06-04 10:33:06.047012: Epoch 701 
2025-06-04 10:33:06.181261: Current learning rate: 0.00337 
2025-06-04 10:35:24.972760: train_loss -0.6952 
2025-06-04 10:35:25.459283: val_loss -0.6964 
2025-06-04 10:35:25.840954: Pseudo dice [np.float32(0.7436)] 
2025-06-04 10:35:26.236693: Epoch time: 139.09 s 
2025-06-04 10:35:32.406378:  
2025-06-04 10:35:32.490917: Epoch 702 
2025-06-04 10:35:32.844081: Current learning rate: 0.00336 
2025-06-04 10:37:53.411259: train_loss -0.6869 
2025-06-04 10:37:53.438495: val_loss -0.6481 
2025-06-04 10:37:53.463526: Pseudo dice [np.float32(0.7738)] 
2025-06-04 10:37:53.482592: Epoch time: 141.01 s 
2025-06-04 10:37:57.592469:  
2025-06-04 10:37:57.841766: Epoch 703 
2025-06-04 10:37:58.049238: Current learning rate: 0.00335 
2025-06-04 10:40:18.007879: train_loss -0.6969 
2025-06-04 10:40:18.482174: val_loss -0.6866 
2025-06-04 10:40:19.101796: Pseudo dice [np.float32(0.7274)] 
2025-06-04 10:40:19.318350: Epoch time: 140.42 s 
2025-06-04 10:40:23.385375:  
2025-06-04 10:40:23.483461: Epoch 704 
2025-06-04 10:40:23.544767: Current learning rate: 0.00334 
2025-06-04 10:42:44.270292: train_loss -0.7173 
2025-06-04 10:42:44.301083: val_loss -0.6375 
2025-06-04 10:42:44.334356: Pseudo dice [np.float32(0.6858)] 
2025-06-04 10:42:44.366410: Epoch time: 140.89 s 
2025-06-04 10:42:49.728260:  
2025-06-04 10:42:49.777978: Epoch 705 
2025-06-04 10:42:49.815254: Current learning rate: 0.00333 
2025-06-04 10:45:06.497034: train_loss -0.6756 
2025-06-04 10:45:06.752512: val_loss -0.6743 
2025-06-04 10:45:06.785912: Pseudo dice [np.float32(0.7969)] 
2025-06-04 10:45:06.806278: Epoch time: 136.77 s 
2025-06-04 10:45:16.348829:  
2025-06-04 10:45:16.420422: Epoch 706 
2025-06-04 10:45:16.443735: Current learning rate: 0.00332 
2025-06-04 10:47:38.155452: train_loss -0.7098 
2025-06-04 10:47:38.747512: val_loss -0.6613 
2025-06-04 10:47:39.324136: Pseudo dice [np.float32(0.6223)] 
2025-06-04 10:47:39.550565: Epoch time: 141.81 s 
2025-06-04 10:47:48.228795:  
2025-06-04 10:47:48.645023: Epoch 707 
2025-06-04 10:47:49.003874: Current learning rate: 0.00331 
2025-06-04 10:50:09.525563: train_loss -0.7124 
2025-06-04 10:50:10.035270: val_loss -0.6341 
2025-06-04 10:50:10.579814: Pseudo dice [np.float32(0.7111)] 
2025-06-04 10:50:11.081475: Epoch time: 141.3 s 
2025-06-04 10:50:15.758313:  
2025-06-04 10:50:15.821411: Epoch 708 
2025-06-04 10:50:16.114581: Current learning rate: 0.0033 
2025-06-04 10:52:37.500378: train_loss -0.7026 
2025-06-04 10:52:37.538239: val_loss -0.6623 
2025-06-04 10:52:37.570646: Pseudo dice [np.float32(0.7877)] 
2025-06-04 10:52:37.591035: Epoch time: 141.74 s 
2025-06-04 10:52:43.624480:  
2025-06-04 10:52:43.654709: Epoch 709 
2025-06-04 10:52:43.677134: Current learning rate: 0.00329 
2025-06-04 10:55:04.512893: train_loss -0.7162 
2025-06-04 10:55:04.744606: val_loss -0.695 
2025-06-04 10:55:04.763460: Pseudo dice [np.float32(0.7756)] 
2025-06-04 10:55:04.783886: Epoch time: 140.89 s 
2025-06-04 10:55:12.045042:  
2025-06-04 10:55:12.071527: Epoch 710 
2025-06-04 10:55:12.094836: Current learning rate: 0.00328 
2025-06-04 10:57:27.203753: train_loss -0.7093 
2025-06-04 10:57:27.234959: val_loss -0.6754 
2025-06-04 10:57:27.260339: Pseudo dice [np.float32(0.7349)] 
2025-06-04 10:57:27.697269: Epoch time: 135.16 s 
2025-06-04 10:57:33.831787:  
2025-06-04 10:57:33.890112: Epoch 711 
2025-06-04 10:57:33.908045: Current learning rate: 0.00327 
2025-06-04 10:59:57.825657: train_loss -0.7181 
2025-06-04 10:59:58.266504: val_loss -0.6518 
2025-06-04 10:59:58.436023: Pseudo dice [np.float32(0.7116)] 
2025-06-04 10:59:58.648542: Epoch time: 144.0 s 
2025-06-04 11:00:02.292154:  
2025-06-04 11:00:02.412746: Epoch 712 
2025-06-04 11:00:02.632359: Current learning rate: 0.00326 
2025-06-04 11:02:25.573658: train_loss -0.7135 
2025-06-04 11:02:25.676605: val_loss -0.6958 
2025-06-04 11:02:25.699684: Pseudo dice [np.float32(0.8033)] 
2025-06-04 11:02:25.715980: Epoch time: 143.28 s 
2025-06-04 11:02:30.187508:  
2025-06-04 11:02:30.467781: Epoch 713 
2025-06-04 11:02:30.743665: Current learning rate: 0.00325 
2025-06-04 11:04:53.229110: train_loss -0.7108 
2025-06-04 11:04:53.474192: val_loss -0.6402 
2025-06-04 11:04:53.774361: Pseudo dice [np.float32(0.7686)] 
2025-06-04 11:04:54.272966: Epoch time: 143.04 s 
2025-06-04 11:04:59.216221:  
2025-06-04 11:04:59.422322: Epoch 714 
2025-06-04 11:04:59.614285: Current learning rate: 0.00324 
2025-06-04 11:07:24.610157: train_loss -0.7103 
2025-06-04 11:07:24.782940: val_loss -0.6325 
2025-06-04 11:07:25.102921: Pseudo dice [np.float32(0.7114)] 
2025-06-04 11:07:25.422259: Epoch time: 145.4 s 
2025-06-04 11:07:28.466696:  
2025-06-04 11:07:28.733170: Epoch 715 
2025-06-04 11:07:28.921310: Current learning rate: 0.00323 
2025-06-04 11:09:50.800620: train_loss -0.6931 
2025-06-04 11:09:50.821277: val_loss -0.6984 
2025-06-04 11:09:51.099396: Pseudo dice [np.float32(0.7306)] 
2025-06-04 11:09:51.350251: Epoch time: 142.34 s 
2025-06-04 11:09:56.105877:  
2025-06-04 11:09:56.651904: Epoch 716 
2025-06-04 11:09:56.932182: Current learning rate: 0.00322 
2025-06-04 11:12:17.695187: train_loss -0.6957 
2025-06-04 11:12:18.024271: val_loss -0.6894 
2025-06-04 11:12:18.326353: Pseudo dice [np.float32(0.8067)] 
2025-06-04 11:12:18.550550: Epoch time: 141.59 s 
2025-06-04 11:12:22.654380:  
2025-06-04 11:12:22.941720: Epoch 717 
2025-06-04 11:12:23.121768: Current learning rate: 0.00321 
2025-06-04 11:14:46.035493: train_loss -0.7244 
2025-06-04 11:14:46.586207: val_loss -0.6711 
2025-06-04 11:14:47.053842: Pseudo dice [np.float32(0.7609)] 
2025-06-04 11:14:47.269981: Epoch time: 143.38 s 
2025-06-04 11:14:50.138526:  
2025-06-04 11:14:50.270330: Epoch 718 
2025-06-04 11:14:50.291993: Current learning rate: 0.0032 
2025-06-04 11:17:13.685757: train_loss -0.7039 
2025-06-04 11:17:13.706687: val_loss -0.6316 
2025-06-04 11:17:13.723477: Pseudo dice [np.float32(0.647)] 
2025-06-04 11:17:13.738209: Epoch time: 143.55 s 
2025-06-04 11:17:18.571748:  
2025-06-04 11:17:18.781507: Epoch 719 
2025-06-04 11:17:19.100087: Current learning rate: 0.00319 
2025-06-04 11:19:37.809467: train_loss -0.6914 
2025-06-04 11:19:38.166163: val_loss -0.6596 
2025-06-04 11:19:38.198485: Pseudo dice [np.float32(0.7415)] 
2025-06-04 11:19:38.231225: Epoch time: 139.24 s 
2025-06-04 11:19:42.617790:  
2025-06-04 11:19:42.822016: Epoch 720 
2025-06-04 11:19:43.005760: Current learning rate: 0.00318 
2025-06-04 11:22:05.296387: train_loss -0.6813 
2025-06-04 11:22:05.317293: val_loss -0.7288 
2025-06-04 11:22:05.334349: Pseudo dice [np.float32(0.789)] 
2025-06-04 11:22:05.352463: Epoch time: 142.78 s 
2025-06-04 11:22:11.164484:  
2025-06-04 11:22:11.358077: Epoch 721 
2025-06-04 11:22:11.523949: Current learning rate: 0.00317 
2025-06-04 11:24:34.086176: train_loss -0.6769 
2025-06-04 11:24:34.302428: val_loss -0.687 
2025-06-04 11:24:34.321770: Pseudo dice [np.float32(0.7293)] 
2025-06-04 11:24:34.722501: Epoch time: 142.92 s 
2025-06-04 11:24:38.836266:  
2025-06-04 11:24:39.015541: Epoch 722 
2025-06-04 11:24:39.306562: Current learning rate: 0.00316 
2025-06-04 11:27:04.868915: train_loss -0.7124 
2025-06-04 11:27:05.173278: val_loss -0.6235 
2025-06-04 11:27:05.639600: Pseudo dice [np.float32(0.7151)] 
2025-06-04 11:27:06.083064: Epoch time: 146.04 s 
2025-06-04 11:27:11.550109:  
2025-06-04 11:27:11.854885: Epoch 723 
2025-06-04 11:27:12.419023: Current learning rate: 0.00315 
2025-06-04 11:29:31.613917: train_loss -0.6979 
2025-06-04 11:29:31.922105: val_loss -0.6702 
2025-06-04 11:29:32.483327: Pseudo dice [np.float32(0.7044)] 
2025-06-04 11:29:32.641381: Epoch time: 140.19 s 
2025-06-04 11:29:38.242915:  
2025-06-04 11:29:38.611462: Epoch 724 
2025-06-04 11:29:38.643353: Current learning rate: 0.00314 
2025-06-04 11:31:56.822254: train_loss -0.6935 
2025-06-04 11:31:57.424706: val_loss -0.7121 
2025-06-04 11:31:57.727370: Pseudo dice [np.float32(0.7582)] 
2025-06-04 11:31:57.857111: Epoch time: 138.58 s 
2025-06-04 11:32:02.511984:  
2025-06-04 11:32:02.865549: Epoch 725 
2025-06-04 11:32:03.231275: Current learning rate: 0.00313 
2025-06-04 11:34:26.405006: train_loss -0.6845 
2025-06-04 11:34:26.428820: val_loss -0.6619 
2025-06-04 11:34:26.446139: Pseudo dice [np.float32(0.7195)] 
2025-06-04 11:34:26.462191: Epoch time: 143.9 s 
2025-06-04 11:34:32.337451:  
2025-06-04 11:34:32.472156: Epoch 726 
2025-06-04 11:34:32.633458: Current learning rate: 0.00312 
2025-06-04 11:36:41.581429: train_loss -0.693 
2025-06-04 11:36:41.602853: val_loss -0.6652 
2025-06-04 11:36:41.623874: Pseudo dice [np.float32(0.7781)] 
2025-06-04 11:36:41.644657: Epoch time: 129.25 s 
2025-06-04 11:36:44.910702:  
2025-06-04 11:36:44.928212: Epoch 727 
2025-06-04 11:36:44.945138: Current learning rate: 0.00311 
2025-06-04 11:38:53.465052: train_loss -0.6893 
2025-06-04 11:38:53.490258: val_loss -0.7008 
2025-06-04 11:38:53.818920: Pseudo dice [np.float32(0.7165)] 
2025-06-04 11:38:54.358221: Epoch time: 128.56 s 
2025-06-04 11:38:59.001572:  
2025-06-04 11:38:59.020741: Epoch 728 
2025-06-04 11:38:59.042811: Current learning rate: 0.0031 
2025-06-04 11:41:17.199537: train_loss -0.7286 
2025-06-04 11:41:17.395526: val_loss -0.6993 
2025-06-04 11:41:17.822641: Pseudo dice [np.float32(0.7159)] 
2025-06-04 11:41:18.575528: Epoch time: 138.2 s 
2025-06-04 11:41:21.006736:  
2025-06-04 11:41:21.072999: Epoch 729 
2025-06-04 11:41:21.129183: Current learning rate: 0.00309 
2025-06-04 11:43:40.236054: train_loss -0.7007 
2025-06-04 11:43:40.745028: val_loss -0.6757 
2025-06-04 11:43:41.231964: Pseudo dice [np.float32(0.7543)] 
2025-06-04 11:43:41.662726: Epoch time: 139.23 s 
2025-06-04 11:43:46.143988:  
2025-06-04 11:43:46.358690: Epoch 730 
2025-06-04 11:43:46.774834: Current learning rate: 0.00308 
2025-06-04 11:46:10.176197: train_loss -0.7043 
2025-06-04 11:46:10.701287: val_loss -0.6721 
2025-06-04 11:46:11.143109: Pseudo dice [np.float32(0.7264)] 
2025-06-04 11:46:11.781128: Epoch time: 144.03 s 
2025-06-04 11:46:16.683829:  
2025-06-04 11:46:16.755898: Epoch 731 
2025-06-04 11:46:16.805722: Current learning rate: 0.00307 
2025-06-04 11:48:37.248547: train_loss -0.6969 
2025-06-04 11:48:37.272080: val_loss -0.6764 
2025-06-04 11:48:37.311665: Pseudo dice [np.float32(0.7868)] 
2025-06-04 11:48:37.331556: Epoch time: 140.57 s 
2025-06-04 11:48:43.707093:  
2025-06-04 11:48:43.756597: Epoch 732 
2025-06-04 11:48:43.777949: Current learning rate: 0.00306 
2025-06-04 11:51:08.942493: train_loss -0.6879 
2025-06-04 11:51:08.968134: val_loss -0.6887 
2025-06-04 11:51:08.985618: Pseudo dice [np.float32(0.7423)] 
2025-06-04 11:51:09.005218: Epoch time: 145.24 s 
2025-06-04 11:51:14.646284:  
2025-06-04 11:51:14.666078: Epoch 733 
2025-06-04 11:51:14.687123: Current learning rate: 0.00305 
2025-06-04 11:53:35.630671: train_loss -0.6994 
2025-06-04 11:53:36.200231: val_loss -0.7101 
2025-06-04 11:53:36.814261: Pseudo dice [np.float32(0.8385)] 
2025-06-04 11:53:37.443483: Epoch time: 140.99 s 
2025-06-04 11:53:42.451348:  
2025-06-04 11:53:42.622857: Epoch 734 
2025-06-04 11:53:42.666875: Current learning rate: 0.00304 
2025-06-04 11:56:03.191475: train_loss -0.7014 
2025-06-04 11:56:03.544408: val_loss -0.6798 
2025-06-04 11:56:04.262079: Pseudo dice [np.float32(0.8082)] 
2025-06-04 11:56:04.795483: Epoch time: 140.74 s 
2025-06-04 11:56:09.360789:  
2025-06-04 11:56:09.817056: Epoch 735 
2025-06-04 11:56:09.854860: Current learning rate: 0.00303 
2025-06-04 11:58:29.137248: train_loss -0.6932 
2025-06-04 11:58:29.158538: val_loss -0.6913 
2025-06-04 11:58:29.178020: Pseudo dice [np.float32(0.7616)] 
2025-06-04 11:58:29.197041: Epoch time: 139.78 s 
2025-06-04 11:58:35.640237:  
2025-06-04 11:58:35.959807: Epoch 736 
2025-06-04 11:58:36.293431: Current learning rate: 0.00302 
2025-06-04 12:00:56.249318: train_loss -0.7058 
2025-06-04 12:00:56.409889: val_loss -0.6556 
2025-06-04 12:00:56.566885: Pseudo dice [np.float32(0.7818)] 
2025-06-04 12:00:56.711842: Epoch time: 140.61 s 
2025-06-04 12:01:01.203070:  
2025-06-04 12:01:01.425346: Epoch 737 
2025-06-04 12:01:01.615225: Current learning rate: 0.00301 
2025-06-04 12:03:22.837898: train_loss -0.7004 
2025-06-04 12:03:23.146220: val_loss -0.6674 
2025-06-04 12:03:23.471886: Pseudo dice [np.float32(0.7595)] 
2025-06-04 12:03:23.726465: Epoch time: 141.64 s 
2025-06-04 12:03:27.072425:  
2025-06-04 12:03:27.092774: Epoch 738 
2025-06-04 12:03:27.111595: Current learning rate: 0.003 
2025-06-04 12:05:54.670263: train_loss -0.7029 
2025-06-04 12:05:54.691789: val_loss -0.6852 
2025-06-04 12:05:54.706818: Pseudo dice [np.float32(0.7592)] 
2025-06-04 12:05:54.832430: Epoch time: 147.6 s 
2025-06-04 12:05:59.032219:  
2025-06-04 12:05:59.137217: Epoch 739 
2025-06-04 12:05:59.157867: Current learning rate: 0.00299 
2025-06-04 12:08:21.210181: train_loss -0.7098 
2025-06-04 12:08:21.600775: val_loss -0.6774 
2025-06-04 12:08:21.916615: Pseudo dice [np.float32(0.7659)] 
2025-06-04 12:08:22.163462: Epoch time: 142.18 s 
2025-06-04 12:08:25.323246:  
2025-06-04 12:08:25.583667: Epoch 740 
2025-06-04 12:08:25.616824: Current learning rate: 0.00297 
2025-06-04 12:10:48.636203: train_loss -0.7066 
2025-06-04 12:10:48.975712: val_loss -0.704 
2025-06-04 12:10:49.197777: Pseudo dice [np.float32(0.8067)] 
2025-06-04 12:10:49.302525: Epoch time: 143.32 s 
2025-06-04 12:10:49.321672: Yayy! New best EMA pseudo Dice: 0.7653999924659729 
2025-06-04 12:10:54.450964:  
2025-06-04 12:10:54.854769: Epoch 741 
2025-06-04 12:10:55.191312: Current learning rate: 0.00296 
2025-06-04 12:13:22.381335: train_loss -0.706 
2025-06-04 12:13:22.402680: val_loss -0.6713 
2025-06-04 12:13:22.420214: Pseudo dice [np.float32(0.7528)] 
2025-06-04 12:13:22.438145: Epoch time: 147.93 s 
2025-06-04 12:13:26.870501:  
2025-06-04 12:13:27.170632: Epoch 742 
2025-06-04 12:13:27.234170: Current learning rate: 0.00295 
2025-06-04 12:15:50.986455: train_loss -0.71 
2025-06-04 12:15:51.421948: val_loss -0.6829 
2025-06-04 12:15:51.704039: Pseudo dice [np.float32(0.7528)] 
2025-06-04 12:15:52.082753: Epoch time: 144.12 s 
2025-06-04 12:15:55.369663:  
2025-06-04 12:15:55.405300: Epoch 743 
2025-06-04 12:15:55.539150: Current learning rate: 0.00294 
2025-06-04 12:18:15.924272: train_loss -0.7298 
2025-06-04 12:18:16.273762: val_loss -0.6729 
2025-06-04 12:18:16.867708: Pseudo dice [np.float32(0.7167)] 
2025-06-04 12:18:16.885599: Epoch time: 140.56 s 
2025-06-04 12:18:20.512696:  
2025-06-04 12:18:20.999118: Epoch 744 
2025-06-04 12:18:21.166069: Current learning rate: 0.00293 
2025-06-04 12:20:44.637335: train_loss -0.6902 
2025-06-04 12:20:44.656759: val_loss -0.6778 
2025-06-04 12:20:44.673411: Pseudo dice [np.float32(0.734)] 
2025-06-04 12:20:44.925992: Epoch time: 144.13 s 
2025-06-04 12:20:49.460687:  
2025-06-04 12:20:49.607331: Epoch 745 
2025-06-04 12:20:50.186090: Current learning rate: 0.00292 
2025-06-04 12:23:15.123123: train_loss -0.685 
2025-06-04 12:23:15.609471: val_loss -0.6363 
2025-06-04 12:23:16.189250: Pseudo dice [np.float32(0.6938)] 
2025-06-04 12:23:16.573696: Epoch time: 145.68 s 
2025-06-04 12:23:21.258564:  
2025-06-04 12:23:21.437201: Epoch 746 
2025-06-04 12:23:21.530046: Current learning rate: 0.00291 
2025-06-04 12:25:47.539716: train_loss -0.7021 
2025-06-04 12:25:47.557125: val_loss -0.664 
2025-06-04 12:25:47.573819: Pseudo dice [np.float32(0.7505)] 
2025-06-04 12:25:47.591274: Epoch time: 146.28 s 
2025-06-04 12:25:53.331969:  
2025-06-04 12:25:53.645264: Epoch 747 
2025-06-04 12:25:53.754193: Current learning rate: 0.0029 
2025-06-04 12:28:15.398592: train_loss -0.6984 
2025-06-04 12:28:15.590568: val_loss -0.6295 
2025-06-04 12:28:15.609891: Pseudo dice [np.float32(0.6881)] 
2025-06-04 12:28:15.629494: Epoch time: 142.07 s 
2025-06-04 12:28:21.214556:  
2025-06-04 12:28:21.700202: Epoch 748 
2025-06-04 12:28:21.999946: Current learning rate: 0.00289 
2025-06-04 12:30:41.152715: train_loss -0.6891 
2025-06-04 12:30:41.474839: val_loss -0.6171 
2025-06-04 12:30:41.928712: Pseudo dice [np.float32(0.7148)] 
2025-06-04 12:30:42.533955: Epoch time: 139.94 s 
2025-06-04 12:30:47.530649:  
2025-06-04 12:30:47.940295: Epoch 749 
2025-06-04 12:30:48.054467: Current learning rate: 0.00288 
2025-06-04 12:33:07.518715: train_loss -0.723 
2025-06-04 12:33:07.539554: val_loss -0.6859 
2025-06-04 12:33:07.559672: Pseudo dice [np.float32(0.8195)] 
2025-06-04 12:33:08.014759: Epoch time: 139.99 s 
2025-06-04 12:33:18.891622:  
2025-06-04 12:33:19.079461: Epoch 750 
2025-06-04 12:33:19.375325: Current learning rate: 0.00287 
2025-06-04 12:35:38.826978: train_loss -0.7025 
2025-06-04 12:35:38.967642: val_loss -0.6189 
2025-06-04 12:35:39.257562: Pseudo dice [np.float32(0.7579)] 
2025-06-04 12:35:39.675355: Epoch time: 139.94 s 
2025-06-04 12:35:44.101952:  
2025-06-04 12:35:44.472799: Epoch 751 
2025-06-04 12:35:44.798281: Current learning rate: 0.00286 
2025-06-04 12:38:02.953870: train_loss -0.6981 
2025-06-04 12:38:02.975528: val_loss -0.6169 
2025-06-04 12:38:02.993093: Pseudo dice [np.float32(0.7111)] 
2025-06-04 12:38:03.241141: Epoch time: 138.85 s 
2025-06-04 12:38:08.533554:  
2025-06-04 12:38:08.737554: Epoch 752 
2025-06-04 12:38:09.110362: Current learning rate: 0.00285 
2025-06-04 12:40:30.243387: train_loss -0.7331 
2025-06-04 12:40:30.264245: val_loss -0.7439 
2025-06-04 12:40:30.283165: Pseudo dice [np.float32(0.8307)] 
2025-06-04 12:40:30.303233: Epoch time: 141.71 s 
2025-06-04 12:40:34.436890:  
2025-06-04 12:40:34.615546: Epoch 753 
2025-06-04 12:40:34.727610: Current learning rate: 0.00284 
2025-06-04 12:42:52.211723: train_loss -0.7124 
2025-06-04 12:42:52.429471: val_loss -0.5951 
2025-06-04 12:42:52.449716: Pseudo dice [np.float32(0.6955)] 
2025-06-04 12:42:52.466686: Epoch time: 137.78 s 
2025-06-04 12:42:57.844865:  
2025-06-04 12:42:57.887119: Epoch 754 
2025-06-04 12:42:57.985861: Current learning rate: 0.00283 
2025-06-04 12:45:22.567875: train_loss -0.703 
2025-06-04 12:45:22.999134: val_loss -0.6948 
2025-06-04 12:45:23.020956: Pseudo dice [np.float32(0.6906)] 
2025-06-04 12:45:23.042800: Epoch time: 144.73 s 
2025-06-04 12:45:28.894193:  
2025-06-04 12:45:29.047480: Epoch 755 
2025-06-04 12:45:29.399690: Current learning rate: 0.00282 
2025-06-04 12:47:54.244431: train_loss -0.7213 
2025-06-04 12:47:54.497830: val_loss -0.6987 
2025-06-04 12:47:54.518411: Pseudo dice [np.float32(0.8346)] 
2025-06-04 12:47:54.537881: Epoch time: 145.35 s 
2025-06-04 12:47:58.405398:  
2025-06-04 12:47:58.461503: Epoch 756 
2025-06-04 12:47:58.516227: Current learning rate: 0.00281 
2025-06-04 12:50:23.211916: train_loss -0.6924 
2025-06-04 12:50:23.621683: val_loss -0.636 
2025-06-04 12:50:24.240275: Pseudo dice [np.float32(0.7354)] 
2025-06-04 12:50:24.797674: Epoch time: 144.81 s 
2025-06-04 12:50:30.719655:  
2025-06-04 12:50:30.761678: Epoch 757 
2025-06-04 12:50:30.845010: Current learning rate: 0.0028 
2025-06-04 12:52:51.386718: train_loss -0.7086 
2025-06-04 12:52:51.967093: val_loss -0.6467 
2025-06-04 12:52:52.539163: Pseudo dice [np.float32(0.653)] 
2025-06-04 12:52:53.018857: Epoch time: 140.67 s 
2025-06-04 12:52:58.978348:  
2025-06-04 12:52:59.257613: Epoch 758 
2025-06-04 12:52:59.582245: Current learning rate: 0.00279 
2025-06-04 12:55:19.150992: train_loss -0.7022 
2025-06-04 12:55:19.378592: val_loss -0.6365 
2025-06-04 12:55:19.967437: Pseudo dice [np.float32(0.6203)] 
2025-06-04 12:55:20.329619: Epoch time: 140.18 s 
2025-06-04 12:55:24.212059:  
2025-06-04 12:55:24.240211: Epoch 759 
2025-06-04 12:55:24.271554: Current learning rate: 0.00278 
2025-06-04 12:57:45.784776: train_loss -0.7127 
2025-06-04 12:57:46.001306: val_loss -0.733 
2025-06-04 12:57:46.538110: Pseudo dice [np.float32(0.8397)] 
2025-06-04 12:57:46.760471: Epoch time: 141.59 s 
2025-06-04 12:57:52.600661:  
2025-06-04 12:57:53.019421: Epoch 760 
2025-06-04 12:57:53.167948: Current learning rate: 0.00277 
2025-06-04 13:00:16.591866: train_loss -0.7031 
2025-06-04 13:00:16.629542: val_loss -0.6835 
2025-06-04 13:00:16.650427: Pseudo dice [np.float32(0.7673)] 
2025-06-04 13:00:16.857464: Epoch time: 144.0 s 
2025-06-04 13:00:21.453678:  
2025-06-04 13:00:21.481062: Epoch 761 
2025-06-04 13:00:21.501427: Current learning rate: 0.00276 
2025-06-04 13:02:41.442339: train_loss -0.7276 
2025-06-04 13:02:41.837083: val_loss -0.658 
2025-06-04 13:02:42.226598: Pseudo dice [np.float32(0.7929)] 
2025-06-04 13:02:42.248455: Epoch time: 139.99 s 
2025-06-04 13:02:45.779482:  
2025-06-04 13:02:45.808506: Epoch 762 
2025-06-04 13:02:45.827646: Current learning rate: 0.00275 
2025-06-04 13:05:03.146864: train_loss -0.7025 
2025-06-04 13:05:03.168804: val_loss -0.6176 
2025-06-04 13:05:03.186721: Pseudo dice [np.float32(0.6041)] 
2025-06-04 13:05:03.203037: Epoch time: 137.37 s 
2025-06-04 13:05:08.462551:  
2025-06-04 13:05:08.517816: Epoch 763 
2025-06-04 13:05:08.860494: Current learning rate: 0.00274 
2025-06-04 13:07:29.122296: train_loss -0.6958 
2025-06-04 13:07:29.142743: val_loss -0.6018 
2025-06-04 13:07:29.156593: Pseudo dice [np.float32(0.6941)] 
2025-06-04 13:07:29.173654: Epoch time: 140.66 s 
2025-06-04 13:07:32.841001:  
2025-06-04 13:07:32.863311: Epoch 764 
2025-06-04 13:07:32.913129: Current learning rate: 0.00273 
2025-06-04 13:09:59.159622: train_loss -0.7097 
2025-06-04 13:09:59.287664: val_loss -0.7063 
2025-06-04 13:09:59.304979: Pseudo dice [np.float32(0.8101)] 
2025-06-04 13:09:59.321613: Epoch time: 146.32 s 
2025-06-04 13:10:04.179863:  
2025-06-04 13:10:04.434680: Epoch 765 
2025-06-04 13:10:04.581954: Current learning rate: 0.00272 
2025-06-04 13:12:25.712109: train_loss -0.7208 
2025-06-04 13:12:26.068137: val_loss -0.6632 
2025-06-04 13:12:26.296598: Pseudo dice [np.float32(0.7588)] 
2025-06-04 13:12:26.562509: Epoch time: 141.53 s 
2025-06-04 13:12:30.526520:  
2025-06-04 13:12:30.630156: Epoch 766 
2025-06-04 13:12:30.820121: Current learning rate: 0.00271 
2025-06-04 13:14:54.972540: train_loss -0.734 
2025-06-04 13:14:54.992941: val_loss -0.6542 
2025-06-04 13:14:55.459415: Pseudo dice [np.float32(0.723)] 
2025-06-04 13:14:55.789542: Epoch time: 144.45 s 
2025-06-04 13:15:00.893612:  
2025-06-04 13:15:00.917213: Epoch 767 
2025-06-04 13:15:01.100450: Current learning rate: 0.0027 
2025-06-04 13:17:22.835352: train_loss -0.6826 
2025-06-04 13:17:23.058687: val_loss -0.6131 
2025-06-04 13:17:23.436924: Pseudo dice [np.float32(0.6751)] 
2025-06-04 13:17:23.458385: Epoch time: 141.94 s 
2025-06-04 13:17:26.540678:  
2025-06-04 13:17:26.691748: Epoch 768 
2025-06-04 13:17:26.792288: Current learning rate: 0.00268 
2025-06-04 13:19:48.206129: train_loss -0.71 
2025-06-04 13:19:48.230875: val_loss -0.7077 
2025-06-04 13:19:48.248819: Pseudo dice [np.float32(0.7548)] 
2025-06-04 13:19:48.266484: Epoch time: 141.67 s 
2025-06-04 13:19:53.037102:  
2025-06-04 13:19:53.363821: Epoch 769 
2025-06-04 13:19:53.457357: Current learning rate: 0.00267 
2025-06-04 13:22:13.855069: train_loss -0.7089 
2025-06-04 13:22:14.264008: val_loss -0.7289 
2025-06-04 13:22:14.284757: Pseudo dice [np.float32(0.8006)] 
2025-06-04 13:22:14.303926: Epoch time: 140.82 s 
2025-06-04 13:22:19.326969:  
2025-06-04 13:22:19.479362: Epoch 770 
2025-06-04 13:22:19.591275: Current learning rate: 0.00266 
2025-06-04 13:24:44.906112: train_loss -0.7076 
2025-06-04 13:24:44.926993: val_loss -0.6668 
2025-06-04 13:24:44.943560: Pseudo dice [np.float32(0.7916)] 
2025-06-04 13:24:44.960031: Epoch time: 145.58 s 
2025-06-04 13:24:50.543930:  
2025-06-04 13:24:50.800997: Epoch 771 
2025-06-04 13:24:50.835365: Current learning rate: 0.00265 
2025-06-04 13:27:11.526543: train_loss -0.6993 
2025-06-04 13:27:11.930190: val_loss -0.6913 
2025-06-04 13:27:12.296447: Pseudo dice [np.float32(0.8261)] 
2025-06-04 13:27:12.327804: Epoch time: 140.98 s 
2025-06-04 13:27:16.208385:  
2025-06-04 13:27:16.351208: Epoch 772 
2025-06-04 13:27:16.664421: Current learning rate: 0.00264 
2025-06-04 13:29:39.714889: train_loss -0.6904 
2025-06-04 13:29:40.358908: val_loss -0.6774 
2025-06-04 13:29:40.381047: Pseudo dice [np.float32(0.7926)] 
2025-06-04 13:29:40.411755: Epoch time: 143.51 s 
2025-06-04 13:29:45.653824:  
2025-06-04 13:29:45.717689: Epoch 773 
2025-06-04 13:29:45.738435: Current learning rate: 0.00263 
2025-06-04 13:32:06.649397: train_loss -0.6868 
2025-06-04 13:32:06.673360: val_loss -0.666 
2025-06-04 13:32:06.709523: Pseudo dice [np.float32(0.7345)] 
2025-06-04 13:32:06.741470: Epoch time: 141.0 s 
2025-06-04 13:32:11.842673:  
2025-06-04 13:32:11.872255: Epoch 774 
2025-06-04 13:32:11.900361: Current learning rate: 0.00262 
2025-06-04 13:34:32.035039: train_loss -0.6912 
2025-06-04 13:34:32.511013: val_loss -0.7159 
2025-06-04 13:34:32.535156: Pseudo dice [np.float32(0.7952)] 
2025-06-04 13:34:32.556115: Epoch time: 140.21 s 
2025-06-04 13:34:38.650612:  
2025-06-04 13:34:38.958273: Epoch 775 
2025-06-04 13:34:39.267516: Current learning rate: 0.00261 
2025-06-04 13:37:00.297905: train_loss -0.7324 
2025-06-04 13:37:00.819746: val_loss -0.6264 
2025-06-04 13:37:01.369786: Pseudo dice [np.float32(0.7546)] 
2025-06-04 13:37:02.097415: Epoch time: 141.65 s 
2025-06-04 13:37:08.697082:  
2025-06-04 13:37:08.925915: Epoch 776 
2025-06-04 13:37:09.064356: Current learning rate: 0.0026 
2025-06-04 13:39:28.954098: train_loss -0.7049 
2025-06-04 13:39:29.301152: val_loss -0.6866 
2025-06-04 13:39:29.886789: Pseudo dice [np.float32(0.7173)] 
2025-06-04 13:39:30.252448: Epoch time: 140.26 s 
2025-06-04 13:39:36.909924:  
2025-06-04 13:39:36.934527: Epoch 777 
2025-06-04 13:39:36.954916: Current learning rate: 0.00259 
2025-06-04 13:41:58.679559: train_loss -0.7383 
2025-06-04 13:41:58.812376: val_loss -0.6645 
2025-06-04 13:41:58.838471: Pseudo dice [np.float32(0.7506)] 
2025-06-04 13:41:58.858219: Epoch time: 141.77 s 
2025-06-04 13:42:06.961860:  
2025-06-04 13:42:07.312747: Epoch 778 
2025-06-04 13:42:07.556194: Current learning rate: 0.00258 
2025-06-04 13:44:33.591987: train_loss -0.7165 
2025-06-04 13:44:33.722030: val_loss -0.658 
2025-06-04 13:44:33.904393: Pseudo dice [np.float32(0.7624)] 
2025-06-04 13:44:34.265677: Epoch time: 146.63 s 
2025-06-04 13:44:40.300195:  
2025-06-04 13:44:40.607140: Epoch 779 
2025-06-04 13:44:41.114008: Current learning rate: 0.00257 
2025-06-04 13:47:04.918410: train_loss -0.7103 
2025-06-04 13:47:04.940917: val_loss -0.6713 
2025-06-04 13:47:04.960778: Pseudo dice [np.float32(0.7548)] 
2025-06-04 13:47:04.981511: Epoch time: 144.62 s 
2025-06-04 13:47:09.584790:  
2025-06-04 13:47:10.031814: Epoch 780 
2025-06-04 13:47:10.219883: Current learning rate: 0.00256 
2025-06-04 13:49:31.419927: train_loss -0.7005 
2025-06-04 13:49:31.443997: val_loss -0.6659 
2025-06-04 13:49:31.486945: Pseudo dice [np.float32(0.8021)] 
2025-06-04 13:49:31.560740: Epoch time: 141.84 s 
2025-06-04 13:49:35.284285:  
2025-06-04 13:49:35.666536: Epoch 781 
2025-06-04 13:49:35.694417: Current learning rate: 0.00255 
2025-06-04 13:51:58.614710: train_loss -0.7228 
2025-06-04 13:51:58.900171: val_loss -0.7049 
2025-06-04 13:51:59.283792: Pseudo dice [np.float32(0.8225)] 
2025-06-04 13:51:59.635081: Epoch time: 143.33 s 
2025-06-04 13:51:59.670802: Yayy! New best EMA pseudo Dice: 0.765999972820282 
2025-06-04 13:52:04.628646:  
2025-06-04 13:52:04.670309: Epoch 782 
2025-06-04 13:52:04.738932: Current learning rate: 0.00254 
2025-06-04 13:54:24.225007: train_loss -0.7166 
2025-06-04 13:54:24.760832: val_loss -0.6568 
2025-06-04 13:54:24.781200: Pseudo dice [np.float32(0.792)] 
2025-06-04 13:54:24.799543: Epoch time: 139.6 s 
2025-06-04 13:54:24.816380: Yayy! New best EMA pseudo Dice: 0.7685999870300293 
2025-06-04 13:54:34.129114:  
2025-06-04 13:54:34.328356: Epoch 783 
2025-06-04 13:54:34.353200: Current learning rate: 0.00253 
2025-06-04 13:56:54.015707: train_loss -0.7164 
2025-06-04 13:56:54.042857: val_loss -0.6798 
2025-06-04 13:56:54.061275: Pseudo dice [np.float32(0.8005)] 
2025-06-04 13:56:54.081670: Epoch time: 139.89 s 
2025-06-04 13:56:54.098968: Yayy! New best EMA pseudo Dice: 0.7717999815940857 
2025-06-04 13:57:03.202231:  
2025-06-04 13:57:03.619669: Epoch 784 
2025-06-04 13:57:03.981264: Current learning rate: 0.00252 
2025-06-04 13:59:24.527636: train_loss -0.7018 
2025-06-04 13:59:24.548848: val_loss -0.7143 
2025-06-04 13:59:24.568224: Pseudo dice [np.float32(0.7776)] 
2025-06-04 13:59:24.705777: Epoch time: 141.33 s 
2025-06-04 13:59:24.984034: Yayy! New best EMA pseudo Dice: 0.7724000215530396 
2025-06-04 13:59:35.122818:  
2025-06-04 13:59:35.448535: Epoch 785 
2025-06-04 13:59:35.636892: Current learning rate: 0.00251 
2025-06-04 14:02:01.075114: train_loss -0.7248 
2025-06-04 14:02:01.098359: val_loss -0.6907 
2025-06-04 14:02:01.539977: Pseudo dice [np.float32(0.8208)] 
2025-06-04 14:02:01.560330: Epoch time: 145.95 s 
2025-06-04 14:02:01.579064: Yayy! New best EMA pseudo Dice: 0.7771999835968018 
2025-06-04 14:02:11.804079:  
2025-06-04 14:02:12.171853: Epoch 786 
2025-06-04 14:02:12.642210: Current learning rate: 0.0025 
2025-06-04 14:04:35.340005: train_loss -0.74 
2025-06-04 14:04:35.360638: val_loss -0.6758 
2025-06-04 14:04:35.380282: Pseudo dice [np.float32(0.7711)] 
2025-06-04 14:04:35.398276: Epoch time: 143.54 s 
2025-06-04 14:04:47.182678:  
2025-06-04 14:04:47.609540: Epoch 787 
2025-06-04 14:04:47.920911: Current learning rate: 0.00249 
2025-06-04 14:07:05.074697: train_loss -0.7334 
2025-06-04 14:07:05.095955: val_loss -0.675 
2025-06-04 14:07:05.378911: Pseudo dice [np.float32(0.6546)] 
2025-06-04 14:07:05.399974: Epoch time: 137.89 s 
2025-06-04 14:07:10.825380:  
2025-06-04 14:07:11.199190: Epoch 788 
2025-06-04 14:07:11.519167: Current learning rate: 0.00248 
2025-06-04 14:09:28.196537: train_loss -0.7365 
2025-06-04 14:09:28.633845: val_loss -0.6833 
2025-06-04 14:09:29.169215: Pseudo dice [np.float32(0.8119)] 
2025-06-04 14:09:29.342042: Epoch time: 137.37 s 
2025-06-04 14:09:34.964185:  
2025-06-04 14:09:35.345595: Epoch 789 
2025-06-04 14:09:35.502815: Current learning rate: 0.00247 
2025-06-04 14:11:50.241290: train_loss -0.73 
2025-06-04 14:11:50.533669: val_loss -0.7437 
2025-06-04 14:11:50.886140: Pseudo dice [np.float32(0.8346)] 
2025-06-04 14:11:50.916207: Epoch time: 135.28 s 
2025-06-04 14:11:55.190367:  
2025-06-04 14:11:55.541984: Epoch 790 
2025-06-04 14:11:55.852002: Current learning rate: 0.00245 
2025-06-04 14:14:12.626177: train_loss -0.7145 
2025-06-04 14:14:12.801241: val_loss -0.7293 
2025-06-04 14:14:13.045877: Pseudo dice [np.float32(0.7473)] 
2025-06-04 14:14:13.329830: Epoch time: 137.44 s 
2025-06-04 14:14:18.771330:  
2025-06-04 14:14:19.082953: Epoch 791 
2025-06-04 14:14:19.337917: Current learning rate: 0.00244 
2025-06-04 14:16:36.946840: train_loss -0.7251 
2025-06-04 14:16:36.966471: val_loss -0.6212 
2025-06-04 14:16:37.224311: Pseudo dice [np.float32(0.7347)] 
2025-06-04 14:16:37.687997: Epoch time: 138.18 s 
2025-06-04 14:16:40.783318:  
2025-06-04 14:16:41.023773: Epoch 792 
2025-06-04 14:16:41.094052: Current learning rate: 0.00243 
2025-06-04 14:19:00.461319: train_loss -0.6974 
2025-06-04 14:19:00.787749: val_loss -0.7074 
2025-06-04 14:19:01.076068: Pseudo dice [np.float32(0.7918)] 
2025-06-04 14:19:01.412346: Epoch time: 139.68 s 
2025-06-04 14:19:05.379675:  
2025-06-04 14:19:05.643933: Epoch 793 
2025-06-04 14:19:05.805718: Current learning rate: 0.00242 
2025-06-04 14:21:27.810124: train_loss -0.7062 
2025-06-04 14:21:28.089646: val_loss -0.6507 
2025-06-04 14:21:28.484095: Pseudo dice [np.float32(0.7201)] 
2025-06-04 14:21:28.832642: Epoch time: 142.43 s 
2025-06-04 14:21:34.228920:  
2025-06-04 14:21:34.280541: Epoch 794 
2025-06-04 14:21:34.474272: Current learning rate: 0.00241 
2025-06-04 14:24:00.186934: train_loss -0.7045 
2025-06-04 14:24:00.487042: val_loss -0.6812 
2025-06-04 14:24:00.512050: Pseudo dice [np.float32(0.8086)] 
2025-06-04 14:24:00.543809: Epoch time: 145.99 s 
2025-06-04 14:24:05.554319:  
2025-06-04 14:24:05.846340: Epoch 795 
2025-06-04 14:24:05.917176: Current learning rate: 0.0024 
2025-06-04 14:26:29.255055: train_loss -0.7225 
2025-06-04 14:26:29.545529: val_loss -0.6465 
2025-06-04 14:26:30.001857: Pseudo dice [np.float32(0.7084)] 
2025-06-04 14:26:30.252243: Epoch time: 143.7 s 
2025-06-04 14:26:34.577206:  
2025-06-04 14:26:34.841089: Epoch 796 
2025-06-04 14:26:34.992315: Current learning rate: 0.00239 
2025-06-04 14:28:52.335273: train_loss -0.7137 
2025-06-04 14:28:52.447936: val_loss -0.6729 
2025-06-04 14:28:52.717290: Pseudo dice [np.float32(0.8318)] 
2025-06-04 14:28:52.929154: Epoch time: 137.76 s 
2025-06-04 14:28:56.400537:  
2025-06-04 14:28:56.543600: Epoch 797 
2025-06-04 14:28:56.566781: Current learning rate: 0.00238 
2025-06-04 14:31:21.441750: train_loss -0.7139 
2025-06-04 14:31:21.965727: val_loss -0.6956 
2025-06-04 14:31:21.987760: Pseudo dice [np.float32(0.7803)] 
2025-06-04 14:31:22.314158: Epoch time: 145.04 s 
2025-06-04 14:31:27.505483:  
2025-06-04 14:31:27.711814: Epoch 798 
2025-06-04 14:31:27.846266: Current learning rate: 0.00237 
2025-06-04 14:33:48.519298: train_loss -0.6977 
2025-06-04 14:33:48.543680: val_loss -0.6653 
2025-06-04 14:33:48.562035: Pseudo dice [np.float32(0.7244)] 
2025-06-04 14:33:48.965686: Epoch time: 141.02 s 
2025-06-04 14:33:55.256143:  
2025-06-04 14:33:55.442018: Epoch 799 
2025-06-04 14:33:55.922784: Current learning rate: 0.00236 
2025-06-04 14:36:14.544002: train_loss -0.7294 
2025-06-04 14:36:15.055400: val_loss -0.6628 
2025-06-04 14:36:15.570348: Pseudo dice [np.float32(0.7713)] 
2025-06-04 14:36:15.900826: Epoch time: 139.29 s 
2025-06-04 14:36:21.807835:  
2025-06-04 14:36:21.830526: Epoch 800 
2025-06-04 14:36:21.849341: Current learning rate: 0.00235 
2025-06-04 14:38:44.847638: train_loss -0.7106 
2025-06-04 14:38:44.870342: val_loss -0.7008 
2025-06-04 14:38:44.888434: Pseudo dice [np.float32(0.7677)] 
2025-06-04 14:38:44.908178: Epoch time: 143.04 s 
2025-06-04 14:38:49.241586:  
2025-06-04 14:38:49.515942: Epoch 801 
2025-06-04 14:38:49.665417: Current learning rate: 0.00234 
2025-06-04 14:41:13.442178: train_loss -0.6909 
2025-06-04 14:41:13.774781: val_loss -0.6554 
2025-06-04 14:41:13.798128: Pseudo dice [np.float32(0.762)] 
2025-06-04 14:41:13.822363: Epoch time: 144.2 s 
2025-06-04 14:41:16.975888:  
2025-06-04 14:41:16.998060: Epoch 802 
2025-06-04 14:41:17.016177: Current learning rate: 0.00233 
2025-06-04 14:43:39.700641: train_loss -0.7368 
2025-06-04 14:43:40.300987: val_loss -0.6582 
2025-06-04 14:43:40.867573: Pseudo dice [np.float32(0.6892)] 
2025-06-04 14:43:41.494203: Epoch time: 142.73 s 
2025-06-04 14:43:47.055531:  
2025-06-04 14:43:47.271821: Epoch 803 
2025-06-04 14:43:47.338811: Current learning rate: 0.00232 
2025-06-04 14:46:08.971512: train_loss -0.6976 
2025-06-04 14:46:09.272703: val_loss -0.6494 
2025-06-04 14:46:09.867269: Pseudo dice [np.float32(0.7355)] 
2025-06-04 14:46:10.238001: Epoch time: 141.92 s 
2025-06-04 14:46:15.576489:  
2025-06-04 14:46:15.754706: Epoch 804 
2025-06-04 14:46:15.804785: Current learning rate: 0.00231 
2025-06-04 14:48:36.164276: train_loss -0.724 
2025-06-04 14:48:36.611225: val_loss -0.6569 
2025-06-04 14:48:37.084440: Pseudo dice [np.float32(0.6926)] 
2025-06-04 14:48:37.872021: Epoch time: 140.59 s 
2025-06-04 14:48:43.009650:  
2025-06-04 14:48:43.263255: Epoch 805 
2025-06-04 14:48:43.314788: Current learning rate: 0.0023 
2025-06-04 14:51:02.927132: train_loss -0.7047 
2025-06-04 14:51:03.216056: val_loss -0.6477 
2025-06-04 14:51:04.180747: Pseudo dice [np.float32(0.734)] 
2025-06-04 14:51:04.503733: Epoch time: 139.92 s 
2025-06-04 14:51:09.874470:  
2025-06-04 14:51:09.897953: Epoch 806 
2025-06-04 14:51:09.918227: Current learning rate: 0.00229 
2025-06-04 14:53:29.978115: train_loss -0.7153 
2025-06-04 14:53:30.007861: val_loss -0.7288 
2025-06-04 14:53:30.035517: Pseudo dice [np.float32(0.8315)] 
2025-06-04 14:53:30.051913: Epoch time: 140.25 s 
2025-06-04 14:53:35.991570:  
2025-06-04 14:53:36.111295: Epoch 807 
2025-06-04 14:53:36.147079: Current learning rate: 0.00228 
2025-06-04 14:55:57.531580: train_loss -0.7192 
2025-06-04 14:55:57.554980: val_loss -0.6924 
2025-06-04 14:55:57.576752: Pseudo dice [np.float32(0.7958)] 
2025-06-04 14:55:57.988436: Epoch time: 141.54 s 
2025-06-04 14:56:01.681040:  
2025-06-04 14:56:01.718774: Epoch 808 
2025-06-04 14:56:01.807803: Current learning rate: 0.00226 
2025-06-04 14:58:24.201734: train_loss -0.7132 
2025-06-04 14:58:24.596488: val_loss -0.6688 
2025-06-04 14:58:24.743296: Pseudo dice [np.float32(0.7822)] 
2025-06-04 14:58:25.103263: Epoch time: 142.52 s 
2025-06-04 14:58:31.408051:  
2025-06-04 14:58:31.751922: Epoch 809 
2025-06-04 14:58:32.155831: Current learning rate: 0.00225 
2025-06-04 15:00:49.376507: train_loss -0.7161 
2025-06-04 15:00:49.401660: val_loss -0.6965 
2025-06-04 15:00:49.419836: Pseudo dice [np.float32(0.7724)] 
2025-06-04 15:00:49.619719: Epoch time: 137.97 s 
2025-06-04 15:00:53.227803:  
2025-06-04 15:00:53.394065: Epoch 810 
2025-06-04 15:00:53.781260: Current learning rate: 0.00224 
2025-06-04 15:03:17.117930: train_loss -0.7307 
2025-06-04 15:03:17.340275: val_loss -0.641 
2025-06-04 15:03:17.358122: Pseudo dice [np.float32(0.7396)] 
2025-06-04 15:03:17.635563: Epoch time: 143.89 s 
2025-06-04 15:03:22.795817:  
2025-06-04 15:03:22.912515: Epoch 811 
2025-06-04 15:03:22.934299: Current learning rate: 0.00223 
2025-06-04 15:05:45.086063: train_loss -0.7091 
2025-06-04 15:05:45.103244: val_loss -0.6398 
2025-06-04 15:05:45.119208: Pseudo dice [np.float32(0.7502)] 
2025-06-04 15:05:45.138856: Epoch time: 142.29 s 
2025-06-04 15:05:50.074413:  
2025-06-04 15:05:50.369376: Epoch 812 
2025-06-04 15:05:50.707119: Current learning rate: 0.00222 
2025-06-04 15:08:15.528674: train_loss -0.7321 
2025-06-04 15:08:15.844975: val_loss -0.687 
2025-06-04 15:08:16.175722: Pseudo dice [np.float32(0.7934)] 
2025-06-04 15:08:16.322290: Epoch time: 145.46 s 
2025-06-04 15:08:18.894884:  
2025-06-04 15:08:18.918074: Epoch 813 
2025-06-04 15:08:18.987682: Current learning rate: 0.00221 
2025-06-04 15:10:40.763869: train_loss -0.7069 
2025-06-04 15:10:40.785989: val_loss -0.6353 
2025-06-04 15:10:40.805259: Pseudo dice [np.float32(0.7217)] 
2025-06-04 15:10:40.832928: Epoch time: 141.87 s 
2025-06-04 15:10:45.351827:  
2025-06-04 15:10:45.755412: Epoch 814 
2025-06-04 15:10:46.194160: Current learning rate: 0.0022 
2025-06-04 15:13:03.301837: train_loss -0.7198 
2025-06-04 15:13:03.326541: val_loss -0.6135 
2025-06-04 15:13:03.346951: Pseudo dice [np.float32(0.6704)] 
2025-06-04 15:13:03.367616: Epoch time: 137.95 s 
2025-06-04 15:13:08.742521:  
2025-06-04 15:13:09.150521: Epoch 815 
2025-06-04 15:13:09.420176: Current learning rate: 0.00219 
2025-06-04 15:15:28.544267: train_loss -0.7055 
2025-06-04 15:15:28.858530: val_loss -0.6692 
2025-06-04 15:15:29.393488: Pseudo dice [np.float32(0.743)] 
2025-06-04 15:15:30.048710: Epoch time: 139.8 s 
2025-06-04 15:15:34.626771:  
2025-06-04 15:15:34.761577: Epoch 816 
2025-06-04 15:15:35.023184: Current learning rate: 0.00218 
2025-06-04 15:17:56.046682: train_loss -0.7131 
2025-06-04 15:17:56.067474: val_loss -0.6836 
2025-06-04 15:17:56.085799: Pseudo dice [np.float32(0.7823)] 
2025-06-04 15:17:56.105914: Epoch time: 141.42 s 
2025-06-04 15:18:02.011931:  
2025-06-04 15:18:02.125960: Epoch 817 
2025-06-04 15:18:02.584888: Current learning rate: 0.00217 
2025-06-04 15:20:20.533087: train_loss -0.6956 
2025-06-04 15:20:20.555033: val_loss -0.6729 
2025-06-04 15:20:20.572972: Pseudo dice [np.float32(0.7216)] 
2025-06-04 15:20:20.590903: Epoch time: 138.56 s 
2025-06-04 15:20:26.834569:  
2025-06-04 15:20:26.929454: Epoch 818 
2025-06-04 15:20:27.006333: Current learning rate: 0.00216 
2025-06-04 15:22:45.923717: train_loss -0.7128 
2025-06-04 15:22:45.950525: val_loss -0.6542 
2025-06-04 15:22:45.970622: Pseudo dice [np.float32(0.7635)] 
2025-06-04 15:22:45.987151: Epoch time: 139.09 s 
2025-06-04 15:22:51.229281:  
2025-06-04 15:22:51.269410: Epoch 819 
2025-06-04 15:22:51.294176: Current learning rate: 0.00215 
2025-06-04 15:25:12.482314: train_loss -0.7228 
2025-06-04 15:25:12.797225: val_loss -0.6784 
2025-06-04 15:25:13.065495: Pseudo dice [np.float32(0.7903)] 
2025-06-04 15:25:13.330715: Epoch time: 141.26 s 
2025-06-04 15:25:18.851360:  
2025-06-04 15:25:18.880415: Epoch 820 
2025-06-04 15:25:19.029362: Current learning rate: 0.00214 
2025-06-04 15:27:38.810075: train_loss -0.7228 
2025-06-04 15:27:38.832015: val_loss -0.6862 
2025-06-04 15:27:38.849548: Pseudo dice [np.float32(0.7433)] 
2025-06-04 15:27:38.866085: Epoch time: 139.96 s 
2025-06-04 15:27:42.664798:  
2025-06-04 15:27:42.703445: Epoch 821 
2025-06-04 15:27:42.738432: Current learning rate: 0.00213 
2025-06-04 15:30:08.614670: train_loss -0.73 
2025-06-04 15:30:08.640909: val_loss -0.7145 
2025-06-04 15:30:08.696225: Pseudo dice [np.float32(0.7508)] 
2025-06-04 15:30:08.720069: Epoch time: 145.95 s 
2025-06-04 15:30:12.658726:  
2025-06-04 15:30:12.674008: Epoch 822 
2025-06-04 15:30:12.692512: Current learning rate: 0.00212 
2025-06-04 15:32:32.976571: train_loss -0.7416 
2025-06-04 15:32:32.995267: val_loss -0.6788 
2025-06-04 15:32:33.179847: Pseudo dice [np.float32(0.7866)] 
2025-06-04 15:32:33.414173: Epoch time: 140.32 s 
2025-06-04 15:32:36.991513:  
2025-06-04 15:32:37.146993: Epoch 823 
2025-06-04 15:32:37.370522: Current learning rate: 0.0021 
2025-06-04 15:35:00.785096: train_loss -0.7175 
2025-06-04 15:35:00.804759: val_loss -0.6298 
2025-06-04 15:35:00.822447: Pseudo dice [np.float32(0.7544)] 
2025-06-04 15:35:00.838112: Epoch time: 143.8 s 
2025-06-04 15:35:04.970606:  
2025-06-04 15:35:05.100290: Epoch 824 
2025-06-04 15:35:05.364037: Current learning rate: 0.00209 
2025-06-04 15:37:28.520383: train_loss -0.7126 
2025-06-04 15:37:28.813679: val_loss -0.6571 
2025-06-04 15:37:29.073571: Pseudo dice [np.float32(0.7137)] 
2025-06-04 15:37:29.447543: Epoch time: 143.55 s 
2025-06-04 15:37:32.791417:  
2025-06-04 15:37:33.197747: Epoch 825 
2025-06-04 15:37:33.526193: Current learning rate: 0.00208 
2025-06-04 15:39:55.488140: train_loss -0.7216 
2025-06-04 15:39:55.837253: val_loss -0.6733 
2025-06-04 15:39:56.225512: Pseudo dice [np.float32(0.8193)] 
2025-06-04 15:39:56.430611: Epoch time: 142.7 s 
2025-06-04 15:39:59.522669:  
2025-06-04 15:39:59.622086: Epoch 826 
2025-06-04 15:39:59.641195: Current learning rate: 0.00207 
2025-06-04 15:42:22.118990: train_loss -0.7084 
2025-06-04 15:42:22.364968: val_loss -0.6957 
2025-06-04 15:42:22.430697: Pseudo dice [np.float32(0.7581)] 
2025-06-04 15:42:22.657744: Epoch time: 142.6 s 
2025-06-04 15:42:25.802739:  
2025-06-04 15:42:25.999535: Epoch 827 
2025-06-04 15:42:26.213334: Current learning rate: 0.00206 
2025-06-04 15:44:46.242986: train_loss -0.7328 
2025-06-04 15:44:46.626850: val_loss -0.7037 
2025-06-04 15:44:47.228097: Pseudo dice [np.float32(0.786)] 
2025-06-04 15:44:47.469614: Epoch time: 140.44 s 
2025-06-04 15:44:52.019223:  
2025-06-04 15:44:52.042338: Epoch 828 
2025-06-04 15:44:52.069643: Current learning rate: 0.00205 
2025-06-04 15:47:11.887964: train_loss -0.7283 
2025-06-04 15:47:11.908273: val_loss -0.7152 
2025-06-04 15:47:12.191714: Pseudo dice [np.float32(0.7786)] 
2025-06-04 15:47:12.441579: Epoch time: 139.87 s 
2025-06-04 15:47:15.871686:  
2025-06-04 15:47:15.905067: Epoch 829 
2025-06-04 15:47:15.994439: Current learning rate: 0.00204 
2025-06-04 15:49:36.816146: train_loss -0.7229 
2025-06-04 15:49:37.090386: val_loss -0.6672 
2025-06-04 15:49:37.596152: Pseudo dice [np.float32(0.759)] 
2025-06-04 15:49:37.844197: Epoch time: 140.95 s 
2025-06-04 15:49:41.454791:  
2025-06-04 15:49:41.662785: Epoch 830 
2025-06-04 15:49:41.926709: Current learning rate: 0.00203 
2025-06-04 15:52:02.687696: train_loss -0.7148 
2025-06-04 15:52:02.709555: val_loss -0.6396 
2025-06-04 15:52:03.015089: Pseudo dice [np.float32(0.7917)] 
2025-06-04 15:52:03.033164: Epoch time: 141.24 s 
2025-06-04 15:52:08.619673:  
2025-06-04 15:52:08.934236: Epoch 831 
2025-06-04 15:52:09.392571: Current learning rate: 0.00202 
2025-06-04 15:54:32.839561: train_loss -0.7206 
2025-06-04 15:54:32.862092: val_loss -0.668 
2025-06-04 15:54:32.879395: Pseudo dice [np.float32(0.8124)] 
2025-06-04 15:54:32.899052: Epoch time: 144.22 s 
2025-06-04 15:54:37.217812:  
2025-06-04 15:54:37.247057: Epoch 832 
2025-06-04 15:54:37.269128: Current learning rate: 0.00201 
2025-06-04 15:56:58.758741: train_loss -0.7205 
2025-06-04 15:56:59.267909: val_loss -0.6714 
2025-06-04 15:57:00.002412: Pseudo dice [np.float32(0.7649)] 
2025-06-04 15:57:00.599483: Epoch time: 141.54 s 
2025-06-04 15:57:05.200747:  
2025-06-04 15:57:05.425402: Epoch 833 
2025-06-04 15:57:05.497837: Current learning rate: 0.002 
2025-06-04 15:59:23.415458: train_loss -0.7174 
2025-06-04 15:59:23.439208: val_loss -0.6605 
2025-06-04 15:59:23.459205: Pseudo dice [np.float32(0.7806)] 
2025-06-04 15:59:23.474615: Epoch time: 138.22 s 
2025-06-04 15:59:27.416658:  
2025-06-04 15:59:27.440524: Epoch 834 
2025-06-04 15:59:27.463323: Current learning rate: 0.00199 
2025-06-04 16:01:48.484679: train_loss -0.7068 
2025-06-04 16:01:48.861094: val_loss -0.7021 
2025-06-04 16:01:49.167856: Pseudo dice [np.float32(0.8176)] 
2025-06-04 16:01:49.189867: Epoch time: 141.07 s 
2025-06-04 16:01:55.785286:  
2025-06-04 16:01:55.843244: Epoch 835 
2025-06-04 16:01:55.867391: Current learning rate: 0.00198 
2025-06-04 16:04:20.591643: train_loss -0.7205 
2025-06-04 16:04:20.612459: val_loss -0.658 
2025-06-04 16:04:20.629478: Pseudo dice [np.float32(0.7083)] 
2025-06-04 16:04:20.650106: Epoch time: 144.81 s 
2025-06-04 16:04:25.818625:  
2025-06-04 16:04:26.036753: Epoch 836 
2025-06-04 16:04:26.061838: Current learning rate: 0.00196 
2025-06-04 16:06:44.218387: train_loss -0.6996 
2025-06-04 16:06:44.742038: val_loss -0.6621 
2025-06-04 16:06:45.206280: Pseudo dice [np.float32(0.7467)] 
2025-06-04 16:06:45.228980: Epoch time: 138.4 s 
2025-06-04 16:06:50.168519:  
2025-06-04 16:06:50.202257: Epoch 837 
2025-06-04 16:06:50.225739: Current learning rate: 0.00195 
2025-06-04 16:09:07.367372: train_loss -0.6886 
2025-06-04 16:09:07.393369: val_loss -0.6277 
2025-06-04 16:09:07.781700: Pseudo dice [np.float32(0.7385)] 
2025-06-04 16:09:08.309913: Epoch time: 137.2 s 
2025-06-04 16:09:13.437501:  
2025-06-04 16:09:13.612172: Epoch 838 
2025-06-04 16:09:13.817405: Current learning rate: 0.00194 
2025-06-04 16:11:35.876098: train_loss -0.6757 
2025-06-04 16:11:36.339272: val_loss -0.6495 
2025-06-04 16:11:36.861832: Pseudo dice [np.float32(0.7038)] 
2025-06-04 16:11:37.048275: Epoch time: 142.44 s 
2025-06-04 16:11:41.706235:  
2025-06-04 16:11:41.873259: Epoch 839 
2025-06-04 16:11:42.300600: Current learning rate: 0.00193 
2025-06-04 16:14:04.308074: train_loss -0.7413 
2025-06-04 16:14:04.333150: val_loss -0.6895 
2025-06-04 16:14:04.649869: Pseudo dice [np.float32(0.7459)] 
2025-06-04 16:14:05.181459: Epoch time: 142.6 s 
2025-06-04 16:14:08.720852:  
2025-06-04 16:14:08.869745: Epoch 840 
2025-06-04 16:14:08.968628: Current learning rate: 0.00192 
2025-06-04 16:16:28.968194: train_loss -0.7237 
2025-06-04 16:16:29.144839: val_loss -0.6337 
2025-06-04 16:16:29.313252: Pseudo dice [np.float32(0.7588)] 
2025-06-04 16:16:29.988794: Epoch time: 140.25 s 
2025-06-04 16:16:33.139175:  
2025-06-04 16:16:33.325315: Epoch 841 
2025-06-04 16:16:33.391486: Current learning rate: 0.00191 
2025-06-04 16:18:53.319808: train_loss -0.7219 
2025-06-04 16:18:53.600337: val_loss -0.7004 
2025-06-04 16:18:53.868887: Pseudo dice [np.float32(0.7465)] 
2025-06-04 16:18:54.090544: Epoch time: 140.18 s 
2025-06-04 16:18:58.526391:  
2025-06-04 16:18:58.845218: Epoch 842 
2025-06-04 16:18:59.082435: Current learning rate: 0.0019 
2025-06-04 16:21:17.217168: train_loss -0.7185 
2025-06-04 16:21:17.515365: val_loss -0.7043 
2025-06-04 16:21:17.767281: Pseudo dice [np.float32(0.8125)] 
2025-06-04 16:21:18.051111: Epoch time: 138.69 s 
2025-06-04 16:21:21.273416:  
2025-06-04 16:21:21.300840: Epoch 843 
2025-06-04 16:21:21.321307: Current learning rate: 0.00189 
2025-06-04 16:23:40.593960: train_loss -0.7337 
2025-06-04 16:23:40.610930: val_loss -0.672 
2025-06-04 16:23:40.628191: Pseudo dice [np.float32(0.7832)] 
2025-06-04 16:23:40.643998: Epoch time: 139.32 s 
2025-06-04 16:23:44.495417:  
2025-06-04 16:23:44.613507: Epoch 844 
2025-06-04 16:23:44.637979: Current learning rate: 0.00188 
2025-06-04 16:26:07.268891: train_loss -0.7299 
2025-06-04 16:26:07.684143: val_loss -0.641 
2025-06-04 16:26:08.164777: Pseudo dice [np.float32(0.7422)] 
2025-06-04 16:26:08.645553: Epoch time: 142.78 s 
2025-06-04 16:26:13.105162:  
2025-06-04 16:26:13.124770: Epoch 845 
2025-06-04 16:26:13.278397: Current learning rate: 0.00187 
2025-06-04 16:28:31.848605: train_loss -0.6922 
2025-06-04 16:28:32.303303: val_loss -0.6212 
2025-06-04 16:28:32.446211: Pseudo dice [np.float32(0.7715)] 
2025-06-04 16:28:32.887280: Epoch time: 138.75 s 
2025-06-04 16:28:36.518000:  
2025-06-04 16:28:36.737742: Epoch 846 
2025-06-04 16:28:36.841864: Current learning rate: 0.00186 
2025-06-04 16:31:02.234887: train_loss -0.7187 
2025-06-04 16:31:02.669535: val_loss -0.6487 
2025-06-04 16:31:02.689120: Pseudo dice [np.float32(0.7726)] 
2025-06-04 16:31:02.707756: Epoch time: 145.72 s 
2025-06-04 16:31:09.277683:  
2025-06-04 16:31:09.453032: Epoch 847 
2025-06-04 16:31:09.508661: Current learning rate: 0.00185 
2025-06-04 16:33:28.185706: train_loss -0.7422 
2025-06-04 16:33:28.733050: val_loss -0.6898 
2025-06-04 16:33:28.762021: Pseudo dice [np.float32(0.7691)] 
2025-06-04 16:33:28.785193: Epoch time: 138.91 s 
2025-06-04 16:33:33.935667:  
2025-06-04 16:33:34.033367: Epoch 848 
2025-06-04 16:33:34.079600: Current learning rate: 0.00184 
2025-06-04 16:35:54.902523: train_loss -0.7317 
2025-06-04 16:35:55.446484: val_loss -0.6367 
2025-06-04 16:35:55.797428: Pseudo dice [np.float32(0.736)] 
2025-06-04 16:35:56.105083: Epoch time: 140.97 s 
2025-06-04 16:36:01.472339:  
2025-06-04 16:36:01.841481: Epoch 849 
2025-06-04 16:36:02.203742: Current learning rate: 0.00182 
2025-06-04 16:38:23.579629: train_loss -0.7162 
2025-06-04 16:38:23.742991: val_loss -0.7059 
2025-06-04 16:38:24.155907: Pseudo dice [np.float32(0.8051)] 
2025-06-04 16:38:24.188319: Epoch time: 142.11 s 
2025-06-04 16:38:33.338699:  
2025-06-04 16:38:33.710025: Epoch 850 
2025-06-04 16:38:33.889652: Current learning rate: 0.00181 
2025-06-04 16:40:52.940605: train_loss -0.7204 
2025-06-04 16:40:53.330417: val_loss -0.7101 
2025-06-04 16:40:53.921625: Pseudo dice [np.float32(0.8187)] 
2025-06-04 16:40:54.135012: Epoch time: 139.6 s 
2025-06-04 16:40:59.498461:  
2025-06-04 16:40:59.876932: Epoch 851 
2025-06-04 16:41:00.352982: Current learning rate: 0.0018 
2025-06-04 16:43:16.297032: train_loss -0.7342 
2025-06-04 16:43:16.729985: val_loss -0.7119 
2025-06-04 16:43:16.904776: Pseudo dice [np.float32(0.8428)] 
2025-06-04 16:43:16.924085: Epoch time: 136.8 s 
2025-06-04 16:43:16.980393: Yayy! New best EMA pseudo Dice: 0.7781999707221985 
2025-06-04 16:43:24.187500:  
2025-06-04 16:43:24.260509: Epoch 852 
2025-06-04 16:43:24.439438: Current learning rate: 0.00179 
2025-06-04 16:45:43.577241: train_loss -0.7536 
2025-06-04 16:45:43.853386: val_loss -0.6399 
2025-06-04 16:45:43.959863: Pseudo dice [np.float32(0.7895)] 
2025-06-04 16:45:44.155869: Epoch time: 139.39 s 
2025-06-04 16:45:44.448946: Yayy! New best EMA pseudo Dice: 0.7792999744415283 
2025-06-04 16:45:52.948570:  
2025-06-04 16:45:53.452681: Epoch 853 
2025-06-04 16:45:53.472281: Current learning rate: 0.00178 
2025-06-04 16:48:15.482918: train_loss -0.7205 
2025-06-04 16:48:15.821597: val_loss -0.6985 
2025-06-04 16:48:16.328438: Pseudo dice [np.float32(0.7734)] 
2025-06-04 16:48:16.960065: Epoch time: 142.54 s 
2025-06-04 16:48:24.962618:  
2025-06-04 16:48:24.986733: Epoch 854 
2025-06-04 16:48:25.137917: Current learning rate: 0.00177 
2025-06-04 16:50:46.110553: train_loss -0.7483 
2025-06-04 16:50:46.675352: val_loss -0.6668 
2025-06-04 16:50:47.107875: Pseudo dice [np.float32(0.7931)] 
2025-06-04 16:50:47.389081: Epoch time: 141.15 s 
2025-06-04 16:50:47.769793: Yayy! New best EMA pseudo Dice: 0.7800999879837036 
2025-06-04 16:50:58.072762:  
2025-06-04 16:50:58.272292: Epoch 855 
2025-06-04 16:50:58.289413: Current learning rate: 0.00176 
2025-06-04 16:53:15.702848: train_loss -0.7408 
2025-06-04 16:53:15.918911: val_loss -0.7158 
2025-06-04 16:53:16.299778: Pseudo dice [np.float32(0.7934)] 
2025-06-04 16:53:16.738453: Epoch time: 137.63 s 
2025-06-04 16:53:17.251757: Yayy! New best EMA pseudo Dice: 0.781499981880188 
2025-06-04 16:53:26.445160:  
2025-06-04 16:53:26.479276: Epoch 856 
2025-06-04 16:53:26.515168: Current learning rate: 0.00175 
2025-06-04 16:55:47.794092: train_loss -0.7306 
2025-06-04 16:55:47.812925: val_loss -0.6733 
2025-06-04 16:55:47.992157: Pseudo dice [np.float32(0.6622)] 
2025-06-04 16:55:48.365176: Epoch time: 141.35 s 
2025-06-04 16:55:56.740336:  
2025-06-04 16:55:57.242873: Epoch 857 
2025-06-04 16:55:57.485482: Current learning rate: 0.00174 
2025-06-04 16:58:19.954426: train_loss -0.7304 
2025-06-04 16:58:20.634587: val_loss -0.6679 
2025-06-04 16:58:21.055647: Pseudo dice [np.float32(0.7919)] 
2025-06-04 16:58:21.587806: Epoch time: 143.22 s 
2025-06-04 16:58:32.273287:  
2025-06-04 16:58:32.751221: Epoch 858 
2025-06-04 16:58:33.210341: Current learning rate: 0.00173 
2025-06-04 17:00:46.523030: train_loss -0.7315 
2025-06-04 17:00:46.547333: val_loss -0.6909 
2025-06-04 17:00:46.916173: Pseudo dice [np.float32(0.7385)] 
2025-06-04 17:00:47.439677: Epoch time: 134.25 s 
2025-06-04 17:00:55.496694:  
2025-06-04 17:00:56.134156: Epoch 859 
2025-06-04 17:00:56.395412: Current learning rate: 0.00172 
2025-06-04 17:03:12.289386: train_loss -0.7204 
2025-06-04 17:03:12.575605: val_loss -0.6741 
2025-06-04 17:03:12.595482: Pseudo dice [np.float32(0.8157)] 
2025-06-04 17:03:13.257195: Epoch time: 136.79 s 
2025-06-04 17:03:18.308304:  
2025-06-04 17:03:18.770998: Epoch 860 
2025-06-04 17:03:18.803008: Current learning rate: 0.0017 
2025-06-04 17:05:38.006868: train_loss -0.7259 
2025-06-04 17:05:38.308648: val_loss -0.6346 
2025-06-04 17:05:38.670796: Pseudo dice [np.float32(0.7936)] 
2025-06-04 17:05:38.861232: Epoch time: 139.7 s 
2025-06-04 17:05:44.089132:  
2025-06-04 17:05:44.498428: Epoch 861 
2025-06-04 17:05:44.906145: Current learning rate: 0.00169 
2025-06-04 17:08:07.109519: train_loss -0.7323 
2025-06-04 17:08:07.243203: val_loss -0.6795 
2025-06-04 17:08:07.777542: Pseudo dice [np.float32(0.7594)] 
2025-06-04 17:08:07.978050: Epoch time: 143.02 s 
2025-06-04 17:08:13.672715:  
2025-06-04 17:08:14.239454: Epoch 862 
2025-06-04 17:08:14.261920: Current learning rate: 0.00168 
2025-06-04 17:10:33.442261: train_loss -0.7212 
2025-06-04 17:10:33.464831: val_loss -0.6822 
2025-06-04 17:10:33.786488: Pseudo dice [np.float32(0.6655)] 
2025-06-04 17:10:34.100251: Epoch time: 139.77 s 
2025-06-04 17:10:37.913557:  
2025-06-04 17:10:38.159293: Epoch 863 
2025-06-04 17:10:38.369493: Current learning rate: 0.00167 
2025-06-04 17:12:58.954496: train_loss -0.7398 
2025-06-04 17:12:59.293064: val_loss -0.698 
2025-06-04 17:12:59.839437: Pseudo dice [np.float32(0.8811)] 
2025-06-04 17:13:00.338004: Epoch time: 141.04 s 
2025-06-04 17:13:04.389462:  
2025-06-04 17:13:04.753174: Epoch 864 
2025-06-04 17:13:04.774266: Current learning rate: 0.00166 
2025-06-04 17:15:24.109518: train_loss -0.7375 
2025-06-04 17:15:24.589854: val_loss -0.7108 
2025-06-04 17:15:24.610489: Pseudo dice [np.float32(0.7439)] 
2025-06-04 17:15:24.627544: Epoch time: 139.72 s 
2025-06-04 17:15:28.390909:  
2025-06-04 17:15:28.413795: Epoch 865 
2025-06-04 17:15:28.428110: Current learning rate: 0.00165 
2025-06-04 17:17:51.803189: train_loss -0.7077 
2025-06-04 17:17:51.825090: val_loss -0.7525 
2025-06-04 17:17:51.842873: Pseudo dice [np.float32(0.8139)] 
2025-06-04 17:17:52.123416: Epoch time: 143.41 s 
2025-06-04 17:17:55.910725:  
2025-06-04 17:17:55.957085: Epoch 866 
2025-06-04 17:17:56.023919: Current learning rate: 0.00164 
2025-06-04 17:20:19.963858: train_loss -0.7322 
2025-06-04 17:20:20.257793: val_loss -0.6552 
2025-06-04 17:20:20.706638: Pseudo dice [np.float32(0.7074)] 
2025-06-04 17:20:21.108785: Epoch time: 144.06 s 
2025-06-04 17:20:25.131353:  
2025-06-04 17:20:25.154102: Epoch 867 
2025-06-04 17:20:25.168078: Current learning rate: 0.00163 
2025-06-04 17:22:42.576715: train_loss -0.7182 
2025-06-04 17:22:42.912320: val_loss -0.7241 
2025-06-04 17:22:43.205941: Pseudo dice [np.float32(0.8138)] 
2025-06-04 17:22:43.228100: Epoch time: 137.45 s 
2025-06-04 17:22:47.504729:  
2025-06-04 17:22:47.656276: Epoch 868 
2025-06-04 17:22:47.763454: Current learning rate: 0.00162 
2025-06-04 17:25:15.717713: train_loss -0.7121 
2025-06-04 17:25:16.163053: val_loss -0.6972 
2025-06-04 17:25:16.508943: Pseudo dice [np.float32(0.8084)] 
2025-06-04 17:25:17.068850: Epoch time: 148.22 s 
2025-06-04 17:25:20.166171:  
2025-06-04 17:25:20.187856: Epoch 869 
2025-06-04 17:25:20.263173: Current learning rate: 0.00161 
2025-06-04 17:27:47.731071: train_loss -0.7372 
2025-06-04 17:27:48.137000: val_loss -0.6622 
2025-06-04 17:27:48.279205: Pseudo dice [np.float32(0.7913)] 
2025-06-04 17:27:48.527817: Epoch time: 147.57 s 
2025-06-04 17:27:52.312500:  
2025-06-04 17:27:52.577596: Epoch 870 
2025-06-04 17:27:52.601157: Current learning rate: 0.00159 
2025-06-04 17:30:15.101916: train_loss -0.7206 
2025-06-04 17:30:15.446078: val_loss -0.7042 
2025-06-04 17:30:15.478361: Pseudo dice [np.float32(0.6904)] 
2025-06-04 17:30:15.512661: Epoch time: 142.79 s 
2025-06-04 17:30:20.723100:  
2025-06-04 17:30:20.887228: Epoch 871 
2025-06-04 17:30:21.231647: Current learning rate: 0.00158 
2025-06-04 17:32:42.880843: train_loss -0.7217 
2025-06-04 17:32:43.530515: val_loss -0.6886 
2025-06-04 17:32:44.177609: Pseudo dice [np.float32(0.762)] 
2025-06-04 17:32:44.806941: Epoch time: 142.16 s 
2025-06-04 17:32:49.080484:  
2025-06-04 17:32:49.169059: Epoch 872 
2025-06-04 17:32:49.355286: Current learning rate: 0.00157 
2025-06-04 17:35:16.238212: train_loss -0.7322 
2025-06-04 17:35:16.277480: val_loss -0.6563 
2025-06-04 17:35:16.767373: Pseudo dice [np.float32(0.7849)] 
2025-06-04 17:35:17.207489: Epoch time: 147.16 s 
2025-06-04 17:35:22.794254:  
2025-06-04 17:35:23.038893: Epoch 873 
2025-06-04 17:35:23.238314: Current learning rate: 0.00156 
2025-06-04 17:37:47.036032: train_loss -0.7434 
2025-06-04 17:37:47.394708: val_loss -0.7018 
2025-06-04 17:37:47.821367: Pseudo dice [np.float32(0.7148)] 
2025-06-04 17:37:48.091214: Epoch time: 144.24 s 
2025-06-04 17:37:54.297212:  
2025-06-04 17:37:54.756860: Epoch 874 
2025-06-04 17:37:55.009540: Current learning rate: 0.00155 
2025-06-04 17:40:16.919733: train_loss -0.717 
2025-06-04 17:40:17.228758: val_loss -0.7207 
2025-06-04 17:40:17.816628: Pseudo dice [np.float32(0.8354)] 
2025-06-04 17:40:18.136910: Epoch time: 142.63 s 
2025-06-04 17:40:23.345238:  
2025-06-04 17:40:23.569985: Epoch 875 
2025-06-04 17:40:23.987235: Current learning rate: 0.00154 
2025-06-04 17:42:47.263984: train_loss -0.7174 
2025-06-04 17:42:47.801821: val_loss -0.6725 
2025-06-04 17:42:48.382369: Pseudo dice [np.float32(0.6886)] 
2025-06-04 17:42:48.689904: Epoch time: 143.92 s 
2025-06-04 17:42:52.844656:  
2025-06-04 17:42:53.131903: Epoch 876 
2025-06-04 17:42:53.187828: Current learning rate: 0.00153 
2025-06-04 17:45:14.306025: train_loss -0.7205 
2025-06-04 17:45:15.030075: val_loss -0.7015 
2025-06-04 17:45:15.456585: Pseudo dice [np.float32(0.7688)] 
2025-06-04 17:45:15.471925: Epoch time: 141.46 s 
2025-06-04 17:45:19.473948:  
2025-06-04 17:45:19.509999: Epoch 877 
2025-06-04 17:45:19.533006: Current learning rate: 0.00152 
2025-06-04 17:47:37.371550: train_loss -0.7196 
2025-06-04 17:47:37.846802: val_loss -0.6756 
2025-06-04 17:47:38.478237: Pseudo dice [np.float32(0.7419)] 
2025-06-04 17:47:38.991709: Epoch time: 137.9 s 
2025-06-04 17:47:42.793530:  
2025-06-04 17:47:42.890968: Epoch 878 
2025-06-04 17:47:43.041797: Current learning rate: 0.00151 
2025-06-04 17:50:02.607557: train_loss -0.7305 
2025-06-04 17:50:03.096145: val_loss -0.6508 
2025-06-04 17:50:03.115237: Pseudo dice [np.float32(0.7612)] 
2025-06-04 17:50:03.134295: Epoch time: 139.82 s 
2025-06-04 17:50:08.653143:  
2025-06-04 17:50:08.675128: Epoch 879 
2025-06-04 17:50:08.712950: Current learning rate: 0.00149 
2025-06-04 17:52:31.351795: train_loss -0.7379 
2025-06-04 17:52:31.613425: val_loss -0.7265 
2025-06-04 17:52:31.636537: Pseudo dice [np.float32(0.7404)] 
2025-06-04 17:52:32.154651: Epoch time: 142.75 s 
2025-06-04 17:52:36.037250:  
2025-06-04 17:52:36.312648: Epoch 880 
2025-06-04 17:52:36.367139: Current learning rate: 0.00148 
2025-06-04 17:54:53.518292: train_loss -0.7209 
2025-06-04 17:54:53.719074: val_loss -0.6576 
2025-06-04 17:54:53.739935: Pseudo dice [np.float32(0.7149)] 
2025-06-04 17:54:53.765746: Epoch time: 137.48 s 
2025-06-04 17:54:59.666875:  
2025-06-04 17:54:59.871809: Epoch 881 
2025-06-04 17:54:59.997872: Current learning rate: 0.00147 
2025-06-04 17:57:19.947097: train_loss -0.7288 
2025-06-04 17:57:20.410529: val_loss -0.716 
2025-06-04 17:57:20.642887: Pseudo dice [np.float32(0.7423)] 
2025-06-04 17:57:21.057432: Epoch time: 140.28 s 
2025-06-04 17:57:27.472829:  
2025-06-04 17:57:27.548466: Epoch 882 
2025-06-04 17:57:27.575093: Current learning rate: 0.00146 
2025-06-04 17:59:49.796926: train_loss -0.7113 
2025-06-04 17:59:50.207646: val_loss -0.618 
2025-06-04 17:59:50.663147: Pseudo dice [np.float32(0.6937)] 
2025-06-04 17:59:51.188426: Epoch time: 142.33 s 
2025-06-04 17:59:56.365413:  
2025-06-04 17:59:56.746536: Epoch 883 
2025-06-04 17:59:57.058586: Current learning rate: 0.00145 
2025-06-04 18:02:19.524883: train_loss -0.6999 
2025-06-04 18:02:19.937848: val_loss -0.6393 
2025-06-04 18:02:20.484612: Pseudo dice [np.float32(0.7482)] 
2025-06-04 18:02:20.889858: Epoch time: 143.16 s 
2025-06-04 18:02:25.997449:  
2025-06-04 18:02:26.378089: Epoch 884 
2025-06-04 18:02:26.852723: Current learning rate: 0.00144 
2025-06-04 18:04:48.162146: train_loss -0.6993 
2025-06-04 18:04:48.571433: val_loss -0.6621 
2025-06-04 18:04:48.655814: Pseudo dice [np.float32(0.7585)] 
2025-06-04 18:04:48.845828: Epoch time: 142.17 s 
2025-06-04 18:04:55.425929:  
2025-06-04 18:04:55.610941: Epoch 885 
2025-06-04 18:04:55.840697: Current learning rate: 0.00143 
2025-06-04 18:07:16.866192: train_loss -0.7278 
2025-06-04 18:07:16.886086: val_loss -0.7095 
2025-06-04 18:07:16.902831: Pseudo dice [np.float32(0.7604)] 
2025-06-04 18:07:16.929080: Epoch time: 141.44 s 
2025-06-04 18:07:21.326905:  
2025-06-04 18:07:21.353819: Epoch 886 
2025-06-04 18:07:21.451321: Current learning rate: 0.00142 
2025-06-04 18:09:41.515727: train_loss -0.726 
2025-06-04 18:09:41.545032: val_loss -0.7153 
2025-06-04 18:09:41.565427: Pseudo dice [np.float32(0.8473)] 
2025-06-04 18:09:41.585071: Epoch time: 140.19 s 
2025-06-04 18:09:48.023209:  
2025-06-04 18:09:48.456876: Epoch 887 
2025-06-04 18:09:48.702135: Current learning rate: 0.00141 
2025-06-04 18:12:04.357508: train_loss -0.7361 
2025-06-04 18:12:04.876714: val_loss -0.6838 
2025-06-04 18:12:05.224936: Pseudo dice [np.float32(0.7637)] 
2025-06-04 18:12:05.439355: Epoch time: 136.34 s 
2025-06-04 18:12:11.188222:  
2025-06-04 18:12:11.354013: Epoch 888 
2025-06-04 18:12:11.441162: Current learning rate: 0.00139 
2025-06-04 18:14:28.566868: train_loss -0.714 
2025-06-04 18:14:28.965143: val_loss -0.6268 
2025-06-04 18:14:29.126476: Pseudo dice [np.float32(0.7703)] 
2025-06-04 18:14:29.403798: Epoch time: 137.38 s 
2025-06-04 18:14:31.713497:  
2025-06-04 18:14:31.795533: Epoch 889 
2025-06-04 18:14:31.822815: Current learning rate: 0.00138 
2025-06-04 18:16:49.440759: train_loss -0.7371 
2025-06-04 18:16:49.930285: val_loss -0.6631 
2025-06-04 18:16:50.335890: Pseudo dice [np.float32(0.8068)] 
2025-06-04 18:16:50.624022: Epoch time: 137.73 s 
2025-06-04 18:16:56.407446:  
2025-06-04 18:16:56.426052: Epoch 890 
2025-06-04 18:16:56.452082: Current learning rate: 0.00137 
2025-06-04 18:19:19.408170: train_loss -0.7315 
2025-06-04 18:19:19.431184: val_loss -0.6993 
2025-06-04 18:19:19.449099: Pseudo dice [np.float32(0.7966)] 
2025-06-04 18:19:19.467469: Epoch time: 143.0 s 
2025-06-04 18:19:22.548657:  
2025-06-04 18:19:22.740633: Epoch 891 
2025-06-04 18:19:22.910263: Current learning rate: 0.00136 
2025-06-04 18:21:45.353025: train_loss -0.6984 
2025-06-04 18:21:45.374106: val_loss -0.7226 
2025-06-04 18:21:45.389474: Pseudo dice [np.float32(0.8109)] 
2025-06-04 18:21:45.405339: Epoch time: 142.81 s 
2025-06-04 18:21:49.141829:  
2025-06-04 18:21:49.159537: Epoch 892 
2025-06-04 18:21:49.264292: Current learning rate: 0.00135 
2025-06-04 18:24:13.434911: train_loss -0.7213 
2025-06-04 18:24:13.804373: val_loss -0.6541 
2025-06-04 18:24:14.364284: Pseudo dice [np.float32(0.747)] 
2025-06-04 18:24:14.555185: Epoch time: 144.3 s 
2025-06-04 18:24:19.473417:  
2025-06-04 18:24:19.717107: Epoch 893 
2025-06-04 18:24:19.806827: Current learning rate: 0.00134 
2025-06-04 18:26:42.539928: train_loss -0.7387 
2025-06-04 18:26:42.968951: val_loss -0.6505 
2025-06-04 18:26:43.422601: Pseudo dice [np.float32(0.7847)] 
2025-06-04 18:26:43.443055: Epoch time: 143.07 s 
2025-06-04 18:26:48.802031:  
2025-06-04 18:26:48.955909: Epoch 894 
2025-06-04 18:26:49.094291: Current learning rate: 0.00133 
2025-06-04 18:29:08.093285: train_loss -0.7321 
2025-06-04 18:29:08.116744: val_loss -0.7266 
2025-06-04 18:29:08.135290: Pseudo dice [np.float32(0.8257)] 
2025-06-04 18:29:08.157125: Epoch time: 139.29 s 
2025-06-04 18:29:12.890719:  
2025-06-04 18:29:13.070564: Epoch 895 
2025-06-04 18:29:13.247526: Current learning rate: 0.00132 
2025-06-04 18:31:37.373513: train_loss -0.7451 
2025-06-04 18:31:37.801335: val_loss -0.7035 
2025-06-04 18:31:38.112249: Pseudo dice [np.float32(0.7149)] 
2025-06-04 18:31:38.551805: Epoch time: 144.49 s 
2025-06-04 18:31:44.342560:  
2025-06-04 18:31:44.530509: Epoch 896 
2025-06-04 18:31:44.654550: Current learning rate: 0.0013 
2025-06-04 18:34:08.976920: train_loss -0.7202 
2025-06-04 18:34:09.305623: val_loss -0.6517 
2025-06-04 18:34:09.885195: Pseudo dice [np.float32(0.772)] 
2025-06-04 18:34:10.477577: Epoch time: 144.64 s 
2025-06-04 18:34:16.021909:  
2025-06-04 18:34:16.195591: Epoch 897 
2025-06-04 18:34:16.514781: Current learning rate: 0.00129 
2025-06-04 18:36:35.134837: train_loss -0.7095 
2025-06-04 18:36:35.704465: val_loss -0.6487 
2025-06-04 18:36:35.957876: Pseudo dice [np.float32(0.7589)] 
2025-06-04 18:36:36.203599: Epoch time: 139.12 s 
2025-06-04 18:36:41.623878:  
2025-06-04 18:36:42.092948: Epoch 898 
2025-06-04 18:36:42.351854: Current learning rate: 0.00128 
2025-06-04 18:39:01.961157: train_loss -0.7075 
2025-06-04 18:39:02.208630: val_loss -0.6866 
2025-06-04 18:39:02.400805: Pseudo dice [np.float32(0.759)] 
2025-06-04 18:39:02.584131: Epoch time: 140.34 s 
2025-06-04 18:39:08.990561:  
2025-06-04 18:39:09.320508: Epoch 899 
2025-06-04 18:39:09.534127: Current learning rate: 0.00127 
2025-06-04 18:41:27.141439: train_loss -0.7413 
2025-06-04 18:41:27.161583: val_loss -0.6862 
2025-06-04 18:41:27.177747: Pseudo dice [np.float32(0.8221)] 
2025-06-04 18:41:27.196799: Epoch time: 138.15 s 
2025-06-04 18:41:32.515629:  
2025-06-04 18:41:32.538857: Epoch 900 
2025-06-04 18:41:32.571178: Current learning rate: 0.00126 
2025-06-04 18:43:52.395999: train_loss -0.7372 
2025-06-04 18:43:52.418713: val_loss -0.6701 
2025-06-04 18:43:52.437720: Pseudo dice [np.float32(0.7802)] 
2025-06-04 18:43:52.456827: Epoch time: 139.88 s 
2025-06-04 18:43:56.649307:  
2025-06-04 18:43:57.019867: Epoch 901 
2025-06-04 18:43:57.354184: Current learning rate: 0.00125 
2025-06-04 18:46:18.519162: train_loss -0.7421 
2025-06-04 18:46:18.777916: val_loss -0.6514 
2025-06-04 18:46:19.004273: Pseudo dice [np.float32(0.7228)] 
2025-06-04 18:46:19.141213: Epoch time: 141.87 s 
2025-06-04 18:46:22.251952:  
2025-06-04 18:46:22.278634: Epoch 902 
2025-06-04 18:46:22.300430: Current learning rate: 0.00124 
2025-06-04 18:48:41.663411: train_loss -0.7463 
2025-06-04 18:48:41.686923: val_loss -0.7071 
2025-06-04 18:48:41.705116: Pseudo dice [np.float32(0.7828)] 
2025-06-04 18:48:41.723753: Epoch time: 139.41 s 
2025-06-04 18:48:46.515786:  
2025-06-04 18:48:46.642913: Epoch 903 
2025-06-04 18:48:47.018711: Current learning rate: 0.00122 
2025-06-04 18:51:08.768916: train_loss -0.7254 
2025-06-04 18:51:08.973566: val_loss -0.6958 
2025-06-04 18:51:09.437646: Pseudo dice [np.float32(0.7779)] 
2025-06-04 18:51:09.790639: Epoch time: 142.26 s 
2025-06-04 18:51:14.847952:  
2025-06-04 18:51:15.148504: Epoch 904 
2025-06-04 18:51:15.471607: Current learning rate: 0.00121 
2025-06-04 18:53:37.624713: train_loss -0.744 
2025-06-04 18:53:37.646604: val_loss -0.7555 
2025-06-04 18:53:37.803759: Pseudo dice [np.float32(0.7689)] 
2025-06-04 18:53:38.202032: Epoch time: 142.78 s 
2025-06-04 18:53:44.273939:  
2025-06-04 18:53:44.310618: Epoch 905 
2025-06-04 18:53:44.342403: Current learning rate: 0.0012 
2025-06-04 18:56:05.921133: train_loss -0.7191 
2025-06-04 18:56:05.944174: val_loss -0.6769 
2025-06-04 18:56:05.965514: Pseudo dice [np.float32(0.7923)] 
2025-06-04 18:56:05.987758: Epoch time: 141.65 s 
2025-06-04 18:56:11.616621:  
2025-06-04 18:56:12.058016: Epoch 906 
2025-06-04 18:56:12.250132: Current learning rate: 0.00119 
2025-06-04 18:58:33.508274: train_loss -0.7382 
2025-06-04 18:58:33.670913: val_loss -0.689 
2025-06-04 18:58:33.742153: Pseudo dice [np.float32(0.7668)] 
2025-06-04 18:58:34.189572: Epoch time: 141.89 s 
2025-06-04 18:58:38.076183:  
2025-06-04 18:58:38.206813: Epoch 907 
2025-06-04 18:58:38.339937: Current learning rate: 0.00118 
2025-06-04 19:01:00.477101: train_loss -0.7247 
2025-06-04 19:01:00.850106: val_loss -0.7285 
2025-06-04 19:01:01.339256: Pseudo dice [np.float32(0.7766)] 
2025-06-04 19:01:01.637937: Epoch time: 142.4 s 
2025-06-04 19:01:05.888675:  
2025-06-04 19:01:06.285659: Epoch 908 
2025-06-04 19:01:06.609194: Current learning rate: 0.00117 
2025-06-04 19:03:29.296705: train_loss -0.7324 
2025-06-04 19:03:29.549093: val_loss -0.7179 
2025-06-04 19:03:30.012108: Pseudo dice [np.float32(0.7752)] 
2025-06-04 19:03:30.492691: Epoch time: 143.41 s 
2025-06-04 19:03:35.654959:  
2025-06-04 19:03:36.011417: Epoch 909 
2025-06-04 19:03:36.147702: Current learning rate: 0.00116 
2025-06-04 19:05:50.983164: train_loss -0.7175 
2025-06-04 19:05:51.225729: val_loss -0.6845 
2025-06-04 19:05:51.532055: Pseudo dice [np.float32(0.7864)] 
2025-06-04 19:05:51.777458: Epoch time: 135.33 s 
2025-06-04 19:05:56.359670:  
2025-06-04 19:05:56.618737: Epoch 910 
2025-06-04 19:05:56.787405: Current learning rate: 0.00115 
2025-06-04 19:08:15.474514: train_loss -0.7212 
2025-06-04 19:08:15.866855: val_loss -0.6275 
2025-06-04 19:08:16.233972: Pseudo dice [np.float32(0.6714)] 
2025-06-04 19:08:16.630491: Epoch time: 139.12 s 
2025-06-04 19:08:20.547952:  
2025-06-04 19:08:20.630001: Epoch 911 
2025-06-04 19:08:20.768819: Current learning rate: 0.00113 
2025-06-04 19:10:41.112559: train_loss -0.755 
2025-06-04 19:10:41.139229: val_loss -0.6545 
2025-06-04 19:10:41.158745: Pseudo dice [np.float32(0.7287)] 
2025-06-04 19:10:41.446538: Epoch time: 140.57 s 
2025-06-04 19:10:48.159068:  
2025-06-04 19:10:48.466213: Epoch 912 
2025-06-04 19:10:48.606027: Current learning rate: 0.00112 
2025-06-04 19:13:02.466680: train_loss -0.7402 
2025-06-04 19:13:02.802647: val_loss -0.6271 
2025-06-04 19:13:03.187705: Pseudo dice [np.float32(0.6708)] 
2025-06-04 19:13:03.589039: Epoch time: 134.31 s 
2025-06-04 19:13:08.602297:  
2025-06-04 19:13:08.694821: Epoch 913 
2025-06-04 19:13:08.714302: Current learning rate: 0.00111 
2025-06-04 19:15:22.372717: train_loss -0.7168 
2025-06-04 19:15:22.504006: val_loss -0.656 
2025-06-04 19:15:22.524569: Pseudo dice [np.float32(0.7397)] 
2025-06-04 19:15:22.543911: Epoch time: 133.77 s 
2025-06-04 19:15:26.855326:  
2025-06-04 19:15:26.954994: Epoch 914 
2025-06-04 19:15:27.121796: Current learning rate: 0.0011 
2025-06-04 19:17:45.271913: train_loss -0.743 
2025-06-04 19:17:45.292320: val_loss -0.6597 
2025-06-04 19:17:45.312960: Pseudo dice [np.float32(0.7577)] 
2025-06-04 19:17:45.557087: Epoch time: 138.42 s 
2025-06-04 19:17:48.914799:  
2025-06-04 19:17:48.974787: Epoch 915 
2025-06-04 19:17:49.017430: Current learning rate: 0.00109 
2025-06-04 19:20:04.580230: train_loss -0.7555 
2025-06-04 19:20:04.603698: val_loss -0.708 
2025-06-04 19:20:04.755239: Pseudo dice [np.float32(0.7903)] 
2025-06-04 19:20:05.222095: Epoch time: 135.67 s 
2025-06-04 19:20:08.966713:  
2025-06-04 19:20:09.162176: Epoch 916 
2025-06-04 19:20:09.287365: Current learning rate: 0.00108 
2025-06-04 19:22:25.134043: train_loss -0.7415 
2025-06-04 19:22:25.153751: val_loss -0.7198 
2025-06-04 19:22:25.344231: Pseudo dice [np.float32(0.8237)] 
2025-06-04 19:22:25.513519: Epoch time: 136.17 s 
2025-06-04 19:22:29.000784:  
2025-06-04 19:22:29.174705: Epoch 917 
2025-06-04 19:22:29.319585: Current learning rate: 0.00106 
2025-06-04 19:24:43.734562: train_loss -0.7256 
2025-06-04 19:24:43.755252: val_loss -0.7109 
2025-06-04 19:24:43.772788: Pseudo dice [np.float32(0.8025)] 
2025-06-04 19:24:43.788814: Epoch time: 134.74 s 
2025-06-04 19:24:47.150512:  
2025-06-04 19:24:47.224067: Epoch 918 
2025-06-04 19:24:47.321299: Current learning rate: 0.00105 
2025-06-04 19:27:00.697422: train_loss -0.7083 
2025-06-04 19:27:00.891013: val_loss -0.6786 
2025-06-04 19:27:00.909150: Pseudo dice [np.float32(0.7946)] 
2025-06-04 19:27:00.941447: Epoch time: 133.55 s 
2025-06-04 19:27:06.030992:  
2025-06-04 19:27:06.105944: Epoch 919 
2025-06-04 19:27:06.146545: Current learning rate: 0.00104 
2025-06-04 19:29:23.002551: train_loss -0.7405 
2025-06-04 19:29:23.599081: val_loss -0.6809 
2025-06-04 19:29:24.165876: Pseudo dice [np.float32(0.7733)] 
2025-06-04 19:29:24.693692: Epoch time: 136.97 s 
2025-06-04 19:29:30.518173:  
2025-06-04 19:29:30.547613: Epoch 920 
2025-06-04 19:29:30.698370: Current learning rate: 0.00103 
2025-06-04 19:31:45.208049: train_loss -0.7379 
2025-06-04 19:31:45.799101: val_loss -0.7278 
2025-06-04 19:31:46.131742: Pseudo dice [np.float32(0.7598)] 
2025-06-04 19:31:46.619357: Epoch time: 134.69 s 
2025-06-04 19:31:50.491147:  
2025-06-04 19:31:50.678963: Epoch 921 
2025-06-04 19:31:50.699615: Current learning rate: 0.00102 
2025-06-04 19:34:07.659036: train_loss -0.7428 
2025-06-04 19:34:07.681850: val_loss -0.6416 
2025-06-04 19:34:08.115390: Pseudo dice [np.float32(0.7146)] 
2025-06-04 19:34:08.389550: Epoch time: 137.17 s 
2025-06-04 19:34:13.316003:  
2025-06-04 19:34:13.787274: Epoch 922 
2025-06-04 19:34:14.087958: Current learning rate: 0.00101 
2025-06-04 19:36:28.694763: train_loss -0.7257 
2025-06-04 19:36:28.845074: val_loss -0.6337 
2025-06-04 19:36:29.286500: Pseudo dice [np.float32(0.7253)] 
2025-06-04 19:36:29.607974: Epoch time: 135.38 s 
2025-06-04 19:36:34.024187:  
2025-06-04 19:36:34.307325: Epoch 923 
2025-06-04 19:36:34.441012: Current learning rate: 0.001 
2025-06-04 19:38:49.655781: train_loss -0.7294 
2025-06-04 19:38:49.973831: val_loss -0.699 
2025-06-04 19:38:50.075715: Pseudo dice [np.float32(0.7574)] 
2025-06-04 19:38:50.478885: Epoch time: 135.63 s 
2025-06-04 19:38:53.818854:  
2025-06-04 19:38:53.970209: Epoch 924 
2025-06-04 19:38:53.996728: Current learning rate: 0.00098 
2025-06-04 19:41:12.014997: train_loss -0.7462 
2025-06-04 19:41:12.038099: val_loss -0.6918 
2025-06-04 19:41:12.054414: Pseudo dice [np.float32(0.7729)] 
2025-06-04 19:41:12.069659: Epoch time: 138.2 s 
2025-06-04 19:41:16.214645:  
2025-06-04 19:41:16.551584: Epoch 925 
2025-06-04 19:41:16.826254: Current learning rate: 0.00097 
2025-06-04 19:43:29.000515: train_loss -0.7361 
2025-06-04 19:43:29.615580: val_loss -0.6948 
2025-06-04 19:43:29.853731: Pseudo dice [np.float32(0.7881)] 
2025-06-04 19:43:30.236678: Epoch time: 132.79 s 
2025-06-04 19:43:33.936207:  
2025-06-04 19:43:33.958107: Epoch 926 
2025-06-04 19:43:34.071131: Current learning rate: 0.00096 
2025-06-04 19:45:48.710477: train_loss -0.7369 
2025-06-04 19:45:48.727495: val_loss -0.6655 
2025-06-04 19:45:48.741830: Pseudo dice [np.float32(0.8146)] 
2025-06-04 19:45:48.757413: Epoch time: 134.78 s 
2025-06-04 19:45:53.088175:  
2025-06-04 19:45:53.111214: Epoch 927 
2025-06-04 19:45:53.136233: Current learning rate: 0.00095 
2025-06-04 19:48:03.612852: train_loss -0.7352 
2025-06-04 19:48:03.804128: val_loss -0.7291 
2025-06-04 19:48:03.822643: Pseudo dice [np.float32(0.8008)] 
2025-06-04 19:48:03.841311: Epoch time: 130.53 s 
2025-06-04 19:48:09.060763:  
2025-06-04 19:48:09.083764: Epoch 928 
2025-06-04 19:48:09.105691: Current learning rate: 0.00094 
2025-06-04 19:50:28.059553: train_loss -0.7182 
2025-06-04 19:50:28.083025: val_loss -0.6644 
2025-06-04 19:50:28.101468: Pseudo dice [np.float32(0.7828)] 
2025-06-04 19:50:28.118905: Epoch time: 139.0 s 
2025-06-04 19:50:35.479645:  
2025-06-04 19:50:35.817286: Epoch 929 
2025-06-04 19:50:36.135077: Current learning rate: 0.00092 
2025-06-04 19:52:51.255299: train_loss -0.7323 
2025-06-04 19:52:51.382977: val_loss -0.5812 
2025-06-04 19:52:51.402434: Pseudo dice [np.float32(0.7111)] 
2025-06-04 19:52:51.418745: Epoch time: 135.78 s 
2025-06-04 19:52:58.957664:  
2025-06-04 19:52:59.482462: Epoch 930 
2025-06-04 19:52:59.500673: Current learning rate: 0.00091 
2025-06-04 19:55:16.208533: train_loss -0.7407 
2025-06-04 19:55:16.235669: val_loss -0.6382 
2025-06-04 19:55:16.568101: Pseudo dice [np.float32(0.6796)] 
2025-06-04 19:55:17.027387: Epoch time: 137.25 s 
2025-06-04 19:55:21.573131:  
2025-06-04 19:55:21.894476: Epoch 931 
2025-06-04 19:55:22.130847: Current learning rate: 0.0009 
2025-06-04 19:57:39.296889: train_loss -0.7264 
2025-06-04 19:57:39.319427: val_loss -0.6416 
2025-06-04 19:57:39.781974: Pseudo dice [np.float32(0.717)] 
2025-06-04 19:57:40.192799: Epoch time: 137.73 s 
2025-06-04 19:57:44.547267:  
2025-06-04 19:57:44.748669: Epoch 932 
2025-06-04 19:57:45.170324: Current learning rate: 0.00089 
2025-06-04 20:00:01.157503: train_loss -0.7415 
2025-06-04 20:00:01.593945: val_loss -0.7063 
2025-06-04 20:00:02.336173: Pseudo dice [np.float32(0.8137)] 
2025-06-04 20:00:02.895726: Epoch time: 136.61 s 
2025-06-04 20:00:06.955834:  
2025-06-04 20:00:07.013741: Epoch 933 
2025-06-04 20:00:07.032116: Current learning rate: 0.00088 
2025-06-04 20:02:26.181730: train_loss -0.7278 
2025-06-04 20:02:26.220641: val_loss -0.683 
2025-06-04 20:02:26.530946: Pseudo dice [np.float32(0.8233)] 
2025-06-04 20:02:27.079810: Epoch time: 139.23 s 
2025-06-04 20:02:32.598564:  
2025-06-04 20:02:32.760568: Epoch 934 
2025-06-04 20:02:32.777833: Current learning rate: 0.00087 
2025-06-04 20:04:49.221959: train_loss -0.7477 
2025-06-04 20:04:49.240516: val_loss -0.7407 
2025-06-04 20:04:49.254764: Pseudo dice [np.float32(0.7995)] 
2025-06-04 20:04:49.268327: Epoch time: 136.62 s 
2025-06-04 20:04:55.883960:  
2025-06-04 20:04:55.948583: Epoch 935 
2025-06-04 20:04:55.966149: Current learning rate: 0.00085 
2025-06-04 20:07:12.034102: train_loss -0.7565 
2025-06-04 20:07:12.412500: val_loss -0.7032 
2025-06-04 20:07:12.786818: Pseudo dice [np.float32(0.781)] 
2025-06-04 20:07:13.138464: Epoch time: 136.15 s 
2025-06-04 20:07:15.996967:  
2025-06-04 20:07:16.026429: Epoch 936 
2025-06-04 20:07:16.050225: Current learning rate: 0.00084 
2025-06-04 20:09:30.914151: train_loss -0.7343 
2025-06-04 20:09:30.933261: val_loss -0.6864 
2025-06-04 20:09:30.946794: Pseudo dice [np.float32(0.8393)] 
2025-06-04 20:09:30.961464: Epoch time: 134.92 s 
2025-06-04 20:09:35.232651:  
2025-06-04 20:09:35.262796: Epoch 937 
2025-06-04 20:09:35.286149: Current learning rate: 0.00083 
2025-06-04 20:11:54.185637: train_loss -0.7598 
2025-06-04 20:11:54.203719: val_loss -0.7002 
2025-06-04 20:11:54.217133: Pseudo dice [np.float32(0.7383)] 
2025-06-04 20:11:54.230150: Epoch time: 138.96 s 
2025-06-04 20:11:57.356184:  
2025-06-04 20:11:57.369462: Epoch 938 
2025-06-04 20:11:57.380156: Current learning rate: 0.00082 
2025-06-04 20:14:15.092415: train_loss -0.745 
2025-06-04 20:14:15.283154: val_loss -0.6749 
2025-06-04 20:14:15.494053: Pseudo dice [np.float32(0.728)] 
2025-06-04 20:14:15.808015: Epoch time: 137.74 s 
2025-06-04 20:14:21.450155:  
2025-06-04 20:14:21.472460: Epoch 939 
2025-06-04 20:14:21.489381: Current learning rate: 0.00081 
2025-06-04 20:16:38.617771: train_loss -0.7437 
2025-06-04 20:16:38.909658: val_loss -0.6601 
2025-06-04 20:16:39.317358: Pseudo dice [np.float32(0.7321)] 
2025-06-04 20:16:39.333234: Epoch time: 137.17 s 
2025-06-04 20:16:43.606577:  
2025-06-04 20:16:43.824039: Epoch 940 
2025-06-04 20:16:43.975341: Current learning rate: 0.00079 
2025-06-04 20:19:05.791483: train_loss -0.7591 
2025-06-04 20:19:06.063806: val_loss -0.6816 
2025-06-04 20:19:06.322489: Pseudo dice [np.float32(0.7504)] 
2025-06-04 20:19:06.552618: Epoch time: 142.19 s 
2025-06-04 20:19:11.576628:  
2025-06-04 20:19:11.688004: Epoch 941 
2025-06-04 20:19:11.807802: Current learning rate: 0.00078 
2025-06-04 20:21:15.927150: train_loss -0.7315 
2025-06-04 20:21:15.944551: val_loss -0.6188 
2025-06-04 20:21:15.960227: Pseudo dice [np.float32(0.765)] 
2025-06-04 20:21:15.972828: Epoch time: 124.35 s 
2025-06-04 20:21:20.502599:  
2025-06-04 20:21:20.791325: Epoch 942 
2025-06-04 20:21:21.155215: Current learning rate: 0.00077 
2025-06-04 20:23:08.145526: train_loss -0.739 
2025-06-04 20:23:08.166145: val_loss -0.6474 
2025-06-04 20:23:08.182162: Pseudo dice [np.float32(0.7405)] 
2025-06-04 20:23:08.196532: Epoch time: 107.64 s 
2025-06-04 20:23:11.051084:  
2025-06-04 20:23:11.247227: Epoch 943 
2025-06-04 20:23:11.464298: Current learning rate: 0.00076 
2025-06-04 20:25:29.286942: train_loss -0.7486 
2025-06-04 20:25:29.522656: val_loss -0.7116 
2025-06-04 20:25:29.539186: Pseudo dice [np.float32(0.782)] 
2025-06-04 20:25:29.552549: Epoch time: 138.24 s 
2025-06-04 20:25:34.673779:  
2025-06-04 20:25:34.695502: Epoch 944 
2025-06-04 20:25:34.714892: Current learning rate: 0.00075 
2025-06-04 20:27:54.124101: train_loss -0.715 
2025-06-04 20:27:54.308287: val_loss -0.6964 
2025-06-04 20:27:54.326775: Pseudo dice [np.float32(0.7874)] 
2025-06-04 20:27:54.341066: Epoch time: 139.45 s 
2025-06-04 20:27:58.365754:  
2025-06-04 20:27:58.386090: Epoch 945 
2025-06-04 20:27:58.431651: Current learning rate: 0.00074 
2025-06-04 20:30:05.319568: train_loss -0.7329 
2025-06-04 20:30:05.336778: val_loss -0.6432 
2025-06-04 20:30:05.350296: Pseudo dice [np.float32(0.7279)] 
2025-06-04 20:30:05.364076: Epoch time: 126.96 s 
2025-06-04 20:30:09.315238:  
2025-06-04 20:30:09.556965: Epoch 946 
2025-06-04 20:30:09.585864: Current learning rate: 0.00072 
2025-06-04 20:32:21.077596: train_loss -0.7517 
2025-06-04 20:32:21.097189: val_loss -0.6506 
2025-06-04 20:32:21.114047: Pseudo dice [np.float32(0.7471)] 
2025-06-04 20:32:21.130279: Epoch time: 131.77 s 
2025-06-04 20:32:25.626569:  
2025-06-04 20:32:25.783521: Epoch 947 
2025-06-04 20:32:25.905492: Current learning rate: 0.00071 
2025-06-04 20:34:41.548793: train_loss -0.7509 
2025-06-04 20:34:41.568293: val_loss -0.6583 
2025-06-04 20:34:41.581097: Pseudo dice [np.float32(0.8084)] 
2025-06-04 20:34:41.594984: Epoch time: 135.92 s 
2025-06-04 20:34:46.097679:  
2025-06-04 20:34:46.291156: Epoch 948 
2025-06-04 20:34:46.307771: Current learning rate: 0.0007 
2025-06-04 20:36:59.009251: train_loss -0.7325 
2025-06-04 20:36:59.346188: val_loss -0.6986 
2025-06-04 20:36:59.984471: Pseudo dice [np.float32(0.8121)] 
2025-06-04 20:37:00.000931: Epoch time: 132.91 s 
2025-06-04 20:37:04.856424:  
2025-06-04 20:37:04.989067: Epoch 949 
2025-06-04 20:37:05.043418: Current learning rate: 0.00069 
2025-06-04 20:39:18.820646: train_loss -0.7299 
2025-06-04 20:39:19.274766: val_loss -0.6686 
2025-06-04 20:39:19.777359: Pseudo dice [np.float32(0.7367)] 
2025-06-04 20:39:20.267927: Epoch time: 133.97 s 
2025-06-04 20:39:26.978507:  
2025-06-04 20:39:27.174659: Epoch 950 
2025-06-04 20:39:27.342584: Current learning rate: 0.00067 
2025-06-04 20:41:42.006367: train_loss -0.7473 
2025-06-04 20:41:42.030919: val_loss -0.7254 
2025-06-04 20:41:42.048309: Pseudo dice [np.float32(0.8314)] 
2025-06-04 20:41:42.062667: Epoch time: 135.03 s 
2025-06-04 20:41:46.732013:  
2025-06-04 20:41:47.038584: Epoch 951 
2025-06-04 20:41:47.250494: Current learning rate: 0.00066 
2025-06-04 20:44:04.927196: train_loss -0.7334 
2025-06-04 20:44:05.360142: val_loss -0.6228 
2025-06-04 20:44:05.379676: Pseudo dice [np.float32(0.7639)] 
2025-06-04 20:44:05.396241: Epoch time: 138.2 s 
2025-06-04 20:44:09.020523:  
2025-06-04 20:44:09.040864: Epoch 952 
2025-06-04 20:44:09.054999: Current learning rate: 0.00065 
2025-06-04 20:46:25.518749: train_loss -0.738 
2025-06-04 20:46:25.538849: val_loss -0.7257 
2025-06-04 20:46:25.553523: Pseudo dice [np.float32(0.7951)] 
2025-06-04 20:46:25.566072: Epoch time: 136.5 s 
2025-06-04 20:46:31.698936:  
2025-06-04 20:46:31.808613: Epoch 953 
2025-06-04 20:46:31.897879: Current learning rate: 0.00064 
2025-06-04 20:48:50.891765: train_loss -0.7416 
2025-06-04 20:48:50.910384: val_loss -0.7269 
2025-06-04 20:48:50.926095: Pseudo dice [np.float32(0.8101)] 
2025-06-04 20:48:50.941259: Epoch time: 139.19 s 
2025-06-04 20:48:55.648318:  
2025-06-04 20:48:55.870007: Epoch 954 
2025-06-04 20:48:55.893869: Current learning rate: 0.00063 
2025-06-04 20:51:13.351067: train_loss -0.7354 
2025-06-04 20:51:13.691802: val_loss -0.6873 
2025-06-04 20:51:14.045455: Pseudo dice [np.float32(0.7115)] 
2025-06-04 20:51:14.388045: Epoch time: 137.7 s 
2025-06-04 20:51:17.631710:  
2025-06-04 20:51:17.828547: Epoch 955 
2025-06-04 20:51:18.094013: Current learning rate: 0.00061 
2025-06-04 20:53:30.119592: train_loss -0.7484 
2025-06-04 20:53:30.137232: val_loss -0.6499 
2025-06-04 20:53:30.150246: Pseudo dice [np.float32(0.7139)] 
2025-06-04 20:53:30.163430: Epoch time: 132.49 s 
2025-06-04 20:53:31.995980:  
2025-06-04 20:53:32.009402: Epoch 956 
2025-06-04 20:53:32.024448: Current learning rate: 0.0006 
2025-06-04 20:55:46.055290: train_loss -0.7444 
2025-06-04 20:55:46.251822: val_loss -0.6775 
2025-06-04 20:55:46.374695: Pseudo dice [np.float32(0.7307)] 
2025-06-04 20:55:46.388902: Epoch time: 134.06 s 
2025-06-04 20:55:49.520386:  
2025-06-04 20:55:49.649909: Epoch 957 
2025-06-04 20:55:49.693983: Current learning rate: 0.00059 
2025-06-04 20:58:07.869552: train_loss -0.7518 
2025-06-04 20:58:07.886946: val_loss -0.7111 
2025-06-04 20:58:07.903298: Pseudo dice [np.float32(0.7684)] 
2025-06-04 20:58:07.917643: Epoch time: 138.35 s 
2025-06-04 20:58:10.920799:  
2025-06-04 20:58:10.945878: Epoch 958 
2025-06-04 20:58:11.055586: Current learning rate: 0.00058 
2025-06-04 21:00:31.485148: train_loss -0.7367 
2025-06-04 21:00:31.502521: val_loss -0.7037 
2025-06-04 21:00:31.515669: Pseudo dice [np.float32(0.7687)] 
2025-06-04 21:00:31.528341: Epoch time: 140.57 s 
2025-06-04 21:00:34.393329:  
2025-06-04 21:00:34.456313: Epoch 959 
2025-06-04 21:00:34.508864: Current learning rate: 0.00056 
2025-06-04 21:02:55.067460: train_loss -0.7405 
2025-06-04 21:02:55.218391: val_loss -0.711 
2025-06-04 21:02:55.509776: Pseudo dice [np.float32(0.8428)] 
2025-06-04 21:02:55.739224: Epoch time: 140.68 s 
2025-06-04 21:02:59.072780:  
2025-06-04 21:02:59.094864: Epoch 960 
2025-06-04 21:02:59.110080: Current learning rate: 0.00055 
2025-06-04 21:05:19.118784: train_loss -0.7235 
2025-06-04 21:05:19.137312: val_loss -0.6667 
2025-06-04 21:05:19.153246: Pseudo dice [np.float32(0.7418)] 
2025-06-04 21:05:19.168094: Epoch time: 140.13 s 
2025-06-04 21:05:24.169517:  
2025-06-04 21:05:24.427161: Epoch 961 
2025-06-04 21:05:24.681031: Current learning rate: 0.00054 
2025-06-04 21:07:38.809957: train_loss -0.7162 
2025-06-04 21:07:38.830459: val_loss -0.6655 
2025-06-04 21:07:38.847340: Pseudo dice [np.float32(0.7535)] 
2025-06-04 21:07:38.863780: Epoch time: 134.64 s 
2025-06-04 21:07:43.587945:  
2025-06-04 21:07:43.615851: Epoch 962 
2025-06-04 21:07:43.636846: Current learning rate: 0.00053 
2025-06-04 21:10:00.450454: train_loss -0.7324 
2025-06-04 21:10:00.468553: val_loss -0.6701 
2025-06-04 21:10:00.483041: Pseudo dice [np.float32(0.8217)] 
2025-06-04 21:10:00.495953: Epoch time: 136.86 s 
2025-06-04 21:10:05.375981:  
2025-06-04 21:10:05.507936: Epoch 963 
2025-06-04 21:10:05.866401: Current learning rate: 0.00051 
2025-06-04 21:12:23.696858: train_loss -0.7344 
2025-06-04 21:12:24.070000: val_loss -0.6775 
2025-06-04 21:12:24.502147: Pseudo dice [np.float32(0.732)] 
2025-06-04 21:12:24.845671: Epoch time: 138.32 s 
2025-06-04 21:12:28.765801:  
2025-06-04 21:12:29.081900: Epoch 964 
2025-06-04 21:12:29.102345: Current learning rate: 0.0005 
2025-06-04 21:14:43.331668: train_loss -0.729 
2025-06-04 21:14:43.985429: val_loss -0.6634 
2025-06-04 21:14:44.499517: Pseudo dice [np.float32(0.7712)] 
2025-06-04 21:14:44.828002: Epoch time: 134.57 s 
2025-06-04 21:14:48.037853:  
2025-06-04 21:14:48.053773: Epoch 965 
2025-06-04 21:14:48.066005: Current learning rate: 0.00049 
2025-06-04 21:17:03.029317: train_loss -0.7501 
2025-06-04 21:17:03.046315: val_loss -0.648 
2025-06-04 21:17:03.060672: Pseudo dice [np.float32(0.7549)] 
2025-06-04 21:17:03.076047: Epoch time: 135.0 s 
2025-06-04 21:17:07.091771:  
2025-06-04 21:17:07.285990: Epoch 966 
2025-06-04 21:17:07.449241: Current learning rate: 0.00048 
2025-06-04 21:19:22.344449: train_loss -0.751 
2025-06-04 21:19:22.706108: val_loss -0.6938 
2025-06-04 21:19:23.080054: Pseudo dice [np.float32(0.7571)] 
2025-06-04 21:19:23.095304: Epoch time: 135.25 s 
2025-06-04 21:19:27.102733:  
2025-06-04 21:19:27.209334: Epoch 967 
2025-06-04 21:19:27.233045: Current learning rate: 0.00046 
2025-06-04 21:21:42.555154: train_loss -0.7325 
2025-06-04 21:21:42.576677: val_loss -0.7211 
2025-06-04 21:21:42.594228: Pseudo dice [np.float32(0.7796)] 
2025-06-04 21:21:42.611806: Epoch time: 135.45 s 
2025-06-04 21:21:48.985127:  
2025-06-04 21:21:49.045602: Epoch 968 
2025-06-04 21:21:49.088065: Current learning rate: 0.00045 
2025-06-04 21:24:10.057424: train_loss -0.7317 
2025-06-04 21:24:10.079387: val_loss -0.6666 
2025-06-04 21:24:10.403463: Pseudo dice [np.float32(0.788)] 
2025-06-04 21:24:10.890574: Epoch time: 141.07 s 
2025-06-04 21:24:15.927645:  
2025-06-04 21:24:16.105065: Epoch 969 
2025-06-04 21:24:16.194612: Current learning rate: 0.00044 
2025-06-04 21:26:31.748159: train_loss -0.7467 
2025-06-04 21:26:31.767293: val_loss -0.7234 
2025-06-04 21:26:31.781046: Pseudo dice [np.float32(0.8381)] 
2025-06-04 21:26:31.794595: Epoch time: 135.82 s 
2025-06-04 21:26:37.721451:  
2025-06-04 21:26:37.749490: Epoch 970 
2025-06-04 21:26:37.784853: Current learning rate: 0.00043 
2025-06-04 21:28:51.108663: train_loss -0.7482 
2025-06-04 21:28:51.471478: val_loss -0.7212 
2025-06-04 21:28:52.037003: Pseudo dice [np.float32(0.7987)] 
2025-06-04 21:28:52.548477: Epoch time: 133.39 s 
2025-06-04 21:28:56.830323:  
2025-06-04 21:28:56.850940: Epoch 971 
2025-06-04 21:28:56.866526: Current learning rate: 0.00041 
2025-06-04 21:31:07.380693: train_loss -0.7364 
2025-06-04 21:31:07.399685: val_loss -0.6712 
2025-06-04 21:31:07.414493: Pseudo dice [np.float32(0.8136)] 
2025-06-04 21:31:07.427706: Epoch time: 130.55 s 
2025-06-04 21:31:07.440327: Yayy! New best EMA pseudo Dice: 0.7821999788284302 
2025-06-04 21:31:12.288190:  
2025-06-04 21:31:12.308218: Epoch 972 
2025-06-04 21:31:12.325083: Current learning rate: 0.0004 
2025-06-04 21:33:27.651457: train_loss -0.7587 
2025-06-04 21:33:27.880692: val_loss -0.7647 
2025-06-04 21:33:27.898829: Pseudo dice [np.float32(0.8232)] 
2025-06-04 21:33:27.912664: Epoch time: 135.37 s 
2025-06-04 21:33:27.925966: Yayy! New best EMA pseudo Dice: 0.786300003528595 
2025-06-04 21:33:30.995488:  
2025-06-04 21:33:31.033998: Epoch 973 
2025-06-04 21:33:31.050269: Current learning rate: 0.00039 
2025-06-04 21:35:46.524161: train_loss -0.7158 
2025-06-04 21:35:46.723070: val_loss -0.684 
2025-06-04 21:35:46.738437: Pseudo dice [np.float32(0.8447)] 
2025-06-04 21:35:46.751702: Epoch time: 135.53 s 
2025-06-04 21:35:46.764173: Yayy! New best EMA pseudo Dice: 0.7921000123023987 
2025-06-04 21:35:51.664042:  
2025-06-04 21:35:51.684937: Epoch 974 
2025-06-04 21:35:51.713587: Current learning rate: 0.00037 
2025-06-04 21:38:07.207250: train_loss -0.7589 
2025-06-04 21:38:07.225235: val_loss -0.7009 
2025-06-04 21:38:07.239243: Pseudo dice [np.float32(0.8125)] 
2025-06-04 21:38:07.252035: Epoch time: 135.54 s 
2025-06-04 21:38:07.265838: Yayy! New best EMA pseudo Dice: 0.7942000031471252 
2025-06-04 21:38:12.526363:  
2025-06-04 21:38:12.593939: Epoch 975 
2025-06-04 21:38:12.616656: Current learning rate: 0.00036 
2025-06-04 21:40:29.162886: train_loss -0.7364 
2025-06-04 21:40:29.178668: val_loss -0.6344 
2025-06-04 21:40:29.192342: Pseudo dice [np.float32(0.6959)] 
2025-06-04 21:40:29.205478: Epoch time: 136.64 s 
2025-06-04 21:40:33.476058:  
2025-06-04 21:40:33.561846: Epoch 976 
2025-06-04 21:40:33.580901: Current learning rate: 0.00035 
2025-06-04 21:42:48.393851: train_loss -0.7592 
2025-06-04 21:42:48.664286: val_loss -0.7166 
2025-06-04 21:42:48.938226: Pseudo dice [np.float32(0.7663)] 
2025-06-04 21:42:49.213575: Epoch time: 134.92 s 
2025-06-04 21:42:51.903584:  
2025-06-04 21:42:51.921474: Epoch 977 
2025-06-04 21:42:51.936182: Current learning rate: 0.00034 
2025-06-04 21:45:08.693139: train_loss -0.7431 
2025-06-04 21:45:08.709780: val_loss -0.7155 
2025-06-04 21:45:08.723434: Pseudo dice [np.float32(0.8427)] 
2025-06-04 21:45:08.736554: Epoch time: 136.79 s 
2025-06-04 21:45:12.182461:  
2025-06-04 21:45:12.199832: Epoch 978 
2025-06-04 21:45:12.214612: Current learning rate: 0.00032 
2025-06-04 21:47:27.694137: train_loss -0.7331 
2025-06-04 21:47:28.125108: val_loss -0.6657 
2025-06-04 21:47:28.437811: Pseudo dice [np.float32(0.7247)] 
2025-06-04 21:47:28.736672: Epoch time: 135.51 s 
2025-06-04 21:47:31.615034:  
2025-06-04 21:47:31.638157: Epoch 979 
2025-06-04 21:47:31.655053: Current learning rate: 0.00031 
2025-06-04 21:49:51.880319: train_loss -0.7488 
2025-06-04 21:49:52.094838: val_loss -0.703 
2025-06-04 21:49:52.488391: Pseudo dice [np.float32(0.7189)] 
2025-06-04 21:49:52.506240: Epoch time: 140.27 s 
2025-06-04 21:49:56.242285:  
2025-06-04 21:49:56.350924: Epoch 980 
2025-06-04 21:49:56.446096: Current learning rate: 0.0003 
2025-06-04 21:52:15.909584: train_loss -0.7246 
2025-06-04 21:52:15.924979: val_loss -0.6563 
2025-06-04 21:52:15.958524: Pseudo dice [np.float32(0.8182)] 
2025-06-04 21:52:15.992037: Epoch time: 139.67 s 
2025-06-04 21:52:21.048572:  
2025-06-04 21:52:21.074030: Epoch 981 
2025-06-04 21:52:21.089913: Current learning rate: 0.00028 
2025-06-04 21:54:37.173805: train_loss -0.7357 
2025-06-04 21:54:37.200277: val_loss -0.7046 
2025-06-04 21:54:37.216165: Pseudo dice [np.float32(0.8276)] 
2025-06-04 21:54:37.960399: Epoch time: 136.13 s 
2025-06-04 21:54:43.145859:  
2025-06-04 21:54:43.433719: Epoch 982 
2025-06-04 21:54:43.527727: Current learning rate: 0.00027 
2025-06-04 21:56:59.379951: train_loss -0.7727 
2025-06-04 21:56:59.399361: val_loss -0.7122 
2025-06-04 21:56:59.413196: Pseudo dice [np.float32(0.7499)] 
2025-06-04 21:56:59.426015: Epoch time: 136.24 s 
2025-06-04 21:57:05.103533:  
2025-06-04 21:57:05.127907: Epoch 983 
2025-06-04 21:57:05.148916: Current learning rate: 0.00026 
2025-06-04 21:59:19.566278: train_loss -0.7409 
2025-06-04 21:59:19.586699: val_loss -0.7276 
2025-06-04 21:59:19.615433: Pseudo dice [np.float32(0.8045)] 
2025-06-04 21:59:19.632209: Epoch time: 134.46 s 
2025-06-04 21:59:23.649299:  
2025-06-04 21:59:23.930714: Epoch 984 
2025-06-04 21:59:24.128644: Current learning rate: 0.00024 
2025-06-04 22:01:32.995865: train_loss -0.7653 
2025-06-04 22:01:33.014748: val_loss -0.6555 
2025-06-04 22:01:33.027786: Pseudo dice [np.float32(0.7133)] 
2025-06-04 22:01:33.040898: Epoch time: 129.35 s 
2025-06-04 22:01:36.758715:  
2025-06-04 22:01:36.777649: Epoch 985 
2025-06-04 22:01:36.791842: Current learning rate: 0.00023 
2025-06-04 22:03:46.765450: train_loss -0.7335 
2025-06-04 22:03:47.249097: val_loss -0.6873 
2025-06-04 22:03:47.376956: Pseudo dice [np.float32(0.7687)] 
2025-06-04 22:03:47.407245: Epoch time: 130.01 s 
2025-06-04 22:03:51.313225:  
2025-06-04 22:03:51.335455: Epoch 986 
2025-06-04 22:03:51.353233: Current learning rate: 0.00021 
2025-06-04 22:06:05.113832: train_loss -0.7472 
2025-06-04 22:06:05.589992: val_loss -0.6676 
2025-06-04 22:06:06.015495: Pseudo dice [np.float32(0.7851)] 
2025-06-04 22:06:06.397259: Epoch time: 133.8 s 
2025-06-04 22:06:09.283718:  
2025-06-04 22:06:09.384253: Epoch 987 
2025-06-04 22:06:09.570087: Current learning rate: 0.0002 
2025-06-04 22:08:25.056417: train_loss -0.7577 
2025-06-04 22:08:25.073662: val_loss -0.7121 
2025-06-04 22:08:25.089270: Pseudo dice [np.float32(0.8066)] 
2025-06-04 22:08:25.102930: Epoch time: 135.77 s 
2025-06-04 22:08:29.701410:  
2025-06-04 22:08:29.731087: Epoch 988 
2025-06-04 22:08:29.748370: Current learning rate: 0.00019 
2025-06-04 22:10:42.337116: train_loss -0.7488 
2025-06-04 22:10:43.007654: val_loss -0.6721 
2025-06-04 22:10:43.363635: Pseudo dice [np.float32(0.7719)] 
2025-06-04 22:10:43.639438: Epoch time: 132.64 s 
2025-06-04 22:10:46.921372:  
2025-06-04 22:10:46.953562: Epoch 989 
2025-06-04 22:10:46.999381: Current learning rate: 0.00017 
2025-06-04 22:12:58.960474: train_loss -0.7368 
2025-06-04 22:12:58.978555: val_loss -0.7127 
2025-06-04 22:12:58.992647: Pseudo dice [np.float32(0.822)] 
2025-06-04 22:12:59.010548: Epoch time: 132.04 s 
2025-06-04 22:13:03.222309:  
2025-06-04 22:13:03.338392: Epoch 990 
2025-06-04 22:13:03.498386: Current learning rate: 0.00016 
2025-06-04 22:15:16.694379: train_loss -0.7508 
2025-06-04 22:15:16.712960: val_loss -0.6885 
2025-06-04 22:15:16.726305: Pseudo dice [np.float32(0.7632)] 
2025-06-04 22:15:16.739088: Epoch time: 133.47 s 
2025-06-04 22:15:21.036765:  
2025-06-04 22:15:21.272702: Epoch 991 
2025-06-04 22:15:21.477137: Current learning rate: 0.00014 
2025-06-04 22:17:32.129864: train_loss -0.7527 
2025-06-04 22:17:32.149861: val_loss -0.6473 
2025-06-04 22:17:32.165741: Pseudo dice [np.float32(0.7709)] 
2025-06-04 22:17:32.179894: Epoch time: 131.1 s 
2025-06-04 22:17:37.263530:  
2025-06-04 22:17:37.467747: Epoch 992 
2025-06-04 22:17:37.602826: Current learning rate: 0.00013 
2025-06-04 22:19:45.623410: train_loss -0.7527 
2025-06-04 22:19:45.642373: val_loss -0.721 
2025-06-04 22:19:45.655951: Pseudo dice [np.float32(0.7913)] 
2025-06-04 22:19:45.668134: Epoch time: 128.36 s 
2025-06-04 22:19:50.459313:  
2025-06-04 22:19:50.622205: Epoch 993 
2025-06-04 22:19:50.871116: Current learning rate: 0.00011 
2025-06-04 22:22:00.723700: train_loss -0.7468 
2025-06-04 22:22:00.741719: val_loss -0.6487 
2025-06-04 22:22:00.755268: Pseudo dice [np.float32(0.7091)] 
2025-06-04 22:22:00.767870: Epoch time: 130.27 s 
2025-06-04 22:22:03.219586:  
2025-06-04 22:22:03.231985: Epoch 994 
2025-06-04 22:22:03.247312: Current learning rate: 0.0001 
2025-06-04 22:24:11.251897: train_loss -0.7322 
2025-06-04 22:24:11.622006: val_loss -0.7043 
2025-06-04 22:24:11.931966: Pseudo dice [np.float32(0.8022)] 
2025-06-04 22:24:12.130621: Epoch time: 128.03 s 
2025-06-04 22:24:15.819885:  
2025-06-04 22:24:15.835244: Epoch 995 
2025-06-04 22:24:15.850902: Current learning rate: 8e-05 
2025-06-04 22:26:25.275799: train_loss -0.7463 
2025-06-04 22:26:25.299946: val_loss -0.6768 
2025-06-04 22:26:25.313024: Pseudo dice [np.float32(0.8299)] 
2025-06-04 22:26:25.325629: Epoch time: 129.46 s 
2025-06-04 22:26:29.692573:  
2025-06-04 22:26:29.789161: Epoch 996 
2025-06-04 22:26:29.806053: Current learning rate: 7e-05 
2025-06-04 22:28:41.539670: train_loss -0.7662 
2025-06-04 22:28:41.724465: val_loss -0.612 
2025-06-04 22:28:41.995318: Pseudo dice [np.float32(0.7378)] 
2025-06-04 22:28:42.304855: Epoch time: 131.85 s 
2025-06-04 22:28:44.961121:  
2025-06-04 22:28:45.047349: Epoch 997 
2025-06-04 22:28:45.100296: Current learning rate: 5e-05 
2025-06-04 22:30:56.369714: train_loss -0.7257 
2025-06-04 22:30:56.752788: val_loss -0.6962 
2025-06-04 22:30:57.090249: Pseudo dice [np.float32(0.8348)] 
2025-06-04 22:30:57.310797: Epoch time: 131.41 s 
2025-06-04 22:31:00.588665:  
2025-06-04 22:31:00.610503: Epoch 998 
2025-06-04 22:31:00.626308: Current learning rate: 4e-05 
2025-06-04 22:33:06.099328: train_loss -0.7553 
2025-06-04 22:33:06.350071: val_loss -0.6734 
2025-06-04 22:33:06.700286: Pseudo dice [np.float32(0.7607)] 
2025-06-04 22:33:06.992865: Epoch time: 125.51 s 
2025-06-04 22:33:10.728740:  
2025-06-04 22:33:10.779754: Epoch 999 
2025-06-04 22:33:10.840856: Current learning rate: 2e-05 
2025-06-04 22:35:20.623412: train_loss -0.7188 
2025-06-04 22:35:20.640430: val_loss -0.6741 
2025-06-04 22:35:20.653738: Pseudo dice [np.float32(0.829)] 
2025-06-04 22:35:20.667330: Epoch time: 129.9 s 
2025-06-04 22:35:27.561271: Training done. 
2025-06-04 22:35:27.682083: Using splits from existing split file: C:\Users\usuario\Documents\Mama_Mia\nnUNet_preprocessed\Dataset111\splits_final.json 
2025-06-04 22:35:27.728851: The split file contains 5 splits. 
2025-06-04 22:35:27.744068: Desired fold for training: 0 
2025-06-04 22:35:27.758309: This split has 960 training and 240 validation cases. 
2025-06-04 22:35:27.774967: predicting case_000 
2025-06-04 22:35:28.020570: case_000, shape torch.Size([1, 88, 512, 512]), rank 0 
2025-06-04 22:36:07.350616: predicting case_006 
2025-06-04 22:36:07.920935: case_006, shape torch.Size([1, 88, 469, 469]), rank 0 
2025-06-04 22:36:24.647605: predicting case_010 
2025-06-04 22:36:24.986449: case_010, shape torch.Size([1, 84, 498, 498]), rank 0 
2025-06-04 22:36:44.359597: predicting case_017 
2025-06-04 22:36:45.120231: case_017, shape torch.Size([1, 81, 469, 469]), rank 0 
2025-06-04 22:36:59.696551: predicting case_020 
2025-06-04 22:37:00.744685: case_020, shape torch.Size([1, 97, 484, 484]), rank 0 
2025-06-04 22:37:28.117540: predicting case_022 
2025-06-04 22:37:28.655616: case_022, shape torch.Size([1, 88, 484, 484]), rank 0 
2025-06-04 22:37:56.182671: predicting case_025 
2025-06-04 22:37:56.757579: case_025, shape torch.Size([1, 88, 512, 512]), rank 0 
2025-06-04 22:38:25.920590: predicting case_029 
2025-06-04 22:38:26.945829: case_029, shape torch.Size([1, 88, 484, 484]), rank 0 
2025-06-04 22:38:51.619897: predicting case_030 
2025-06-04 22:38:51.890961: case_030, shape torch.Size([1, 100, 484, 484]), rank 0 
2025-06-04 22:39:14.692082: predicting case_033 
2025-06-04 22:39:14.975259: case_033, shape torch.Size([1, 94, 526, 526]), rank 0 
2025-06-04 22:39:38.404315: predicting case_041 
2025-06-04 22:39:38.738238: case_041, shape torch.Size([1, 80, 484, 484]), rank 0 
2025-06-04 22:39:54.023384: predicting case_047 
2025-06-04 22:39:54.361461: case_047, shape torch.Size([1, 83, 498, 498]), rank 0 
2025-06-04 22:40:09.647397: predicting case_052 
2025-06-04 22:40:09.924741: case_052, shape torch.Size([1, 88, 512, 512]), rank 0 
2025-06-04 22:40:32.883720: predicting case_056 
2025-06-04 22:40:33.083843: case_056, shape torch.Size([1, 72, 455, 455]), rank 0 
2025-06-04 22:40:42.902222: predicting case_058 
2025-06-04 22:40:43.182324: case_058, shape torch.Size([1, 88, 512, 512]), rank 0 
2025-06-04 22:41:06.125344: predicting case_059 
2025-06-04 22:41:06.446568: case_059, shape torch.Size([1, 93, 569, 569]), rank 0 
2025-06-04 22:41:29.392115: predicting case_065 
2025-06-04 22:41:29.763349: case_065, shape torch.Size([1, 92, 540, 540]), rank 0 
2025-06-04 22:41:52.678370: predicting case_068 
2025-06-04 22:41:52.924592: case_068, shape torch.Size([1, 80, 427, 427]), rank 0 
2025-06-04 22:42:02.729223: predicting case_070 
2025-06-04 22:42:02.942291: case_070, shape torch.Size([1, 96, 484, 484]), rank 0 
2025-06-04 22:42:25.802031: predicting case_072 
2025-06-04 22:42:26.182738: case_072, shape torch.Size([1, 112, 498, 498]), rank 0 
2025-06-04 22:42:49.012430: predicting case_073 
2025-06-04 22:42:49.283345: case_073, shape torch.Size([1, 88, 512, 512]), rank 0 
2025-06-04 22:43:12.066140: predicting case_076 
2025-06-04 22:43:12.288480: case_076, shape torch.Size([1, 88, 512, 512]), rank 0 
2025-06-04 22:43:35.099398: predicting case_082 
2025-06-04 22:43:35.347424: case_082, shape torch.Size([1, 79, 455, 455]), rank 0 
2025-06-04 22:43:45.159961: predicting case_089 
2025-06-04 22:43:45.479423: case_089, shape torch.Size([1, 104, 498, 498]), rank 0 
2025-06-04 22:44:08.257308: predicting case_090 
2025-06-04 22:44:08.470829: case_090, shape torch.Size([1, 78, 441, 441]), rank 0 
2025-06-04 22:44:18.419402: predicting case_092 
2025-06-04 22:44:18.970421: case_092, shape torch.Size([1, 94, 441, 441]), rank 0 
2025-06-04 22:44:33.508894: predicting case_097 
2025-06-04 22:44:33.819144: case_097, shape torch.Size([1, 100, 512, 512]), rank 0 
2025-06-04 22:44:56.536468: predicting case_1000 
2025-06-04 22:44:56.720109: case_1000, shape torch.Size([1, 80, 427, 427]), rank 0 
2025-06-04 22:45:06.476503: predicting case_1003 
2025-06-04 22:45:06.562215: case_1003, shape torch.Size([1, 80, 213, 213]), rank 0 
2025-06-04 22:45:09.028668: predicting case_1013 
2025-06-04 22:45:09.180493: case_1013, shape torch.Size([1, 90, 320, 320]), rank 0 
2025-06-04 22:45:17.413841: predicting case_1016 
2025-06-04 22:45:17.603230: case_1016, shape torch.Size([1, 80, 427, 427]), rank 0 
2025-06-04 22:45:27.350581: predicting case_1020 
2025-06-04 22:45:27.465507: case_1020, shape torch.Size([1, 80, 256, 256]), rank 0 
2025-06-04 22:45:29.945823: predicting case_1032 
2025-06-04 22:45:30.219889: case_1032, shape torch.Size([1, 97, 512, 512]), rank 0 
2025-06-04 22:45:52.944501: predicting case_1034 
2025-06-04 22:45:53.030013: case_1034, shape torch.Size([1, 79, 220, 220]), rank 0 
2025-06-04 22:45:55.504550: predicting case_1043 
2025-06-04 22:45:55.745886: case_1043, shape torch.Size([1, 80, 455, 455]), rank 0 
2025-06-04 22:46:05.491710: predicting case_1044 
2025-06-04 22:46:05.588198: case_1044, shape torch.Size([1, 80, 243, 243]), rank 0 
2025-06-04 22:46:08.058086: predicting case_1045 
2025-06-04 22:46:08.302502: case_1045, shape torch.Size([1, 80, 512, 512]), rank 0 
2025-06-04 22:46:23.457248: predicting case_1046 
2025-06-04 22:46:23.574143: case_1046, shape torch.Size([1, 80, 270, 270]), rank 0 
2025-06-04 22:46:26.063079: predicting case_1048 
2025-06-04 22:46:26.332039: case_1048, shape torch.Size([1, 86, 512, 512]), rank 0 
2025-06-04 22:46:49.150276: predicting case_1049 
2025-06-04 22:46:49.255182: case_1049, shape torch.Size([1, 80, 235, 235]), rank 0 
2025-06-04 22:46:51.742979: predicting case_1056 
2025-06-04 22:46:51.835726: case_1056, shape torch.Size([1, 79, 256, 256]), rank 0 
2025-06-04 22:46:54.305146: predicting case_1066 
2025-06-04 22:46:54.372572: case_1066, shape torch.Size([1, 79, 192, 192]), rank 0 
2025-06-04 22:46:55.042552: predicting case_1070 
2025-06-04 22:46:55.150090: case_1070, shape torch.Size([1, 80, 263, 263]), rank 0 
2025-06-04 22:46:57.652174: predicting case_1079 
2025-06-04 22:46:57.744123: case_1079, shape torch.Size([1, 80, 206, 206]), rank 0 
2025-06-04 22:47:00.208625: predicting case_1081 
2025-06-04 22:47:00.300070: case_1081, shape torch.Size([1, 80, 221, 221]), rank 0 
2025-06-04 22:47:02.758710: predicting case_1084 
2025-06-04 22:47:02.830710: case_1084, shape torch.Size([1, 80, 209, 209]), rank 0 
2025-06-04 22:47:05.299822: predicting case_1089 
2025-06-04 22:47:05.387997: case_1089, shape torch.Size([1, 80, 256, 256]), rank 0 
2025-06-04 22:47:07.860458: predicting case_1091 
2025-06-04 22:47:07.946443: case_1091, shape torch.Size([1, 80, 213, 213]), rank 0 
2025-06-04 22:47:10.406615: predicting case_1096 
2025-06-04 22:47:10.508213: case_1096, shape torch.Size([1, 79, 256, 256]), rank 0 
2025-06-04 22:47:12.974818: predicting case_1098 
2025-06-04 22:47:13.030156: case_1098, shape torch.Size([1, 80, 206, 206]), rank 0 
2025-06-04 22:47:15.489798: predicting case_1105 
2025-06-04 22:47:15.630847: case_1105, shape torch.Size([1, 80, 213, 213]), rank 0 
2025-06-04 22:47:18.095533: predicting case_111 
2025-06-04 22:47:18.385959: case_111, shape torch.Size([1, 89, 512, 512]), rank 0 
2025-06-04 22:47:41.506729: predicting case_1111 
2025-06-04 22:47:41.775496: case_1111, shape torch.Size([1, 80, 235, 235]), rank 0 
2025-06-04 22:47:44.243841: predicting case_1125 
2025-06-04 22:47:44.304886: case_1125, shape torch.Size([1, 79, 199, 199]), rank 0 
2025-06-04 22:47:46.789520: predicting case_1126 
2025-06-04 22:47:46.876451: case_1126, shape torch.Size([1, 80, 249, 249]), rank 0 
2025-06-04 22:47:49.343098: predicting case_113 
2025-06-04 22:47:49.616615: case_113, shape torch.Size([1, 79, 484, 484]), rank 0 
2025-06-04 22:48:04.756190: predicting case_1136 
2025-06-04 22:48:05.035635: case_1136, shape torch.Size([1, 97, 455, 455]), rank 0 
2025-06-04 22:48:19.600901: predicting case_1139 
2025-06-04 22:48:19.852577: case_1139, shape torch.Size([1, 86, 455, 455]), rank 0 
2025-06-04 22:48:34.432590: predicting case_1149 
2025-06-04 22:48:34.527917: case_1149, shape torch.Size([1, 80, 242, 242]), rank 0 
2025-06-04 22:48:36.996913: predicting case_115 
2025-06-04 22:48:37.231297: case_115, shape torch.Size([1, 80, 498, 498]), rank 0 
2025-06-04 22:48:52.427711: predicting case_1152 
2025-06-04 22:48:52.486326: case_1152, shape torch.Size([1, 79, 206, 206]), rank 0 
2025-06-04 22:48:54.949263: predicting case_1160 
2025-06-04 22:48:55.054081: case_1160, shape torch.Size([1, 60, 284, 284]), rank 0 
2025-06-04 22:48:57.565086: predicting case_1163 
2025-06-04 22:48:57.701793: case_1163, shape torch.Size([1, 60, 256, 256]), rank 0 
2025-06-04 22:49:00.164910: predicting case_1164 
2025-06-04 22:49:00.273488: case_1164, shape torch.Size([1, 69, 256, 256]), rank 0 
2025-06-04 22:49:02.753296: predicting case_1181 
2025-06-04 22:49:02.845200: case_1181, shape torch.Size([1, 60, 256, 256]), rank 0 
2025-06-04 22:49:05.308789: predicting case_1183 
2025-06-04 22:49:05.404164: case_1183, shape torch.Size([1, 70, 256, 256]), rank 0 
2025-06-04 22:49:07.871897: predicting case_1185 
2025-06-04 22:49:08.012890: case_1185, shape torch.Size([1, 60, 256, 256]), rank 0 
2025-06-04 22:49:10.477464: predicting case_1189 
2025-06-04 22:49:10.598682: case_1189, shape torch.Size([1, 66, 313, 313]), rank 0 
2025-06-04 22:49:16.116790: predicting case_1191 
2025-06-04 22:49:16.246217: case_1191, shape torch.Size([1, 60, 256, 256]), rank 0 
2025-06-04 22:49:18.725652: predicting case_122 
2025-06-04 22:49:19.049060: case_122, shape torch.Size([1, 107, 512, 512]), rank 0 
2025-06-04 22:49:41.749495: predicting case_128 
2025-06-04 22:49:41.959335: case_128, shape torch.Size([1, 71, 484, 484]), rank 0 
2025-06-04 22:49:57.175017: predicting case_139 
2025-06-04 22:49:57.881575: case_139, shape torch.Size([1, 88, 498, 498]), rank 0 
2025-06-04 22:50:20.670904: predicting case_143 
2025-06-04 22:50:20.912558: case_143, shape torch.Size([1, 88, 455, 455]), rank 0 
2025-06-04 22:50:35.468312: predicting case_147 
2025-06-04 22:50:35.729621: case_147, shape torch.Size([1, 85, 512, 512]), rank 0 
2025-06-04 22:50:58.480848: predicting case_158 
2025-06-04 22:50:58.773674: case_158, shape torch.Size([1, 88, 484, 484]), rank 0 
2025-06-04 22:51:21.465190: predicting case_159 
2025-06-04 22:51:21.756234: case_159, shape torch.Size([1, 90, 569, 569]), rank 0 
2025-06-04 22:51:44.541672: predicting case_180 
2025-06-04 22:51:44.807909: case_180, shape torch.Size([1, 87, 512, 512]), rank 0 
2025-06-04 22:52:07.568880: predicting case_181 
2025-06-04 22:52:07.837287: case_181, shape torch.Size([1, 88, 484, 484]), rank 0 
2025-06-04 22:52:30.543840: predicting case_190 
2025-06-04 22:52:30.812154: case_190, shape torch.Size([1, 95, 526, 526]), rank 0 
2025-06-04 22:52:53.544851: predicting case_199 
2025-06-04 22:52:53.834311: case_199, shape torch.Size([1, 97, 512, 512]), rank 0 
2025-06-04 22:53:16.553729: predicting case_208 
2025-06-04 22:53:16.707284: case_208, shape torch.Size([1, 63, 313, 313]), rank 0 
2025-06-04 22:53:22.599729: predicting case_211 
2025-06-04 22:53:22.759216: case_211, shape torch.Size([1, 45, 256, 256]), rank 0 
2025-06-04 22:53:24.451531: predicting case_214 
2025-06-04 22:53:24.592846: case_214, shape torch.Size([1, 69, 284, 284]), rank 0 
2025-06-04 22:53:27.080806: predicting case_219 
2025-06-04 22:53:27.201307: case_219, shape torch.Size([1, 60, 284, 284]), rank 0 
2025-06-04 22:53:29.671748: predicting case_223 
2025-06-04 22:53:29.802635: case_223, shape torch.Size([1, 80, 256, 256]), rank 0 
2025-06-04 22:53:32.268011: predicting case_234 
2025-06-04 22:53:32.363253: case_234, shape torch.Size([1, 60, 284, 284]), rank 0 
2025-06-04 22:53:34.836736: predicting case_236 
2025-06-04 22:53:34.945959: case_236, shape torch.Size([1, 70, 256, 256]), rank 0 
2025-06-04 22:53:37.413890: predicting case_249 
2025-06-04 22:53:37.521083: case_249, shape torch.Size([1, 72, 256, 256]), rank 0 
2025-06-04 22:53:39.990151: predicting case_255 
2025-06-04 22:53:40.054197: case_255, shape torch.Size([1, 60, 284, 284]), rank 0 
2025-06-04 22:53:42.504964: predicting case_256 
2025-06-04 22:53:42.607105: case_256, shape torch.Size([1, 60, 284, 284]), rank 0 
2025-06-04 22:53:45.077390: predicting case_268 
2025-06-04 22:53:45.148400: case_268, shape torch.Size([1, 60, 284, 284]), rank 0 
2025-06-04 22:53:47.609522: predicting case_289 
2025-06-04 22:53:47.695044: case_289, shape torch.Size([1, 73, 256, 256]), rank 0 
2025-06-04 22:53:50.162840: predicting case_293 
2025-06-04 22:53:50.246448: case_293, shape torch.Size([1, 60, 284, 284]), rank 0 
2025-06-04 22:53:52.705719: predicting case_299 
2025-06-04 22:53:52.956622: case_299, shape torch.Size([1, 192, 313, 313]), rank 0 
2025-06-04 22:54:09.313335: predicting case_302 
2025-06-04 22:54:09.425285: case_302, shape torch.Size([1, 66, 284, 284]), rank 0 
2025-06-04 22:54:11.932734: predicting case_310 
2025-06-04 22:54:12.007498: case_310, shape torch.Size([1, 80, 228, 228]), rank 0 
2025-06-04 22:54:14.469985: predicting case_311 
2025-06-04 22:54:14.860468: case_311, shape torch.Size([1, 97, 540, 540]), rank 0 
2025-06-04 22:54:37.544741: predicting case_321 
2025-06-04 22:54:37.684215: case_321, shape torch.Size([1, 88, 263, 263]), rank 0 
2025-06-04 22:54:41.377161: predicting case_322 
2025-06-04 22:54:41.501774: case_322, shape torch.Size([1, 80, 329, 329]), rank 0 
2025-06-04 22:54:47.017443: predicting case_330 
2025-06-04 22:54:47.132519: case_330, shape torch.Size([1, 80, 270, 270]), rank 0 
2025-06-04 22:54:49.614187: predicting case_339 
2025-06-04 22:54:49.689550: case_339, shape torch.Size([1, 80, 213, 213]), rank 0 
2025-06-04 22:54:52.148264: predicting case_341 
2025-06-04 22:54:52.239916: case_341, shape torch.Size([1, 80, 328, 328]), rank 0 
2025-06-04 22:54:57.768779: predicting case_345 
2025-06-04 22:54:57.842307: case_345, shape torch.Size([1, 80, 228, 228]), rank 0 
2025-06-04 22:55:00.329311: predicting case_357 
2025-06-04 22:55:00.395114: case_357, shape torch.Size([1, 80, 249, 249]), rank 0 
2025-06-04 22:55:02.859593: predicting case_378 
2025-06-04 22:55:02.963072: case_378, shape torch.Size([1, 80, 242, 242]), rank 0 
2025-06-04 22:55:05.434203: predicting case_387 
2025-06-04 22:55:05.553833: case_387, shape torch.Size([1, 80, 220, 220]), rank 0 
2025-06-04 22:55:08.008265: predicting case_388 
2025-06-04 22:55:08.078650: case_388, shape torch.Size([1, 80, 206, 206]), rank 0 
2025-06-04 22:55:10.547036: predicting case_393 
2025-06-04 22:55:10.809356: case_393, shape torch.Size([1, 86, 469, 469]), rank 0 
2025-06-04 22:55:25.347521: predicting case_396 
2025-06-04 22:55:25.409724: case_396, shape torch.Size([1, 80, 228, 228]), rank 0 
2025-06-04 22:55:27.881661: predicting case_398 
2025-06-04 22:55:27.978326: case_398, shape torch.Size([1, 80, 242, 242]), rank 0 
2025-06-04 22:55:30.446130: predicting case_399 
2025-06-04 22:55:30.529161: case_399, shape torch.Size([1, 80, 242, 242]), rank 0 
2025-06-04 22:55:33.002273: predicting case_404 
2025-06-04 22:55:33.072747: case_404, shape torch.Size([1, 80, 220, 220]), rank 0 
2025-06-04 22:55:35.978019: predicting case_427 
2025-06-04 22:55:36.210074: case_427, shape torch.Size([1, 80, 235, 235]), rank 0 
2025-06-04 22:55:39.024149: predicting case_435 
2025-06-04 22:55:39.173542: case_435, shape torch.Size([1, 80, 256, 256]), rank 0 
2025-06-04 22:55:41.786027: predicting case_437 
2025-06-04 22:55:41.884670: case_437, shape torch.Size([1, 79, 256, 256]), rank 0 
2025-06-04 22:55:44.340270: predicting case_445 
2025-06-04 22:55:44.447575: case_445, shape torch.Size([1, 80, 249, 249]), rank 0 
2025-06-04 22:55:46.934966: predicting case_446 
2025-06-04 22:55:46.991104: case_446, shape torch.Size([1, 79, 206, 206]), rank 0 
2025-06-04 22:55:49.443642: predicting case_448 
2025-06-04 22:55:49.547055: case_448, shape torch.Size([1, 80, 328, 328]), rank 0 
2025-06-04 22:55:55.031604: predicting case_458 
2025-06-04 22:55:55.098161: case_458, shape torch.Size([1, 80, 220, 220]), rank 0 
2025-06-04 22:55:57.558417: predicting case_473 
2025-06-04 22:55:57.615299: case_473, shape torch.Size([1, 80, 199, 199]), rank 0 
2025-06-04 22:56:00.065016: predicting case_476 
2025-06-04 22:56:00.128468: case_476, shape torch.Size([1, 80, 228, 228]), rank 0 
2025-06-04 22:56:02.594005: predicting case_477 
2025-06-04 22:56:02.657116: case_477, shape torch.Size([1, 80, 228, 228]), rank 0 
2025-06-04 22:56:05.107443: predicting case_482 
2025-06-04 22:56:05.227986: case_482, shape torch.Size([1, 79, 256, 256]), rank 0 
2025-06-04 22:56:07.698580: predicting case_486 
2025-06-04 22:56:07.789229: case_486, shape torch.Size([1, 80, 228, 228]), rank 0 
2025-06-04 22:56:10.254537: predicting case_498 
2025-06-04 22:56:10.386073: case_498, shape torch.Size([1, 80, 313, 313]), rank 0 
2025-06-04 22:56:15.934468: predicting case_500 
2025-06-04 22:56:16.012069: case_500, shape torch.Size([1, 80, 213, 213]), rank 0 
2025-06-04 22:56:18.470162: predicting case_503 
2025-06-04 22:56:18.550790: case_503, shape torch.Size([1, 79, 213, 213]), rank 0 
2025-06-04 22:56:21.011749: predicting case_505 
2025-06-04 22:56:21.228622: case_505, shape torch.Size([1, 80, 398, 398]), rank 0 
2025-06-04 22:56:30.928833: predicting case_508 
2025-06-04 22:56:31.055519: case_508, shape torch.Size([1, 79, 256, 256]), rank 0 
2025-06-04 22:56:33.544955: predicting case_515 
2025-06-04 22:56:33.607104: case_515, shape torch.Size([1, 80, 220, 220]), rank 0 
2025-06-04 22:56:36.064478: predicting case_518 
2025-06-04 22:56:36.313071: case_518, shape torch.Size([1, 88, 455, 455]), rank 0 
2025-06-04 22:56:50.857166: predicting case_525 
2025-06-04 22:56:50.956582: case_525, shape torch.Size([1, 80, 235, 235]), rank 0 
2025-06-04 22:56:53.426430: predicting case_526 
2025-06-04 22:56:53.502472: case_526, shape torch.Size([1, 80, 220, 220]), rank 0 
2025-06-04 22:56:55.980824: predicting case_528 
2025-06-04 22:56:56.302059: case_528, shape torch.Size([1, 97, 540, 540]), rank 0 
2025-06-04 22:57:19.021318: predicting case_536 
2025-06-04 22:57:19.321002: case_536, shape torch.Size([1, 86, 512, 512]), rank 0 
2025-06-04 22:57:42.120436: predicting case_538 
2025-06-04 22:57:42.214622: case_538, shape torch.Size([1, 80, 256, 256]), rank 0 
2025-06-04 22:57:44.701692: predicting case_539 
2025-06-04 22:57:44.828021: case_539, shape torch.Size([1, 80, 329, 329]), rank 0 
2025-06-04 22:57:50.736043: predicting case_540 
2025-06-04 22:57:51.044633: case_540, shape torch.Size([1, 90, 329, 329]), rank 0 
2025-06-04 22:57:59.370302: predicting case_556 
2025-06-04 22:57:59.636742: case_556, shape torch.Size([1, 96, 427, 427]), rank 0 
2025-06-04 22:58:14.194447: predicting case_568 
2025-06-04 22:58:14.262785: case_568, shape torch.Size([1, 80, 213, 213]), rank 0 
2025-06-04 22:58:16.738360: predicting case_572 
2025-06-04 22:58:16.825913: case_572, shape torch.Size([1, 80, 256, 256]), rank 0 
2025-06-04 22:58:19.304765: predicting case_577 
2025-06-04 22:58:19.408562: case_577, shape torch.Size([1, 80, 249, 249]), rank 0 
2025-06-04 22:58:21.876134: predicting case_584 
2025-06-04 22:58:22.112358: case_584, shape torch.Size([1, 97, 441, 441]), rank 0 
2025-06-04 22:58:36.651120: predicting case_585 
2025-06-04 22:58:36.914476: case_585, shape torch.Size([1, 97, 455, 455]), rank 0 
2025-06-04 22:58:51.463201: predicting case_587 
2025-06-04 22:58:51.561226: case_587, shape torch.Size([1, 80, 235, 235]), rank 0 
2025-06-04 22:58:54.063468: predicting case_592 
2025-06-04 22:58:54.188293: case_592, shape torch.Size([1, 80, 328, 328]), rank 0 
2025-06-04 22:59:00.092706: predicting case_594 
2025-06-04 22:59:00.203567: case_594, shape torch.Size([1, 91, 231, 231]), rank 0 
2025-06-04 22:59:04.244903: predicting case_595 
2025-06-04 22:59:04.348543: case_595, shape torch.Size([1, 80, 228, 228]), rank 0 
2025-06-04 22:59:06.909137: predicting case_599 
2025-06-04 22:59:07.200183: case_599, shape torch.Size([1, 102, 455, 455]), rank 0 
2025-06-04 22:59:21.762104: predicting case_603 
2025-06-04 22:59:22.003628: case_603, shape torch.Size([1, 88, 427, 427]), rank 0 
2025-06-04 22:59:36.613025: predicting case_604 
2025-06-04 22:59:36.695106: case_604, shape torch.Size([1, 80, 206, 206]), rank 0 
2025-06-04 22:59:39.174899: predicting case_609 
2025-06-04 22:59:39.321149: case_609, shape torch.Size([1, 100, 256, 256]), rank 0 
2025-06-04 22:59:43.002634: predicting case_612 
2025-06-04 22:59:43.144835: case_612, shape torch.Size([1, 80, 284, 284]), rank 0 
2025-06-04 22:59:45.616664: predicting case_614 
2025-06-04 22:59:45.697568: case_614, shape torch.Size([1, 79, 199, 199]), rank 0 
2025-06-04 22:59:48.151135: predicting case_615 
2025-06-04 22:59:48.222747: case_615, shape torch.Size([1, 79, 213, 213]), rank 0 
2025-06-04 22:59:50.695834: predicting case_616 
2025-06-04 22:59:50.770723: case_616, shape torch.Size([1, 80, 256, 256]), rank 0 
2025-06-04 22:59:53.230215: predicting case_621 
2025-06-04 22:59:53.336777: case_621, shape torch.Size([1, 81, 213, 213]), rank 0 
2025-06-04 22:59:55.795386: predicting case_623 
2025-06-04 22:59:55.916268: case_623, shape torch.Size([1, 79, 256, 256]), rank 0 
2025-06-04 22:59:58.369197: predicting case_624 
2025-06-04 22:59:58.660388: case_624, shape torch.Size([1, 100, 512, 512]), rank 0 
2025-06-04 23:00:21.357145: predicting case_636 
2025-06-04 23:00:21.464174: case_636, shape torch.Size([1, 79, 213, 213]), rank 0 
2025-06-04 23:00:23.946819: predicting case_641 
2025-06-04 23:00:24.038958: case_641, shape torch.Size([1, 79, 256, 256]), rank 0 
2025-06-04 23:00:26.523335: predicting case_646 
2025-06-04 23:00:26.593893: case_646, shape torch.Size([1, 79, 185, 185]), rank 0 
2025-06-04 23:00:27.253527: predicting case_648 
2025-06-04 23:00:27.328396: case_648, shape torch.Size([1, 80, 213, 213]), rank 0 
2025-06-04 23:00:29.790529: predicting case_653 
2025-06-04 23:00:29.884195: case_653, shape torch.Size([1, 80, 256, 256]), rank 0 
2025-06-04 23:00:32.355721: predicting case_654 
2025-06-04 23:00:32.423198: case_654, shape torch.Size([1, 80, 242, 242]), rank 0 
2025-06-04 23:00:34.904512: predicting case_657 
2025-06-04 23:00:34.990047: case_657, shape torch.Size([1, 80, 235, 235]), rank 0 
2025-06-04 23:00:37.466634: predicting case_660 
2025-06-04 23:00:37.573048: case_660, shape torch.Size([1, 79, 256, 256]), rank 0 
2025-06-04 23:00:40.045647: predicting case_663 
2025-06-04 23:00:40.179731: case_663, shape torch.Size([1, 80, 256, 256]), rank 0 
2025-06-04 23:00:42.643670: predicting case_667 
2025-06-04 23:00:42.730816: case_667, shape torch.Size([1, 80, 228, 228]), rank 0 
2025-06-04 23:00:45.188426: predicting case_673 
2025-06-04 23:00:45.325989: case_673, shape torch.Size([1, 80, 256, 256]), rank 0 
2025-06-04 23:00:47.798748: predicting case_677 
2025-06-04 23:00:48.107741: case_677, shape torch.Size([1, 90, 512, 512]), rank 0 
2025-06-04 23:01:10.822804: predicting case_678 
2025-06-04 23:01:10.937841: case_678, shape torch.Size([1, 79, 256, 256]), rank 0 
2025-06-04 23:01:13.771304: predicting case_679 
2025-06-04 23:01:14.026083: case_679, shape torch.Size([1, 80, 277, 277]), rank 0 
2025-06-04 23:01:16.958088: predicting case_680 
2025-06-04 23:01:17.249148: case_680, shape torch.Size([1, 80, 256, 256]), rank 0 
2025-06-04 23:01:20.332454: predicting case_681 
2025-06-04 23:01:20.657626: case_681, shape torch.Size([1, 80, 398, 398]), rank 0 
2025-06-04 23:01:30.363056: predicting case_690 
2025-06-04 23:01:30.437643: case_690, shape torch.Size([1, 79, 220, 220]), rank 0 
2025-06-04 23:01:32.889407: predicting case_695 
2025-06-04 23:01:33.007291: case_695, shape torch.Size([1, 77, 302, 302]), rank 0 
2025-06-04 23:01:38.502256: predicting case_698 
2025-06-04 23:01:38.557146: case_698, shape torch.Size([1, 80, 213, 213]), rank 0 
2025-06-04 23:01:41.019104: predicting case_700 
2025-06-04 23:01:41.186968: case_700, shape torch.Size([1, 90, 356, 356]), rank 0 
2025-06-04 23:01:49.368554: predicting case_701 
2025-06-04 23:01:49.467784: case_701, shape torch.Size([1, 80, 256, 256]), rank 0 
2025-06-04 23:01:51.955075: predicting case_707 
2025-06-04 23:01:52.118805: case_707, shape torch.Size([1, 80, 256, 256]), rank 0 
2025-06-04 23:01:54.589443: predicting case_714 
2025-06-04 23:01:54.648352: case_714, shape torch.Size([1, 80, 199, 199]), rank 0 
2025-06-04 23:01:57.114279: predicting case_726 
2025-06-04 23:01:57.204442: case_726, shape torch.Size([1, 80, 220, 220]), rank 0 
2025-06-04 23:01:59.665183: predicting case_728 
2025-06-04 23:01:59.783588: case_728, shape torch.Size([1, 90, 284, 284]), rank 0 
2025-06-04 23:02:03.459425: predicting case_733 
2025-06-04 23:02:03.553412: case_733, shape torch.Size([1, 80, 228, 228]), rank 0 
2025-06-04 23:02:06.014193: predicting case_735 
2025-06-04 23:02:06.112784: case_735, shape torch.Size([1, 79, 256, 256]), rank 0 
2025-06-04 23:02:08.587137: predicting case_738 
2025-06-04 23:02:08.643350: case_738, shape torch.Size([1, 79, 213, 213]), rank 0 
2025-06-04 23:02:11.109208: predicting case_741 
2025-06-04 23:02:11.263061: case_741, shape torch.Size([1, 79, 256, 256]), rank 0 
2025-06-04 23:02:13.756103: predicting case_747 
2025-06-04 23:02:14.176136: case_747, shape torch.Size([1, 86, 569, 569]), rank 0 
2025-06-04 23:02:36.902084: predicting case_758 
2025-06-04 23:02:36.996029: case_758, shape torch.Size([1, 80, 235, 235]), rank 0 
2025-06-04 23:02:39.475692: predicting case_761 
2025-06-04 23:02:39.564785: case_761, shape torch.Size([1, 80, 256, 256]), rank 0 
2025-06-04 23:02:42.033189: predicting case_765 
2025-06-04 23:02:42.122396: case_765, shape torch.Size([1, 80, 243, 243]), rank 0 
2025-06-04 23:02:44.602414: predicting case_766 
2025-06-04 23:02:44.751412: case_766, shape torch.Size([1, 80, 256, 256]), rank 0 
2025-06-04 23:02:47.292008: predicting case_774 
2025-06-04 23:02:47.525086: case_774, shape torch.Size([1, 80, 455, 455]), rank 0 
2025-06-04 23:02:57.296144: predicting case_776 
2025-06-04 23:02:57.571959: case_776, shape torch.Size([1, 88, 512, 512]), rank 0 
2025-06-04 23:03:20.327348: predicting case_783 
2025-06-04 23:03:20.457873: case_783, shape torch.Size([1, 80, 256, 256]), rank 0 
2025-06-04 23:03:22.952384: predicting case_786 
2025-06-04 23:03:23.063523: case_786, shape torch.Size([1, 79, 256, 256]), rank 0 
2025-06-04 23:03:25.564401: predicting case_790 
2025-06-04 23:03:25.628764: case_790, shape torch.Size([1, 79, 228, 228]), rank 0 
2025-06-04 23:03:28.090648: predicting case_792 
2025-06-04 23:03:28.194716: case_792, shape torch.Size([1, 79, 256, 256]), rank 0 
2025-06-04 23:03:31.096370: predicting case_798 
2025-06-04 23:03:31.230283: case_798, shape torch.Size([1, 80, 242, 242]), rank 0 
2025-06-04 23:03:34.387645: predicting case_801 
2025-06-04 23:03:34.542173: case_801, shape torch.Size([1, 79, 213, 213]), rank 0 
2025-06-04 23:03:37.461175: predicting case_803 
2025-06-04 23:03:37.570820: case_803, shape torch.Size([1, 80, 270, 270]), rank 0 
2025-06-04 23:03:40.201796: predicting case_810 
2025-06-04 23:03:40.332323: case_810, shape torch.Size([1, 84, 299, 299]), rank 0 
2025-06-04 23:03:45.822764: predicting case_811 
2025-06-04 23:03:45.938076: case_811, shape torch.Size([1, 80, 256, 256]), rank 0 
2025-06-04 23:03:48.401720: predicting case_812 
2025-06-04 23:03:48.568287: case_812, shape torch.Size([1, 80, 256, 256]), rank 0 
2025-06-04 23:03:51.052932: predicting case_816 
2025-06-04 23:03:51.130880: case_816, shape torch.Size([1, 80, 213, 213]), rank 0 
2025-06-04 23:03:53.588611: predicting case_823 
2025-06-04 23:03:53.826297: case_823, shape torch.Size([1, 96, 455, 455]), rank 0 
2025-06-04 23:04:08.311816: predicting case_830 
2025-06-04 23:04:08.422371: case_830, shape torch.Size([1, 80, 242, 242]), rank 0 
2025-06-04 23:04:10.903210: predicting case_831 
2025-06-04 23:04:11.021980: case_831, shape torch.Size([1, 80, 328, 328]), rank 0 
2025-06-04 23:04:16.523484: predicting case_832 
2025-06-04 23:04:16.590138: case_832, shape torch.Size([1, 81, 213, 213]), rank 0 
2025-06-04 23:04:19.054782: predicting case_836 
2025-06-04 23:04:19.249593: case_836, shape torch.Size([1, 80, 427, 427]), rank 0 
2025-06-04 23:04:28.970668: predicting case_838 
2025-06-04 23:04:29.063752: case_838, shape torch.Size([1, 80, 242, 242]), rank 0 
2025-06-04 23:04:31.549620: predicting case_840 
2025-06-04 23:04:31.647124: case_840, shape torch.Size([1, 80, 249, 249]), rank 0 
2025-06-04 23:04:34.132055: predicting case_846 
2025-06-04 23:04:34.212761: case_846, shape torch.Size([1, 80, 213, 213]), rank 0 
2025-06-04 23:04:36.680487: predicting case_847 
2025-06-04 23:04:36.776358: case_847, shape torch.Size([1, 80, 228, 228]), rank 0 
2025-06-04 23:04:39.583252: predicting case_857 
2025-06-04 23:04:39.747260: case_857, shape torch.Size([1, 80, 242, 242]), rank 0 
2025-06-04 23:04:42.677651: predicting case_858 
2025-06-04 23:04:42.975213: case_858, shape torch.Size([1, 80, 256, 256]), rank 0 
2025-06-04 23:04:45.814782: predicting case_862 
2025-06-04 23:04:46.005501: case_862, shape torch.Size([1, 80, 242, 242]), rank 0 
2025-06-04 23:04:48.704794: predicting case_867 
2025-06-04 23:04:48.817526: case_867, shape torch.Size([1, 90, 320, 320]), rank 0 
2025-06-04 23:04:57.022159: predicting case_868 
2025-06-04 23:04:57.170583: case_868, shape torch.Size([1, 80, 256, 256]), rank 0 
2025-06-04 23:04:59.647324: predicting case_870 
2025-06-04 23:04:59.805107: case_870, shape torch.Size([1, 80, 256, 256]), rank 0 
2025-06-04 23:05:02.274509: predicting case_877 
2025-06-04 23:05:02.373426: case_877, shape torch.Size([1, 79, 235, 235]), rank 0 
2025-06-04 23:05:04.843786: predicting case_878 
2025-06-04 23:05:04.957687: case_878, shape torch.Size([1, 79, 256, 256]), rank 0 
2025-06-04 23:05:07.419521: predicting case_888 
2025-06-04 23:05:07.514170: case_888, shape torch.Size([1, 79, 256, 256]), rank 0 
2025-06-04 23:05:09.987457: predicting case_893 
2025-06-04 23:05:10.090387: case_893, shape torch.Size([1, 80, 270, 270]), rank 0 
2025-06-04 23:05:12.604882: predicting case_899 
2025-06-04 23:05:12.692064: case_899, shape torch.Size([1, 80, 256, 256]), rank 0 
2025-06-04 23:05:15.152982: predicting case_912 
2025-06-04 23:05:15.252091: case_912, shape torch.Size([1, 90, 289, 289]), rank 0 
2025-06-04 23:05:23.455229: predicting case_916 
2025-06-04 23:05:23.611477: case_916, shape torch.Size([1, 80, 398, 398]), rank 0 
2025-06-04 23:05:33.342871: predicting case_929 
2025-06-04 23:05:33.616765: case_929, shape torch.Size([1, 86, 427, 427]), rank 0 
2025-06-04 23:05:48.268191: predicting case_930 
2025-06-04 23:05:48.485865: case_930, shape torch.Size([1, 89, 302, 302]), rank 0 
2025-06-04 23:05:56.752429: predicting case_940 
2025-06-04 23:05:56.830645: case_940, shape torch.Size([1, 80, 213, 213]), rank 0 
2025-06-04 23:05:59.286936: predicting case_943 
2025-06-04 23:05:59.416718: case_943, shape torch.Size([1, 80, 277, 277]), rank 0 
2025-06-04 23:06:01.898984: predicting case_960 
2025-06-04 23:06:01.988694: case_960, shape torch.Size([1, 80, 199, 199]), rank 0 
2025-06-04 23:06:04.447315: predicting case_970 
2025-06-04 23:06:04.523722: case_970, shape torch.Size([1, 80, 242, 242]), rank 0 
2025-06-04 23:06:07.019387: predicting case_976 
2025-06-04 23:06:07.081814: case_976, shape torch.Size([1, 80, 256, 256]), rank 0 
2025-06-04 23:06:09.551169: predicting case_977 
2025-06-04 23:06:09.656415: case_977, shape torch.Size([1, 80, 228, 228]), rank 0 
2025-06-04 23:06:12.120004: predicting case_979 
2025-06-04 23:06:12.234456: case_979, shape torch.Size([1, 90, 258, 258]), rank 0 
2025-06-04 23:06:15.917597: predicting case_985 
2025-06-04 23:06:16.023397: case_985, shape torch.Size([1, 79, 256, 256]), rank 0 
2025-06-04 23:06:18.496672: predicting case_990 
2025-06-04 23:06:18.589124: case_990, shape torch.Size([1, 80, 242, 242]), rank 0 
2025-06-04 23:06:21.067175: predicting case_995 
2025-06-04 23:06:21.131565: case_995, shape torch.Size([1, 80, 235, 235]), rank 0 
2025-06-04 23:06:54.605064: Validation complete 
2025-06-04 23:06:54.619854: Mean Validation Dice:  0.7614428404251276 
