
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2025-06-03 10:47:12.294037: do_dummy_2d_data_aug: True 
2025-06-03 10:47:12.305110: Creating new 5-fold cross-validation split... 
2025-06-03 10:47:12.344397: Desired fold for training: 0 
2025-06-03 10:47:12.356956: This split has 960 training and 240 validation cases. 

This is the configuration used by this training:
Configuration name: 3d_fullres
 {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [56, 192, 192], 'median_image_size_in_voxels': [80.0, 256.0, 256.0], 'spacing': [2.0, 0.7031000256538391, 0.7031000256538391], 'normalization_schemes': ['ZScoreNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[1, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [1, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': False} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset112', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [2.0, 0.7031000256538391, 0.7031000256538391], 'original_median_shape_after_transp': [80, 256, 256], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 23.653905868530273, 'mean': 4.020004749298096, 'median': 3.5714452266693115, 'min': -1.6504470109939575, 'percentile_00_5': -0.011717911809682846, 'percentile_99_5': 12.634408016204816, 'std': 2.412421941757202}}} 
 
2025-06-03 10:48:19.588773: Unable to plot network architecture: 
2025-06-03 10:48:19.600240: No module named 'hiddenlayer' 
2025-06-03 10:48:19.656505:  
2025-06-03 10:48:19.671429: Epoch 0 
2025-06-03 10:48:19.685871: Current learning rate: 0.01 
2025-06-03 10:50:00.818850: train_loss -0.2022 
2025-06-03 10:50:01.092211: val_loss -0.3428 
2025-06-03 10:50:01.971189: Pseudo dice [np.float32(0.4501)] 
2025-06-03 10:50:02.179975: Epoch time: 101.16 s 
2025-06-03 10:50:02.327317: Yayy! New best EMA pseudo Dice: 0.45010000467300415 
2025-06-03 10:50:03.969744:  
2025-06-03 10:50:03.981573: Epoch 1 
2025-06-03 10:50:03.993898: Current learning rate: 0.00999 
2025-06-03 10:51:43.011063: train_loss -0.4063 
2025-06-03 10:51:43.325796: val_loss -0.4085 
2025-06-03 10:51:43.604374: Pseudo dice [np.float32(0.4677)] 
2025-06-03 10:51:44.050684: Epoch time: 99.04 s 
2025-06-03 10:51:44.071592: Yayy! New best EMA pseudo Dice: 0.45190000534057617 
2025-06-03 10:51:45.750732:  
2025-06-03 10:51:45.763287: Epoch 2 
2025-06-03 10:51:45.772640: Current learning rate: 0.00998 
2025-06-03 10:53:25.048962: train_loss -0.3908 
2025-06-03 10:53:25.063999: val_loss -0.3208 
2025-06-03 10:53:25.077099: Pseudo dice [np.float32(0.3153)] 
2025-06-03 10:53:25.089824: Epoch time: 99.3 s 
2025-06-03 10:53:27.654145:  
2025-06-03 10:53:27.667416: Epoch 3 
2025-06-03 10:53:27.681153: Current learning rate: 0.00997 
2025-06-03 10:55:06.638867: train_loss -0.4456 
2025-06-03 10:55:06.654842: val_loss -0.4728 
2025-06-03 10:55:06.668114: Pseudo dice [np.float32(0.4747)] 
2025-06-03 10:55:06.680317: Epoch time: 98.99 s 
2025-06-03 10:55:09.014462:  
2025-06-03 10:55:09.032007: Epoch 4 
2025-06-03 10:55:09.046493: Current learning rate: 0.00996 
2025-06-03 10:56:44.858020: train_loss -0.4363 
2025-06-03 10:56:44.874849: val_loss -0.4304 
2025-06-03 10:56:44.887103: Pseudo dice [np.float32(0.4302)] 
2025-06-03 10:56:44.897817: Epoch time: 95.85 s 
2025-06-03 10:56:47.302104:  
2025-06-03 10:56:47.314534: Epoch 5 
2025-06-03 10:56:47.328575: Current learning rate: 0.00995 
2025-06-03 10:58:25.443796: train_loss -0.4847 
2025-06-03 10:58:25.460629: val_loss -0.4954 
2025-06-03 10:58:25.473408: Pseudo dice [np.float32(0.5151)] 
2025-06-03 10:58:25.485256: Epoch time: 98.14 s 
2025-06-03 10:58:27.728776:  
2025-06-03 10:58:27.747204: Epoch 6 
2025-06-03 10:58:27.761502: Current learning rate: 0.00995 
2025-06-03 11:00:07.461577: train_loss -0.4771 
2025-06-03 11:00:07.478472: val_loss -0.441 
2025-06-03 11:00:07.490794: Pseudo dice [np.float32(0.4458)] 
2025-06-03 11:00:07.503218: Epoch time: 99.73 s 
2025-06-03 11:00:10.006489:  
2025-06-03 11:00:10.024400: Epoch 7 
2025-06-03 11:00:10.036541: Current learning rate: 0.00994 
2025-06-03 11:01:48.482931: train_loss -0.4812 
2025-06-03 11:01:48.500634: val_loss -0.4824 
2025-06-03 11:01:48.513106: Pseudo dice [np.float32(0.4749)] 
2025-06-03 11:01:48.525372: Epoch time: 98.48 s 
2025-06-03 11:01:50.672991:  
2025-06-03 11:01:50.685357: Epoch 8 
2025-06-03 11:01:50.696165: Current learning rate: 0.00993 
2025-06-03 11:03:28.570400: train_loss -0.5058 
2025-06-03 11:03:28.934598: val_loss -0.4823 
2025-06-03 11:03:29.309693: Pseudo dice [np.float32(0.5176)] 
2025-06-03 11:03:29.709155: Epoch time: 97.9 s 
2025-06-03 11:03:29.724646: Yayy! New best EMA pseudo Dice: 0.45730000734329224 
2025-06-03 11:03:32.719493:  
2025-06-03 11:03:32.730813: Epoch 9 
2025-06-03 11:03:32.740574: Current learning rate: 0.00992 
2025-06-03 11:05:10.363504: train_loss -0.5136 
2025-06-03 11:05:10.381133: val_loss -0.4708 
2025-06-03 11:05:10.394097: Pseudo dice [np.float32(0.4641)] 
2025-06-03 11:05:10.406337: Epoch time: 97.65 s 
2025-06-03 11:05:10.418600: Yayy! New best EMA pseudo Dice: 0.4580000042915344 
2025-06-03 11:05:13.612172:  
2025-06-03 11:05:13.624498: Epoch 10 
2025-06-03 11:05:13.635302: Current learning rate: 0.00991 
2025-06-03 11:06:49.348173: train_loss -0.4885 
2025-06-03 11:06:49.375328: val_loss -0.4474 
2025-06-03 11:06:49.393778: Pseudo dice [np.float32(0.3952)] 
2025-06-03 11:06:49.406044: Epoch time: 95.74 s 
2025-06-03 11:06:51.947037:  
2025-06-03 11:06:51.958711: Epoch 11 
2025-06-03 11:06:51.973511: Current learning rate: 0.0099 
2025-06-03 11:08:30.949225: train_loss -0.4757 
2025-06-03 11:08:30.965997: val_loss -0.4898 
2025-06-03 11:08:30.978550: Pseudo dice [np.float32(0.565)] 
2025-06-03 11:08:30.990398: Epoch time: 99.0 s 
2025-06-03 11:08:31.003232: Yayy! New best EMA pseudo Dice: 0.46299999952316284 
2025-06-03 11:08:33.960022:  
2025-06-03 11:08:33.973276: Epoch 12 
2025-06-03 11:08:33.983617: Current learning rate: 0.00989 
2025-06-03 11:10:11.912147: train_loss -0.4982 
2025-06-03 11:10:12.236821: val_loss -0.4905 
2025-06-03 11:10:12.252124: Pseudo dice [np.float32(0.4335)] 
2025-06-03 11:10:12.263997: Epoch time: 97.96 s 
2025-06-03 11:10:14.711835:  
2025-06-03 11:10:14.726044: Epoch 13 
2025-06-03 11:10:14.741013: Current learning rate: 0.00988 
2025-06-03 11:11:53.638663: train_loss -0.5243 
2025-06-03 11:11:53.655192: val_loss -0.5122 
2025-06-03 11:11:53.667542: Pseudo dice [np.float32(0.5441)] 
2025-06-03 11:11:54.029486: Epoch time: 98.93 s 
2025-06-03 11:11:54.396933: Yayy! New best EMA pseudo Dice: 0.4684999883174896 
2025-06-03 11:11:57.330011:  
2025-06-03 11:11:57.348587: Epoch 14 
2025-06-03 11:11:57.359390: Current learning rate: 0.00987 
2025-06-03 11:13:36.915348: train_loss -0.5315 
2025-06-03 11:13:37.242426: val_loss -0.4684 
2025-06-03 11:13:37.647229: Pseudo dice [np.float32(0.4318)] 
2025-06-03 11:13:38.070259: Epoch time: 99.59 s 
2025-06-03 11:13:39.819713:  
2025-06-03 11:13:39.838665: Epoch 15 
2025-06-03 11:13:39.852874: Current learning rate: 0.00986 
2025-06-03 11:15:16.532768: train_loss -0.5279 
2025-06-03 11:15:16.549207: val_loss -0.4952 
2025-06-03 11:15:16.562008: Pseudo dice [np.float32(0.5239)] 
2025-06-03 11:15:16.575135: Epoch time: 96.71 s 
2025-06-03 11:15:16.587688: Yayy! New best EMA pseudo Dice: 0.4706999957561493 
2025-06-03 11:15:19.494618:  
2025-06-03 11:15:19.507120: Epoch 16 
2025-06-03 11:15:19.515921: Current learning rate: 0.00986 
2025-06-03 11:16:58.035476: train_loss -0.5177 
2025-06-03 11:16:58.340065: val_loss -0.5502 
2025-06-03 11:16:58.673553: Pseudo dice [np.float32(0.5297)] 
2025-06-03 11:16:59.016779: Epoch time: 98.54 s 
2025-06-03 11:16:59.371578: Yayy! New best EMA pseudo Dice: 0.4765999913215637 
2025-06-03 11:17:01.910529:  
2025-06-03 11:17:01.922987: Epoch 17 
2025-06-03 11:17:01.934127: Current learning rate: 0.00985 
2025-06-03 11:18:38.755648: train_loss -0.5404 
2025-06-03 11:18:38.771977: val_loss -0.5302 
2025-06-03 11:18:38.785727: Pseudo dice [np.float32(0.5225)] 
2025-06-03 11:18:38.798468: Epoch time: 96.85 s 
2025-06-03 11:18:38.810706: Yayy! New best EMA pseudo Dice: 0.4812000095844269 
2025-06-03 11:18:41.921020:  
2025-06-03 11:18:41.940415: Epoch 18 
2025-06-03 11:18:41.954657: Current learning rate: 0.00984 
2025-06-03 11:20:21.662923: train_loss -0.5344 
2025-06-03 11:20:21.680323: val_loss -0.4911 
2025-06-03 11:20:21.739147: Pseudo dice [np.float32(0.4627)] 
2025-06-03 11:20:22.002025: Epoch time: 99.74 s 
2025-06-03 11:20:24.471286:  
2025-06-03 11:20:24.482918: Epoch 19 
2025-06-03 11:20:24.492898: Current learning rate: 0.00983 
2025-06-03 11:22:03.744743: train_loss -0.5529 
2025-06-03 11:22:03.766075: val_loss -0.5647 
2025-06-03 11:22:03.778479: Pseudo dice [np.float32(0.5779)] 
2025-06-03 11:22:03.791390: Epoch time: 99.27 s 
2025-06-03 11:22:03.803367: Yayy! New best EMA pseudo Dice: 0.48919999599456787 
2025-06-03 11:22:07.035726:  
2025-06-03 11:22:07.050351: Epoch 20 
2025-06-03 11:22:07.061345: Current learning rate: 0.00982 
2025-06-03 11:23:43.853004: train_loss -0.566 
2025-06-03 11:23:43.870575: val_loss -0.5304 
2025-06-03 11:23:43.883655: Pseudo dice [np.float32(0.5744)] 
2025-06-03 11:23:43.899415: Epoch time: 96.82 s 
2025-06-03 11:23:43.912648: Yayy! New best EMA pseudo Dice: 0.4977000057697296 
2025-06-03 11:23:46.435442:  
2025-06-03 11:23:46.448304: Epoch 21 
2025-06-03 11:23:46.458602: Current learning rate: 0.00981 
2025-06-03 11:25:20.913832: train_loss -0.5706 
2025-06-03 11:25:21.241591: val_loss -0.5234 
2025-06-03 11:25:21.486757: Pseudo dice [np.float32(0.5265)] 
2025-06-03 11:25:21.792790: Epoch time: 94.48 s 
2025-06-03 11:25:21.956879: Yayy! New best EMA pseudo Dice: 0.5005999803543091 
2025-06-03 11:25:23.680522:  
2025-06-03 11:25:23.694391: Epoch 22 
2025-06-03 11:25:23.703735: Current learning rate: 0.0098 
2025-06-03 11:27:03.439814: train_loss -0.5354 
2025-06-03 11:27:03.773030: val_loss -0.5501 
2025-06-03 11:27:04.126324: Pseudo dice [np.float32(0.493)] 
2025-06-03 11:27:04.460406: Epoch time: 99.76 s 
2025-06-03 11:27:05.886229:  
2025-06-03 11:27:05.902047: Epoch 23 
2025-06-03 11:27:05.914288: Current learning rate: 0.00979 
2025-06-03 11:28:43.635970: train_loss -0.5398 
2025-06-03 11:28:43.654953: val_loss -0.5299 
2025-06-03 11:28:43.669253: Pseudo dice [np.float32(0.4543)] 
2025-06-03 11:28:43.684142: Epoch time: 97.75 s 
2025-06-03 11:28:46.907717:  
2025-06-03 11:28:46.921522: Epoch 24 
2025-06-03 11:28:46.932402: Current learning rate: 0.00978 
2025-06-03 11:30:25.043770: train_loss -0.5702 
2025-06-03 11:30:25.217175: val_loss -0.5473 
2025-06-03 11:30:25.544387: Pseudo dice [np.float32(0.5747)] 
2025-06-03 11:30:25.873701: Epoch time: 98.14 s 
2025-06-03 11:30:26.198475: Yayy! New best EMA pseudo Dice: 0.5031999945640564 
2025-06-03 11:30:27.973657:  
2025-06-03 11:30:27.990817: Epoch 25 
2025-06-03 11:30:28.005897: Current learning rate: 0.00977 
2025-06-03 11:32:06.849468: train_loss -0.5385 
2025-06-03 11:32:06.868099: val_loss -0.6171 
2025-06-03 11:32:06.880657: Pseudo dice [np.float32(0.6744)] 
2025-06-03 11:32:06.893208: Epoch time: 98.88 s 
2025-06-03 11:32:06.906365: Yayy! New best EMA pseudo Dice: 0.5202999711036682 
2025-06-03 11:32:09.863307:  
2025-06-03 11:32:09.875386: Epoch 26 
2025-06-03 11:32:09.885851: Current learning rate: 0.00977 
2025-06-03 11:33:45.314033: train_loss -0.5659 
2025-06-03 11:33:45.337464: val_loss -0.5239 
2025-06-03 11:33:45.356353: Pseudo dice [np.float32(0.5653)] 
2025-06-03 11:33:45.369098: Epoch time: 95.45 s 
2025-06-03 11:33:45.381852: Yayy! New best EMA pseudo Dice: 0.5248000025749207 
2025-06-03 11:33:48.038176:  
2025-06-03 11:33:48.053645: Epoch 27 
2025-06-03 11:33:48.065490: Current learning rate: 0.00976 
2025-06-03 11:35:26.081343: train_loss -0.5457 
2025-06-03 11:35:26.390343: val_loss -0.5118 
2025-06-03 11:35:26.582290: Pseudo dice [np.float32(0.5469)] 
2025-06-03 11:35:26.598302: Epoch time: 98.04 s 
2025-06-03 11:35:26.613192: Yayy! New best EMA pseudo Dice: 0.5270000100135803 
2025-06-03 11:35:28.758524:  
2025-06-03 11:35:28.777880: Epoch 28 
2025-06-03 11:35:28.786740: Current learning rate: 0.00975 
2025-06-03 11:37:07.499597: train_loss -0.6017 
2025-06-03 11:37:07.522106: val_loss -0.5648 
2025-06-03 11:37:07.540156: Pseudo dice [np.float32(0.5753)] 
2025-06-03 11:37:07.553053: Epoch time: 98.74 s 
2025-06-03 11:37:07.566956: Yayy! New best EMA pseudo Dice: 0.5318999886512756 
2025-06-03 11:37:10.712964:  
2025-06-03 11:37:10.726526: Epoch 29 
2025-06-03 11:37:10.739344: Current learning rate: 0.00974 
2025-06-03 11:38:46.268208: train_loss -0.5733 
2025-06-03 11:38:46.579342: val_loss -0.5314 
2025-06-03 11:38:46.883892: Pseudo dice [np.float32(0.5787)] 
2025-06-03 11:38:47.179530: Epoch time: 95.56 s 
2025-06-03 11:38:47.459352: Yayy! New best EMA pseudo Dice: 0.5364999771118164 
2025-06-03 11:38:49.620920:  
2025-06-03 11:38:49.634555: Epoch 30 
2025-06-03 11:38:49.645046: Current learning rate: 0.00973 
2025-06-03 11:40:27.409649: train_loss -0.5502 
2025-06-03 11:40:27.428601: val_loss -0.4526 
2025-06-03 11:40:27.441377: Pseudo dice [np.float32(0.4974)] 
2025-06-03 11:40:27.453742: Epoch time: 97.79 s 
2025-06-03 11:40:29.795999:  
2025-06-03 11:40:29.813248: Epoch 31 
2025-06-03 11:40:29.830385: Current learning rate: 0.00972 
2025-06-03 11:42:08.823089: train_loss -0.559 
2025-06-03 11:42:08.933361: val_loss -0.5524 
2025-06-03 11:42:09.233985: Pseudo dice [np.float32(0.541)] 
2025-06-03 11:42:09.458196: Epoch time: 99.03 s 
2025-06-03 11:42:11.205786:  
2025-06-03 11:42:11.224558: Epoch 32 
2025-06-03 11:42:11.234467: Current learning rate: 0.00971 
2025-06-03 11:43:47.605498: train_loss -0.5619 
2025-06-03 11:43:47.774542: val_loss -0.5754 
2025-06-03 11:43:48.006356: Pseudo dice [np.float32(0.6193)] 
2025-06-03 11:43:48.271684: Epoch time: 96.4 s 
2025-06-03 11:43:48.508612: Yayy! New best EMA pseudo Dice: 0.5421000123023987 
2025-06-03 11:43:50.650444:  
2025-06-03 11:43:50.670426: Epoch 33 
2025-06-03 11:43:50.687592: Current learning rate: 0.0097 
2025-06-03 11:45:28.027596: train_loss -0.5903 
2025-06-03 11:45:28.045378: val_loss -0.5719 
2025-06-03 11:45:28.058585: Pseudo dice [np.float32(0.5757)] 
2025-06-03 11:45:28.072783: Epoch time: 97.38 s 
2025-06-03 11:45:28.085173: Yayy! New best EMA pseudo Dice: 0.5454000234603882 
2025-06-03 11:45:31.236488:  
2025-06-03 11:45:31.247517: Epoch 34 
2025-06-03 11:45:31.260593: Current learning rate: 0.00969 
2025-06-03 11:47:09.038538: train_loss -0.6044 
2025-06-03 11:47:09.152184: val_loss -0.5179 
2025-06-03 11:47:09.360068: Pseudo dice [np.float32(0.5715)] 
2025-06-03 11:47:09.376685: Epoch time: 97.8 s 
2025-06-03 11:47:09.392329: Yayy! New best EMA pseudo Dice: 0.5479999780654907 
2025-06-03 11:47:12.160758:  
2025-06-03 11:47:12.177540: Epoch 35 
2025-06-03 11:47:12.188752: Current learning rate: 0.00968 
2025-06-03 11:48:48.016708: train_loss -0.5926 
2025-06-03 11:48:48.036072: val_loss -0.6124 
2025-06-03 11:48:48.050884: Pseudo dice [np.float32(0.6723)] 
2025-06-03 11:48:48.063646: Epoch time: 95.86 s 
2025-06-03 11:48:48.077430: Yayy! New best EMA pseudo Dice: 0.5605000257492065 
2025-06-03 11:48:50.414026:  
2025-06-03 11:48:50.427665: Epoch 36 
2025-06-03 11:48:50.438035: Current learning rate: 0.00968 
2025-06-03 11:50:29.515119: train_loss -0.5849 
2025-06-03 11:50:29.762923: val_loss -0.534 
2025-06-03 11:50:30.055825: Pseudo dice [np.float32(0.5401)] 
2025-06-03 11:50:30.332063: Epoch time: 99.1 s 
2025-06-03 11:50:31.921899:  
2025-06-03 11:50:31.940727: Epoch 37 
2025-06-03 11:50:31.954502: Current learning rate: 0.00967 
2025-06-03 11:52:11.458294: train_loss -0.5754 
2025-06-03 11:52:11.481259: val_loss -0.5975 
2025-06-03 11:52:11.496243: Pseudo dice [np.float32(0.6578)] 
2025-06-03 11:52:11.511161: Epoch time: 99.54 s 
2025-06-03 11:52:11.526172: Yayy! New best EMA pseudo Dice: 0.5684000253677368 
2025-06-03 11:52:14.652290:  
2025-06-03 11:52:14.667569: Epoch 38 
2025-06-03 11:52:14.679482: Current learning rate: 0.00966 
2025-06-03 11:53:51.839560: train_loss -0.5827 
2025-06-03 11:53:51.857468: val_loss -0.5401 
2025-06-03 11:53:51.870786: Pseudo dice [np.float32(0.5545)] 
2025-06-03 11:53:51.883588: Epoch time: 97.19 s 
2025-06-03 11:53:54.123762:  
2025-06-03 11:53:54.138632: Epoch 39 
2025-06-03 11:53:54.151429: Current learning rate: 0.00965 
2025-06-03 11:55:30.464162: train_loss -0.5779 
2025-06-03 11:55:30.581544: val_loss -0.5496 
2025-06-03 11:55:30.597867: Pseudo dice [np.float32(0.5418)] 
2025-06-03 11:55:30.612069: Epoch time: 96.34 s 
2025-06-03 11:55:33.348726:  
2025-06-03 11:55:33.362048: Epoch 40 
2025-06-03 11:55:33.377354: Current learning rate: 0.00964 
2025-06-03 11:57:13.479984: train_loss -0.6104 
2025-06-03 11:57:13.760991: val_loss -0.5875 
2025-06-03 11:57:14.193313: Pseudo dice [np.float32(0.5659)] 
2025-06-03 11:57:14.419845: Epoch time: 100.13 s 
2025-06-03 11:57:16.278428:  
2025-06-03 11:57:16.292226: Epoch 41 
2025-06-03 11:57:16.305002: Current learning rate: 0.00963 
2025-06-03 11:58:53.503536: train_loss -0.5621 
2025-06-03 11:58:53.527028: val_loss -0.5696 
2025-06-03 11:58:53.541749: Pseudo dice [np.float32(0.5959)] 
2025-06-03 11:58:53.555581: Epoch time: 97.23 s 
2025-06-03 11:58:56.189648:  
2025-06-03 11:58:56.206297: Epoch 42 
2025-06-03 11:58:56.222464: Current learning rate: 0.00962 
2025-06-03 12:00:30.664723: train_loss -0.5987 
2025-06-03 12:00:30.683733: val_loss -0.5859 
2025-06-03 12:00:30.697950: Pseudo dice [np.float32(0.5411)] 
2025-06-03 12:00:30.711538: Epoch time: 94.48 s 
2025-06-03 12:00:33.464233:  
2025-06-03 12:00:33.481176: Epoch 43 
2025-06-03 12:00:33.492433: Current learning rate: 0.00961 
2025-06-03 12:02:10.787710: train_loss -0.584 
2025-06-03 12:02:10.805678: val_loss -0.5653 
2025-06-03 12:02:10.818671: Pseudo dice [np.float32(0.5819)] 
2025-06-03 12:02:10.831950: Epoch time: 97.33 s 
2025-06-03 12:02:13.537021:  
2025-06-03 12:02:13.549984: Epoch 44 
2025-06-03 12:02:13.566311: Current learning rate: 0.0096 
2025-06-03 12:03:50.410064: train_loss -0.5794 
2025-06-03 12:03:50.648164: val_loss -0.58 
2025-06-03 12:03:50.993779: Pseudo dice [np.float32(0.5961)] 
2025-06-03 12:03:51.290249: Epoch time: 96.87 s 
2025-06-03 12:03:51.553189: Yayy! New best EMA pseudo Dice: 0.5697000026702881 
2025-06-03 12:03:53.928891:  
2025-06-03 12:03:53.943147: Epoch 45 
2025-06-03 12:03:53.953564: Current learning rate: 0.00959 
2025-06-03 12:05:30.715179: train_loss -0.5805 
2025-06-03 12:05:30.917077: val_loss -0.5599 
2025-06-03 12:05:31.208504: Pseudo dice [np.float32(0.5617)] 
2025-06-03 12:05:31.327983: Epoch time: 96.79 s 
2025-06-03 12:05:33.157282:  
2025-06-03 12:05:33.169492: Epoch 46 
2025-06-03 12:05:33.182739: Current learning rate: 0.00959 
2025-06-03 12:07:10.724698: train_loss -0.6244 
2025-06-03 12:07:10.939618: val_loss -0.6067 
2025-06-03 12:07:11.126638: Pseudo dice [np.float32(0.6023)] 
2025-06-03 12:07:11.396801: Epoch time: 97.57 s 
2025-06-03 12:07:11.675613: Yayy! New best EMA pseudo Dice: 0.5722000002861023 
2025-06-03 12:07:13.969642:  
2025-06-03 12:07:13.983209: Epoch 47 
2025-06-03 12:07:13.996792: Current learning rate: 0.00958 
2025-06-03 12:08:50.449894: train_loss -0.5666 
2025-06-03 12:08:50.465384: val_loss -0.6159 
2025-06-03 12:08:50.479097: Pseudo dice [np.float32(0.657)] 
2025-06-03 12:08:50.492290: Epoch time: 96.48 s 
2025-06-03 12:08:50.505002: Yayy! New best EMA pseudo Dice: 0.5806999802589417 
2025-06-03 12:08:52.769080:  
2025-06-03 12:08:52.780941: Epoch 48 
2025-06-03 12:08:52.792311: Current learning rate: 0.00957 
2025-06-03 12:10:20.351124: train_loss -0.631 
2025-06-03 12:10:20.393479: val_loss -0.562 
2025-06-03 12:10:20.431550: Pseudo dice [np.float32(0.5293)] 
2025-06-03 12:10:20.461211: Epoch time: 87.58 s 
2025-06-03 12:10:21.816348:  
2025-06-03 12:10:21.829560: Epoch 49 
2025-06-03 12:10:21.840469: Current learning rate: 0.00956 
2025-06-03 12:11:44.477420: train_loss -0.5757 
2025-06-03 12:11:44.656905: val_loss -0.6116 
2025-06-03 12:11:44.838259: Pseudo dice [np.float32(0.6664)] 
2025-06-03 12:11:45.062231: Epoch time: 82.66 s 
2025-06-03 12:11:45.900873: Yayy! New best EMA pseudo Dice: 0.5845999717712402 
2025-06-03 12:11:47.483635:  
2025-06-03 12:11:47.495717: Epoch 50 
2025-06-03 12:11:47.504788: Current learning rate: 0.00955 
2025-06-03 12:13:25.788841: train_loss -0.571 
2025-06-03 12:13:26.034500: val_loss -0.5167 
2025-06-03 12:13:26.049286: Pseudo dice [np.float32(0.4313)] 
2025-06-03 12:13:26.062032: Epoch time: 98.31 s 
2025-06-03 12:13:28.548638:  
2025-06-03 12:13:28.562166: Epoch 51 
2025-06-03 12:13:28.572997: Current learning rate: 0.00954 
2025-06-03 12:15:05.659394: train_loss -0.5813 
2025-06-03 12:15:05.676130: val_loss -0.5363 
2025-06-03 12:15:05.691394: Pseudo dice [np.float32(0.5924)] 
2025-06-03 12:15:05.706704: Epoch time: 97.11 s 
2025-06-03 12:15:08.349410:  
2025-06-03 12:15:08.367453: Epoch 52 
2025-06-03 12:15:08.380394: Current learning rate: 0.00953 
2025-06-03 12:16:43.690643: train_loss -0.5838 
2025-06-03 12:16:43.709531: val_loss -0.5733 
2025-06-03 12:16:43.723294: Pseudo dice [np.float32(0.6214)] 
2025-06-03 12:16:43.737198: Epoch time: 95.34 s 
2025-06-03 12:16:46.873929:  
2025-06-03 12:16:46.886729: Epoch 53 
2025-06-03 12:16:46.897483: Current learning rate: 0.00952 
2025-06-03 12:18:22.933857: train_loss -0.5954 
2025-06-03 12:18:23.219244: val_loss -0.5893 
2025-06-03 12:18:23.435812: Pseudo dice [np.float32(0.5757)] 
2025-06-03 12:18:23.712244: Epoch time: 96.06 s 
2025-06-03 12:18:25.560864:  
2025-06-03 12:18:25.574780: Epoch 54 
2025-06-03 12:18:25.591744: Current learning rate: 0.00951 
2025-06-03 12:20:03.280031: train_loss -0.6287 
2025-06-03 12:20:03.589061: val_loss -0.5376 
2025-06-03 12:20:03.904310: Pseudo dice [np.float32(0.4993)] 
2025-06-03 12:20:04.069374: Epoch time: 97.72 s 
2025-06-03 12:20:06.148434:  
2025-06-03 12:20:06.166614: Epoch 55 
2025-06-03 12:20:06.179014: Current learning rate: 0.0095 
2025-06-03 12:21:42.254651: train_loss -0.6024 
2025-06-03 12:21:42.476006: val_loss -0.6003 
2025-06-03 12:21:42.815819: Pseudo dice [np.float32(0.6456)] 
2025-06-03 12:21:43.171823: Epoch time: 96.11 s 
2025-06-03 12:21:45.265725:  
2025-06-03 12:21:45.279486: Epoch 56 
2025-06-03 12:21:45.296300: Current learning rate: 0.00949 
2025-06-03 12:23:24.564734: train_loss -0.6087 
2025-06-03 12:23:24.583361: val_loss -0.5209 
2025-06-03 12:23:24.597847: Pseudo dice [np.float32(0.6127)] 
2025-06-03 12:23:24.613196: Epoch time: 99.3 s 
2025-06-03 12:23:27.516363:  
2025-06-03 12:23:27.528921: Epoch 57 
2025-06-03 12:23:27.545716: Current learning rate: 0.00949 
2025-06-03 12:25:04.302661: train_loss -0.6121 
2025-06-03 12:25:04.321950: val_loss -0.649 
2025-06-03 12:25:04.335643: Pseudo dice [np.float32(0.6799)] 
2025-06-03 12:25:04.349913: Epoch time: 96.79 s 
2025-06-03 12:25:04.363696: Yayy! New best EMA pseudo Dice: 0.5900999903678894 
2025-06-03 12:25:06.977156:  
2025-06-03 12:25:06.991467: Epoch 58 
2025-06-03 12:25:07.008189: Current learning rate: 0.00948 
2025-06-03 12:26:43.003999: train_loss -0.6009 
2025-06-03 12:26:43.023455: val_loss -0.6207 
2025-06-03 12:26:43.037512: Pseudo dice [np.float32(0.6947)] 
2025-06-03 12:26:43.052631: Epoch time: 96.03 s 
2025-06-03 12:26:43.067750: Yayy! New best EMA pseudo Dice: 0.6004999876022339 
2025-06-03 12:26:46.530350:  
2025-06-03 12:26:46.544873: Epoch 59 
2025-06-03 12:26:46.557413: Current learning rate: 0.00947 
2025-06-03 12:28:21.689758: train_loss -0.6066 
2025-06-03 12:28:21.708031: val_loss -0.5446 
2025-06-03 12:28:21.898196: Pseudo dice [np.float32(0.585)] 
2025-06-03 12:28:21.915109: Epoch time: 95.16 s 
2025-06-03 12:28:24.071854:  
2025-06-03 12:28:24.092875: Epoch 60 
2025-06-03 12:28:24.104285: Current learning rate: 0.00946 
2025-06-03 12:30:02.927627: train_loss -0.5968 
2025-06-03 12:30:02.946883: val_loss -0.5693 
2025-06-03 12:30:02.959359: Pseudo dice [np.float32(0.6034)] 
2025-06-03 12:30:02.971199: Epoch time: 98.86 s 
2025-06-03 12:30:05.798476:  
2025-06-03 12:30:05.815674: Epoch 61 
2025-06-03 12:30:05.828663: Current learning rate: 0.00945 
2025-06-03 12:31:29.681088: train_loss -0.5971 
2025-06-03 12:31:29.723979: val_loss -0.6948 
2025-06-03 12:31:29.769874: Pseudo dice [np.float32(0.7376)] 
2025-06-03 12:31:29.801442: Epoch time: 83.88 s 
2025-06-03 12:31:29.823593: Yayy! New best EMA pseudo Dice: 0.6132000088691711 
2025-06-03 12:31:31.585597:  
2025-06-03 12:31:31.606718: Epoch 62 
2025-06-03 12:31:31.625072: Current learning rate: 0.00944 
2025-06-03 12:32:55.027648: train_loss -0.5766 
2025-06-03 12:32:55.070641: val_loss -0.5646 
2025-06-03 12:32:55.099301: Pseudo dice [np.float32(0.5763)] 
2025-06-03 12:32:55.130805: Epoch time: 83.44 s 
2025-06-03 12:32:56.470137:  
2025-06-03 12:32:56.485234: Epoch 63 
2025-06-03 12:32:56.497234: Current learning rate: 0.00943 
2025-06-03 12:34:19.076064: train_loss -0.618 
2025-06-03 12:34:19.096749: val_loss -0.5892 
2025-06-03 12:34:19.113136: Pseudo dice [np.float32(0.5854)] 
2025-06-03 12:34:19.128987: Epoch time: 82.61 s 
2025-06-03 12:34:21.391186:  
2025-06-03 12:34:21.411979: Epoch 64 
2025-06-03 12:34:21.427666: Current learning rate: 0.00942 
2025-06-03 12:35:58.925466: train_loss -0.6145 
2025-06-03 12:35:59.179426: val_loss -0.616 
2025-06-03 12:35:59.513425: Pseudo dice [np.float32(0.613)] 
2025-06-03 12:35:59.901134: Epoch time: 97.54 s 
2025-06-03 12:36:02.175999:  
2025-06-03 12:36:02.190457: Epoch 65 
2025-06-03 12:36:02.201751: Current learning rate: 0.00941 
2025-06-03 12:37:40.659131: train_loss -0.602 
2025-06-03 12:37:40.678523: val_loss -0.6122 
2025-06-03 12:37:40.693830: Pseudo dice [np.float32(0.6694)] 
2025-06-03 12:37:40.708612: Epoch time: 98.48 s 
2025-06-03 12:37:40.721915: Yayy! New best EMA pseudo Dice: 0.6139000058174133 
2025-06-03 12:37:43.345147:  
2025-06-03 12:37:43.359937: Epoch 66 
2025-06-03 12:37:43.370289: Current learning rate: 0.0094 
2025-06-03 12:39:22.030241: train_loss -0.5849 
2025-06-03 12:39:22.050350: val_loss -0.6155 
2025-06-03 12:39:22.064428: Pseudo dice [np.float32(0.6094)] 
2025-06-03 12:39:22.079370: Epoch time: 98.69 s 
2025-06-03 12:39:25.337616:  
2025-06-03 12:39:25.352199: Epoch 67 
2025-06-03 12:39:25.365068: Current learning rate: 0.00939 
2025-06-03 12:41:04.119370: train_loss -0.623 
2025-06-03 12:41:04.137954: val_loss -0.5913 
2025-06-03 12:41:04.153941: Pseudo dice [np.float32(0.5567)] 
2025-06-03 12:41:04.168671: Epoch time: 98.78 s 
2025-06-03 12:41:06.637345:  
2025-06-03 12:41:06.656608: Epoch 68 
2025-06-03 12:41:06.668815: Current learning rate: 0.00939 
2025-06-03 12:42:39.691171: train_loss -0.6235 
2025-06-03 12:42:39.993724: val_loss -0.609 
2025-06-03 12:42:40.344627: Pseudo dice [np.float32(0.645)] 
2025-06-03 12:42:40.590409: Epoch time: 93.06 s 
2025-06-03 12:42:42.084516:  
2025-06-03 12:42:42.103338: Epoch 69 
2025-06-03 12:42:42.119053: Current learning rate: 0.00938 
2025-06-03 12:44:18.908525: train_loss -0.5814 
2025-06-03 12:44:18.992523: val_loss -0.6572 
2025-06-03 12:44:19.007492: Pseudo dice [np.float32(0.7184)] 
2025-06-03 12:44:19.020941: Epoch time: 96.83 s 
2025-06-03 12:44:19.035373: Yayy! New best EMA pseudo Dice: 0.6222000122070312 
2025-06-03 12:44:20.740459:  
2025-06-03 12:44:20.754601: Epoch 70 
2025-06-03 12:44:20.764634: Current learning rate: 0.00937 
2025-06-03 12:45:56.544614: train_loss -0.5807 
2025-06-03 12:45:56.734610: val_loss -0.6242 
2025-06-03 12:45:57.043735: Pseudo dice [np.float32(0.6376)] 
2025-06-03 12:45:57.208709: Epoch time: 95.81 s 
2025-06-03 12:45:57.223624: Yayy! New best EMA pseudo Dice: 0.6237000226974487 
2025-06-03 12:45:59.182885:  
2025-06-03 12:45:59.194746: Epoch 71 
2025-06-03 12:45:59.208568: Current learning rate: 0.00936 
2025-06-03 12:47:35.532170: train_loss -0.63 
2025-06-03 12:47:35.645930: val_loss -0.5903 
2025-06-03 12:47:35.841766: Pseudo dice [np.float32(0.5852)] 
2025-06-03 12:47:36.004971: Epoch time: 96.35 s 
2025-06-03 12:47:37.180694:  
2025-06-03 12:47:37.198776: Epoch 72 
2025-06-03 12:47:37.213849: Current learning rate: 0.00935 
2025-06-03 12:49:13.346689: train_loss -0.6226 
2025-06-03 12:49:13.362500: val_loss -0.5897 
2025-06-03 12:49:13.378315: Pseudo dice [np.float32(0.6304)] 
2025-06-03 12:49:13.391572: Epoch time: 96.17 s 
2025-06-03 12:49:15.198319:  
2025-06-03 12:49:15.211774: Epoch 73 
2025-06-03 12:49:15.223648: Current learning rate: 0.00934 
2025-06-03 12:50:50.754681: train_loss -0.6379 
2025-06-03 12:50:50.885742: val_loss -0.5505 
2025-06-03 12:50:51.128550: Pseudo dice [np.float32(0.5991)] 
2025-06-03 12:50:51.398430: Epoch time: 95.56 s 
2025-06-03 12:50:53.754991:  
2025-06-03 12:50:53.766228: Epoch 74 
2025-06-03 12:50:53.775452: Current learning rate: 0.00933 
2025-06-03 12:52:29.252256: train_loss -0.6261 
2025-06-03 12:52:29.465691: val_loss -0.6322 
2025-06-03 12:52:29.653591: Pseudo dice [np.float32(0.6618)] 
2025-06-03 12:52:29.899462: Epoch time: 95.5 s 
2025-06-03 12:52:32.093114:  
2025-06-03 12:52:32.108465: Epoch 75 
2025-06-03 12:52:32.122868: Current learning rate: 0.00932 
2025-06-03 12:54:08.523637: train_loss -0.6017 
2025-06-03 12:54:08.549307: val_loss -0.5767 
2025-06-03 12:54:08.563797: Pseudo dice [np.float32(0.6136)] 
2025-06-03 12:54:08.578120: Epoch time: 96.43 s 
2025-06-03 12:54:10.506768:  
2025-06-03 12:54:10.521674: Epoch 76 
2025-06-03 12:54:10.532594: Current learning rate: 0.00931 
2025-06-03 12:55:45.831602: train_loss -0.6219 
2025-06-03 12:55:46.099300: val_loss -0.6114 
2025-06-03 12:55:46.354380: Pseudo dice [np.float32(0.6351)] 
2025-06-03 12:55:46.644936: Epoch time: 95.33 s 
2025-06-03 12:55:48.413996:  
2025-06-03 12:55:48.433199: Epoch 77 
2025-06-03 12:55:48.445822: Current learning rate: 0.0093 
2025-06-03 12:57:26.243801: train_loss -0.6404 
2025-06-03 12:57:26.263885: val_loss -0.6034 
2025-06-03 12:57:26.280480: Pseudo dice [np.float32(0.653)] 
2025-06-03 12:57:26.296351: Epoch time: 97.83 s 
2025-06-03 12:57:26.311753: Yayy! New best EMA pseudo Dice: 0.6263999938964844 
2025-06-03 12:57:28.772824:  
2025-06-03 12:57:28.785556: Epoch 78 
2025-06-03 12:57:28.797520: Current learning rate: 0.0093 
2025-06-03 12:59:04.268151: train_loss -0.6417 
2025-06-03 12:59:04.548695: val_loss -0.6421 
2025-06-03 12:59:04.731578: Pseudo dice [np.float32(0.6947)] 
2025-06-03 12:59:04.748954: Epoch time: 95.5 s 
2025-06-03 12:59:04.763220: Yayy! New best EMA pseudo Dice: 0.6331999897956848 
2025-06-03 12:59:08.475844:  
2025-06-03 12:59:08.489644: Epoch 79 
2025-06-03 12:59:08.500041: Current learning rate: 0.00929 
2025-06-03 13:00:44.738501: train_loss -0.6422 
2025-06-03 13:00:44.756502: val_loss -0.6379 
2025-06-03 13:00:44.771843: Pseudo dice [np.float32(0.6279)] 
2025-06-03 13:00:45.057997: Epoch time: 96.26 s 
2025-06-03 13:00:46.999895:  
2025-06-03 13:00:47.012776: Epoch 80 
2025-06-03 13:00:47.024150: Current learning rate: 0.00928 
2025-06-03 13:02:25.115929: train_loss -0.6194 
2025-06-03 13:02:25.314439: val_loss -0.6141 
2025-06-03 13:02:25.544444: Pseudo dice [np.float32(0.629)] 
2025-06-03 13:02:25.754950: Epoch time: 98.12 s 
2025-06-03 13:02:26.982463:  
2025-06-03 13:02:27.002031: Epoch 81 
2025-06-03 13:02:27.017462: Current learning rate: 0.00927 
2025-06-03 13:04:03.463969: train_loss -0.6085 
2025-06-03 13:04:03.639956: val_loss -0.6269 
2025-06-03 13:04:03.782390: Pseudo dice [np.float32(0.6546)] 
2025-06-03 13:04:03.797267: Epoch time: 96.48 s 
2025-06-03 13:04:03.810510: Yayy! New best EMA pseudo Dice: 0.6345000267028809 
2025-06-03 13:04:05.711774:  
2025-06-03 13:04:05.725812: Epoch 82 
2025-06-03 13:04:05.737700: Current learning rate: 0.00926 
2025-06-03 13:05:41.833980: train_loss -0.6191 
2025-06-03 13:05:42.030354: val_loss -0.5442 
2025-06-03 13:05:42.236713: Pseudo dice [np.float32(0.5847)] 
2025-06-03 13:05:42.484634: Epoch time: 96.12 s 
2025-06-03 13:05:44.426376:  
2025-06-03 13:05:44.444804: Epoch 83 
2025-06-03 13:05:44.457845: Current learning rate: 0.00925 
2025-06-03 13:07:20.790342: train_loss -0.6254 
2025-06-03 13:07:21.082442: val_loss -0.5991 
2025-06-03 13:07:21.330755: Pseudo dice [np.float32(0.6189)] 
2025-06-03 13:07:21.591520: Epoch time: 96.36 s 
2025-06-03 13:07:23.190596:  
2025-06-03 13:07:23.208520: Epoch 84 
2025-06-03 13:07:23.218655: Current learning rate: 0.00924 
2025-06-03 13:08:58.874221: train_loss -0.6246 
2025-06-03 13:08:58.895329: val_loss -0.6375 
2025-06-03 13:08:58.912686: Pseudo dice [np.float32(0.7201)] 
2025-06-03 13:08:58.927177: Epoch time: 95.68 s 
2025-06-03 13:08:58.943521: Yayy! New best EMA pseudo Dice: 0.6376000046730042 
2025-06-03 13:09:01.552839:  
2025-06-03 13:09:01.573246: Epoch 85 
2025-06-03 13:09:01.585943: Current learning rate: 0.00923 
2025-06-03 13:10:39.212848: train_loss -0.6283 
2025-06-03 13:10:39.489598: val_loss -0.6485 
2025-06-03 13:10:39.659839: Pseudo dice [np.float32(0.6393)] 
2025-06-03 13:10:39.676802: Epoch time: 97.66 s 
2025-06-03 13:10:39.693225: Yayy! New best EMA pseudo Dice: 0.6377999782562256 
2025-06-03 13:10:41.803815:  
2025-06-03 13:10:41.822005: Epoch 86 
2025-06-03 13:10:41.837899: Current learning rate: 0.00922 
2025-06-03 13:12:19.070970: train_loss -0.5832 
2025-06-03 13:12:19.090094: val_loss -0.6215 
2025-06-03 13:12:19.106154: Pseudo dice [np.float32(0.6112)] 
2025-06-03 13:12:19.121314: Epoch time: 97.27 s 
2025-06-03 13:12:20.736669:  
2025-06-03 13:12:20.752711: Epoch 87 
2025-06-03 13:12:20.764149: Current learning rate: 0.00921 
2025-06-03 13:13:58.968305: train_loss -0.6216 
2025-06-03 13:13:59.219143: val_loss -0.5781 
2025-06-03 13:13:59.523638: Pseudo dice [np.float32(0.5527)] 
2025-06-03 13:13:59.541539: Epoch time: 98.23 s 
2025-06-03 13:14:01.614811:  
2025-06-03 13:14:01.628155: Epoch 88 
2025-06-03 13:14:01.639944: Current learning rate: 0.0092 
2025-06-03 13:15:38.224190: train_loss -0.6253 
2025-06-03 13:15:38.469853: val_loss -0.6121 
2025-06-03 13:15:38.725078: Pseudo dice [np.float32(0.6105)] 
2025-06-03 13:15:38.958499: Epoch time: 96.61 s 
2025-06-03 13:15:40.891333:  
2025-06-03 13:15:40.909498: Epoch 89 
2025-06-03 13:15:40.919896: Current learning rate: 0.0092 
2025-06-03 13:17:18.751150: train_loss -0.6266 
2025-06-03 13:17:18.979207: val_loss -0.5762 
2025-06-03 13:17:18.996392: Pseudo dice [np.float32(0.6383)] 
2025-06-03 13:17:19.011469: Epoch time: 97.86 s 
2025-06-03 13:17:21.070856:  
2025-06-03 13:17:21.084405: Epoch 90 
2025-06-03 13:17:21.094285: Current learning rate: 0.00919 
2025-06-03 13:18:57.884313: train_loss -0.5895 
2025-06-03 13:18:58.140984: val_loss -0.6573 
2025-06-03 13:18:58.348874: Pseudo dice [np.float32(0.7497)] 
2025-06-03 13:18:58.365736: Epoch time: 96.82 s 
2025-06-03 13:18:58.381061: Yayy! New best EMA pseudo Dice: 0.6388999819755554 
2025-06-03 13:19:01.179064:  
2025-06-03 13:19:01.191984: Epoch 91 
2025-06-03 13:19:01.203382: Current learning rate: 0.00918 
2025-06-03 13:20:38.553243: train_loss -0.6011 
2025-06-03 13:20:38.572955: val_loss -0.5983 
2025-06-03 13:20:38.587245: Pseudo dice [np.float32(0.6783)] 
2025-06-03 13:20:38.601560: Epoch time: 97.38 s 
2025-06-03 13:20:38.615882: Yayy! New best EMA pseudo Dice: 0.642799973487854 
2025-06-03 13:20:41.787066:  
2025-06-03 13:20:41.798681: Epoch 92 
2025-06-03 13:20:41.814361: Current learning rate: 0.00917 
2025-06-03 13:22:18.870671: train_loss -0.6232 
2025-06-03 13:22:18.890801: val_loss -0.6141 
2025-06-03 13:22:18.905150: Pseudo dice [np.float32(0.6899)] 
2025-06-03 13:22:18.920112: Epoch time: 97.09 s 
2025-06-03 13:22:18.935491: Yayy! New best EMA pseudo Dice: 0.6474999785423279 
2025-06-03 13:22:21.152293:  
2025-06-03 13:22:21.168374: Epoch 93 
2025-06-03 13:22:21.185031: Current learning rate: 0.00916 
2025-06-03 13:24:00.119761: train_loss -0.6422 
2025-06-03 13:24:00.313086: val_loss -0.6589 
2025-06-03 13:24:00.530518: Pseudo dice [np.float32(0.6749)] 
2025-06-03 13:24:00.749007: Epoch time: 98.97 s 
2025-06-03 13:24:01.011314: Yayy! New best EMA pseudo Dice: 0.6503000259399414 
2025-06-03 13:24:03.281924:  
2025-06-03 13:24:03.300234: Epoch 94 
2025-06-03 13:24:03.311808: Current learning rate: 0.00915 
2025-06-03 13:25:39.962061: train_loss -0.6471 
2025-06-03 13:25:40.204118: val_loss -0.6026 
2025-06-03 13:25:40.425240: Pseudo dice [np.float32(0.623)] 
2025-06-03 13:25:40.587564: Epoch time: 96.68 s 
2025-06-03 13:25:41.818244:  
2025-06-03 13:25:41.834086: Epoch 95 
2025-06-03 13:25:41.847236: Current learning rate: 0.00914 
2025-06-03 13:27:20.265284: train_loss -0.6574 
2025-06-03 13:27:20.460650: val_loss -0.6404 
2025-06-03 13:27:20.486710: Pseudo dice [np.float32(0.6674)] 
2025-06-03 13:27:20.503912: Epoch time: 98.45 s 
2025-06-03 13:27:22.106020:  
2025-06-03 13:27:22.119258: Epoch 96 
2025-06-03 13:27:22.130354: Current learning rate: 0.00913 
2025-06-03 13:28:58.231263: train_loss -0.6344 
2025-06-03 13:28:58.422217: val_loss -0.5927 
2025-06-03 13:28:58.440673: Pseudo dice [np.float32(0.6596)] 
2025-06-03 13:28:58.456559: Epoch time: 96.13 s 
2025-06-03 13:28:58.472204: Yayy! New best EMA pseudo Dice: 0.6504999995231628 
2025-06-03 13:29:01.391427:  
2025-06-03 13:29:01.404730: Epoch 97 
2025-06-03 13:29:01.415442: Current learning rate: 0.00912 
2025-06-03 13:30:37.507744: train_loss -0.6363 
2025-06-03 13:30:37.764287: val_loss -0.6094 
2025-06-03 13:30:37.979577: Pseudo dice [np.float32(0.6297)] 
2025-06-03 13:30:38.182183: Epoch time: 96.12 s 
2025-06-03 13:30:39.325277:  
2025-06-03 13:30:39.346772: Epoch 98 
2025-06-03 13:30:39.358429: Current learning rate: 0.00911 
2025-06-03 13:32:16.724456: train_loss -0.605 
2025-06-03 13:32:16.894510: val_loss -0.6102 
2025-06-03 13:32:17.075472: Pseudo dice [np.float32(0.582)] 
2025-06-03 13:32:17.380007: Epoch time: 97.4 s 
2025-06-03 13:32:18.966303:  
2025-06-03 13:32:18.982628: Epoch 99 
2025-06-03 13:32:18.993477: Current learning rate: 0.0091 
2025-06-03 13:33:57.371370: train_loss -0.6397 
2025-06-03 13:33:57.390512: val_loss -0.6875 
2025-06-03 13:33:57.404777: Pseudo dice [np.float32(0.7576)] 
2025-06-03 13:33:57.419094: Epoch time: 98.41 s 
2025-06-03 13:33:58.389112: Yayy! New best EMA pseudo Dice: 0.6534000039100647 
2025-06-03 13:34:00.224591:  
2025-06-03 13:34:00.242703: Epoch 100 
2025-06-03 13:34:00.259269: Current learning rate: 0.0091 
2025-06-03 13:35:36.572572: train_loss -0.6186 
2025-06-03 13:35:36.680499: val_loss -0.6159 
2025-06-03 13:35:36.696011: Pseudo dice [np.float32(0.629)] 
2025-06-03 13:35:36.711458: Epoch time: 96.35 s 
2025-06-03 13:35:38.290642:  
2025-06-03 13:35:38.303743: Epoch 101 
2025-06-03 13:35:38.314272: Current learning rate: 0.00909 
2025-06-03 13:37:16.145905: train_loss -0.6206 
2025-06-03 13:37:16.165258: val_loss -0.6225 
2025-06-03 13:37:16.180634: Pseudo dice [np.float32(0.6368)] 
2025-06-03 13:37:16.195932: Epoch time: 97.86 s 
2025-06-03 13:37:17.632103:  
2025-06-03 13:37:17.650862: Epoch 102 
2025-06-03 13:37:17.668656: Current learning rate: 0.00908 
2025-06-03 13:38:55.199715: train_loss -0.6108 
2025-06-03 13:38:55.457308: val_loss -0.5561 
2025-06-03 13:38:55.648271: Pseudo dice [np.float32(0.5464)] 
2025-06-03 13:38:55.817079: Epoch time: 97.57 s 
2025-06-03 13:38:57.271123:  
2025-06-03 13:38:57.288070: Epoch 103 
2025-06-03 13:38:57.297776: Current learning rate: 0.00907 
2025-06-03 13:40:36.576548: train_loss -0.6033 
2025-06-03 13:40:36.597496: val_loss -0.5766 
2025-06-03 13:40:36.612382: Pseudo dice [np.float32(0.643)] 
2025-06-03 13:40:36.625708: Epoch time: 99.31 s 
2025-06-03 13:40:38.796949:  
2025-06-03 13:40:38.810472: Epoch 104 
2025-06-03 13:40:38.821741: Current learning rate: 0.00906 
2025-06-03 13:42:16.028726: train_loss -0.6355 
2025-06-03 13:42:16.213129: val_loss -0.6443 
2025-06-03 13:42:16.507007: Pseudo dice [np.float32(0.7226)] 
2025-06-03 13:42:16.841428: Epoch time: 97.23 s 
2025-06-03 13:42:18.212402:  
2025-06-03 13:42:18.229866: Epoch 105 
2025-06-03 13:42:18.240873: Current learning rate: 0.00905 
2025-06-03 13:43:56.399444: train_loss -0.6329 
2025-06-03 13:43:56.543942: val_loss -0.6078 
2025-06-03 13:43:56.736604: Pseudo dice [np.float32(0.6363)] 
2025-06-03 13:43:56.856269: Epoch time: 98.19 s 
2025-06-03 13:43:58.035494:  
2025-06-03 13:43:58.055733: Epoch 106 
2025-06-03 13:43:58.070684: Current learning rate: 0.00904 
2025-06-03 13:45:34.876554: train_loss -0.6621 
2025-06-03 13:45:35.187795: val_loss -0.6429 
2025-06-03 13:45:35.390998: Pseudo dice [np.float32(0.6647)] 
2025-06-03 13:45:35.405792: Epoch time: 96.84 s 
2025-06-03 13:45:36.748370:  
2025-06-03 13:45:36.761971: Epoch 107 
2025-06-03 13:45:36.771805: Current learning rate: 0.00903 
2025-06-03 13:47:15.312919: train_loss -0.6305 
2025-06-03 13:47:15.489471: val_loss -0.6038 
2025-06-03 13:47:15.792710: Pseudo dice [np.float32(0.6115)] 
2025-06-03 13:47:16.080300: Epoch time: 98.57 s 
2025-06-03 13:47:17.723347:  
2025-06-03 13:47:17.738000: Epoch 108 
2025-06-03 13:47:17.758639: Current learning rate: 0.00902 
2025-06-03 13:48:54.065707: train_loss -0.6228 
2025-06-03 13:48:54.086255: val_loss -0.5072 
2025-06-03 13:48:54.102248: Pseudo dice [np.float32(0.5241)] 
2025-06-03 13:48:54.117092: Epoch time: 96.34 s 
2025-06-03 13:48:56.260067:  
2025-06-03 13:48:56.271950: Epoch 109 
2025-06-03 13:48:56.283730: Current learning rate: 0.00901 
2025-06-03 13:50:33.719730: train_loss -0.6362 
2025-06-03 13:50:33.738709: val_loss -0.6087 
2025-06-03 13:50:33.752100: Pseudo dice [np.float32(0.6906)] 
2025-06-03 13:50:33.765931: Epoch time: 97.46 s 
2025-06-03 13:50:37.346192:  
2025-06-03 13:50:37.477438: Epoch 110 
2025-06-03 13:50:37.622897: Current learning rate: 0.009 
2025-06-03 13:52:15.563197: train_loss -0.6355 
2025-06-03 13:52:15.580999: val_loss -0.6075 
2025-06-03 13:52:15.598233: Pseudo dice [np.float32(0.7416)] 
2025-06-03 13:52:15.613979: Epoch time: 98.22 s 
2025-06-03 13:52:18.590307:  
2025-06-03 13:52:18.602904: Epoch 111 
2025-06-03 13:52:18.613911: Current learning rate: 0.009 
2025-06-03 13:53:56.133178: train_loss -0.6342 
2025-06-03 13:53:56.153523: val_loss -0.5617 
2025-06-03 13:53:56.167262: Pseudo dice [np.float32(0.5515)] 
2025-06-03 13:53:56.183863: Epoch time: 97.54 s 
2025-06-03 13:53:58.505542:  
2025-06-03 13:53:58.535476: Epoch 112 
2025-06-03 13:53:58.547351: Current learning rate: 0.00899 
2025-06-03 13:55:35.293887: train_loss -0.6478 
2025-06-03 13:55:35.610801: val_loss -0.6662 
2025-06-03 13:55:35.818963: Pseudo dice [np.float32(0.6874)] 
2025-06-03 13:55:35.834741: Epoch time: 96.79 s 
2025-06-03 13:55:37.748417:  
2025-06-03 13:55:37.765088: Epoch 113 
2025-06-03 13:55:37.776618: Current learning rate: 0.00898 
2025-06-03 13:57:18.769701: train_loss -0.6475 
2025-06-03 13:57:19.028946: val_loss -0.6169 
2025-06-03 13:57:19.286095: Pseudo dice [np.float32(0.6464)] 
2025-06-03 13:57:19.481226: Epoch time: 101.02 s 
2025-06-03 13:57:21.258379:  
2025-06-03 13:57:21.274837: Epoch 114 
2025-06-03 13:57:21.288228: Current learning rate: 0.00897 
2025-06-03 13:58:58.761501: train_loss -0.6228 
2025-06-03 13:58:58.780262: val_loss -0.624 
2025-06-03 13:58:58.993440: Pseudo dice [np.float32(0.6704)] 
2025-06-03 13:58:59.265146: Epoch time: 97.5 s 
2025-06-03 13:59:00.748582:  
2025-06-03 13:59:00.759881: Epoch 115 
2025-06-03 13:59:00.770310: Current learning rate: 0.00896 
2025-06-03 14:00:40.194419: train_loss -0.643 
2025-06-03 14:00:40.379005: val_loss -0.6642 
2025-06-03 14:00:40.394875: Pseudo dice [np.float32(0.7024)] 
2025-06-03 14:00:40.408773: Epoch time: 99.45 s 
2025-06-03 14:00:42.551344:  
2025-06-03 14:00:42.569047: Epoch 116 
2025-06-03 14:00:42.583222: Current learning rate: 0.00895 
2025-06-03 14:02:19.371063: train_loss -0.6156 
2025-06-03 14:02:19.390544: val_loss -0.6655 
2025-06-03 14:02:19.405355: Pseudo dice [np.float32(0.6873)] 
2025-06-03 14:02:19.418648: Epoch time: 96.82 s 
2025-06-03 14:02:19.431497: Yayy! New best EMA pseudo Dice: 0.6559000015258789 
2025-06-03 14:02:22.273611:  
2025-06-03 14:02:22.289942: Epoch 117 
2025-06-03 14:02:22.307811: Current learning rate: 0.00894 
2025-06-03 14:04:03.818014: train_loss -0.6556 
2025-06-03 14:04:04.195167: val_loss -0.6261 
2025-06-03 14:04:04.447582: Pseudo dice [np.float32(0.7197)] 
2025-06-03 14:04:04.687621: Epoch time: 101.55 s 
2025-06-03 14:04:04.873947: Yayy! New best EMA pseudo Dice: 0.6622999906539917 
2025-06-03 14:04:06.411065:  
2025-06-03 14:04:06.427961: Epoch 118 
2025-06-03 14:04:06.450484: Current learning rate: 0.00893 
2025-06-03 14:05:44.035578: train_loss -0.6367 
2025-06-03 14:05:44.242856: val_loss -0.6771 
2025-06-03 14:05:44.409540: Pseudo dice [np.float32(0.7183)] 
2025-06-03 14:05:44.592044: Epoch time: 97.63 s 
2025-06-03 14:05:44.727651: Yayy! New best EMA pseudo Dice: 0.667900025844574 
2025-06-03 14:05:46.264409:  
2025-06-03 14:05:46.282873: Epoch 119 
2025-06-03 14:05:46.298427: Current learning rate: 0.00892 
2025-06-03 14:07:23.202838: train_loss -0.6346 
2025-06-03 14:07:23.219047: val_loss -0.5619 
2025-06-03 14:07:23.233251: Pseudo dice [np.float32(0.5601)] 
2025-06-03 14:07:23.247437: Epoch time: 96.94 s 
2025-06-03 14:07:24.633495:  
2025-06-03 14:07:24.649207: Epoch 120 
2025-06-03 14:07:24.661644: Current learning rate: 0.00891 
2025-06-03 14:09:02.116640: train_loss -0.6326 
2025-06-03 14:09:02.215916: val_loss -0.6499 
2025-06-03 14:09:02.231786: Pseudo dice [np.float32(0.6688)] 
2025-06-03 14:09:02.245631: Epoch time: 97.48 s 
2025-06-03 14:09:04.169951:  
2025-06-03 14:09:04.188933: Epoch 121 
2025-06-03 14:09:04.204328: Current learning rate: 0.0089 
2025-06-03 14:10:41.757230: train_loss -0.6375 
2025-06-03 14:10:41.914772: val_loss -0.6289 
2025-06-03 14:10:42.123967: Pseudo dice [np.float32(0.662)] 
2025-06-03 14:10:42.323863: Epoch time: 97.59 s 
2025-06-03 14:10:43.518575:  
2025-06-03 14:10:43.531586: Epoch 122 
2025-06-03 14:10:43.542059: Current learning rate: 0.00889 
2025-06-03 14:12:19.777889: train_loss -0.6438 
2025-06-03 14:12:19.797198: val_loss -0.6106 
2025-06-03 14:12:19.811404: Pseudo dice [np.float32(0.6803)] 
2025-06-03 14:12:19.825195: Epoch time: 96.26 s 
2025-06-03 14:12:21.604241:  
2025-06-03 14:12:21.619582: Epoch 123 
2025-06-03 14:12:21.630603: Current learning rate: 0.00889 
2025-06-03 14:13:58.474508: train_loss -0.61 
2025-06-03 14:13:58.493057: val_loss -0.6288 
2025-06-03 14:13:58.506964: Pseudo dice [np.float32(0.7273)] 
2025-06-03 14:13:58.520287: Epoch time: 96.87 s 
2025-06-03 14:14:00.462239:  
2025-06-03 14:14:00.475087: Epoch 124 
2025-06-03 14:14:00.485426: Current learning rate: 0.00888 
2025-06-03 14:15:39.191975: train_loss -0.6511 
2025-06-03 14:15:39.213619: val_loss -0.6404 
2025-06-03 14:15:39.228561: Pseudo dice [np.float32(0.6399)] 
2025-06-03 14:15:39.242021: Epoch time: 98.73 s 
2025-06-03 14:15:41.019813:  
2025-06-03 14:15:41.032369: Epoch 125 
2025-06-03 14:15:41.042352: Current learning rate: 0.00887 
2025-06-03 14:17:15.760328: train_loss -0.6467 
2025-06-03 14:17:15.939528: val_loss -0.6387 
2025-06-03 14:17:16.198417: Pseudo dice [np.float32(0.6336)] 
2025-06-03 14:17:16.438555: Epoch time: 94.74 s 
2025-06-03 14:17:17.813404:  
2025-06-03 14:17:17.832122: Epoch 126 
2025-06-03 14:17:17.842342: Current learning rate: 0.00886 
2025-06-03 14:18:54.158446: train_loss -0.6138 
2025-06-03 14:18:54.178233: val_loss -0.6577 
2025-06-03 14:18:54.195477: Pseudo dice [np.float32(0.7234)] 
2025-06-03 14:18:54.211250: Epoch time: 96.35 s 
2025-06-03 14:18:56.138343:  
2025-06-03 14:18:56.153086: Epoch 127 
2025-06-03 14:18:56.164154: Current learning rate: 0.00885 
2025-06-03 14:20:32.284246: train_loss -0.6371 
2025-06-03 14:20:32.306188: val_loss -0.6337 
2025-06-03 14:20:32.321203: Pseudo dice [np.float32(0.5741)] 
2025-06-03 14:20:32.335903: Epoch time: 96.15 s 
2025-06-03 14:20:35.311701:  
2025-06-03 14:20:35.328425: Epoch 128 
2025-06-03 14:20:35.339801: Current learning rate: 0.00884 
2025-06-03 14:22:13.638113: train_loss -0.6823 
2025-06-03 14:22:13.787828: val_loss -0.6285 
2025-06-03 14:22:13.804682: Pseudo dice [np.float32(0.6674)] 
2025-06-03 14:22:13.821612: Epoch time: 98.33 s 
2025-06-03 14:22:16.651137:  
2025-06-03 14:22:16.669225: Epoch 129 
2025-06-03 14:22:16.681615: Current learning rate: 0.00883 
2025-06-03 14:23:53.067145: train_loss -0.6477 
2025-06-03 14:23:53.087335: val_loss -0.6566 
2025-06-03 14:23:53.103715: Pseudo dice [np.float32(0.702)] 
2025-06-03 14:23:53.120561: Epoch time: 96.42 s 
2025-06-03 14:23:54.773097:  
2025-06-03 14:23:54.795442: Epoch 130 
2025-06-03 14:23:54.814409: Current learning rate: 0.00882 
2025-06-03 14:25:34.814621: train_loss -0.6086 
2025-06-03 14:25:34.835588: val_loss -0.6109 
2025-06-03 14:25:34.852983: Pseudo dice [np.float32(0.6445)] 
2025-06-03 14:25:34.869371: Epoch time: 100.04 s 
2025-06-03 14:25:36.427922:  
2025-06-03 14:25:36.442422: Epoch 131 
2025-06-03 14:25:36.454715: Current learning rate: 0.00881 
2025-06-03 14:27:11.646497: train_loss -0.6801 
2025-06-03 14:27:11.912276: val_loss -0.6422 
2025-06-03 14:27:12.163829: Pseudo dice [np.float32(0.6976)] 
2025-06-03 14:27:12.436213: Epoch time: 95.22 s 
2025-06-03 14:27:13.792648:  
2025-06-03 14:27:13.810843: Epoch 132 
2025-06-03 14:27:13.823172: Current learning rate: 0.0088 
2025-06-03 14:28:49.052595: train_loss -0.6234 
2025-06-03 14:28:49.075788: val_loss -0.5549 
2025-06-03 14:28:49.092201: Pseudo dice [np.float32(0.5672)] 
2025-06-03 14:28:49.106142: Epoch time: 95.26 s 
2025-06-03 14:28:51.307198:  
2025-06-03 14:28:51.324586: Epoch 133 
2025-06-03 14:28:51.336161: Current learning rate: 0.00879 
2025-06-03 14:30:29.974961: train_loss -0.6312 
2025-06-03 14:30:30.141712: val_loss -0.6467 
2025-06-03 14:30:30.417909: Pseudo dice [np.float32(0.6815)] 
2025-06-03 14:30:30.673343: Epoch time: 98.67 s 
2025-06-03 14:30:32.335083:  
2025-06-03 14:30:32.348641: Epoch 134 
2025-06-03 14:30:32.360217: Current learning rate: 0.00879 
2025-06-03 14:32:09.010425: train_loss -0.6172 
2025-06-03 14:32:09.029943: val_loss -0.5764 
2025-06-03 14:32:09.045391: Pseudo dice [np.float32(0.6012)] 
2025-06-03 14:32:09.059214: Epoch time: 96.68 s 
2025-06-03 14:32:11.797550:  
2025-06-03 14:32:11.811951: Epoch 135 
2025-06-03 14:32:11.826438: Current learning rate: 0.00878 
2025-06-03 14:33:49.038577: train_loss -0.6461 
2025-06-03 14:33:49.127861: val_loss -0.663 
2025-06-03 14:33:49.150451: Pseudo dice [np.float32(0.7453)] 
2025-06-03 14:33:49.165905: Epoch time: 97.24 s 
2025-06-03 14:33:52.054594:  
2025-06-03 14:33:52.069918: Epoch 136 
2025-06-03 14:33:52.081606: Current learning rate: 0.00877 
2025-06-03 14:35:25.866086: train_loss -0.6338 
2025-06-03 14:35:25.888125: val_loss -0.5788 
2025-06-03 14:35:25.904413: Pseudo dice [np.float32(0.6043)] 
2025-06-03 14:35:25.920192: Epoch time: 93.81 s 
2025-06-03 14:35:28.344467:  
2025-06-03 14:35:28.360365: Epoch 137 
2025-06-03 14:35:28.371670: Current learning rate: 0.00876 
2025-06-03 14:37:04.915132: train_loss -0.646 
2025-06-03 14:37:05.097878: val_loss -0.6406 
2025-06-03 14:37:05.372040: Pseudo dice [np.float32(0.7198)] 
2025-06-03 14:37:05.546558: Epoch time: 96.57 s 
2025-06-03 14:37:07.974102:  
2025-06-03 14:37:07.992009: Epoch 138 
2025-06-03 14:37:08.004808: Current learning rate: 0.00875 
2025-06-03 14:38:46.594389: train_loss -0.6089 
2025-06-03 14:38:46.616341: val_loss -0.5649 
2025-06-03 14:38:46.632686: Pseudo dice [np.float32(0.5445)] 
2025-06-03 14:38:46.649532: Epoch time: 98.62 s 
2025-06-03 14:38:48.742535:  
2025-06-03 14:38:48.758824: Epoch 139 
2025-06-03 14:38:48.771657: Current learning rate: 0.00874 
2025-06-03 14:40:25.514494: train_loss -0.6267 
2025-06-03 14:40:25.874851: val_loss -0.5891 
2025-06-03 14:40:26.034491: Pseudo dice [np.float32(0.6484)] 
2025-06-03 14:40:26.058661: Epoch time: 96.77 s 
2025-06-03 14:40:27.651903:  
2025-06-03 14:40:27.665699: Epoch 140 
2025-06-03 14:40:27.682765: Current learning rate: 0.00873 
2025-06-03 14:42:02.478212: train_loss -0.6509 
2025-06-03 14:42:02.621379: val_loss -0.5551 
2025-06-03 14:42:02.803198: Pseudo dice [np.float32(0.6144)] 
2025-06-03 14:42:03.031104: Epoch time: 94.83 s 
2025-06-03 14:42:07.156920:  
2025-06-03 14:42:07.172599: Epoch 141 
2025-06-03 14:42:07.183326: Current learning rate: 0.00872 
2025-06-03 14:43:45.988827: train_loss -0.6696 
2025-06-03 14:43:46.320943: val_loss -0.5845 
2025-06-03 14:43:46.613697: Pseudo dice [np.float32(0.6348)] 
2025-06-03 14:43:46.823029: Epoch time: 98.83 s 
2025-06-03 14:43:48.838252:  
2025-06-03 14:43:48.851966: Epoch 142 
2025-06-03 14:43:48.863054: Current learning rate: 0.00871 
2025-06-03 14:45:30.330236: train_loss -0.6688 
2025-06-03 14:45:30.441289: val_loss -0.5758 
2025-06-03 14:45:30.488129: Pseudo dice [np.float32(0.607)] 
2025-06-03 14:45:30.516466: Epoch time: 101.49 s 
2025-06-03 14:45:31.661678:  
2025-06-03 14:45:31.676363: Epoch 143 
2025-06-03 14:45:31.689492: Current learning rate: 0.0087 
2025-06-03 14:47:07.326869: train_loss -0.6119 
2025-06-03 14:47:07.550522: val_loss -0.6543 
2025-06-03 14:47:07.568238: Pseudo dice [np.float32(0.5897)] 
2025-06-03 14:47:07.582713: Epoch time: 95.67 s 
2025-06-03 14:47:09.714495:  
2025-06-03 14:47:09.725867: Epoch 144 
2025-06-03 14:47:09.738972: Current learning rate: 0.00869 
2025-06-03 14:48:45.684188: train_loss -0.6177 
2025-06-03 14:48:45.861025: val_loss -0.5636 
2025-06-03 14:48:45.880497: Pseudo dice [np.float32(0.5865)] 
2025-06-03 14:48:45.894384: Epoch time: 95.97 s 
2025-06-03 14:48:48.035736:  
2025-06-03 14:48:48.048550: Epoch 145 
2025-06-03 14:48:48.058828: Current learning rate: 0.00868 
2025-06-03 14:50:27.956850: train_loss -0.6232 
2025-06-03 14:50:28.233595: val_loss -0.5692 
2025-06-03 14:50:28.453805: Pseudo dice [np.float32(0.5574)] 
2025-06-03 14:50:28.640974: Epoch time: 99.92 s 
2025-06-03 14:50:31.262669:  
2025-06-03 14:50:31.280186: Epoch 146 
2025-06-03 14:50:31.293971: Current learning rate: 0.00868 
2025-06-03 14:52:08.904254: train_loss -0.6266 
2025-06-03 14:52:08.928242: val_loss -0.5985 
2025-06-03 14:52:08.943284: Pseudo dice [np.float32(0.5754)] 
2025-06-03 14:52:08.958364: Epoch time: 97.64 s 
2025-06-03 14:52:10.936196:  
2025-06-03 14:52:10.951905: Epoch 147 
2025-06-03 14:52:10.967109: Current learning rate: 0.00867 
2025-06-03 14:53:48.772017: train_loss -0.6097 
2025-06-03 14:53:48.790392: val_loss -0.586 
2025-06-03 14:53:48.806736: Pseudo dice [np.float32(0.6148)] 
2025-06-03 14:53:48.822054: Epoch time: 97.84 s 
2025-06-03 14:53:50.498834:  
2025-06-03 14:53:50.521384: Epoch 148 
2025-06-03 14:53:50.535799: Current learning rate: 0.00866 
2025-06-03 14:55:28.167199: train_loss -0.6401 
2025-06-03 14:55:28.432957: val_loss -0.59 
2025-06-03 14:55:28.671384: Pseudo dice [np.float32(0.6377)] 
2025-06-03 14:55:28.822025: Epoch time: 97.67 s 
2025-06-03 14:55:30.602351:  
2025-06-03 14:55:30.616119: Epoch 149 
2025-06-03 14:55:30.628992: Current learning rate: 0.00865 
2025-06-03 14:57:08.440859: train_loss -0.6366 
2025-06-03 14:57:08.466269: val_loss -0.6297 
2025-06-03 14:57:08.489742: Pseudo dice [np.float32(0.7041)] 
2025-06-03 14:57:08.506161: Epoch time: 97.84 s 
2025-06-03 14:57:11.183087:  
2025-06-03 14:57:11.201507: Epoch 150 
2025-06-03 14:57:11.215153: Current learning rate: 0.00864 
2025-06-03 14:58:49.568861: train_loss -0.6376 
2025-06-03 14:58:49.796827: val_loss -0.6233 
2025-06-03 14:58:50.129246: Pseudo dice [np.float32(0.6425)] 
2025-06-03 14:58:50.148026: Epoch time: 98.39 s 
2025-06-03 14:58:52.103230:  
2025-06-03 14:58:52.120078: Epoch 151 
2025-06-03 14:58:52.131963: Current learning rate: 0.00863 
2025-06-03 15:00:29.362775: train_loss -0.6607 
2025-06-03 15:00:29.623555: val_loss -0.6737 
2025-06-03 15:00:29.799983: Pseudo dice [np.float32(0.6723)] 
2025-06-03 15:00:29.816388: Epoch time: 97.26 s 
2025-06-03 15:00:31.249635:  
2025-06-03 15:00:31.265568: Epoch 152 
2025-06-03 15:00:31.279204: Current learning rate: 0.00862 
2025-06-03 15:02:10.392547: train_loss -0.629 
2025-06-03 15:02:10.627686: val_loss -0.657 
2025-06-03 15:02:10.650670: Pseudo dice [np.float32(0.7044)] 
2025-06-03 15:02:10.666983: Epoch time: 99.14 s 
2025-06-03 15:02:12.615398:  
2025-06-03 15:02:12.630030: Epoch 153 
2025-06-03 15:02:12.640902: Current learning rate: 0.00861 
2025-06-03 15:03:48.765445: train_loss -0.647 
2025-06-03 15:03:48.977934: val_loss -0.598 
2025-06-03 15:03:48.993995: Pseudo dice [np.float32(0.7082)] 
2025-06-03 15:03:49.008997: Epoch time: 96.15 s 
2025-06-03 15:03:50.478004:  
2025-06-03 15:03:50.501667: Epoch 154 
2025-06-03 15:03:50.511672: Current learning rate: 0.0086 
2025-06-03 15:05:27.694224: train_loss -0.6392 
2025-06-03 15:05:27.835286: val_loss -0.6203 
2025-06-03 15:05:28.085164: Pseudo dice [np.float32(0.7051)] 
2025-06-03 15:05:28.309097: Epoch time: 97.22 s 
2025-06-03 15:05:30.269627:  
2025-06-03 15:05:30.283650: Epoch 155 
2025-06-03 15:05:30.294564: Current learning rate: 0.00859 
2025-06-03 15:07:07.853456: train_loss -0.6818 
2025-06-03 15:07:08.121244: val_loss -0.6718 
2025-06-03 15:07:08.263537: Pseudo dice [np.float32(0.7575)] 
2025-06-03 15:07:08.280589: Epoch time: 97.59 s 
2025-06-03 15:07:11.045796:  
2025-06-03 15:07:11.060093: Epoch 156 
2025-06-03 15:07:11.070778: Current learning rate: 0.00858 
2025-06-03 15:08:47.689557: train_loss -0.6627 
2025-06-03 15:08:47.869491: val_loss -0.6462 
2025-06-03 15:08:48.110596: Pseudo dice [np.float32(0.667)] 
2025-06-03 15:08:48.308409: Epoch time: 96.64 s 
2025-06-03 15:08:50.567743:  
2025-06-03 15:08:50.586874: Epoch 157 
2025-06-03 15:08:50.597739: Current learning rate: 0.00858 
2025-06-03 15:10:27.223481: train_loss -0.6577 
2025-06-03 15:10:27.246767: val_loss -0.6822 
2025-06-03 15:10:27.260757: Pseudo dice [np.float32(0.7434)] 
2025-06-03 15:10:27.276050: Epoch time: 96.66 s 
2025-06-03 15:10:27.290844: Yayy! New best EMA pseudo Dice: 0.6723999977111816 
2025-06-03 15:10:30.226109:  
2025-06-03 15:10:30.238789: Epoch 158 
2025-06-03 15:10:30.250453: Current learning rate: 0.00857 
2025-06-03 15:12:08.101527: train_loss -0.6499 
2025-06-03 15:12:08.225268: val_loss -0.5724 
2025-06-03 15:12:08.352583: Pseudo dice [np.float32(0.6211)] 
2025-06-03 15:12:08.502444: Epoch time: 97.88 s 
2025-06-03 15:12:09.697500:  
2025-06-03 15:12:09.713831: Epoch 159 
2025-06-03 15:12:09.726434: Current learning rate: 0.00856 
2025-06-03 15:13:47.277791: train_loss -0.6371 
2025-06-03 15:13:47.546469: val_loss -0.6059 
2025-06-03 15:13:47.711900: Pseudo dice [np.float32(0.6215)] 
2025-06-03 15:13:47.949648: Epoch time: 97.58 s 
2025-06-03 15:13:49.560590:  
2025-06-03 15:13:49.574821: Epoch 160 
2025-06-03 15:13:49.588512: Current learning rate: 0.00855 
2025-06-03 15:15:24.858362: train_loss -0.6498 
2025-06-03 15:15:25.133922: val_loss -0.6338 
2025-06-03 15:15:25.394238: Pseudo dice [np.float32(0.7112)] 
2025-06-03 15:15:25.699878: Epoch time: 95.3 s 
2025-06-03 15:15:27.826186:  
2025-06-03 15:15:27.837681: Epoch 161 
2025-06-03 15:15:27.848811: Current learning rate: 0.00854 
2025-06-03 15:17:05.012896: train_loss -0.647 
2025-06-03 15:17:05.036970: val_loss -0.5801 
2025-06-03 15:17:05.056983: Pseudo dice [np.float32(0.6241)] 
2025-06-03 15:17:05.072133: Epoch time: 97.19 s 
2025-06-03 15:17:08.256843:  
2025-06-03 15:17:08.271363: Epoch 162 
2025-06-03 15:17:08.282206: Current learning rate: 0.00853 
2025-06-03 15:18:45.654630: train_loss -0.6397 
2025-06-03 15:18:45.674896: val_loss -0.7008 
2025-06-03 15:18:45.688389: Pseudo dice [np.float32(0.7038)] 
2025-06-03 15:18:45.704409: Epoch time: 97.4 s 
2025-06-03 15:18:48.657080:  
2025-06-03 15:18:48.670059: Epoch 163 
2025-06-03 15:18:48.680510: Current learning rate: 0.00852 
2025-06-03 15:20:25.954454: train_loss -0.6432 
2025-06-03 15:20:26.227332: val_loss -0.6177 
2025-06-03 15:20:26.489849: Pseudo dice [np.float32(0.6396)] 
2025-06-03 15:20:26.632529: Epoch time: 97.3 s 
2025-06-03 15:20:28.080658:  
2025-06-03 15:20:28.096234: Epoch 164 
2025-06-03 15:20:28.107764: Current learning rate: 0.00851 
2025-06-03 15:22:05.225038: train_loss -0.6306 
2025-06-03 15:22:05.244468: val_loss -0.5759 
2025-06-03 15:22:05.260539: Pseudo dice [np.float32(0.5881)] 
2025-06-03 15:22:05.276146: Epoch time: 97.15 s 
2025-06-03 15:22:07.492679:  
2025-06-03 15:22:07.505980: Epoch 165 
2025-06-03 15:22:07.517479: Current learning rate: 0.0085 
2025-06-03 15:23:43.156842: train_loss -0.6298 
2025-06-03 15:23:43.428612: val_loss -0.5863 
2025-06-03 15:23:43.710601: Pseudo dice [np.float32(0.6285)] 
2025-06-03 15:23:43.827736: Epoch time: 95.66 s 
2025-06-03 15:23:44.945825:  
2025-06-03 15:23:44.959557: Epoch 166 
2025-06-03 15:23:44.973777: Current learning rate: 0.00849 
2025-06-03 15:25:23.222876: train_loss -0.6586 
2025-06-03 15:25:23.242563: val_loss -0.6069 
2025-06-03 15:25:23.257614: Pseudo dice [np.float32(0.6577)] 
2025-06-03 15:25:23.271717: Epoch time: 98.28 s 
2025-06-03 15:25:24.725388:  
2025-06-03 15:25:24.742550: Epoch 167 
2025-06-03 15:25:24.758098: Current learning rate: 0.00848 
2025-06-03 15:27:03.580719: train_loss -0.6385 
2025-06-03 15:27:03.717159: val_loss -0.6875 
2025-06-03 15:27:03.881367: Pseudo dice [np.float32(0.7986)] 
2025-06-03 15:27:04.053525: Epoch time: 98.86 s 
2025-06-03 15:27:05.572474:  
2025-06-03 15:27:05.591116: Epoch 168 
2025-06-03 15:27:05.602818: Current learning rate: 0.00847 
2025-06-03 15:28:41.244853: train_loss -0.6451 
2025-06-03 15:28:41.502506: val_loss -0.5907 
2025-06-03 15:28:41.738791: Pseudo dice [np.float32(0.6146)] 
2025-06-03 15:28:42.008360: Epoch time: 95.67 s 
2025-06-03 15:28:43.364034:  
2025-06-03 15:28:43.382161: Epoch 169 
2025-06-03 15:28:43.397109: Current learning rate: 0.00847 
2025-06-03 15:30:21.094361: train_loss -0.6501 
2025-06-03 15:30:21.211964: val_loss -0.5859 
2025-06-03 15:30:21.410337: Pseudo dice [np.float32(0.6375)] 
2025-06-03 15:30:21.619676: Epoch time: 97.73 s 
2025-06-03 15:30:23.297009:  
2025-06-03 15:30:23.307941: Epoch 170 
2025-06-03 15:30:23.320188: Current learning rate: 0.00846 
2025-06-03 15:32:00.117667: train_loss -0.643 
2025-06-03 15:32:00.267817: val_loss -0.6102 
2025-06-03 15:32:00.285220: Pseudo dice [np.float32(0.6714)] 
2025-06-03 15:32:00.299219: Epoch time: 96.82 s 
2025-06-03 15:32:02.393816:  
2025-06-03 15:32:02.407170: Epoch 171 
2025-06-03 15:32:02.419098: Current learning rate: 0.00845 
2025-06-03 15:33:40.884274: train_loss -0.6427 
2025-06-03 15:33:41.038837: val_loss -0.6682 
2025-06-03 15:33:41.055819: Pseudo dice [np.float32(0.7223)] 
2025-06-03 15:33:41.070725: Epoch time: 98.49 s 
2025-06-03 15:33:42.563966:  
2025-06-03 15:33:42.576970: Epoch 172 
2025-06-03 15:33:42.587758: Current learning rate: 0.00844 
2025-06-03 15:35:19.244959: train_loss -0.6359 
2025-06-03 15:35:19.551306: val_loss -0.5996 
2025-06-03 15:35:19.763583: Pseudo dice [np.float32(0.6416)] 
2025-06-03 15:35:19.929878: Epoch time: 96.68 s 
2025-06-03 15:35:21.337126:  
2025-06-03 15:35:21.348934: Epoch 173 
2025-06-03 15:35:21.363663: Current learning rate: 0.00843 
2025-06-03 15:36:58.257930: train_loss -0.6573 
2025-06-03 15:36:58.534581: val_loss -0.6796 
2025-06-03 15:36:58.845656: Pseudo dice [np.float32(0.7329)] 
2025-06-03 15:36:59.063364: Epoch time: 96.92 s 
2025-06-03 15:37:00.620545:  
2025-06-03 15:37:00.639134: Epoch 174 
2025-06-03 15:37:00.650718: Current learning rate: 0.00842 
2025-06-03 15:38:36.828223: train_loss -0.6551 
2025-06-03 15:38:37.055259: val_loss -0.6254 
2025-06-03 15:38:37.231558: Pseudo dice [np.float32(0.7341)] 
2025-06-03 15:38:37.249967: Epoch time: 96.21 s 
2025-06-03 15:38:37.265422: Yayy! New best EMA pseudo Dice: 0.6783000230789185 
2025-06-03 15:38:39.148002:  
2025-06-03 15:38:39.166507: Epoch 175 
2025-06-03 15:38:39.180169: Current learning rate: 0.00841 
2025-06-03 15:40:16.995219: train_loss -0.6545 
2025-06-03 15:40:17.011486: val_loss -0.6264 
2025-06-03 15:40:17.025718: Pseudo dice [np.float32(0.6737)] 
2025-06-03 15:40:17.039957: Epoch time: 97.85 s 
2025-06-03 15:40:18.807119:  
2025-06-03 15:40:18.821460: Epoch 176 
2025-06-03 15:40:18.831723: Current learning rate: 0.0084 
2025-06-03 15:41:56.254958: train_loss -0.6524 
2025-06-03 15:41:56.438018: val_loss -0.6553 
2025-06-03 15:41:56.676278: Pseudo dice [np.float32(0.7027)] 
2025-06-03 15:41:57.000059: Epoch time: 97.45 s 
2025-06-03 15:41:57.276952: Yayy! New best EMA pseudo Dice: 0.6802999973297119 
2025-06-03 15:41:59.963892:  
2025-06-03 15:41:59.977666: Epoch 177 
2025-06-03 15:41:59.988064: Current learning rate: 0.00839 
2025-06-03 15:43:37.883641: train_loss -0.6292 
2025-06-03 15:43:37.906961: val_loss -0.6449 
2025-06-03 15:43:37.921754: Pseudo dice [np.float32(0.6931)] 
2025-06-03 15:43:37.936592: Epoch time: 97.92 s 
2025-06-03 15:43:37.951413: Yayy! New best EMA pseudo Dice: 0.6815999746322632 
2025-06-03 15:43:40.907309:  
2025-06-03 15:43:40.925886: Epoch 178 
2025-06-03 15:43:40.941309: Current learning rate: 0.00838 
2025-06-03 15:45:18.336064: train_loss -0.6644 
2025-06-03 15:45:18.633779: val_loss -0.5901 
2025-06-03 15:45:18.929456: Pseudo dice [np.float32(0.6394)] 
2025-06-03 15:45:19.143533: Epoch time: 97.43 s 
2025-06-03 15:45:21.019659:  
2025-06-03 15:45:21.037575: Epoch 179 
2025-06-03 15:45:21.053180: Current learning rate: 0.00837 
2025-06-03 15:46:59.055462: train_loss -0.6714 
2025-06-03 15:46:59.367250: val_loss -0.588 
2025-06-03 15:46:59.611715: Pseudo dice [np.float32(0.6327)] 
2025-06-03 15:46:59.879246: Epoch time: 98.04 s 
2025-06-03 15:47:01.483626:  
2025-06-03 15:47:01.500211: Epoch 180 
2025-06-03 15:47:01.511622: Current learning rate: 0.00836 
2025-06-03 15:48:37.524998: train_loss -0.6424 
2025-06-03 15:48:37.547579: val_loss -0.6223 
2025-06-03 15:48:37.562811: Pseudo dice [np.float32(0.7409)] 
2025-06-03 15:48:37.577790: Epoch time: 96.04 s 
2025-06-03 15:48:40.308255:  
2025-06-03 15:48:40.325749: Epoch 181 
2025-06-03 15:48:40.335781: Current learning rate: 0.00836 
2025-06-03 15:50:16.395338: train_loss -0.6696 
2025-06-03 15:50:16.590012: val_loss -0.6209 
2025-06-03 15:50:16.814983: Pseudo dice [np.float32(0.6834)] 
2025-06-03 15:50:17.126873: Epoch time: 96.09 s 
2025-06-03 15:50:19.556614:  
2025-06-03 15:50:19.570467: Epoch 182 
2025-06-03 15:50:19.580750: Current learning rate: 0.00835 
2025-06-03 15:51:56.585496: train_loss -0.6323 
2025-06-03 15:51:56.889109: val_loss -0.5803 
2025-06-03 15:51:57.176653: Pseudo dice [np.float32(0.593)] 
2025-06-03 15:51:57.454910: Epoch time: 97.03 s 
2025-06-03 15:51:59.570246:  
2025-06-03 15:51:59.583546: Epoch 183 
2025-06-03 15:51:59.595054: Current learning rate: 0.00834 
2025-06-03 15:53:38.757229: train_loss -0.6296 
2025-06-03 15:53:38.774412: val_loss -0.6769 
2025-06-03 15:53:38.789235: Pseudo dice [np.float32(0.7641)] 
2025-06-03 15:53:38.803627: Epoch time: 99.19 s 
2025-06-03 15:53:40.503992:  
2025-06-03 15:53:40.520045: Epoch 184 
2025-06-03 15:53:40.534223: Current learning rate: 0.00833 
2025-06-03 15:55:17.824350: train_loss -0.662 
2025-06-03 15:55:18.101658: val_loss -0.6185 
2025-06-03 15:55:18.187491: Pseudo dice [np.float32(0.686)] 
2025-06-03 15:55:18.203638: Epoch time: 97.32 s 
2025-06-03 15:55:19.786514:  
2025-06-03 15:55:19.798514: Epoch 185 
2025-06-03 15:55:19.809833: Current learning rate: 0.00832 
2025-06-03 15:56:51.392546: train_loss -0.6259 
2025-06-03 15:56:51.561178: val_loss -0.6101 
2025-06-03 15:56:51.578137: Pseudo dice [np.float32(0.6141)] 
2025-06-03 15:56:51.592130: Epoch time: 91.61 s 
2025-06-03 15:56:53.602428:  
2025-06-03 15:56:53.630580: Epoch 186 
2025-06-03 15:56:53.647862: Current learning rate: 0.00831 
2025-06-03 15:58:23.050739: train_loss -0.6813 
2025-06-03 15:58:23.176970: val_loss -0.6303 
2025-06-03 15:58:23.384788: Pseudo dice [np.float32(0.7464)] 
2025-06-03 15:58:23.400110: Epoch time: 89.45 s 
2025-06-03 15:58:23.427181: Yayy! New best EMA pseudo Dice: 0.6816999912261963 
2025-06-03 15:58:25.943544:  
2025-06-03 15:58:25.962177: Epoch 187 
2025-06-03 15:58:25.977376: Current learning rate: 0.0083 
2025-06-03 15:59:54.925160: train_loss -0.643 
2025-06-03 15:59:55.037864: val_loss -0.6133 
2025-06-03 15:59:55.132974: Pseudo dice [np.float32(0.6268)] 
2025-06-03 15:59:55.224115: Epoch time: 88.98 s 
2025-06-03 15:59:56.439564:  
2025-06-03 15:59:56.451955: Epoch 188 
2025-06-03 15:59:56.463397: Current learning rate: 0.00829 
2025-06-03 16:01:25.489390: train_loss -0.6392 
2025-06-03 16:01:25.659304: val_loss -0.6037 
2025-06-03 16:01:25.995908: Pseudo dice [np.float32(0.6736)] 
2025-06-03 16:01:26.106052: Epoch time: 89.05 s 
2025-06-03 16:01:27.364562:  
2025-06-03 16:01:27.380816: Epoch 189 
2025-06-03 16:01:27.392219: Current learning rate: 0.00828 
2025-06-03 16:02:59.562815: train_loss -0.6345 
2025-06-03 16:02:59.726986: val_loss -0.6184 
2025-06-03 16:02:59.744044: Pseudo dice [np.float32(0.6881)] 
2025-06-03 16:02:59.759380: Epoch time: 92.2 s 
2025-06-03 16:03:01.515271:  
2025-06-03 16:03:01.533529: Epoch 190 
2025-06-03 16:03:01.544710: Current learning rate: 0.00827 
2025-06-03 16:04:30.907043: train_loss -0.6467 
2025-06-03 16:04:31.089388: val_loss -0.6332 
2025-06-03 16:04:31.161737: Pseudo dice [np.float32(0.6651)] 
2025-06-03 16:04:31.317953: Epoch time: 89.39 s 
2025-06-03 16:04:32.537722:  
2025-06-03 16:04:32.555610: Epoch 191 
2025-06-03 16:04:32.566975: Current learning rate: 0.00826 
2025-06-03 16:06:00.648515: train_loss -0.6495 
2025-06-03 16:06:00.738870: val_loss -0.6234 
2025-06-03 16:06:00.950117: Pseudo dice [np.float32(0.7347)] 
2025-06-03 16:06:01.048384: Epoch time: 88.11 s 
2025-06-03 16:06:01.154147: Yayy! New best EMA pseudo Dice: 0.6818000078201294 
2025-06-03 16:06:02.636007:  
2025-06-03 16:06:02.648489: Epoch 192 
2025-06-03 16:06:02.662856: Current learning rate: 0.00825 
2025-06-03 16:07:32.451314: train_loss -0.6348 
2025-06-03 16:07:32.467306: val_loss -0.5067 
2025-06-03 16:07:32.480688: Pseudo dice [np.float32(0.4948)] 
2025-06-03 16:07:32.494605: Epoch time: 89.82 s 
2025-06-03 16:07:34.100903:  
2025-06-03 16:07:34.113209: Epoch 193 
2025-06-03 16:07:34.123893: Current learning rate: 0.00824 
2025-06-03 16:09:08.201815: train_loss -0.6251 
2025-06-03 16:09:08.217636: val_loss -0.657 
2025-06-03 16:09:08.232693: Pseudo dice [np.float32(0.6942)] 
2025-06-03 16:09:08.247475: Epoch time: 94.1 s 
2025-06-03 16:09:09.707491:  
2025-06-03 16:09:09.722576: Epoch 194 
2025-06-03 16:09:09.733403: Current learning rate: 0.00824 
2025-06-03 16:10:38.738242: train_loss -0.6457 
2025-06-03 16:10:38.820450: val_loss -0.6692 
2025-06-03 16:10:38.997268: Pseudo dice [np.float32(0.6287)] 
2025-06-03 16:10:39.136166: Epoch time: 89.03 s 
2025-06-03 16:10:40.319959:  
2025-06-03 16:10:40.332348: Epoch 195 
2025-06-03 16:10:40.343099: Current learning rate: 0.00823 
2025-06-03 16:12:09.282014: train_loss -0.6394 
2025-06-03 16:12:09.298976: val_loss -0.661 
2025-06-03 16:12:09.313672: Pseudo dice [np.float32(0.7311)] 
2025-06-03 16:12:09.326383: Epoch time: 88.96 s 
2025-06-03 16:12:10.770813:  
2025-06-03 16:12:10.783453: Epoch 196 
2025-06-03 16:12:10.793438: Current learning rate: 0.00822 
2025-06-03 16:13:38.962240: train_loss -0.6557 
2025-06-03 16:13:38.986593: val_loss -0.5893 
2025-06-03 16:13:39.133178: Pseudo dice [np.float32(0.6661)] 
2025-06-03 16:13:39.294194: Epoch time: 88.19 s 
2025-06-03 16:13:40.756074:  
2025-06-03 16:13:40.774420: Epoch 197 
2025-06-03 16:13:40.785412: Current learning rate: 0.00821 
2025-06-03 16:15:08.911814: train_loss -0.6763 
2025-06-03 16:15:09.076310: val_loss -0.6501 
2025-06-03 16:15:09.262624: Pseudo dice [np.float32(0.6916)] 
2025-06-03 16:15:09.437171: Epoch time: 88.16 s 
2025-06-03 16:15:10.752169:  
2025-06-03 16:15:10.764888: Epoch 198 
2025-06-03 16:15:10.776006: Current learning rate: 0.0082 
2025-06-03 16:16:41.166522: train_loss -0.6243 
2025-06-03 16:16:41.184990: val_loss -0.6859 
2025-06-03 16:16:41.199907: Pseudo dice [np.float32(0.7354)] 
2025-06-03 16:16:41.214939: Epoch time: 90.42 s 
2025-06-03 16:16:42.462007:  
2025-06-03 16:16:42.480488: Epoch 199 
2025-06-03 16:16:42.495559: Current learning rate: 0.00819 
2025-06-03 16:18:13.637697: train_loss -0.6618 
2025-06-03 16:18:13.774170: val_loss -0.641 
2025-06-03 16:18:13.908607: Pseudo dice [np.float32(0.7082)] 
2025-06-03 16:18:14.120445: Epoch time: 91.18 s 
2025-06-03 16:18:15.817655:  
2025-06-03 16:18:15.830508: Epoch 200 
2025-06-03 16:18:15.841462: Current learning rate: 0.00818 
2025-06-03 16:19:43.465721: train_loss -0.6567 
2025-06-03 16:19:43.535406: val_loss -0.6469 
2025-06-03 16:19:43.714153: Pseudo dice [np.float32(0.7207)] 
2025-06-03 16:19:43.873401: Epoch time: 87.65 s 
2025-06-03 16:19:43.951437: Yayy! New best EMA pseudo Dice: 0.6847000122070312 
2025-06-03 16:19:45.652573:  
2025-06-03 16:19:45.671991: Epoch 201 
2025-06-03 16:19:45.689222: Current learning rate: 0.00817 
2025-06-03 16:21:16.638666: train_loss -0.6263 
2025-06-03 16:21:16.733281: val_loss -0.5818 
2025-06-03 16:21:16.815688: Pseudo dice [np.float32(0.6907)] 
2025-06-03 16:21:16.891514: Epoch time: 90.99 s 
2025-06-03 16:21:16.981561: Yayy! New best EMA pseudo Dice: 0.6852999925613403 
2025-06-03 16:21:18.534297:  
2025-06-03 16:21:18.548241: Epoch 202 
2025-06-03 16:21:18.561691: Current learning rate: 0.00816 
2025-06-03 16:22:48.340492: train_loss -0.6792 
2025-06-03 16:22:48.357924: val_loss -0.6587 
2025-06-03 16:22:48.373214: Pseudo dice [np.float32(0.7661)] 
2025-06-03 16:22:48.388608: Epoch time: 89.81 s 
2025-06-03 16:22:48.403577: Yayy! New best EMA pseudo Dice: 0.6934000253677368 
2025-06-03 16:22:50.101808:  
2025-06-03 16:22:50.129840: Epoch 203 
2025-06-03 16:22:50.141022: Current learning rate: 0.00815 
2025-06-03 16:24:21.581937: train_loss -0.6685 
2025-06-03 16:24:21.610951: val_loss -0.6665 
2025-06-03 16:24:21.633171: Pseudo dice [np.float32(0.7712)] 
2025-06-03 16:24:21.647733: Epoch time: 91.48 s 
2025-06-03 16:24:21.662705: Yayy! New best EMA pseudo Dice: 0.701200008392334 
2025-06-03 16:24:23.679274:  
2025-06-03 16:24:23.691718: Epoch 204 
2025-06-03 16:24:23.703622: Current learning rate: 0.00814 
2025-06-03 16:25:52.712753: train_loss -0.6934 
2025-06-03 16:25:52.847828: val_loss -0.673 
2025-06-03 16:25:53.133828: Pseudo dice [np.float32(0.6485)] 
2025-06-03 16:25:53.151618: Epoch time: 89.03 s 
2025-06-03 16:25:54.495102:  
2025-06-03 16:25:54.509827: Epoch 205 
2025-06-03 16:25:54.527036: Current learning rate: 0.00813 
2025-06-03 16:27:23.615229: train_loss -0.6534 
2025-06-03 16:27:23.632277: val_loss -0.5761 
2025-06-03 16:27:23.653242: Pseudo dice [np.float32(0.6636)] 
2025-06-03 16:27:23.668552: Epoch time: 89.12 s 
2025-06-03 16:27:24.951687:  
2025-06-03 16:27:24.970231: Epoch 206 
2025-06-03 16:27:24.986667: Current learning rate: 0.00813 
2025-06-03 16:28:54.446350: train_loss -0.5963 
2025-06-03 16:28:54.585211: val_loss -0.5909 
2025-06-03 16:28:54.601302: Pseudo dice [np.float32(0.6402)] 
2025-06-03 16:28:54.615959: Epoch time: 89.5 s 
2025-06-03 16:28:56.409240:  
2025-06-03 16:28:56.430417: Epoch 207 
2025-06-03 16:28:56.441741: Current learning rate: 0.00812 
2025-06-03 16:30:21.260465: train_loss -0.6475 
2025-06-03 16:30:21.452383: val_loss -0.6394 
2025-06-03 16:30:21.596803: Pseudo dice [np.float32(0.6963)] 
2025-06-03 16:30:21.791695: Epoch time: 84.85 s 
2025-06-03 16:30:23.439534:  
2025-06-03 16:30:23.458795: Epoch 208 
2025-06-03 16:30:23.469228: Current learning rate: 0.00811 
2025-06-03 16:31:50.396045: train_loss -0.6467 
2025-06-03 16:31:50.411970: val_loss -0.6641 
2025-06-03 16:31:50.427428: Pseudo dice [np.float32(0.7794)] 
2025-06-03 16:31:50.440702: Epoch time: 86.96 s 
2025-06-03 16:31:51.990627:  
2025-06-03 16:31:52.001846: Epoch 209 
2025-06-03 16:31:52.011628: Current learning rate: 0.0081 
2025-06-03 16:33:22.620355: train_loss -0.6488 
2025-06-03 16:33:22.638981: val_loss -0.6154 
2025-06-03 16:33:22.653950: Pseudo dice [np.float32(0.75)] 
2025-06-03 16:33:22.668721: Epoch time: 90.63 s 
2025-06-03 16:33:22.683342: Yayy! New best EMA pseudo Dice: 0.7027000188827515 
2025-06-03 16:33:24.180980:  
2025-06-03 16:33:24.201567: Epoch 210 
2025-06-03 16:33:24.217027: Current learning rate: 0.00809 
2025-06-03 16:34:51.295369: train_loss -0.6697 
2025-06-03 16:34:51.410738: val_loss -0.5642 
2025-06-03 16:34:51.625519: Pseudo dice [np.float32(0.6341)] 
2025-06-03 16:34:51.775257: Epoch time: 87.12 s 
2025-06-03 16:34:53.082017:  
2025-06-03 16:34:53.101190: Epoch 211 
2025-06-03 16:34:53.118538: Current learning rate: 0.00808 
2025-06-03 16:36:20.770365: train_loss -0.6938 
2025-06-03 16:36:20.792979: val_loss -0.6111 
2025-06-03 16:36:20.806300: Pseudo dice [np.float32(0.6865)] 
2025-06-03 16:36:20.827468: Epoch time: 87.69 s 
2025-06-03 16:36:22.305423:  
2025-06-03 16:36:22.334854: Epoch 212 
2025-06-03 16:36:22.351743: Current learning rate: 0.00807 
2025-06-03 16:37:51.198894: train_loss -0.6421 
2025-06-03 16:37:51.307014: val_loss -0.6959 
2025-06-03 16:37:51.501625: Pseudo dice [np.float32(0.7029)] 
2025-06-03 16:37:51.703280: Epoch time: 88.89 s 
2025-06-03 16:37:53.466328:  
2025-06-03 16:37:53.493172: Epoch 213 
2025-06-03 16:37:53.517609: Current learning rate: 0.00806 
2025-06-03 16:39:22.499428: train_loss -0.6429 
2025-06-03 16:39:22.521672: val_loss -0.7292 
2025-06-03 16:39:22.536120: Pseudo dice [np.float32(0.8271)] 
2025-06-03 16:39:22.550762: Epoch time: 89.03 s 
2025-06-03 16:39:22.565247: Yayy! New best EMA pseudo Dice: 0.7088000178337097 
2025-06-03 16:39:25.008992:  
2025-06-03 16:39:25.022520: Epoch 214 
2025-06-03 16:39:25.033911: Current learning rate: 0.00805 
2025-06-03 16:40:54.905545: train_loss -0.6745 
2025-06-03 16:40:54.929362: val_loss -0.647 
2025-06-03 16:40:54.944025: Pseudo dice [np.float32(0.7056)] 
2025-06-03 16:40:54.958992: Epoch time: 89.9 s 
2025-06-03 16:40:57.527982:  
2025-06-03 16:40:57.558222: Epoch 215 
2025-06-03 16:40:57.571227: Current learning rate: 0.00804 
2025-06-03 16:42:26.792741: train_loss -0.6583 
2025-06-03 16:42:26.964335: val_loss -0.6279 
2025-06-03 16:42:27.179883: Pseudo dice [np.float32(0.6592)] 
2025-06-03 16:42:27.327154: Epoch time: 89.27 s 
2025-06-03 16:42:28.797963:  
2025-06-03 16:42:28.810391: Epoch 216 
2025-06-03 16:42:28.821030: Current learning rate: 0.00803 
2025-06-03 16:43:55.774652: train_loss -0.6567 
2025-06-03 16:43:55.789083: val_loss -0.6679 
2025-06-03 16:43:55.825226: Pseudo dice [np.float32(0.6605)] 
2025-06-03 16:43:56.025020: Epoch time: 86.98 s 
2025-06-03 16:43:57.364566:  
2025-06-03 16:43:57.377228: Epoch 217 
2025-06-03 16:43:57.390503: Current learning rate: 0.00802 
2025-06-03 16:45:23.394077: train_loss -0.658 
2025-06-03 16:45:23.608545: val_loss -0.6164 
2025-06-03 16:45:23.766899: Pseudo dice [np.float32(0.6994)] 
2025-06-03 16:45:23.925052: Epoch time: 86.03 s 
2025-06-03 16:45:25.200531:  
2025-06-03 16:45:25.215417: Epoch 218 
2025-06-03 16:45:25.230354: Current learning rate: 0.00801 
2025-06-03 16:46:54.238068: train_loss -0.639 
2025-06-03 16:46:54.335586: val_loss -0.6242 
2025-06-03 16:46:54.450801: Pseudo dice [np.float32(0.649)] 
2025-06-03 16:46:54.565959: Epoch time: 89.04 s 
2025-06-03 16:46:55.702944:  
2025-06-03 16:46:55.714757: Epoch 219 
2025-06-03 16:46:55.729344: Current learning rate: 0.00801 
2025-06-03 16:48:22.066956: train_loss -0.6222 
2025-06-03 16:48:22.086541: val_loss -0.6424 
2025-06-03 16:48:22.101882: Pseudo dice [np.float32(0.7436)] 
2025-06-03 16:48:22.117297: Epoch time: 86.37 s 
2025-06-03 16:48:23.947001:  
2025-06-03 16:48:23.959170: Epoch 220 
2025-06-03 16:48:23.969001: Current learning rate: 0.008 
2025-06-03 16:49:44.003449: train_loss -0.6702 
2025-06-03 16:49:44.089590: val_loss -0.7068 
2025-06-03 16:49:44.205670: Pseudo dice [np.float32(0.7629)] 
2025-06-03 16:49:44.273633: Epoch time: 80.06 s 
2025-06-03 16:49:45.414499:  
2025-06-03 16:49:45.426940: Epoch 221 
2025-06-03 16:49:45.438538: Current learning rate: 0.00799 
2025-06-03 16:51:08.139877: train_loss -0.6622 
2025-06-03 16:51:08.164998: val_loss -0.6262 
2025-06-03 16:51:08.179807: Pseudo dice [np.float32(0.7051)] 
2025-06-03 16:51:08.195892: Epoch time: 82.73 s 
2025-06-03 16:51:09.964818:  
2025-06-03 16:51:09.984172: Epoch 222 
2025-06-03 16:51:10.000047: Current learning rate: 0.00798 
2025-06-03 16:52:30.873782: train_loss -0.6093 
2025-06-03 16:52:30.970050: val_loss -0.6448 
2025-06-03 16:52:31.087951: Pseudo dice [np.float32(0.7276)] 
2025-06-03 16:52:31.105702: Epoch time: 80.91 s 
2025-06-03 16:52:32.961614:  
2025-06-03 16:52:32.981407: Epoch 223 
2025-06-03 16:52:33.002006: Current learning rate: 0.00797 
2025-06-03 16:53:47.532364: train_loss -0.6156 
2025-06-03 16:53:47.558368: val_loss -0.6167 
2025-06-03 16:53:47.652771: Pseudo dice [np.float32(0.683)] 
2025-06-03 16:53:47.732939: Epoch time: 74.57 s 
2025-06-03 16:53:49.211313:  
2025-06-03 16:53:49.228768: Epoch 224 
2025-06-03 16:53:49.239413: Current learning rate: 0.00796 
2025-06-03 16:55:12.499963: train_loss -0.6505 
2025-06-03 16:55:12.519753: val_loss -0.6244 
2025-06-03 16:55:12.533869: Pseudo dice [np.float32(0.6513)] 
2025-06-03 16:55:12.547969: Epoch time: 83.29 s 
2025-06-03 16:55:14.609447:  
2025-06-03 16:55:14.634514: Epoch 225 
2025-06-03 16:55:14.644276: Current learning rate: 0.00795 
2025-06-03 16:56:46.292398: train_loss -0.6432 
2025-06-03 16:56:46.311752: val_loss -0.6473 
2025-06-03 16:56:46.326402: Pseudo dice [np.float32(0.7023)] 
2025-06-03 16:56:46.340117: Epoch time: 91.68 s 
2025-06-03 16:56:47.454551:  
2025-06-03 16:56:47.476719: Epoch 226 
2025-06-03 16:56:47.489751: Current learning rate: 0.00794 
2025-06-03 16:58:17.483106: train_loss -0.647 
2025-06-03 16:58:17.594799: val_loss -0.6236 
2025-06-03 16:58:17.767803: Pseudo dice [np.float32(0.5754)] 
2025-06-03 16:58:17.892382: Epoch time: 90.03 s 
2025-06-03 16:58:18.974231:  
2025-06-03 16:58:19.002114: Epoch 227 
2025-06-03 16:58:19.028590: Current learning rate: 0.00793 
2025-06-03 16:59:46.339940: train_loss -0.6476 
2025-06-03 16:59:46.365621: val_loss -0.6633 
2025-06-03 16:59:46.381044: Pseudo dice [np.float32(0.6873)] 
2025-06-03 16:59:46.394320: Epoch time: 87.37 s 
2025-06-03 16:59:48.466576:  
2025-06-03 16:59:48.478372: Epoch 228 
2025-06-03 16:59:48.488223: Current learning rate: 0.00792 
2025-06-03 17:01:17.866959: train_loss -0.6951 
2025-06-03 17:01:18.003663: val_loss -0.6942 
2025-06-03 17:01:18.213081: Pseudo dice [np.float32(0.7669)] 
2025-06-03 17:01:18.385350: Epoch time: 89.4 s 
2025-06-03 17:01:19.869028:  
2025-06-03 17:01:19.882382: Epoch 229 
2025-06-03 17:01:19.894288: Current learning rate: 0.00791 
2025-06-03 17:02:50.919710: train_loss -0.6666 
2025-06-03 17:02:51.141104: val_loss -0.6766 
2025-06-03 17:02:51.157393: Pseudo dice [np.float32(0.725)] 
2025-06-03 17:02:51.173137: Epoch time: 91.05 s 
2025-06-03 17:02:52.476559:  
2025-06-03 17:02:52.496118: Epoch 230 
2025-06-03 17:02:52.506843: Current learning rate: 0.0079 
2025-06-03 17:04:23.415772: train_loss -0.6662 
2025-06-03 17:04:23.570959: val_loss -0.5408 
2025-06-03 17:04:23.695258: Pseudo dice [np.float32(0.6075)] 
2025-06-03 17:04:24.206457: Epoch time: 90.94 s 
2025-06-03 17:04:25.473963:  
2025-06-03 17:04:25.488552: Epoch 231 
2025-06-03 17:04:25.502497: Current learning rate: 0.00789 
2025-06-03 17:05:46.343944: train_loss -0.6409 
2025-06-03 17:05:46.367416: val_loss -0.5906 
2025-06-03 17:05:46.386560: Pseudo dice [np.float32(0.6833)] 
2025-06-03 17:05:46.402477: Epoch time: 80.87 s 
2025-06-03 17:05:47.345484:  
2025-06-03 17:05:47.363300: Epoch 232 
2025-06-03 17:05:47.373736: Current learning rate: 0.00789 
2025-06-03 17:07:13.356262: train_loss -0.647 
2025-06-03 17:07:13.375732: val_loss -0.6413 
2025-06-03 17:07:13.390502: Pseudo dice [np.float32(0.6629)] 
2025-06-03 17:07:13.404856: Epoch time: 86.01 s 
2025-06-03 17:07:15.098943:  
2025-06-03 17:07:15.112603: Epoch 233 
2025-06-03 17:07:15.123893: Current learning rate: 0.00788 
2025-06-03 17:08:47.067812: train_loss -0.6489 
2025-06-03 17:08:47.087511: val_loss -0.6333 
2025-06-03 17:08:47.102715: Pseudo dice [np.float32(0.6164)] 
2025-06-03 17:08:47.117510: Epoch time: 91.97 s 
2025-06-03 17:08:49.284948:  
2025-06-03 17:08:49.310565: Epoch 234 
2025-06-03 17:08:49.334305: Current learning rate: 0.00787 
2025-06-03 17:10:21.813852: train_loss -0.6651 
2025-06-03 17:10:22.018917: val_loss -0.6431 
2025-06-03 17:10:22.206688: Pseudo dice [np.float32(0.7301)] 
2025-06-03 17:10:22.919925: Epoch time: 92.53 s 
2025-06-03 17:10:24.766119:  
2025-06-03 17:10:24.788503: Epoch 235 
2025-06-03 17:10:24.804263: Current learning rate: 0.00786 
2025-06-03 17:11:55.530272: train_loss -0.6877 
2025-06-03 17:11:55.550827: val_loss -0.6032 
2025-06-03 17:11:55.564654: Pseudo dice [np.float32(0.6554)] 
2025-06-03 17:11:55.578935: Epoch time: 90.77 s 
2025-06-03 17:11:57.410453:  
2025-06-03 17:11:57.422419: Epoch 236 
2025-06-03 17:11:57.432757: Current learning rate: 0.00785 
2025-06-03 17:13:28.499071: train_loss -0.6552 
2025-06-03 17:13:28.735938: val_loss -0.5995 
2025-06-03 17:13:28.990565: Pseudo dice [np.float32(0.6411)] 
2025-06-03 17:13:29.266895: Epoch time: 91.09 s 
2025-06-03 17:13:30.539474:  
2025-06-03 17:13:30.552099: Epoch 237 
2025-06-03 17:13:30.564426: Current learning rate: 0.00784 
2025-06-03 17:15:02.217604: train_loss -0.6802 
2025-06-03 17:15:02.236182: val_loss -0.6248 
2025-06-03 17:15:02.251402: Pseudo dice [np.float32(0.7022)] 
2025-06-03 17:15:02.265362: Epoch time: 91.68 s 
2025-06-03 17:15:03.822636:  
2025-06-03 17:15:03.835228: Epoch 238 
2025-06-03 17:15:03.845645: Current learning rate: 0.00783 
2025-06-03 17:16:44.757091: train_loss -0.6627 
2025-06-03 17:16:45.240555: val_loss -0.5634 
2025-06-03 17:16:45.743420: Pseudo dice [np.float32(0.5322)] 
2025-06-03 17:16:46.562597: Epoch time: 100.94 s 
2025-06-03 17:16:49.965567:  
2025-06-03 17:16:50.006560: Epoch 239 
2025-06-03 17:16:50.026862: Current learning rate: 0.00782 
2025-06-03 17:18:55.053792: train_loss -0.6643 
2025-06-03 17:18:55.210090: val_loss -0.5906 
2025-06-03 17:18:56.016289: Pseudo dice [np.float32(0.6492)] 
2025-06-03 17:18:56.535694: Epoch time: 125.09 s 
2025-06-03 17:19:00.614854:  
2025-06-03 17:19:00.733689: Epoch 240 
2025-06-03 17:19:00.749400: Current learning rate: 0.00781 
2025-06-03 17:21:07.593544: train_loss -0.6342 
2025-06-03 17:21:07.613033: val_loss -0.612 
2025-06-03 17:21:07.627650: Pseudo dice [np.float32(0.6723)] 
2025-06-03 17:21:07.642040: Epoch time: 126.98 s 
2025-06-03 17:21:11.925725:  
2025-06-03 17:21:11.941113: Epoch 241 
2025-06-03 17:21:11.954819: Current learning rate: 0.0078 
2025-06-03 17:23:19.263893: train_loss -0.6389 
2025-06-03 17:23:19.283545: val_loss -0.6196 
2025-06-03 17:23:19.298721: Pseudo dice [np.float32(0.6407)] 
2025-06-03 17:23:19.313845: Epoch time: 127.34 s 
2025-06-03 17:23:23.688343:  
2025-06-03 17:23:23.701786: Epoch 242 
2025-06-03 17:23:23.712943: Current learning rate: 0.00779 
2025-06-03 17:25:30.125370: train_loss -0.6312 
2025-06-03 17:25:30.490742: val_loss -0.6477 
2025-06-03 17:25:30.763559: Pseudo dice [np.float32(0.8054)] 
2025-06-03 17:25:31.189235: Epoch time: 126.44 s 
2025-06-03 17:25:34.536319:  
2025-06-03 17:25:34.553328: Epoch 243 
2025-06-03 17:25:34.566599: Current learning rate: 0.00778 
2025-06-03 17:27:44.570330: train_loss -0.6625 
2025-06-03 17:27:44.587646: val_loss -0.6847 
2025-06-03 17:27:44.603339: Pseudo dice [np.float32(0.7715)] 
2025-06-03 17:27:44.617458: Epoch time: 130.04 s 
2025-06-03 17:27:48.691869:  
2025-06-03 17:27:48.772450: Epoch 244 
2025-06-03 17:27:48.809965: Current learning rate: 0.00777 
2025-06-03 17:30:02.710503: train_loss -0.6404 
2025-06-03 17:30:03.061559: val_loss -0.612 
2025-06-03 17:30:03.481284: Pseudo dice [np.float32(0.5993)] 
2025-06-03 17:30:03.905479: Epoch time: 134.02 s 
2025-06-03 17:30:06.698316:  
2025-06-03 17:30:06.718904: Epoch 245 
2025-06-03 17:30:06.734202: Current learning rate: 0.00777 
2025-06-03 17:32:20.233252: train_loss -0.6688 
2025-06-03 17:32:20.378171: val_loss -0.5913 
2025-06-03 17:32:20.618823: Pseudo dice [np.float32(0.6809)] 
2025-06-03 17:32:20.843633: Epoch time: 133.54 s 
2025-06-03 17:32:23.352066:  
2025-06-03 17:32:23.485995: Epoch 246 
2025-06-03 17:32:23.649325: Current learning rate: 0.00776 
2025-06-03 17:34:36.954089: train_loss -0.6744 
2025-06-03 17:34:37.535655: val_loss -0.6431 
2025-06-03 17:34:37.994117: Pseudo dice [np.float32(0.7355)] 
2025-06-03 17:34:38.314996: Epoch time: 133.6 s 
2025-06-03 17:34:41.492401:  
2025-06-03 17:34:41.654814: Epoch 247 
2025-06-03 17:34:41.726721: Current learning rate: 0.00775 
2025-06-03 17:36:53.666893: train_loss -0.617 
2025-06-03 17:36:53.688242: val_loss -0.6393 
2025-06-03 17:36:53.702310: Pseudo dice [np.float32(0.7564)] 
2025-06-03 17:36:53.717178: Epoch time: 132.18 s 
2025-06-03 17:36:58.457118:  
2025-06-03 17:36:58.530391: Epoch 248 
2025-06-03 17:36:58.575901: Current learning rate: 0.00774 
2025-06-03 17:39:06.489516: train_loss -0.6452 
2025-06-03 17:39:07.005001: val_loss -0.6136 
2025-06-03 17:39:07.519129: Pseudo dice [np.float32(0.6686)] 
2025-06-03 17:39:08.085037: Epoch time: 128.03 s 
2025-06-03 17:39:13.986376:  
2025-06-03 17:39:14.142089: Epoch 249 
2025-06-03 17:39:14.306870: Current learning rate: 0.00773 
2025-06-03 17:41:24.081895: train_loss -0.6215 
2025-06-03 17:41:24.456658: val_loss -0.5957 
2025-06-03 17:41:24.866990: Pseudo dice [np.float32(0.6789)] 
2025-06-03 17:41:25.217095: Epoch time: 130.1 s 
2025-06-03 17:41:30.112924:  
2025-06-03 17:41:30.129686: Epoch 250 
2025-06-03 17:41:30.147566: Current learning rate: 0.00772 
2025-06-03 17:43:40.558686: train_loss -0.6224 
2025-06-03 17:43:40.582740: val_loss -0.617 
2025-06-03 17:43:40.601865: Pseudo dice [np.float32(0.6987)] 
2025-06-03 17:43:40.621561: Epoch time: 130.45 s 
2025-06-03 17:43:45.793082:  
2025-06-03 17:43:45.830011: Epoch 251 
2025-06-03 17:43:45.861386: Current learning rate: 0.00771 
2025-06-03 17:45:52.166080: train_loss -0.6595 
2025-06-03 17:45:52.894571: val_loss -0.6248 
2025-06-03 17:45:53.072478: Pseudo dice [np.float32(0.6349)] 
2025-06-03 17:45:53.089195: Epoch time: 126.38 s 
2025-06-03 17:45:56.537485:  
2025-06-03 17:45:56.559048: Epoch 252 
2025-06-03 17:45:56.580563: Current learning rate: 0.0077 
2025-06-03 17:48:06.360426: train_loss -0.6775 
2025-06-03 17:48:06.379654: val_loss -0.6787 
2025-06-03 17:48:06.394361: Pseudo dice [np.float32(0.693)] 
2025-06-03 17:48:06.408576: Epoch time: 129.83 s 
2025-06-03 17:48:11.416459:  
2025-06-03 17:48:11.594162: Epoch 253 
2025-06-03 17:48:11.664322: Current learning rate: 0.00769 
2025-06-03 17:50:18.268570: train_loss -0.6594 
2025-06-03 17:50:18.626407: val_loss -0.6998 
2025-06-03 17:50:18.809641: Pseudo dice [np.float32(0.765)] 
2025-06-03 17:50:18.823460: Epoch time: 126.85 s 
2025-06-03 17:50:24.127041:  
2025-06-03 17:50:24.149696: Epoch 254 
2025-06-03 17:50:24.169752: Current learning rate: 0.00768 
2025-06-03 17:52:34.506717: train_loss -0.6804 
2025-06-03 17:52:34.531951: val_loss -0.6225 
2025-06-03 17:52:34.884415: Pseudo dice [np.float32(0.6619)] 
2025-06-03 17:52:35.410672: Epoch time: 130.38 s 
2025-06-03 17:52:40.012094:  
2025-06-03 17:52:40.028383: Epoch 255 
2025-06-03 17:52:40.045047: Current learning rate: 0.00767 
2025-06-03 17:54:49.213713: train_loss -0.6546 
2025-06-03 17:54:49.236492: val_loss -0.6232 
2025-06-03 17:54:49.251021: Pseudo dice [np.float32(0.7176)] 
2025-06-03 17:54:49.265888: Epoch time: 129.2 s 
2025-06-03 17:54:53.180614:  
2025-06-03 17:54:53.199362: Epoch 256 
2025-06-03 17:54:53.212426: Current learning rate: 0.00766 
2025-06-03 17:56:58.462437: train_loss -0.6769 
2025-06-03 17:56:58.627029: val_loss -0.6533 
2025-06-03 17:56:58.645086: Pseudo dice [np.float32(0.7389)] 
2025-06-03 17:56:58.660127: Epoch time: 125.28 s 
2025-06-03 17:57:05.203214:  
2025-06-03 17:57:05.224984: Epoch 257 
2025-06-03 17:57:05.273411: Current learning rate: 0.00765 
2025-06-03 17:59:14.812279: train_loss -0.6782 
2025-06-03 17:59:15.223724: val_loss -0.6037 
2025-06-03 17:59:15.700269: Pseudo dice [np.float32(0.6256)] 
2025-06-03 17:59:15.822245: Epoch time: 129.61 s 
2025-06-03 17:59:18.607775:  
2025-06-03 17:59:18.641117: Epoch 258 
2025-06-03 17:59:18.657941: Current learning rate: 0.00764 
2025-06-03 18:01:28.231311: train_loss -0.6444 
2025-06-03 18:01:28.619148: val_loss -0.7022 
2025-06-03 18:01:28.702078: Pseudo dice [np.float32(0.7255)] 
2025-06-03 18:01:28.885783: Epoch time: 129.63 s 
2025-06-03 18:01:31.385725:  
2025-06-03 18:01:31.446239: Epoch 259 
2025-06-03 18:01:31.486174: Current learning rate: 0.00764 
2025-06-03 18:03:42.307095: train_loss -0.701 
2025-06-03 18:03:42.511729: val_loss -0.602 
2025-06-03 18:03:42.656654: Pseudo dice [np.float32(0.6403)] 
2025-06-03 18:03:42.670090: Epoch time: 130.92 s 
2025-06-03 18:03:46.410691:  
2025-06-03 18:03:46.429389: Epoch 260 
2025-06-03 18:03:46.446017: Current learning rate: 0.00763 
2025-06-03 18:05:49.482632: train_loss -0.6909 
2025-06-03 18:05:49.974548: val_loss -0.666 
2025-06-03 18:05:50.099403: Pseudo dice [np.float32(0.7157)] 
2025-06-03 18:05:50.114104: Epoch time: 123.07 s 
2025-06-03 18:05:55.849475:  
2025-06-03 18:05:55.869435: Epoch 261 
2025-06-03 18:05:55.890568: Current learning rate: 0.00762 
2025-06-03 18:08:02.375339: train_loss -0.6755 
2025-06-03 18:08:02.466753: val_loss -0.5934 
2025-06-03 18:08:02.483712: Pseudo dice [np.float32(0.6183)] 
2025-06-03 18:08:02.498597: Epoch time: 126.53 s 
2025-06-03 18:08:04.974053:  
2025-06-03 18:08:04.987128: Epoch 262 
2025-06-03 18:08:04.999080: Current learning rate: 0.00761 
2025-06-03 18:10:15.355023: train_loss -0.6555 
2025-06-03 18:10:15.693966: val_loss -0.6669 
2025-06-03 18:10:16.047972: Pseudo dice [np.float32(0.6614)] 
2025-06-03 18:10:16.349846: Epoch time: 130.38 s 
2025-06-03 18:10:19.884925:  
2025-06-03 18:10:19.905034: Epoch 263 
2025-06-03 18:10:19.923582: Current learning rate: 0.0076 
2025-06-03 18:12:31.627484: train_loss -0.6391 
2025-06-03 18:12:31.645783: val_loss -0.602 
2025-06-03 18:12:31.661366: Pseudo dice [np.float32(0.6834)] 
2025-06-03 18:12:31.674409: Epoch time: 131.74 s 
2025-06-03 18:12:34.437521:  
2025-06-03 18:12:34.538539: Epoch 264 
2025-06-03 18:12:34.558115: Current learning rate: 0.00759 
2025-06-03 18:14:46.529343: train_loss -0.6213 
2025-06-03 18:14:46.731066: val_loss -0.6586 
2025-06-03 18:14:46.902785: Pseudo dice [np.float32(0.675)] 
2025-06-03 18:14:47.183409: Epoch time: 132.09 s 
2025-06-03 18:14:50.279527:  
2025-06-03 18:14:50.388348: Epoch 265 
2025-06-03 18:14:50.457532: Current learning rate: 0.00758 
2025-06-03 18:17:01.895359: train_loss -0.6188 
2025-06-03 18:17:02.260195: val_loss -0.6642 
2025-06-03 18:17:02.275971: Pseudo dice [np.float32(0.6775)] 
2025-06-03 18:17:02.290061: Epoch time: 131.62 s 
2025-06-03 18:17:05.041315:  
2025-06-03 18:17:05.119472: Epoch 266 
2025-06-03 18:17:05.146672: Current learning rate: 0.00757 
2025-06-03 18:19:14.753975: train_loss -0.6595 
2025-06-03 18:19:14.775314: val_loss -0.704 
2025-06-03 18:19:14.790391: Pseudo dice [np.float32(0.7059)] 
2025-06-03 18:19:14.804312: Epoch time: 129.71 s 
2025-06-03 18:19:18.933488:  
2025-06-03 18:19:18.960007: Epoch 267 
2025-06-03 18:19:19.032741: Current learning rate: 0.00756 
2025-06-03 18:21:30.448014: train_loss -0.6346 
2025-06-03 18:21:31.018735: val_loss -0.6476 
2025-06-03 18:21:31.228886: Pseudo dice [np.float32(0.7081)] 
2025-06-03 18:21:31.247183: Epoch time: 131.52 s 
2025-06-03 18:21:35.667790:  
2025-06-03 18:21:35.852856: Epoch 268 
2025-06-03 18:21:36.011577: Current learning rate: 0.00755 
2025-06-03 18:23:42.643131: train_loss -0.6617 
2025-06-03 18:23:42.668208: val_loss -0.6429 
2025-06-03 18:23:42.682671: Pseudo dice [np.float32(0.7059)] 
2025-06-03 18:23:42.697574: Epoch time: 126.98 s 
2025-06-03 18:23:48.637745:  
2025-06-03 18:23:48.805670: Epoch 269 
2025-06-03 18:23:48.826418: Current learning rate: 0.00754 
2025-06-03 18:26:00.051085: train_loss -0.6954 
2025-06-03 18:26:00.074395: val_loss -0.7113 
2025-06-03 18:26:00.089880: Pseudo dice [np.float32(0.7926)] 
2025-06-03 18:26:00.109542: Epoch time: 131.42 s 
2025-06-03 18:26:07.247396:  
2025-06-03 18:26:07.419863: Epoch 270 
2025-06-03 18:26:07.644465: Current learning rate: 0.00753 
2025-06-03 18:28:15.451145: train_loss -0.6648 
2025-06-03 18:28:15.627460: val_loss -0.7093 
2025-06-03 18:28:15.645484: Pseudo dice [np.float32(0.7257)] 
2025-06-03 18:28:15.661266: Epoch time: 128.26 s 
2025-06-03 18:28:20.653617:  
2025-06-03 18:28:20.675627: Epoch 271 
2025-06-03 18:28:20.695221: Current learning rate: 0.00752 
2025-06-03 18:30:29.900578: train_loss -0.6588 
2025-06-03 18:30:30.368279: val_loss -0.5964 
2025-06-03 18:30:30.389151: Pseudo dice [np.float32(0.6576)] 
2025-06-03 18:30:30.405093: Epoch time: 129.25 s 
2025-06-03 18:30:36.061928:  
2025-06-03 18:30:36.225774: Epoch 272 
2025-06-03 18:30:36.439242: Current learning rate: 0.00751 
2025-06-03 18:32:43.775326: train_loss -0.6563 
2025-06-03 18:32:43.931648: val_loss -0.6004 
2025-06-03 18:32:43.949126: Pseudo dice [np.float32(0.701)] 
2025-06-03 18:32:43.966939: Epoch time: 127.72 s 
2025-06-03 18:32:49.419742:  
2025-06-03 18:32:49.570947: Epoch 273 
2025-06-03 18:32:49.735731: Current learning rate: 0.00751 
2025-06-03 18:35:04.815685: train_loss -0.6513 
2025-06-03 18:35:05.334524: val_loss -0.6546 
2025-06-03 18:35:05.885025: Pseudo dice [np.float32(0.7542)] 
2025-06-03 18:35:06.419426: Epoch time: 135.4 s 
2025-06-03 18:35:11.112739:  
2025-06-03 18:35:11.131969: Epoch 274 
2025-06-03 18:35:11.151115: Current learning rate: 0.0075 
2025-06-03 18:37:25.752396: train_loss -0.6597 
2025-06-03 18:37:26.130742: val_loss -0.6705 
2025-06-03 18:37:26.408489: Pseudo dice [np.float32(0.7019)] 
2025-06-03 18:37:26.424491: Epoch time: 134.64 s 
2025-06-03 18:37:29.975754:  
2025-06-03 18:37:30.045061: Epoch 275 
2025-06-03 18:37:30.064904: Current learning rate: 0.00749 
2025-06-03 18:39:40.893925: train_loss -0.6429 
2025-06-03 18:39:40.915250: val_loss -0.6065 
2025-06-03 18:39:40.931332: Pseudo dice [np.float32(0.6559)] 
2025-06-03 18:39:40.945506: Epoch time: 130.92 s 
2025-06-03 18:39:44.761953:  
2025-06-03 18:39:44.942051: Epoch 276 
2025-06-03 18:39:44.994524: Current learning rate: 0.00748 
2025-06-03 18:41:50.653018: train_loss -0.6777 
2025-06-03 18:41:51.040166: val_loss -0.6153 
2025-06-03 18:41:51.765409: Pseudo dice [np.float32(0.7233)] 
2025-06-03 18:41:52.159652: Epoch time: 125.89 s 
2025-06-03 18:41:57.768489:  
2025-06-03 18:41:57.788965: Epoch 277 
2025-06-03 18:41:57.804721: Current learning rate: 0.00747 
2025-06-03 18:44:08.772050: train_loss -0.6162 
2025-06-03 18:44:08.792116: val_loss -0.6049 
2025-06-03 18:44:08.936785: Pseudo dice [np.float32(0.6839)] 
2025-06-03 18:44:08.953187: Epoch time: 131.01 s 
2025-06-03 18:44:13.403159:  
2025-06-03 18:44:13.424354: Epoch 278 
2025-06-03 18:44:13.442685: Current learning rate: 0.00746 
2025-06-03 18:46:22.226171: train_loss -0.6354 
2025-06-03 18:46:22.484319: val_loss -0.59 
2025-06-03 18:46:22.500908: Pseudo dice [np.float32(0.7063)] 
2025-06-03 18:46:22.517877: Epoch time: 128.83 s 
2025-06-03 18:46:25.729347:  
2025-06-03 18:46:25.753399: Epoch 279 
2025-06-03 18:46:25.772759: Current learning rate: 0.00745 
2025-06-03 18:48:31.062265: train_loss -0.6405 
2025-06-03 18:48:31.467054: val_loss -0.681 
2025-06-03 18:48:31.484615: Pseudo dice [np.float32(0.712)] 
2025-06-03 18:48:31.499904: Epoch time: 125.34 s 
2025-06-03 18:48:34.747482:  
2025-06-03 18:48:34.854836: Epoch 280 
2025-06-03 18:48:34.868880: Current learning rate: 0.00744 
2025-06-03 18:50:42.851836: train_loss -0.654 
2025-06-03 18:50:43.018121: val_loss -0.603 
2025-06-03 18:50:43.379300: Pseudo dice [np.float32(0.6797)] 
2025-06-03 18:50:43.755685: Epoch time: 128.11 s 
2025-06-03 18:50:45.735252:  
2025-06-03 18:50:45.746906: Epoch 281 
2025-06-03 18:50:45.759943: Current learning rate: 0.00743 
2025-06-03 18:52:56.985260: train_loss -0.6657 
2025-06-03 18:52:57.003951: val_loss -0.6351 
2025-06-03 18:52:57.019383: Pseudo dice [np.float32(0.7502)] 
2025-06-03 18:52:57.033478: Epoch time: 131.25 s 
2025-06-03 18:52:59.716115:  
2025-06-03 18:52:59.793664: Epoch 282 
2025-06-03 18:52:59.846730: Current learning rate: 0.00742 
2025-06-03 18:55:07.403068: train_loss -0.6672 
2025-06-03 18:55:07.427659: val_loss -0.5944 
2025-06-03 18:55:07.442326: Pseudo dice [np.float32(0.6469)] 
2025-06-03 18:55:07.456486: Epoch time: 127.69 s 
2025-06-03 18:55:11.551836:  
2025-06-03 18:55:11.664804: Epoch 283 
2025-06-03 18:55:11.805554: Current learning rate: 0.00741 
2025-06-03 18:57:23.519775: train_loss -0.6615 
2025-06-03 18:57:23.720300: val_loss -0.6142 
2025-06-03 18:57:23.980427: Pseudo dice [np.float32(0.6447)] 
2025-06-03 18:57:24.114823: Epoch time: 131.97 s 
2025-06-03 18:57:26.227051:  
2025-06-03 18:57:26.242984: Epoch 284 
2025-06-03 18:57:26.257468: Current learning rate: 0.0074 
2025-06-03 18:59:39.070805: train_loss -0.6739 
2025-06-03 18:59:39.476922: val_loss -0.616 
2025-06-03 18:59:39.931803: Pseudo dice [np.float32(0.7035)] 
2025-06-03 18:59:40.356006: Epoch time: 132.85 s 
2025-06-03 18:59:43.676108:  
2025-06-03 18:59:43.693242: Epoch 285 
2025-06-03 18:59:43.707631: Current learning rate: 0.00739 
2025-06-03 19:01:51.083503: train_loss -0.6858 
2025-06-03 19:01:51.453061: val_loss -0.6429 
2025-06-03 19:01:51.847983: Pseudo dice [np.float32(0.6772)] 
2025-06-03 19:01:52.228947: Epoch time: 127.41 s 
2025-06-03 19:01:56.844723:  
2025-06-03 19:01:57.010482: Epoch 286 
2025-06-03 19:01:57.049812: Current learning rate: 0.00738 
2025-06-03 19:04:07.608073: train_loss -0.6722 
2025-06-03 19:04:07.629187: val_loss -0.6784 
2025-06-03 19:04:07.646033: Pseudo dice [np.float32(0.7119)] 
2025-06-03 19:04:07.661672: Epoch time: 130.77 s 
2025-06-03 19:04:12.376433:  
2025-06-03 19:04:12.391826: Epoch 287 
2025-06-03 19:04:12.407006: Current learning rate: 0.00738 
2025-06-03 19:06:19.653706: train_loss -0.6742 
2025-06-03 19:06:20.166759: val_loss -0.6907 
2025-06-03 19:06:20.842062: Pseudo dice [np.float32(0.7584)] 
2025-06-03 19:06:21.676256: Epoch time: 127.28 s 
2025-06-03 19:06:25.579877:  
2025-06-03 19:06:25.602989: Epoch 288 
2025-06-03 19:06:25.660905: Current learning rate: 0.00737 
2025-06-03 19:08:32.812376: train_loss -0.6497 
2025-06-03 19:08:33.170218: val_loss -0.694 
2025-06-03 19:08:33.639904: Pseudo dice [np.float32(0.7408)] 
2025-06-03 19:08:33.772342: Epoch time: 127.23 s 
2025-06-03 19:08:38.046667:  
2025-06-03 19:08:38.070698: Epoch 289 
2025-06-03 19:08:38.096782: Current learning rate: 0.00736 
2025-06-03 19:10:52.782914: train_loss -0.6487 
2025-06-03 19:10:52.972178: val_loss -0.6362 
2025-06-03 19:10:52.987092: Pseudo dice [np.float32(0.7302)] 
2025-06-03 19:10:53.002150: Epoch time: 134.74 s 
2025-06-03 19:10:56.951593:  
2025-06-03 19:10:57.167522: Epoch 290 
2025-06-03 19:10:57.458709: Current learning rate: 0.00735 
2025-06-03 19:13:06.278097: train_loss -0.6875 
2025-06-03 19:13:06.678501: val_loss -0.6607 
2025-06-03 19:13:07.059865: Pseudo dice [np.float32(0.6958)] 
2025-06-03 19:13:07.216095: Epoch time: 129.33 s 
2025-06-03 19:13:09.593837:  
2025-06-03 19:13:09.630968: Epoch 291 
2025-06-03 19:13:09.662567: Current learning rate: 0.00734 
2025-06-03 19:15:19.898754: train_loss -0.6764 
2025-06-03 19:15:20.085265: val_loss -0.6639 
2025-06-03 19:15:20.328784: Pseudo dice [np.float32(0.7154)] 
2025-06-03 19:15:20.349926: Epoch time: 130.31 s 
2025-06-03 19:15:23.939528:  
2025-06-03 19:15:24.289034: Epoch 292 
2025-06-03 19:15:24.306453: Current learning rate: 0.00733 
2025-06-03 19:17:38.374784: train_loss -0.673 
2025-06-03 19:17:38.397179: val_loss -0.6257 
2025-06-03 19:17:38.415159: Pseudo dice [np.float32(0.6405)] 
2025-06-03 19:17:38.431633: Epoch time: 134.44 s 
2025-06-03 19:17:42.003652:  
2025-06-03 19:17:42.161564: Epoch 293 
2025-06-03 19:17:42.209785: Current learning rate: 0.00732 
2025-06-03 19:19:50.175602: train_loss -0.6897 
2025-06-03 19:19:50.616524: val_loss -0.6187 
2025-06-03 19:19:50.998657: Pseudo dice [np.float32(0.6551)] 
2025-06-03 19:19:51.428344: Epoch time: 128.17 s 
2025-06-03 19:19:53.661039:  
2025-06-03 19:19:53.679454: Epoch 294 
2025-06-03 19:19:53.693121: Current learning rate: 0.00731 
2025-06-03 19:22:02.461081: train_loss -0.6698 
2025-06-03 19:22:02.816342: val_loss -0.5956 
2025-06-03 19:22:02.989269: Pseudo dice [np.float32(0.5958)] 
2025-06-03 19:22:03.006236: Epoch time: 128.8 s 
2025-06-03 19:22:07.065768:  
2025-06-03 19:22:07.133220: Epoch 295 
2025-06-03 19:22:07.165172: Current learning rate: 0.0073 
2025-06-03 19:24:15.505162: train_loss -0.678 
2025-06-03 19:24:15.962273: val_loss -0.7008 
2025-06-03 19:24:15.978796: Pseudo dice [np.float32(0.7422)] 
2025-06-03 19:24:15.993327: Epoch time: 128.44 s 
2025-06-03 19:24:20.417309:  
2025-06-03 19:24:20.434478: Epoch 296 
2025-06-03 19:24:20.451831: Current learning rate: 0.00729 
2025-06-03 19:26:30.925217: train_loss -0.6586 
2025-06-03 19:26:30.943554: val_loss -0.6458 
2025-06-03 19:26:30.959083: Pseudo dice [np.float32(0.7785)] 
2025-06-03 19:26:30.975731: Epoch time: 130.51 s 
2025-06-03 19:26:34.916132:  
2025-06-03 19:26:34.942269: Epoch 297 
2025-06-03 19:26:34.964322: Current learning rate: 0.00728 
2025-06-03 19:28:45.487309: train_loss -0.6672 
2025-06-03 19:28:45.506072: val_loss -0.6394 
2025-06-03 19:28:46.296256: Pseudo dice [np.float32(0.6922)] 
2025-06-03 19:28:46.653589: Epoch time: 130.57 s 
2025-06-03 19:28:48.775998:  
2025-06-03 19:28:48.795132: Epoch 298 
2025-06-03 19:28:48.810893: Current learning rate: 0.00727 
2025-06-03 19:30:57.595361: train_loss -0.6732 
2025-06-03 19:30:57.614593: val_loss -0.6465 
2025-06-03 19:30:57.628814: Pseudo dice [np.float32(0.7382)] 
2025-06-03 19:30:57.642501: Epoch time: 128.82 s 
2025-06-03 19:31:00.814374:  
2025-06-03 19:31:00.835819: Epoch 299 
2025-06-03 19:31:00.850507: Current learning rate: 0.00726 
2025-06-03 19:33:06.005467: train_loss -0.6628 
2025-06-03 19:33:06.023627: val_loss -0.629 
2025-06-03 19:33:06.038120: Pseudo dice [np.float32(0.7364)] 
2025-06-03 19:33:06.051743: Epoch time: 125.19 s 
2025-06-03 19:33:09.311255:  
2025-06-03 19:33:09.334690: Epoch 300 
2025-06-03 19:33:09.351780: Current learning rate: 0.00725 
2025-06-03 19:35:16.182817: train_loss -0.6932 
2025-06-03 19:35:16.411665: val_loss -0.6163 
2025-06-03 19:35:16.775918: Pseudo dice [np.float32(0.7183)] 
2025-06-03 19:35:16.793174: Epoch time: 126.87 s 
2025-06-03 19:35:20.069605:  
2025-06-03 19:35:20.082197: Epoch 301 
2025-06-03 19:35:20.093570: Current learning rate: 0.00724 
2025-06-03 19:37:29.014201: train_loss -0.6912 
2025-06-03 19:37:29.397333: val_loss -0.6525 
2025-06-03 19:37:29.745734: Pseudo dice [np.float32(0.7598)] 
2025-06-03 19:37:30.167530: Epoch time: 128.95 s 
2025-06-03 19:37:30.452545: Yayy! New best EMA pseudo Dice: 0.7128999829292297 
2025-06-03 19:37:33.897439:  
2025-06-03 19:37:34.000566: Epoch 302 
2025-06-03 19:37:34.014183: Current learning rate: 0.00724 
2025-06-03 19:39:44.374043: train_loss -0.6663 
2025-06-03 19:39:44.390726: val_loss -0.6396 
2025-06-03 19:39:44.405777: Pseudo dice [np.float32(0.695)] 
2025-06-03 19:39:44.419625: Epoch time: 130.48 s 
2025-06-03 19:39:47.408806:  
2025-06-03 19:39:47.423924: Epoch 303 
2025-06-03 19:39:47.559462: Current learning rate: 0.00723 
2025-06-03 19:41:56.574656: train_loss -0.653 
2025-06-03 19:41:56.934648: val_loss -0.6421 
2025-06-03 19:41:57.271162: Pseudo dice [np.float32(0.7541)] 
2025-06-03 19:41:57.576641: Epoch time: 129.17 s 
2025-06-03 19:41:57.819512: Yayy! New best EMA pseudo Dice: 0.715399980545044 
2025-06-03 19:42:01.520009:  
2025-06-03 19:42:01.640311: Epoch 304 
2025-06-03 19:42:01.802242: Current learning rate: 0.00722 
2025-06-03 19:44:12.798548: train_loss -0.673 
2025-06-03 19:44:13.274186: val_loss -0.6674 
2025-06-03 19:44:13.576699: Pseudo dice [np.float32(0.7407)] 
2025-06-03 19:44:13.882226: Epoch time: 131.28 s 
2025-06-03 19:44:14.154388: Yayy! New best EMA pseudo Dice: 0.7179999947547913 
2025-06-03 19:44:18.617691:  
2025-06-03 19:44:18.895689: Epoch 305 
2025-06-03 19:44:19.142196: Current learning rate: 0.00721 
2025-06-03 19:46:32.152596: train_loss -0.6911 
2025-06-03 19:46:32.594779: val_loss -0.6406 
2025-06-03 19:46:32.952660: Pseudo dice [np.float32(0.6806)] 
2025-06-03 19:46:33.266667: Epoch time: 133.54 s 
2025-06-03 19:46:36.171697:  
2025-06-03 19:46:36.288190: Epoch 306 
2025-06-03 19:46:36.407079: Current learning rate: 0.0072 
2025-06-03 19:48:51.427517: train_loss -0.6812 
2025-06-03 19:48:51.447134: val_loss -0.6306 
2025-06-03 19:48:51.464508: Pseudo dice [np.float32(0.7125)] 
2025-06-03 19:48:51.480748: Epoch time: 135.26 s 
2025-06-03 19:48:54.872511:  
2025-06-03 19:48:54.977304: Epoch 307 
2025-06-03 19:48:55.065083: Current learning rate: 0.00719 
2025-06-03 19:51:06.634332: train_loss -0.6885 
2025-06-03 19:51:06.657645: val_loss -0.6707 
2025-06-03 19:51:06.673303: Pseudo dice [np.float32(0.7555)] 
2025-06-03 19:51:06.689301: Epoch time: 131.76 s 
2025-06-03 19:51:06.704635: Yayy! New best EMA pseudo Dice: 0.7182000279426575 
2025-06-03 19:51:12.790494:  
2025-06-03 19:51:12.927981: Epoch 308 
2025-06-03 19:51:13.097064: Current learning rate: 0.00718 
2025-06-03 19:53:24.854271: train_loss -0.7078 
2025-06-03 19:53:24.875276: val_loss -0.6609 
2025-06-03 19:53:24.891342: Pseudo dice [np.float32(0.7195)] 
2025-06-03 19:53:24.910781: Epoch time: 132.07 s 
2025-06-03 19:53:24.925992: Yayy! New best EMA pseudo Dice: 0.7182999849319458 
2025-06-03 19:53:28.369445:  
2025-06-03 19:53:28.397050: Epoch 309 
2025-06-03 19:53:28.502099: Current learning rate: 0.00717 
2025-06-03 19:55:41.652298: train_loss -0.6789 
2025-06-03 19:55:41.672076: val_loss -0.6775 
2025-06-03 19:55:41.686487: Pseudo dice [np.float32(0.7227)] 
2025-06-03 19:55:41.700458: Epoch time: 133.29 s 
2025-06-03 19:55:41.714379: Yayy! New best EMA pseudo Dice: 0.7188000082969666 
2025-06-03 19:55:47.103618:  
2025-06-03 19:55:47.181056: Epoch 310 
2025-06-03 19:55:47.348777: Current learning rate: 0.00716 
2025-06-03 19:57:57.911305: train_loss -0.6827 
2025-06-03 19:57:58.303329: val_loss -0.5927 
2025-06-03 19:57:58.899393: Pseudo dice [np.float32(0.6882)] 
2025-06-03 19:57:59.309868: Epoch time: 130.81 s 
2025-06-03 19:58:02.223022:  
2025-06-03 19:58:02.317627: Epoch 311 
2025-06-03 19:58:02.335580: Current learning rate: 0.00715 
2025-06-03 20:00:15.870802: train_loss -0.6459 
2025-06-03 20:00:16.410438: val_loss -0.723 
2025-06-03 20:00:16.938477: Pseudo dice [np.float32(0.7912)] 
2025-06-03 20:00:17.145248: Epoch time: 133.65 s 
2025-06-03 20:00:17.161120: Yayy! New best EMA pseudo Dice: 0.7232999801635742 
2025-06-03 20:00:22.684366:  
2025-06-03 20:00:22.872653: Epoch 312 
2025-06-03 20:00:23.033845: Current learning rate: 0.00714 
2025-06-03 20:02:32.280091: train_loss -0.6691 
2025-06-03 20:02:32.910835: val_loss -0.6756 
2025-06-03 20:02:33.485057: Pseudo dice [np.float32(0.7664)] 
2025-06-03 20:02:33.651724: Epoch time: 129.6 s 
2025-06-03 20:02:33.729985: Yayy! New best EMA pseudo Dice: 0.7275999784469604 
2025-06-03 20:02:37.295901:  
2025-06-03 20:02:37.420023: Epoch 313 
2025-06-03 20:02:37.603933: Current learning rate: 0.00713 
2025-06-03 20:04:47.155412: train_loss -0.6835 
2025-06-03 20:04:47.461571: val_loss -0.609 
2025-06-03 20:04:47.479609: Pseudo dice [np.float32(0.6836)] 
2025-06-03 20:04:47.493219: Epoch time: 129.86 s 
2025-06-03 20:04:50.425174:  
2025-06-03 20:04:50.483150: Epoch 314 
2025-06-03 20:04:50.559683: Current learning rate: 0.00712 
2025-06-03 20:07:00.161349: train_loss -0.6629 
2025-06-03 20:07:00.177850: val_loss -0.6267 
2025-06-03 20:07:00.193636: Pseudo dice [np.float32(0.7008)] 
2025-06-03 20:07:00.208918: Epoch time: 129.74 s 
2025-06-03 20:07:05.118217:  
2025-06-03 20:07:05.156976: Epoch 315 
2025-06-03 20:07:05.172803: Current learning rate: 0.00711 
2025-06-03 20:09:17.531742: train_loss -0.6632 
2025-06-03 20:09:17.841923: val_loss -0.6347 
2025-06-03 20:09:18.222687: Pseudo dice [np.float32(0.7506)] 
2025-06-03 20:09:18.534341: Epoch time: 132.41 s 
2025-06-03 20:09:22.691698:  
2025-06-03 20:09:22.948246: Epoch 316 
2025-06-03 20:09:23.014397: Current learning rate: 0.0071 
2025-06-03 20:11:30.418048: train_loss -0.6378 
2025-06-03 20:11:30.542758: val_loss -0.6282 
2025-06-03 20:11:30.810064: Pseudo dice [np.float32(0.6459)] 
2025-06-03 20:11:31.028689: Epoch time: 127.73 s 
2025-06-03 20:11:33.583410:  
2025-06-03 20:11:33.602522: Epoch 317 
2025-06-03 20:11:33.616385: Current learning rate: 0.0071 
2025-06-03 20:13:42.437556: train_loss -0.6487 
2025-06-03 20:13:42.628157: val_loss -0.6841 
2025-06-03 20:13:42.651269: Pseudo dice [np.float32(0.7855)] 
2025-06-03 20:13:42.667729: Epoch time: 128.86 s 
2025-06-03 20:13:46.329375:  
2025-06-03 20:13:46.403947: Epoch 318 
2025-06-03 20:13:46.455574: Current learning rate: 0.00709 
2025-06-03 20:15:52.652478: train_loss -0.6886 
2025-06-03 20:15:53.016092: val_loss -0.6719 
2025-06-03 20:15:53.553072: Pseudo dice [np.float32(0.7051)] 
2025-06-03 20:15:54.103518: Epoch time: 126.33 s 
2025-06-03 20:15:58.124621:  
2025-06-03 20:15:58.141094: Epoch 319 
2025-06-03 20:15:58.155151: Current learning rate: 0.00708 
2025-06-03 20:18:06.960787: train_loss -0.6492 
2025-06-03 20:18:07.368779: val_loss -0.6891 
2025-06-03 20:18:07.777406: Pseudo dice [np.float32(0.7458)] 
2025-06-03 20:18:08.073119: Epoch time: 128.84 s 
2025-06-03 20:18:12.027688:  
2025-06-03 20:18:12.049608: Epoch 320 
2025-06-03 20:18:12.068048: Current learning rate: 0.00707 
2025-06-03 20:20:21.771684: train_loss -0.6538 
2025-06-03 20:20:21.787321: val_loss -0.6486 
2025-06-03 20:20:21.802364: Pseudo dice [np.float32(0.7356)] 
2025-06-03 20:20:21.838927: Epoch time: 129.75 s 
2025-06-03 20:20:25.512894:  
2025-06-03 20:20:25.710220: Epoch 321 
2025-06-03 20:20:25.742367: Current learning rate: 0.00706 
2025-06-03 20:22:36.162902: train_loss -0.6789 
2025-06-03 20:22:36.186839: val_loss -0.6685 
2025-06-03 20:22:36.200932: Pseudo dice [np.float32(0.7507)] 
2025-06-03 20:22:36.216033: Epoch time: 130.65 s 
2025-06-03 20:22:41.009945:  
2025-06-03 20:22:41.062893: Epoch 322 
2025-06-03 20:22:41.143822: Current learning rate: 0.00705 
2025-06-03 20:24:46.260605: train_loss -0.6678 
2025-06-03 20:24:46.540883: val_loss -0.6071 
2025-06-03 20:24:46.558108: Pseudo dice [np.float32(0.6801)] 
2025-06-03 20:24:46.574416: Epoch time: 125.25 s 
2025-06-03 20:24:51.571777:  
2025-06-03 20:24:51.586788: Epoch 323 
2025-06-03 20:24:51.606680: Current learning rate: 0.00704 
2025-06-03 20:27:00.335264: train_loss -0.6828 
2025-06-03 20:27:00.352553: val_loss -0.5852 
2025-06-03 20:27:00.368943: Pseudo dice [np.float32(0.668)] 
2025-06-03 20:27:00.386221: Epoch time: 128.77 s 
2025-06-03 20:27:03.598622:  
2025-06-03 20:27:03.790664: Epoch 324 
2025-06-03 20:27:03.961698: Current learning rate: 0.00703 
2025-06-03 20:29:15.502531: train_loss -0.6484 
2025-06-03 20:29:15.985766: val_loss -0.7038 
2025-06-03 20:29:16.003305: Pseudo dice [np.float32(0.7829)] 
2025-06-03 20:29:16.018858: Epoch time: 131.91 s 
2025-06-03 20:29:20.672753:  
2025-06-03 20:29:20.693215: Epoch 325 
2025-06-03 20:29:20.709116: Current learning rate: 0.00702 
2025-06-03 20:31:28.554721: train_loss -0.6433 
2025-06-03 20:31:28.574398: val_loss -0.6448 
2025-06-03 20:31:28.589488: Pseudo dice [np.float32(0.7544)] 
2025-06-03 20:31:28.604327: Epoch time: 127.88 s 
2025-06-03 20:31:34.386852:  
2025-06-03 20:31:34.407514: Epoch 326 
2025-06-03 20:31:34.421955: Current learning rate: 0.00701 
2025-06-03 20:33:42.537662: train_loss -0.672 
2025-06-03 20:33:42.557905: val_loss -0.6368 
2025-06-03 20:33:43.002725: Pseudo dice [np.float32(0.6955)] 
2025-06-03 20:33:43.020020: Epoch time: 128.15 s 
2025-06-03 20:33:48.185798:  
2025-06-03 20:33:48.353403: Epoch 327 
2025-06-03 20:33:48.495815: Current learning rate: 0.007 
2025-06-03 20:36:00.354561: train_loss -0.6612 
2025-06-03 20:36:00.374424: val_loss -0.6231 
2025-06-03 20:36:00.389457: Pseudo dice [np.float32(0.6926)] 
2025-06-03 20:36:00.402660: Epoch time: 132.17 s 
2025-06-03 20:36:05.254618:  
2025-06-03 20:36:05.557544: Epoch 328 
2025-06-03 20:36:05.771692: Current learning rate: 0.00699 
2025-06-03 20:38:16.544372: train_loss -0.6617 
2025-06-03 20:38:16.792016: val_loss -0.625 
2025-06-03 20:38:16.986235: Pseudo dice [np.float32(0.6467)] 
2025-06-03 20:38:17.003512: Epoch time: 131.29 s 
2025-06-03 20:38:20.259441:  
2025-06-03 20:38:20.278529: Epoch 329 
2025-06-03 20:38:20.289650: Current learning rate: 0.00698 
2025-06-03 20:40:29.692512: train_loss -0.6621 
2025-06-03 20:40:30.023926: val_loss -0.6591 
2025-06-03 20:40:30.292318: Pseudo dice [np.float32(0.7956)] 
2025-06-03 20:40:30.510201: Epoch time: 129.43 s 
2025-06-03 20:40:34.293205:  
2025-06-03 20:40:34.371866: Epoch 330 
2025-06-03 20:40:34.476422: Current learning rate: 0.00697 
2025-06-03 20:42:43.971724: train_loss -0.6881 
2025-06-03 20:42:44.303371: val_loss -0.6758 
2025-06-03 20:42:44.637076: Pseudo dice [np.float32(0.7851)] 
2025-06-03 20:42:44.973143: Epoch time: 129.68 s 
2025-06-03 20:42:45.194857: Yayy! New best EMA pseudo Dice: 0.7278000116348267 
2025-06-03 20:42:50.087091:  
2025-06-03 20:42:50.137432: Epoch 331 
2025-06-03 20:42:50.151877: Current learning rate: 0.00696 
2025-06-03 20:44:54.189462: train_loss -0.6636 
2025-06-03 20:44:54.303923: val_loss -0.6433 
2025-06-03 20:44:54.320601: Pseudo dice [np.float32(0.6741)] 
2025-06-03 20:44:54.336009: Epoch time: 124.1 s 
2025-06-03 20:44:56.920446:  
2025-06-03 20:44:57.014924: Epoch 332 
2025-06-03 20:44:57.147940: Current learning rate: 0.00696 
2025-06-03 20:47:07.160148: train_loss -0.6509 
2025-06-03 20:47:07.459928: val_loss -0.6426 
2025-06-03 20:47:07.476593: Pseudo dice [np.float32(0.6924)] 
2025-06-03 20:47:07.491400: Epoch time: 130.24 s 
2025-06-03 20:47:13.050577:  
2025-06-03 20:47:13.133695: Epoch 333 
2025-06-03 20:47:13.183133: Current learning rate: 0.00695 
2025-06-03 20:49:26.195810: train_loss -0.7079 
2025-06-03 20:49:26.646583: val_loss -0.6446 
2025-06-03 20:49:27.018300: Pseudo dice [np.float32(0.7355)] 
2025-06-03 20:49:27.190279: Epoch time: 133.15 s 
2025-06-03 20:49:31.354166:  
2025-06-03 20:49:31.404976: Epoch 334 
2025-06-03 20:49:31.487113: Current learning rate: 0.00694 
2025-06-03 20:51:42.161228: train_loss -0.6749 
2025-06-03 20:51:42.761153: val_loss -0.6885 
2025-06-03 20:51:43.332109: Pseudo dice [np.float32(0.7438)] 
2025-06-03 20:51:43.837713: Epoch time: 130.81 s 
2025-06-03 20:51:47.796435:  
2025-06-03 20:51:47.817528: Epoch 335 
2025-06-03 20:51:47.845169: Current learning rate: 0.00693 
2025-06-03 20:53:56.575596: train_loss -0.693 
2025-06-03 20:53:56.922886: val_loss -0.642 
2025-06-03 20:53:56.940840: Pseudo dice [np.float32(0.7339)] 
2025-06-03 20:53:56.955956: Epoch time: 128.78 s 
2025-06-03 20:54:02.889330:  
2025-06-03 20:54:02.964390: Epoch 336 
2025-06-03 20:54:02.985482: Current learning rate: 0.00692 
2025-06-03 20:56:15.357422: train_loss -0.7126 
2025-06-03 20:56:15.835790: val_loss -0.681 
2025-06-03 20:56:16.448092: Pseudo dice [np.float32(0.7041)] 
2025-06-03 20:56:17.046025: Epoch time: 132.47 s 
2025-06-03 20:56:20.426628:  
2025-06-03 20:56:20.465143: Epoch 337 
2025-06-03 20:56:20.480441: Current learning rate: 0.00691 
2025-06-03 20:58:34.914931: train_loss -0.6943 
2025-06-03 20:58:35.196481: val_loss -0.6675 
2025-06-03 20:58:35.478853: Pseudo dice [np.float32(0.7468)] 
2025-06-03 20:58:35.497741: Epoch time: 134.49 s 
2025-06-03 20:58:41.346082:  
2025-06-03 20:58:41.464303: Epoch 338 
2025-06-03 20:58:41.625458: Current learning rate: 0.0069 
2025-06-03 21:00:51.631236: train_loss -0.6729 
2025-06-03 21:00:51.966814: val_loss -0.6376 
2025-06-03 21:00:52.438123: Pseudo dice [np.float32(0.7627)] 
2025-06-03 21:00:53.081728: Epoch time: 130.29 s 
2025-06-03 21:00:53.403531: Yayy! New best EMA pseudo Dice: 0.728600025177002 
2025-06-03 21:00:58.025025:  
2025-06-03 21:00:58.145182: Epoch 339 
2025-06-03 21:00:58.269493: Current learning rate: 0.00689 
2025-06-03 21:03:04.730608: train_loss -0.6984 
2025-06-03 21:03:05.066158: val_loss -0.6047 
2025-06-03 21:03:05.609044: Pseudo dice [np.float32(0.6611)] 
2025-06-03 21:03:06.036819: Epoch time: 126.71 s 
2025-06-03 21:03:09.792261:  
2025-06-03 21:03:09.830407: Epoch 340 
2025-06-03 21:03:09.854924: Current learning rate: 0.00688 
2025-06-03 21:05:20.959958: train_loss -0.6692 
2025-06-03 21:05:21.450859: val_loss -0.5718 
2025-06-03 21:05:21.771959: Pseudo dice [np.float32(0.6405)] 
2025-06-03 21:05:21.791116: Epoch time: 131.17 s 
2025-06-03 21:05:25.907897:  
2025-06-03 21:05:25.930363: Epoch 341 
2025-06-03 21:05:25.945423: Current learning rate: 0.00687 
2025-06-03 21:07:38.459018: train_loss -0.6673 
2025-06-03 21:07:38.801917: val_loss -0.6041 
2025-06-03 21:07:39.075944: Pseudo dice [np.float32(0.6537)] 
2025-06-03 21:07:39.096116: Epoch time: 132.55 s 
2025-06-03 21:07:43.752181:  
2025-06-03 21:07:43.771512: Epoch 342 
2025-06-03 21:07:43.787469: Current learning rate: 0.00686 
2025-06-03 21:09:54.164848: train_loss -0.6644 
2025-06-03 21:09:54.544134: val_loss -0.6012 
2025-06-03 21:09:54.895110: Pseudo dice [np.float32(0.6866)] 
2025-06-03 21:09:55.391565: Epoch time: 130.41 s 
2025-06-03 21:09:58.228177:  
2025-06-03 21:09:58.255747: Epoch 343 
2025-06-03 21:09:58.301704: Current learning rate: 0.00685 
2025-06-03 21:12:09.865236: train_loss -0.686 
2025-06-03 21:12:09.885636: val_loss -0.655 
2025-06-03 21:12:10.070554: Pseudo dice [np.float32(0.777)] 
2025-06-03 21:12:10.432974: Epoch time: 131.64 s 
2025-06-03 21:12:14.123072:  
2025-06-03 21:12:14.144899: Epoch 344 
2025-06-03 21:12:14.219722: Current learning rate: 0.00684 
2025-06-03 21:14:22.148911: train_loss -0.6844 
2025-06-03 21:14:22.168479: val_loss -0.6664 
2025-06-03 21:14:22.183580: Pseudo dice [np.float32(0.7469)] 
2025-06-03 21:14:22.198960: Epoch time: 128.03 s 
2025-06-03 21:14:25.905024:  
2025-06-03 21:14:26.057819: Epoch 345 
2025-06-03 21:14:26.116607: Current learning rate: 0.00683 
2025-06-03 21:16:35.362430: train_loss -0.6808 
2025-06-03 21:16:35.382587: val_loss -0.6125 
2025-06-03 21:16:35.399689: Pseudo dice [np.float32(0.6421)] 
2025-06-03 21:16:35.416138: Epoch time: 129.46 s 
2025-06-03 21:16:39.993066:  
2025-06-03 21:16:40.048501: Epoch 346 
2025-06-03 21:16:40.184590: Current learning rate: 0.00682 
2025-06-03 21:18:46.544638: train_loss -0.6774 
2025-06-03 21:18:47.049438: val_loss -0.6795 
2025-06-03 21:18:47.365537: Pseudo dice [np.float32(0.7425)] 
2025-06-03 21:18:47.813605: Epoch time: 126.55 s 
2025-06-03 21:18:50.502824:  
2025-06-03 21:18:50.522219: Epoch 347 
2025-06-03 21:18:50.538740: Current learning rate: 0.00681 
2025-06-03 21:20:59.994955: train_loss -0.6857 
2025-06-03 21:21:00.021930: val_loss -0.6922 
2025-06-03 21:21:00.379963: Pseudo dice [np.float32(0.8042)] 
2025-06-03 21:21:00.396060: Epoch time: 129.49 s 
2025-06-03 21:21:04.348215:  
2025-06-03 21:21:04.455446: Epoch 348 
2025-06-03 21:21:04.650405: Current learning rate: 0.0068 
2025-06-03 21:23:12.323051: train_loss -0.6902 
2025-06-03 21:23:12.725066: val_loss -0.7194 
2025-06-03 21:23:13.164136: Pseudo dice [np.float32(0.8007)] 
2025-06-03 21:23:13.182524: Epoch time: 127.98 s 
2025-06-03 21:23:13.399607: Yayy! New best EMA pseudo Dice: 0.7293000221252441 
2025-06-03 21:23:18.447937:  
2025-06-03 21:23:18.462315: Epoch 349 
2025-06-03 21:23:18.478604: Current learning rate: 0.0068 
2025-06-03 21:25:26.772816: train_loss -0.6908 
2025-06-03 21:25:27.206025: val_loss -0.689 
2025-06-03 21:25:27.529829: Pseudo dice [np.float32(0.7776)] 
2025-06-03 21:25:27.547140: Epoch time: 128.33 s 
2025-06-03 21:25:29.297316: Yayy! New best EMA pseudo Dice: 0.7340999841690063 
2025-06-03 21:25:35.471829:  
2025-06-03 21:25:35.681355: Epoch 350 
2025-06-03 21:25:35.932605: Current learning rate: 0.00679 
2025-06-03 21:27:45.121239: train_loss -0.6735 
2025-06-03 21:27:45.160306: val_loss -0.6295 
2025-06-03 21:27:45.176605: Pseudo dice [np.float32(0.7277)] 
2025-06-03 21:27:45.190599: Epoch time: 129.65 s 
2025-06-03 21:27:49.470186:  
2025-06-03 21:27:49.584579: Epoch 351 
2025-06-03 21:27:49.835785: Current learning rate: 0.00678 
2025-06-03 21:30:00.274505: train_loss -0.6817 
2025-06-03 21:30:00.494070: val_loss -0.6843 
2025-06-03 21:30:00.829487: Pseudo dice [np.float32(0.7523)] 
2025-06-03 21:30:01.056684: Epoch time: 130.81 s 
2025-06-03 21:30:01.173902: Yayy! New best EMA pseudo Dice: 0.7353000044822693 
2025-06-03 21:30:05.867386:  
2025-06-03 21:30:06.056337: Epoch 352 
2025-06-03 21:30:06.307719: Current learning rate: 0.00677 
2025-06-03 21:32:15.926360: train_loss -0.6643 
2025-06-03 21:32:15.942055: val_loss -0.6228 
2025-06-03 21:32:15.957144: Pseudo dice [np.float32(0.7047)] 
2025-06-03 21:32:15.971335: Epoch time: 130.06 s 
2025-06-03 21:32:19.008838:  
2025-06-03 21:32:19.062405: Epoch 353 
2025-06-03 21:32:19.080599: Current learning rate: 0.00676 
2025-06-03 21:34:23.555686: train_loss -0.6631 
2025-06-03 21:34:23.891684: val_loss -0.6438 
2025-06-03 21:34:24.270244: Pseudo dice [np.float32(0.7304)] 
2025-06-03 21:34:24.605060: Epoch time: 124.55 s 
2025-06-03 21:34:29.026657:  
2025-06-03 21:34:29.049329: Epoch 354 
2025-06-03 21:34:29.068413: Current learning rate: 0.00675 
2025-06-03 21:36:36.747108: train_loss -0.7105 
2025-06-03 21:36:37.029851: val_loss -0.6323 
2025-06-03 21:36:37.386160: Pseudo dice [np.float32(0.7041)] 
2025-06-03 21:36:37.659726: Epoch time: 127.72 s 
2025-06-03 21:36:39.453173:  
2025-06-03 21:36:39.466096: Epoch 355 
2025-06-03 21:36:39.477287: Current learning rate: 0.00674 
2025-06-03 21:38:44.007244: train_loss -0.6638 
2025-06-03 21:38:44.131329: val_loss -0.6966 
2025-06-03 21:38:44.398786: Pseudo dice [np.float32(0.773)] 
2025-06-03 21:38:44.704917: Epoch time: 124.56 s 
2025-06-03 21:38:49.939705:  
2025-06-03 21:38:50.071240: Epoch 356 
2025-06-03 21:38:50.196589: Current learning rate: 0.00673 
2025-06-03 21:41:02.634543: train_loss -0.6735 
2025-06-03 21:41:02.877488: val_loss -0.6406 
2025-06-03 21:41:02.893949: Pseudo dice [np.float32(0.6751)] 
2025-06-03 21:41:02.909193: Epoch time: 132.7 s 
2025-06-03 21:41:06.007864:  
2025-06-03 21:41:06.129491: Epoch 357 
2025-06-03 21:41:06.178075: Current learning rate: 0.00672 
2025-06-03 21:43:17.312652: train_loss -0.6803 
2025-06-03 21:43:17.653383: val_loss -0.6833 
2025-06-03 21:43:17.938879: Pseudo dice [np.float32(0.7157)] 
2025-06-03 21:43:18.248873: Epoch time: 131.31 s 
2025-06-03 21:43:21.640878:  
2025-06-03 21:43:21.658776: Epoch 358 
2025-06-03 21:43:21.676293: Current learning rate: 0.00671 
2025-06-03 21:45:34.888273: train_loss -0.6788 
2025-06-03 21:45:34.908190: val_loss -0.7085 
2025-06-03 21:45:34.923069: Pseudo dice [np.float32(0.8022)] 
2025-06-03 21:45:34.938403: Epoch time: 133.25 s 
2025-06-03 21:45:38.555058:  
2025-06-03 21:45:38.713990: Epoch 359 
2025-06-03 21:45:38.928603: Current learning rate: 0.0067 
2025-06-03 21:47:48.425581: train_loss -0.6655 
2025-06-03 21:47:48.693570: val_loss -0.6771 
2025-06-03 21:47:49.096429: Pseudo dice [np.float32(0.7828)] 
2025-06-03 21:47:49.497786: Epoch time: 129.87 s 
2025-06-03 21:47:49.846308: Yayy! New best EMA pseudo Dice: 0.7390000224113464 
2025-06-03 21:47:54.077064:  
2025-06-03 21:47:54.096694: Epoch 360 
2025-06-03 21:47:54.118678: Current learning rate: 0.00669 
2025-06-03 21:50:11.713481: train_loss -0.6568 
2025-06-03 21:50:11.732745: val_loss -0.6964 
2025-06-03 21:50:11.747111: Pseudo dice [np.float32(0.7314)] 
2025-06-03 21:50:11.762468: Epoch time: 137.64 s 
2025-06-03 21:50:14.749876:  
2025-06-03 21:50:14.963710: Epoch 361 
2025-06-03 21:50:15.017918: Current learning rate: 0.00668 
2025-06-03 21:52:31.047379: train_loss -0.6715 
2025-06-03 21:52:31.449147: val_loss -0.6156 
2025-06-03 21:52:31.754794: Pseudo dice [np.float32(0.6538)] 
2025-06-03 21:52:32.047409: Epoch time: 136.3 s 
2025-06-03 21:52:34.452871:  
2025-06-03 21:52:34.471942: Epoch 362 
2025-06-03 21:52:34.493507: Current learning rate: 0.00667 
2025-06-03 21:54:49.111077: train_loss -0.6302 
2025-06-03 21:54:49.325325: val_loss -0.6882 
2025-06-03 21:54:49.340529: Pseudo dice [np.float32(0.7304)] 
2025-06-03 21:54:49.354445: Epoch time: 134.66 s 
2025-06-03 21:54:52.005559:  
2025-06-03 21:54:52.060467: Epoch 363 
2025-06-03 21:54:52.088858: Current learning rate: 0.00666 
2025-06-03 21:57:05.290507: train_loss -0.6804 
2025-06-03 21:57:05.305543: val_loss -0.678 
2025-06-03 21:57:05.320551: Pseudo dice [np.float32(0.7418)] 
2025-06-03 21:57:05.334964: Epoch time: 133.29 s 
2025-06-03 21:57:10.761430:  
2025-06-03 21:57:10.779523: Epoch 364 
2025-06-03 21:57:10.795407: Current learning rate: 0.00665 
2025-06-03 21:59:20.480362: train_loss -0.6687 
2025-06-03 21:59:20.499820: val_loss -0.6643 
2025-06-03 21:59:20.514668: Pseudo dice [np.float32(0.8052)] 
2025-06-03 21:59:20.529120: Epoch time: 129.72 s 
2025-06-03 21:59:26.839323:  
2025-06-03 21:59:26.855789: Epoch 365 
2025-06-03 21:59:26.874939: Current learning rate: 0.00665 
2025-06-03 22:01:35.934282: train_loss -0.6801 
2025-06-03 22:01:36.422527: val_loss -0.6466 
2025-06-03 22:01:36.940015: Pseudo dice [np.float32(0.7526)] 
2025-06-03 22:01:37.443954: Epoch time: 129.1 s 
2025-06-03 22:01:37.748211: Yayy! New best EMA pseudo Dice: 0.7398999929428101 
2025-06-03 22:01:43.550179:  
2025-06-03 22:01:43.590901: Epoch 366 
2025-06-03 22:01:43.723040: Current learning rate: 0.00664 
2025-06-03 22:03:53.840653: train_loss -0.6858 
2025-06-03 22:03:53.858972: val_loss -0.637 
2025-06-03 22:03:53.873545: Pseudo dice [np.float32(0.6827)] 
2025-06-03 22:03:53.888074: Epoch time: 130.29 s 
2025-06-03 22:03:58.116256:  
2025-06-03 22:03:58.187560: Epoch 367 
2025-06-03 22:03:58.295075: Current learning rate: 0.00663 
2025-06-03 22:06:08.401317: train_loss -0.7092 
2025-06-03 22:06:08.422194: val_loss -0.6795 
2025-06-03 22:06:08.436958: Pseudo dice [np.float32(0.7779)] 
2025-06-03 22:06:08.453243: Epoch time: 130.29 s 
2025-06-03 22:06:12.466172:  
2025-06-03 22:06:12.495363: Epoch 368 
2025-06-03 22:06:12.512966: Current learning rate: 0.00662 
2025-06-03 22:08:22.639345: train_loss -0.6778 
2025-06-03 22:08:22.663364: val_loss -0.5978 
2025-06-03 22:08:22.679346: Pseudo dice [np.float32(0.5973)] 
2025-06-03 22:08:22.693315: Epoch time: 130.18 s 
2025-06-03 22:08:28.154625:  
2025-06-03 22:08:28.174364: Epoch 369 
2025-06-03 22:08:28.192737: Current learning rate: 0.00661 
2025-06-03 22:10:35.993817: train_loss -0.662 
2025-06-03 22:10:36.017986: val_loss -0.6007 
2025-06-03 22:10:36.032273: Pseudo dice [np.float32(0.6341)] 
2025-06-03 22:10:36.047093: Epoch time: 127.84 s 
2025-06-03 22:10:40.758740:  
2025-06-03 22:10:40.886095: Epoch 370 
2025-06-03 22:10:40.990645: Current learning rate: 0.0066 
2025-06-03 22:12:52.459232: train_loss -0.6602 
2025-06-03 22:12:52.484284: val_loss -0.5764 
2025-06-03 22:12:52.816797: Pseudo dice [np.float32(0.5436)] 
2025-06-03 22:12:53.204951: Epoch time: 131.7 s 
2025-06-03 22:12:57.648002:  
2025-06-03 22:12:57.666002: Epoch 371 
2025-06-03 22:12:57.683023: Current learning rate: 0.00659 
2025-06-03 22:15:12.489853: train_loss -0.6408 
2025-06-03 22:15:12.515621: val_loss -0.5993 
2025-06-03 22:15:12.530981: Pseudo dice [np.float32(0.6632)] 
2025-06-03 22:15:12.546331: Epoch time: 134.84 s 
2025-06-03 22:15:16.839474:  
2025-06-03 22:15:16.858769: Epoch 372 
2025-06-03 22:15:16.878940: Current learning rate: 0.00658 
2025-06-03 22:17:26.911457: train_loss -0.6625 
2025-06-03 22:17:27.236368: val_loss -0.6788 
2025-06-03 22:17:28.031215: Pseudo dice [np.float32(0.704)] 
2025-06-03 22:17:28.532304: Epoch time: 130.07 s 
2025-06-03 22:17:30.988847:  
2025-06-03 22:17:31.061907: Epoch 373 
2025-06-03 22:17:31.124681: Current learning rate: 0.00657 
2025-06-03 22:19:45.081931: train_loss -0.6451 
2025-06-03 22:19:45.610949: val_loss -0.5798 
2025-06-03 22:19:45.865241: Pseudo dice [np.float32(0.6196)] 
2025-06-03 22:19:45.897136: Epoch time: 134.1 s 
2025-06-03 22:19:49.201029:  
2025-06-03 22:19:49.422378: Epoch 374 
2025-06-03 22:19:49.654307: Current learning rate: 0.00656 
2025-06-03 22:21:59.521272: train_loss -0.6532 
2025-06-03 22:21:59.541579: val_loss -0.6394 
2025-06-03 22:21:59.557581: Pseudo dice [np.float32(0.726)] 
2025-06-03 22:21:59.573724: Epoch time: 130.32 s 
2025-06-03 22:22:02.947078:  
2025-06-03 22:22:03.220438: Epoch 375 
2025-06-03 22:22:03.242090: Current learning rate: 0.00655 
2025-06-03 22:24:11.275904: train_loss -0.6539 
2025-06-03 22:24:11.725305: val_loss -0.662 
2025-06-03 22:24:12.167428: Pseudo dice [np.float32(0.7264)] 
2025-06-03 22:24:12.646365: Epoch time: 128.33 s 
2025-06-03 22:24:16.748235:  
2025-06-03 22:24:16.767996: Epoch 376 
2025-06-03 22:24:16.787736: Current learning rate: 0.00654 
2025-06-03 22:26:24.085896: train_loss -0.6702 
2025-06-03 22:26:24.454354: val_loss -0.6481 
2025-06-03 22:26:24.794206: Pseudo dice [np.float32(0.759)] 
2025-06-03 22:26:25.332059: Epoch time: 127.34 s 
2025-06-03 22:26:29.070312:  
2025-06-03 22:26:29.093035: Epoch 377 
2025-06-03 22:26:29.140363: Current learning rate: 0.00653 
2025-06-03 22:28:36.051030: train_loss -0.6944 
2025-06-03 22:28:36.173079: val_loss -0.6692 
2025-06-03 22:28:36.420100: Pseudo dice [np.float32(0.7289)] 
2025-06-03 22:28:36.635697: Epoch time: 126.98 s 
2025-06-03 22:28:39.111711:  
2025-06-03 22:28:39.134295: Epoch 378 
2025-06-03 22:28:39.151299: Current learning rate: 0.00652 
2025-06-03 22:30:50.977358: train_loss -0.6577 
2025-06-03 22:30:51.207021: val_loss -0.6437 
2025-06-03 22:30:51.509847: Pseudo dice [np.float32(0.7568)] 
2025-06-03 22:30:51.760746: Epoch time: 131.87 s 
2025-06-03 22:30:54.115973:  
2025-06-03 22:30:54.132947: Epoch 379 
2025-06-03 22:30:54.144293: Current learning rate: 0.00651 
2025-06-03 22:33:01.402449: train_loss -0.6696 
2025-06-03 22:33:01.737365: val_loss -0.6494 
2025-06-03 22:33:02.103784: Pseudo dice [np.float32(0.7317)] 
2025-06-03 22:33:02.404264: Epoch time: 127.29 s 
2025-06-03 22:33:05.690496:  
2025-06-03 22:33:05.729555: Epoch 380 
2025-06-03 22:33:05.755347: Current learning rate: 0.0065 
2025-06-03 22:35:13.633055: train_loss -0.6797 
2025-06-03 22:35:13.657451: val_loss -0.5672 
2025-06-03 22:35:13.672575: Pseudo dice [np.float32(0.575)] 
2025-06-03 22:35:13.687717: Epoch time: 127.94 s 
2025-06-03 22:35:18.511649:  
2025-06-03 22:35:18.638258: Epoch 381 
2025-06-03 22:35:18.769901: Current learning rate: 0.00649 
2025-06-03 22:37:29.642816: train_loss -0.6645 
2025-06-03 22:37:29.844154: val_loss -0.6166 
2025-06-03 22:37:30.106480: Pseudo dice [np.float32(0.6844)] 
2025-06-03 22:37:30.283479: Epoch time: 131.13 s 
2025-06-03 22:37:34.109493:  
2025-06-03 22:37:34.259037: Epoch 382 
2025-06-03 22:37:34.443573: Current learning rate: 0.00648 
2025-06-03 22:39:46.275102: train_loss -0.6853 
2025-06-03 22:39:46.290922: val_loss -0.6361 
2025-06-03 22:39:46.306261: Pseudo dice [np.float32(0.7495)] 
2025-06-03 22:39:46.321645: Epoch time: 132.17 s 
2025-06-03 22:39:49.191774:  
2025-06-03 22:39:49.251096: Epoch 383 
2025-06-03 22:39:49.385382: Current learning rate: 0.00648 
2025-06-03 22:41:59.779221: train_loss -0.6928 
2025-06-03 22:42:00.136162: val_loss -0.6337 
2025-06-03 22:42:00.470774: Pseudo dice [np.float32(0.6949)] 
2025-06-03 22:42:00.762360: Epoch time: 130.59 s 
2025-06-03 22:42:04.759242:  
2025-06-03 22:42:04.817133: Epoch 384 
2025-06-03 22:42:04.834414: Current learning rate: 0.00647 
2025-06-03 22:44:16.761541: train_loss -0.6451 
2025-06-03 22:44:16.784771: val_loss -0.5962 
2025-06-03 22:44:16.800193: Pseudo dice [np.float32(0.6705)] 
2025-06-03 22:44:16.815517: Epoch time: 132.0 s 
2025-06-03 22:44:21.526980:  
2025-06-03 22:44:21.579218: Epoch 385 
2025-06-03 22:44:21.642061: Current learning rate: 0.00646 
2025-06-03 22:46:35.951314: train_loss -0.6667 
2025-06-03 22:46:35.971255: val_loss -0.7322 
2025-06-03 22:46:35.986068: Pseudo dice [np.float32(0.7843)] 
2025-06-03 22:46:35.999945: Epoch time: 134.43 s 
2025-06-03 22:46:40.039349:  
2025-06-03 22:46:40.118860: Epoch 386 
2025-06-03 22:46:40.141276: Current learning rate: 0.00645 
2025-06-03 22:48:54.362506: train_loss -0.6807 
2025-06-03 22:48:54.387537: val_loss -0.6338 
2025-06-03 22:48:54.403452: Pseudo dice [np.float32(0.693)] 
2025-06-03 22:48:54.418661: Epoch time: 134.32 s 
2025-06-03 22:48:58.834715:  
2025-06-03 22:48:58.944231: Epoch 387 
2025-06-03 22:48:59.037246: Current learning rate: 0.00644 
2025-06-03 22:51:16.314563: train_loss -0.6818 
2025-06-03 22:51:16.337933: val_loss -0.6266 
2025-06-03 22:51:16.352712: Pseudo dice [np.float32(0.7052)] 
2025-06-03 22:51:16.367330: Epoch time: 137.48 s 
2025-06-03 22:51:20.651544:  
2025-06-03 22:51:20.693884: Epoch 388 
2025-06-03 22:51:20.733013: Current learning rate: 0.00643 
2025-06-03 22:53:30.185760: train_loss -0.6785 
2025-06-03 22:53:30.205568: val_loss -0.6703 
2025-06-03 22:53:30.220629: Pseudo dice [np.float32(0.7746)] 
2025-06-03 22:53:30.235560: Epoch time: 129.54 s 
2025-06-03 22:53:33.508646:  
2025-06-03 22:53:33.528652: Epoch 389 
2025-06-03 22:53:33.545042: Current learning rate: 0.00642 
2025-06-03 22:55:43.464983: train_loss -0.6769 
2025-06-03 22:55:43.481897: val_loss -0.5958 
2025-06-03 22:55:43.497247: Pseudo dice [np.float32(0.7073)] 
2025-06-03 22:55:43.542456: Epoch time: 129.96 s 
2025-06-03 22:55:47.689698:  
2025-06-03 22:55:47.775315: Epoch 390 
2025-06-03 22:55:47.812411: Current learning rate: 0.00641 
2025-06-03 22:57:54.369294: train_loss -0.6742 
2025-06-03 22:57:54.725574: val_loss -0.6254 
2025-06-03 22:57:55.229985: Pseudo dice [np.float32(0.6655)] 
2025-06-03 22:57:55.663133: Epoch time: 126.68 s 
2025-06-03 22:58:03.324542:  
2025-06-03 22:58:03.427902: Epoch 391 
2025-06-03 22:58:03.445929: Current learning rate: 0.0064 
2025-06-03 23:00:12.195474: train_loss -0.6721 
2025-06-03 23:00:12.482348: val_loss -0.6169 
2025-06-03 23:00:12.501805: Pseudo dice [np.float32(0.6438)] 
2025-06-03 23:00:12.518188: Epoch time: 128.87 s 
2025-06-03 23:00:18.736272:  
2025-06-03 23:00:18.756458: Epoch 392 
2025-06-03 23:00:18.776834: Current learning rate: 0.00639 
2025-06-03 23:02:28.682895: train_loss -0.6458 
2025-06-03 23:02:28.701457: val_loss -0.6244 
2025-06-03 23:02:28.718340: Pseudo dice [np.float32(0.7145)] 
2025-06-03 23:02:28.736265: Epoch time: 129.95 s 
2025-06-03 23:02:31.640788:  
2025-06-03 23:02:31.662726: Epoch 393 
2025-06-03 23:02:31.680780: Current learning rate: 0.00638 
2025-06-03 23:04:37.412950: train_loss -0.6551 
2025-06-03 23:04:37.435095: val_loss -0.5706 
2025-06-03 23:04:37.450514: Pseudo dice [np.float32(0.62)] 
2025-06-03 23:04:37.465496: Epoch time: 125.77 s 
2025-06-03 23:04:43.426477:  
2025-06-03 23:04:43.446149: Epoch 394 
2025-06-03 23:04:43.464431: Current learning rate: 0.00637 
2025-06-03 23:06:55.416210: train_loss -0.6825 
2025-06-03 23:06:55.692631: val_loss -0.6475 
2025-06-03 23:06:56.026900: Pseudo dice [np.float32(0.7362)] 
2025-06-03 23:06:56.431747: Epoch time: 131.99 s 
2025-06-03 23:07:02.525250:  
2025-06-03 23:07:02.573947: Epoch 395 
2025-06-03 23:07:02.587579: Current learning rate: 0.00636 
2025-06-03 23:09:08.152316: train_loss -0.6876 
2025-06-03 23:09:08.498885: val_loss -0.6681 
2025-06-03 23:09:08.520889: Pseudo dice [np.float32(0.6776)] 
2025-06-03 23:09:08.535355: Epoch time: 125.63 s 
2025-06-03 23:09:13.637477:  
2025-06-03 23:09:13.658845: Epoch 396 
2025-06-03 23:09:13.680393: Current learning rate: 0.00635 
2025-06-03 23:11:22.915441: train_loss -0.6613 
2025-06-03 23:11:23.521697: val_loss -0.6585 
2025-06-03 23:11:24.034217: Pseudo dice [np.float32(0.7048)] 
2025-06-03 23:11:24.529632: Epoch time: 129.28 s 
2025-06-03 23:11:29.571542:  
2025-06-03 23:11:29.593229: Epoch 397 
2025-06-03 23:11:29.609745: Current learning rate: 0.00634 
2025-06-03 23:13:41.475862: train_loss -0.6925 
2025-06-03 23:13:42.028689: val_loss -0.6803 
2025-06-03 23:13:42.205902: Pseudo dice [np.float32(0.7137)] 
2025-06-03 23:13:42.724493: Epoch time: 131.91 s 
2025-06-03 23:13:46.018655:  
2025-06-03 23:13:46.038676: Epoch 398 
2025-06-03 23:13:46.055545: Current learning rate: 0.00633 
2025-06-03 23:15:57.716417: train_loss -0.6803 
2025-06-03 23:15:58.356610: val_loss -0.6215 
2025-06-03 23:15:58.806273: Pseudo dice [np.float32(0.6658)] 
2025-06-03 23:15:59.151464: Epoch time: 131.7 s 
2025-06-03 23:16:02.536430:  
2025-06-03 23:16:02.649166: Epoch 399 
2025-06-03 23:16:02.671182: Current learning rate: 0.00632 
2025-06-03 23:18:12.637226: train_loss -0.6728 
2025-06-03 23:18:12.661282: val_loss -0.6302 
2025-06-03 23:18:12.682066: Pseudo dice [np.float32(0.724)] 
2025-06-03 23:18:12.701262: Epoch time: 130.1 s 
2025-06-03 23:18:18.266253:  
2025-06-03 23:18:18.319889: Epoch 400 
2025-06-03 23:18:18.344854: Current learning rate: 0.00631 
2025-06-03 23:20:33.657694: train_loss -0.674 
2025-06-03 23:20:33.688998: val_loss -0.6822 
2025-06-03 23:20:33.707861: Pseudo dice [np.float32(0.6984)] 
2025-06-03 23:20:33.725686: Epoch time: 135.39 s 
2025-06-03 23:20:37.112638:  
2025-06-03 23:20:37.174999: Epoch 401 
2025-06-03 23:20:37.269627: Current learning rate: 0.0063 
2025-06-03 23:22:50.539153: train_loss -0.6866 
2025-06-03 23:22:50.790533: val_loss -0.664 
2025-06-03 23:22:50.808645: Pseudo dice [np.float32(0.7698)] 
2025-06-03 23:22:50.974333: Epoch time: 133.43 s 
2025-06-03 23:22:56.616151:  
2025-06-03 23:22:56.886184: Epoch 402 
2025-06-03 23:22:57.060982: Current learning rate: 0.0063 
2025-06-03 23:25:04.019440: train_loss -0.6911 
2025-06-03 23:25:04.409408: val_loss -0.6909 
2025-06-03 23:25:04.796011: Pseudo dice [np.float32(0.7654)] 
2025-06-03 23:25:05.221645: Epoch time: 127.41 s 
2025-06-03 23:25:10.359666:  
2025-06-03 23:25:10.527870: Epoch 403 
2025-06-03 23:25:10.545405: Current learning rate: 0.00629 
2025-06-03 23:27:16.226610: train_loss -0.7165 
2025-06-03 23:27:16.611749: val_loss -0.677 
2025-06-03 23:27:16.851672: Pseudo dice [np.float32(0.7723)] 
2025-06-03 23:27:16.870340: Epoch time: 125.87 s 
2025-06-03 23:27:19.335473:  
2025-06-03 23:27:19.366162: Epoch 404 
2025-06-03 23:27:19.381410: Current learning rate: 0.00628 
2025-06-03 23:29:22.252640: train_loss -0.6858 
2025-06-03 23:29:22.418400: val_loss -0.6428 
2025-06-03 23:29:22.436188: Pseudo dice [np.float32(0.7324)] 
2025-06-03 23:29:22.450356: Epoch time: 122.92 s 
2025-06-03 23:29:25.890624:  
2025-06-03 23:29:25.906149: Epoch 405 
2025-06-03 23:29:25.922766: Current learning rate: 0.00627 
2025-06-03 23:31:39.419113: train_loss -0.6667 
2025-06-03 23:31:39.579339: val_loss -0.6878 
2025-06-03 23:31:39.844497: Pseudo dice [np.float32(0.7819)] 
2025-06-03 23:31:40.065061: Epoch time: 133.53 s 
2025-06-03 23:31:41.874345:  
2025-06-03 23:31:41.902346: Epoch 406 
2025-06-03 23:31:41.922997: Current learning rate: 0.00626 
2025-06-03 23:33:51.998104: train_loss -0.6533 
2025-06-03 23:33:52.022259: val_loss -0.5563 
2025-06-03 23:33:52.037778: Pseudo dice [np.float32(0.6409)] 
2025-06-03 23:33:52.052699: Epoch time: 130.13 s 
2025-06-03 23:33:55.761467:  
2025-06-03 23:33:55.880519: Epoch 407 
2025-06-03 23:33:55.968378: Current learning rate: 0.00625 
2025-06-03 23:36:06.495146: train_loss -0.6652 
2025-06-03 23:36:06.787150: val_loss -0.5998 
2025-06-03 23:36:07.194261: Pseudo dice [np.float32(0.627)] 
2025-06-03 23:36:07.528556: Epoch time: 130.74 s 
2025-06-03 23:36:10.162601:  
2025-06-03 23:36:10.233499: Epoch 408 
2025-06-03 23:36:10.270392: Current learning rate: 0.00624 
2025-06-03 23:38:15.294851: train_loss -0.6796 
2025-06-03 23:38:15.319463: val_loss -0.6147 
2025-06-03 23:38:15.334381: Pseudo dice [np.float32(0.6427)] 
2025-06-03 23:38:15.349874: Epoch time: 125.13 s 
2025-06-03 23:38:21.876563:  
2025-06-03 23:38:21.948686: Epoch 409 
2025-06-03 23:38:22.074611: Current learning rate: 0.00623 
2025-06-03 23:40:36.016459: train_loss -0.6729 
2025-06-03 23:40:36.036441: val_loss -0.6769 
2025-06-03 23:40:36.051899: Pseudo dice [np.float32(0.8128)] 
2025-06-03 23:40:36.068171: Epoch time: 134.14 s 
2025-06-03 23:40:39.239851:  
2025-06-03 23:40:39.312043: Epoch 410 
2025-06-03 23:40:39.428184: Current learning rate: 0.00622 
2025-06-03 23:42:50.891706: train_loss -0.6855 
2025-06-03 23:42:50.908686: val_loss -0.6673 
2025-06-03 23:42:50.924065: Pseudo dice [np.float32(0.8333)] 
2025-06-03 23:42:50.939109: Epoch time: 131.65 s 
2025-06-03 23:42:53.931635:  
2025-06-03 23:42:53.961610: Epoch 411 
2025-06-03 23:42:53.997983: Current learning rate: 0.00621 
2025-06-03 23:45:09.984655: train_loss -0.6654 
2025-06-03 23:45:10.009047: val_loss -0.6622 
2025-06-03 23:45:10.024249: Pseudo dice [np.float32(0.7445)] 
2025-06-03 23:45:10.039431: Epoch time: 136.06 s 
2025-06-03 23:45:13.547701:  
2025-06-03 23:45:13.653656: Epoch 412 
2025-06-03 23:45:13.816389: Current learning rate: 0.0062 
2025-06-03 23:47:26.966228: train_loss -0.7079 
2025-06-03 23:47:26.984836: val_loss -0.6665 
2025-06-03 23:47:27.000569: Pseudo dice [np.float32(0.7761)] 
2025-06-03 23:47:27.016385: Epoch time: 133.42 s 
2025-06-03 23:47:29.770044:  
2025-06-03 23:47:29.934877: Epoch 413 
2025-06-03 23:47:30.078054: Current learning rate: 0.00619 
2025-06-03 23:49:46.377024: train_loss -0.6811 
2025-06-03 23:49:46.392330: val_loss -0.7125 
2025-06-03 23:49:46.407109: Pseudo dice [np.float32(0.7865)] 
2025-06-03 23:49:46.421894: Epoch time: 136.61 s 
2025-06-03 23:49:50.227693:  
2025-06-03 23:49:50.331558: Epoch 414 
2025-06-03 23:49:50.348412: Current learning rate: 0.00618 
2025-06-03 23:52:02.207265: train_loss -0.6601 
2025-06-03 23:52:02.231353: val_loss -0.6308 
2025-06-03 23:52:02.246395: Pseudo dice [np.float32(0.7672)] 
2025-06-03 23:52:02.260532: Epoch time: 131.98 s 
2025-06-03 23:52:02.276056: Yayy! New best EMA pseudo Dice: 0.7400000095367432 
2025-06-03 23:52:08.465722:  
2025-06-03 23:52:08.629333: Epoch 415 
2025-06-03 23:52:08.826566: Current learning rate: 0.00617 
2025-06-03 23:54:22.247075: train_loss -0.7005 
2025-06-03 23:54:22.264985: val_loss -0.7176 
2025-06-03 23:54:22.278747: Pseudo dice [np.float32(0.7969)] 
2025-06-03 23:54:22.293067: Epoch time: 133.78 s 
2025-06-03 23:54:22.307860: Yayy! New best EMA pseudo Dice: 0.7457000017166138 
2025-06-03 23:54:27.320006:  
2025-06-03 23:54:27.342925: Epoch 416 
2025-06-03 23:54:27.361008: Current learning rate: 0.00616 
2025-06-03 23:56:36.386028: train_loss -0.6808 
2025-06-03 23:56:36.929336: val_loss -0.6643 
2025-06-03 23:56:37.426150: Pseudo dice [np.float32(0.7686)] 
2025-06-03 23:56:37.952231: Epoch time: 129.07 s 
2025-06-03 23:56:38.254977: Yayy! New best EMA pseudo Dice: 0.7480000257492065 
2025-06-03 23:56:43.268343:  
2025-06-03 23:56:43.362806: Epoch 417 
2025-06-03 23:56:43.377670: Current learning rate: 0.00615 
2025-06-03 23:58:52.853832: train_loss -0.6916 
2025-06-03 23:58:53.170248: val_loss -0.6252 
2025-06-03 23:58:53.640272: Pseudo dice [np.float32(0.7501)] 
2025-06-03 23:58:53.658041: Epoch time: 129.59 s 
2025-06-03 23:58:53.672346: Yayy! New best EMA pseudo Dice: 0.748199999332428 
2025-06-03 23:58:56.980285:  
2025-06-03 23:58:56.998412: Epoch 418 
2025-06-03 23:58:57.015512: Current learning rate: 0.00614 
2025-06-04 00:01:07.942536: train_loss -0.7196 
2025-06-04 00:01:07.959108: val_loss -0.7199 
2025-06-04 00:01:07.974291: Pseudo dice [np.float32(0.8245)] 
2025-06-04 00:01:07.989377: Epoch time: 130.96 s 
2025-06-04 00:01:08.003605: Yayy! New best EMA pseudo Dice: 0.7558000087738037 
2025-06-04 00:01:12.423793:  
2025-06-04 00:01:12.449157: Epoch 419 
2025-06-04 00:01:12.468244: Current learning rate: 0.00613 
2025-06-04 00:03:24.647646: train_loss -0.6662 
2025-06-04 00:03:25.100141: val_loss -0.6181 
2025-06-04 00:03:25.474034: Pseudo dice [np.float32(0.7317)] 
2025-06-04 00:03:25.972662: Epoch time: 132.23 s 
2025-06-04 00:03:29.264880:  
2025-06-04 00:03:29.426596: Epoch 420 
2025-06-04 00:03:29.578525: Current learning rate: 0.00612 
2025-06-04 00:05:41.850352: train_loss -0.6774 
2025-06-04 00:05:41.870017: val_loss -0.6738 
2025-06-04 00:05:41.886917: Pseudo dice [np.float32(0.7115)] 
2025-06-04 00:05:41.901996: Epoch time: 132.59 s 
2025-06-04 00:05:45.286040:  
2025-06-04 00:05:45.347432: Epoch 421 
2025-06-04 00:05:45.366995: Current learning rate: 0.00612 
2025-06-04 00:07:56.896058: train_loss -0.6752 
2025-06-04 00:07:56.916668: val_loss -0.5607 
2025-06-04 00:07:56.935071: Pseudo dice [np.float32(0.6394)] 
2025-06-04 00:07:56.951715: Epoch time: 131.61 s 
2025-06-04 00:08:00.768101:  
2025-06-04 00:08:00.791337: Epoch 422 
2025-06-04 00:08:00.810138: Current learning rate: 0.00611 
2025-06-04 00:10:16.027302: train_loss -0.6659 
2025-06-04 00:10:16.046962: val_loss -0.6211 
2025-06-04 00:10:16.061645: Pseudo dice [np.float32(0.6393)] 
2025-06-04 00:10:16.079075: Epoch time: 135.26 s 
2025-06-04 00:10:20.251156:  
2025-06-04 00:10:20.272069: Epoch 423 
2025-06-04 00:10:20.288391: Current learning rate: 0.0061 
2025-06-04 00:12:32.299892: train_loss -0.6861 
2025-06-04 00:12:32.537629: val_loss -0.6594 
2025-06-04 00:12:32.862091: Pseudo dice [np.float32(0.6908)] 
2025-06-04 00:12:32.976325: Epoch time: 132.05 s 
2025-06-04 00:12:38.463933:  
2025-06-04 00:12:38.701465: Epoch 424 
2025-06-04 00:12:38.944156: Current learning rate: 0.00609 
2025-06-04 00:14:49.485802: train_loss -0.6739 
2025-06-04 00:14:49.860197: val_loss -0.7063 
2025-06-04 00:14:50.334369: Pseudo dice [np.float32(0.7161)] 
2025-06-04 00:14:50.447951: Epoch time: 131.02 s 
2025-06-04 00:14:53.592406:  
2025-06-04 00:14:53.803677: Epoch 425 
2025-06-04 00:14:53.972241: Current learning rate: 0.00608 
2025-06-04 00:17:00.416244: train_loss -0.6824 
2025-06-04 00:17:00.436750: val_loss -0.6869 
2025-06-04 00:17:00.457270: Pseudo dice [np.float32(0.721)] 
2025-06-04 00:17:00.676389: Epoch time: 126.83 s 
2025-06-04 00:17:03.370329:  
2025-06-04 00:17:03.390630: Epoch 426 
2025-06-04 00:17:03.407164: Current learning rate: 0.00607 
2025-06-04 00:19:09.760412: train_loss -0.6826 
2025-06-04 00:19:09.779385: val_loss -0.681 
2025-06-04 00:19:09.794659: Pseudo dice [np.float32(0.7673)] 
2025-06-04 00:19:09.809420: Epoch time: 126.39 s 
2025-06-04 00:19:13.779464:  
2025-06-04 00:19:13.852985: Epoch 427 
2025-06-04 00:19:13.900141: Current learning rate: 0.00606 
2025-06-04 00:21:17.572833: train_loss -0.6994 
2025-06-04 00:21:17.590706: val_loss -0.6131 
2025-06-04 00:21:17.606227: Pseudo dice [np.float32(0.7252)] 
2025-06-04 00:21:17.621016: Epoch time: 123.79 s 
2025-06-04 00:21:19.906060:  
2025-06-04 00:21:19.971753: Epoch 428 
2025-06-04 00:21:19.992756: Current learning rate: 0.00605 
2025-06-04 00:23:28.994137: train_loss -0.6789 
2025-06-04 00:23:29.281488: val_loss -0.6734 
2025-06-04 00:23:29.454503: Pseudo dice [np.float32(0.7928)] 
2025-06-04 00:23:29.780855: Epoch time: 129.09 s 
2025-06-04 00:23:34.375687:  
2025-06-04 00:23:34.388531: Epoch 429 
2025-06-04 00:23:34.399755: Current learning rate: 0.00604 
2025-06-04 00:25:44.632317: train_loss -0.6703 
2025-06-04 00:25:44.790547: val_loss -0.5756 
2025-06-04 00:25:44.811002: Pseudo dice [np.float32(0.7506)] 
2025-06-04 00:25:44.825722: Epoch time: 130.26 s 
2025-06-04 00:25:49.005359:  
2025-06-04 00:25:49.024413: Epoch 430 
2025-06-04 00:25:49.039507: Current learning rate: 0.00603 
2025-06-04 00:27:56.109919: train_loss -0.6666 
2025-06-04 00:27:56.127777: val_loss -0.6254 
2025-06-04 00:27:56.142408: Pseudo dice [np.float32(0.6104)] 
2025-06-04 00:27:56.157020: Epoch time: 127.11 s 
2025-06-04 00:28:00.021725:  
2025-06-04 00:28:00.048669: Epoch 431 
2025-06-04 00:28:00.074918: Current learning rate: 0.00602 
2025-06-04 00:30:06.211526: train_loss -0.6707 
2025-06-04 00:30:06.313868: val_loss -0.6286 
2025-06-04 00:30:06.477906: Pseudo dice [np.float32(0.7365)] 
2025-06-04 00:30:06.918617: Epoch time: 126.19 s 
2025-06-04 00:30:10.344112:  
2025-06-04 00:30:10.450908: Epoch 432 
2025-06-04 00:30:10.529602: Current learning rate: 0.00601 
2025-06-04 00:32:20.490239: train_loss -0.6851 
2025-06-04 00:32:21.122981: val_loss -0.6836 
2025-06-04 00:32:21.498070: Pseudo dice [np.float32(0.7776)] 
2025-06-04 00:32:21.514227: Epoch time: 130.15 s 
2025-06-04 00:32:24.105475:  
2025-06-04 00:32:24.192740: Epoch 433 
2025-06-04 00:32:24.205261: Current learning rate: 0.006 
2025-06-04 00:34:33.205297: train_loss -0.67 
2025-06-04 00:34:33.576054: val_loss -0.5976 
2025-06-04 00:34:33.886324: Pseudo dice [np.float32(0.6703)] 
2025-06-04 00:34:33.903628: Epoch time: 129.1 s 
2025-06-04 00:34:38.282006:  
2025-06-04 00:34:38.339440: Epoch 434 
2025-06-04 00:34:38.383403: Current learning rate: 0.00599 
2025-06-04 00:36:48.725785: train_loss -0.6578 
2025-06-04 00:36:49.086997: val_loss -0.6336 
2025-06-04 00:36:49.567545: Pseudo dice [np.float32(0.6906)] 
2025-06-04 00:36:49.837941: Epoch time: 130.45 s 
2025-06-04 00:36:52.888287:  
2025-06-04 00:36:53.000678: Epoch 435 
2025-06-04 00:36:53.154560: Current learning rate: 0.00598 
2025-06-04 00:39:05.219375: train_loss -0.6609 
2025-06-04 00:39:05.566255: val_loss -0.6688 
2025-06-04 00:39:05.835286: Pseudo dice [np.float32(0.6976)] 
2025-06-04 00:39:06.266322: Epoch time: 132.33 s 
2025-06-04 00:39:09.571194:  
2025-06-04 00:39:09.691072: Epoch 436 
2025-06-04 00:39:09.885062: Current learning rate: 0.00597 
2025-06-04 00:41:23.943358: train_loss -0.6847 
2025-06-04 00:41:24.323544: val_loss -0.6154 
2025-06-04 00:41:24.606901: Pseudo dice [np.float32(0.6975)] 
2025-06-04 00:41:24.623662: Epoch time: 134.37 s 
2025-06-04 00:41:27.843122:  
2025-06-04 00:41:27.900564: Epoch 437 
2025-06-04 00:41:27.920077: Current learning rate: 0.00596 
2025-06-04 00:43:42.182057: train_loss -0.6616 
2025-06-04 00:43:43.024052: val_loss -0.612 
2025-06-04 00:43:43.526227: Pseudo dice [np.float32(0.6929)] 
2025-06-04 00:43:43.929331: Epoch time: 134.34 s 
2025-06-04 00:43:46.533302:  
2025-06-04 00:43:46.616124: Epoch 438 
2025-06-04 00:43:46.670935: Current learning rate: 0.00595 
2025-06-04 00:45:54.384937: train_loss -0.6499 
2025-06-04 00:45:54.405077: val_loss -0.6724 
2025-06-04 00:45:54.420811: Pseudo dice [np.float32(0.7935)] 
2025-06-04 00:45:54.434345: Epoch time: 127.85 s 
2025-06-04 00:46:00.386479:  
2025-06-04 00:46:00.560786: Epoch 439 
2025-06-04 00:46:00.609511: Current learning rate: 0.00594 
2025-06-04 00:48:14.138935: train_loss -0.6975 
2025-06-04 00:48:14.160223: val_loss -0.5889 
2025-06-04 00:48:14.175420: Pseudo dice [np.float32(0.6849)] 
2025-06-04 00:48:14.190645: Epoch time: 133.76 s 
2025-06-04 00:48:19.092371:  
2025-06-04 00:48:19.222190: Epoch 440 
2025-06-04 00:48:19.361377: Current learning rate: 0.00593 
2025-06-04 00:50:32.881315: train_loss -0.6246 
2025-06-04 00:50:33.366149: val_loss -0.6607 
2025-06-04 00:50:33.825081: Pseudo dice [np.float32(0.7698)] 
2025-06-04 00:50:34.367760: Epoch time: 133.79 s 
2025-06-04 00:50:39.079530:  
2025-06-04 00:50:39.159491: Epoch 441 
2025-06-04 00:50:39.182747: Current learning rate: 0.00592 
2025-06-04 00:52:49.781632: train_loss -0.6832 
2025-06-04 00:52:50.281964: val_loss -0.6613 
2025-06-04 00:52:50.762624: Pseudo dice [np.float32(0.7594)] 
2025-06-04 00:52:51.262021: Epoch time: 130.7 s 
2025-06-04 00:52:55.575885:  
2025-06-04 00:52:55.701059: Epoch 442 
2025-06-04 00:52:55.719102: Current learning rate: 0.00592 
2025-06-04 00:55:09.068681: train_loss -0.6774 
2025-06-04 00:55:09.089134: val_loss -0.6733 
2025-06-04 00:55:09.105360: Pseudo dice [np.float32(0.7239)] 
2025-06-04 00:55:09.123415: Epoch time: 133.49 s 
2025-06-04 00:55:14.025194:  
2025-06-04 00:55:14.243231: Epoch 443 
2025-06-04 00:55:14.421941: Current learning rate: 0.00591 
2025-06-04 00:57:22.690860: train_loss -0.6703 
2025-06-04 00:57:23.215673: val_loss -0.7123 
2025-06-04 00:57:23.730496: Pseudo dice [np.float32(0.7746)] 
2025-06-04 00:57:24.083425: Epoch time: 128.67 s 
2025-06-04 00:57:27.227367:  
2025-06-04 00:57:27.491876: Epoch 444 
2025-06-04 00:57:27.849808: Current learning rate: 0.0059 
2025-06-04 00:59:34.779286: train_loss -0.6878 
2025-06-04 00:59:34.801579: val_loss -0.6497 
2025-06-04 00:59:34.816458: Pseudo dice [np.float32(0.7057)] 
2025-06-04 00:59:34.831815: Epoch time: 127.55 s 
2025-06-04 00:59:39.367365:  
2025-06-04 00:59:39.503175: Epoch 445 
2025-06-04 00:59:39.529405: Current learning rate: 0.00589 
2025-06-04 01:01:50.273298: train_loss -0.7002 
2025-06-04 01:01:50.652963: val_loss -0.6885 
2025-06-04 01:01:50.668700: Pseudo dice [np.float32(0.8092)] 
2025-06-04 01:01:50.682587: Epoch time: 130.91 s 
2025-06-04 01:01:54.874008:  
2025-06-04 01:01:54.920106: Epoch 446 
2025-06-04 01:01:54.942673: Current learning rate: 0.00588 
2025-06-04 01:04:06.893806: train_loss -0.6852 
2025-06-04 01:04:06.921026: val_loss -0.6727 
2025-06-04 01:04:07.070281: Pseudo dice [np.float32(0.7247)] 
2025-06-04 01:04:07.088032: Epoch time: 132.02 s 
2025-06-04 01:04:11.846573:  
2025-06-04 01:04:11.863953: Epoch 447 
2025-06-04 01:04:11.882846: Current learning rate: 0.00587 
2025-06-04 01:06:22.033406: train_loss -0.6562 
2025-06-04 01:06:22.207469: val_loss -0.5751 
2025-06-04 01:06:22.227888: Pseudo dice [np.float32(0.6816)] 
2025-06-04 01:06:22.247447: Epoch time: 130.19 s 
2025-06-04 01:06:27.896243:  
2025-06-04 01:06:28.004006: Epoch 448 
2025-06-04 01:06:28.069858: Current learning rate: 0.00586 
2025-06-04 01:08:37.375712: train_loss -0.673 
2025-06-04 01:08:37.492913: val_loss -0.6508 
2025-06-04 01:08:37.533325: Pseudo dice [np.float32(0.7052)] 
2025-06-04 01:08:37.552186: Epoch time: 129.48 s 
2025-06-04 01:08:42.493093:  
2025-06-04 01:08:42.582735: Epoch 449 
2025-06-04 01:08:42.600480: Current learning rate: 0.00585 
2025-06-04 01:10:51.917220: train_loss -0.6681 
2025-06-04 01:10:52.080192: val_loss -0.6679 
2025-06-04 01:10:52.297330: Pseudo dice [np.float32(0.671)] 
2025-06-04 01:10:52.577819: Epoch time: 129.43 s 
2025-06-04 01:10:59.372207:  
2025-06-04 01:10:59.405251: Epoch 450 
2025-06-04 01:10:59.419188: Current learning rate: 0.00584 
2025-06-04 01:13:10.134685: train_loss -0.6515 
2025-06-04 01:13:10.921382: val_loss -0.6101 
2025-06-04 01:13:11.334097: Pseudo dice [np.float32(0.7073)] 
2025-06-04 01:13:11.542300: Epoch time: 130.77 s 
2025-06-04 01:13:13.650478:  
2025-06-04 01:13:13.667899: Epoch 451 
2025-06-04 01:13:13.686879: Current learning rate: 0.00583 
2025-06-04 01:15:24.125670: train_loss -0.6824 
2025-06-04 01:15:24.653832: val_loss -0.7288 
2025-06-04 01:15:24.915190: Pseudo dice [np.float32(0.7928)] 
2025-06-04 01:15:25.123807: Epoch time: 130.48 s 
2025-06-04 01:15:27.619811:  
2025-06-04 01:15:27.643632: Epoch 452 
2025-06-04 01:15:27.663330: Current learning rate: 0.00582 
2025-06-04 01:17:38.326861: train_loss -0.701 
2025-06-04 01:17:38.690956: val_loss -0.6128 
2025-06-04 01:17:39.189800: Pseudo dice [np.float32(0.7414)] 
2025-06-04 01:17:39.603046: Epoch time: 130.71 s 
2025-06-04 01:17:42.653672:  
2025-06-04 01:17:42.763632: Epoch 453 
2025-06-04 01:17:42.921518: Current learning rate: 0.00581 
2025-06-04 01:19:53.585303: train_loss -0.6675 
2025-06-04 01:19:54.044046: val_loss -0.69 
2025-06-04 01:19:54.293351: Pseudo dice [np.float32(0.6707)] 
2025-06-04 01:19:54.330754: Epoch time: 130.93 s 
2025-06-04 01:19:58.088771:  
2025-06-04 01:19:58.116257: Epoch 454 
2025-06-04 01:19:58.146734: Current learning rate: 0.0058 
2025-06-04 01:22:04.047099: train_loss -0.6605 
2025-06-04 01:22:04.547234: val_loss -0.6127 
2025-06-04 01:22:04.565115: Pseudo dice [np.float32(0.7113)] 
2025-06-04 01:22:04.588115: Epoch time: 125.96 s 
2025-06-04 01:22:08.888927:  
2025-06-04 01:22:08.927812: Epoch 455 
2025-06-04 01:22:08.956242: Current learning rate: 0.00579 
2025-06-04 01:24:18.820524: train_loss -0.6397 
2025-06-04 01:24:19.196100: val_loss -0.6457 
2025-06-04 01:24:19.465126: Pseudo dice [np.float32(0.6676)] 
2025-06-04 01:24:19.633604: Epoch time: 129.93 s 
2025-06-04 01:24:21.377826:  
2025-06-04 01:24:21.393312: Epoch 456 
2025-06-04 01:24:21.408303: Current learning rate: 0.00578 
2025-06-04 01:26:31.978537: train_loss -0.6739 
2025-06-04 01:26:32.290801: val_loss -0.6461 
2025-06-04 01:26:32.684122: Pseudo dice [np.float32(0.6413)] 
2025-06-04 01:26:32.990626: Epoch time: 130.6 s 
2025-06-04 01:26:35.229207:  
2025-06-04 01:26:35.247376: Epoch 457 
2025-06-04 01:26:35.261584: Current learning rate: 0.00577 
2025-06-04 01:28:45.783997: train_loss -0.682 
2025-06-04 01:28:45.800970: val_loss -0.6816 
2025-06-04 01:28:45.816337: Pseudo dice [np.float32(0.7702)] 
2025-06-04 01:28:45.831692: Epoch time: 130.56 s 
2025-06-04 01:28:49.036559:  
2025-06-04 01:28:49.151625: Epoch 458 
2025-06-04 01:28:49.252319: Current learning rate: 0.00576 
2025-06-04 01:30:59.682133: train_loss -0.6765 
2025-06-04 01:30:59.699838: val_loss -0.6627 
2025-06-04 01:30:59.714300: Pseudo dice [np.float32(0.7224)] 
2025-06-04 01:30:59.728453: Epoch time: 130.65 s 
2025-06-04 01:31:02.221726:  
2025-06-04 01:31:02.351463: Epoch 459 
2025-06-04 01:31:02.413978: Current learning rate: 0.00575 
2025-06-04 01:33:15.172945: train_loss -0.6733 
2025-06-04 01:33:15.633279: val_loss -0.6131 
2025-06-04 01:33:15.862774: Pseudo dice [np.float32(0.781)] 
2025-06-04 01:33:15.879509: Epoch time: 132.95 s 
2025-06-04 01:33:18.648270:  
2025-06-04 01:33:18.685761: Epoch 460 
2025-06-04 01:33:18.779060: Current learning rate: 0.00574 
2025-06-04 01:35:30.656729: train_loss -0.6936 
2025-06-04 01:35:30.790690: val_loss -0.6391 
2025-06-04 01:35:31.284055: Pseudo dice [np.float32(0.7258)] 
2025-06-04 01:35:31.301759: Epoch time: 132.01 s 
2025-06-04 01:35:34.379058:  
2025-06-04 01:35:34.424202: Epoch 461 
2025-06-04 01:35:34.561883: Current learning rate: 0.00573 
2025-06-04 01:37:48.581013: train_loss -0.6709 
2025-06-04 01:37:49.095194: val_loss -0.6546 
2025-06-04 01:37:49.234285: Pseudo dice [np.float32(0.7229)] 
2025-06-04 01:37:49.248661: Epoch time: 134.2 s 
2025-06-04 01:37:52.369516:  
2025-06-04 01:37:52.399606: Epoch 462 
2025-06-04 01:37:52.430275: Current learning rate: 0.00572 
2025-06-04 01:40:05.508807: train_loss -0.6983 
2025-06-04 01:40:05.686902: val_loss -0.6562 
2025-06-04 01:40:06.093907: Pseudo dice [np.float32(0.7047)] 
2025-06-04 01:40:06.110491: Epoch time: 133.14 s 
2025-06-04 01:40:10.626159:  
2025-06-04 01:40:10.843379: Epoch 463 
2025-06-04 01:40:11.061066: Current learning rate: 0.00571 
2025-06-04 01:42:23.276048: train_loss -0.7023 
2025-06-04 01:42:23.583026: val_loss -0.6938 
2025-06-04 01:42:23.707273: Pseudo dice [np.float32(0.763)] 
2025-06-04 01:42:24.337290: Epoch time: 132.65 s 
2025-06-04 01:42:26.917025:  
2025-06-04 01:42:26.935995: Epoch 464 
2025-06-04 01:42:26.951276: Current learning rate: 0.0057 
2025-06-04 01:44:35.389926: train_loss -0.6751 
2025-06-04 01:44:35.560056: val_loss -0.6637 
2025-06-04 01:44:35.575919: Pseudo dice [np.float32(0.7178)] 
2025-06-04 01:44:35.590231: Epoch time: 128.48 s 
2025-06-04 01:44:39.452751:  
2025-06-04 01:44:39.476628: Epoch 465 
2025-06-04 01:44:39.504995: Current learning rate: 0.0057 
2025-06-04 01:46:50.863703: train_loss -0.6828 
2025-06-04 01:46:51.402014: val_loss -0.6418 
2025-06-04 01:46:52.050384: Pseudo dice [np.float32(0.7195)] 
2025-06-04 01:46:52.325262: Epoch time: 131.41 s 
2025-06-04 01:46:55.139482:  
2025-06-04 01:46:55.180998: Epoch 466 
2025-06-04 01:46:55.199125: Current learning rate: 0.00569 
2025-06-04 01:49:06.350284: train_loss -0.7114 
2025-06-04 01:49:06.559235: val_loss -0.7123 
2025-06-04 01:49:06.958835: Pseudo dice [np.float32(0.7935)] 
2025-06-04 01:49:07.318103: Epoch time: 131.21 s 
2025-06-04 01:49:09.967420:  
2025-06-04 01:49:10.045640: Epoch 467 
2025-06-04 01:49:10.065597: Current learning rate: 0.00568 
2025-06-04 01:51:23.555384: train_loss -0.6924 
2025-06-04 01:51:23.578860: val_loss -0.6539 
2025-06-04 01:51:23.594199: Pseudo dice [np.float32(0.7803)] 
2025-06-04 01:51:23.609132: Epoch time: 133.59 s 
2025-06-04 01:51:26.733014:  
2025-06-04 01:51:26.912926: Epoch 468 
2025-06-04 01:51:27.066027: Current learning rate: 0.00567 
2025-06-04 01:53:40.970776: train_loss -0.6746 
2025-06-04 01:53:41.293397: val_loss -0.6586 
2025-06-04 01:53:41.613846: Pseudo dice [np.float32(0.7792)] 
2025-06-04 01:53:41.993046: Epoch time: 134.24 s 
2025-06-04 01:53:46.049834:  
2025-06-04 01:53:46.267425: Epoch 469 
2025-06-04 01:53:46.395442: Current learning rate: 0.00566 
2025-06-04 01:55:56.522319: train_loss -0.6763 
2025-06-04 01:55:56.542066: val_loss -0.6291 
2025-06-04 01:55:56.556850: Pseudo dice [np.float32(0.6923)] 
2025-06-04 01:55:56.571692: Epoch time: 130.47 s 
2025-06-04 01:56:01.562829:  
2025-06-04 01:56:01.833980: Epoch 470 
2025-06-04 01:56:02.091188: Current learning rate: 0.00565 
2025-06-04 01:58:14.600101: train_loss -0.6787 
2025-06-04 01:58:15.128612: val_loss -0.6302 
2025-06-04 01:58:15.634045: Pseudo dice [np.float32(0.7092)] 
2025-06-04 01:58:16.094794: Epoch time: 133.04 s 
2025-06-04 01:58:19.653114:  
2025-06-04 01:58:19.835872: Epoch 471 
2025-06-04 01:58:19.982203: Current learning rate: 0.00564 
2025-06-04 02:00:33.233309: train_loss -0.6872 
2025-06-04 02:00:33.253436: val_loss -0.7269 
2025-06-04 02:00:33.268847: Pseudo dice [np.float32(0.7359)] 
2025-06-04 02:00:33.283280: Epoch time: 133.58 s 
2025-06-04 02:00:36.534907:  
2025-06-04 02:00:36.654472: Epoch 472 
2025-06-04 02:00:36.756436: Current learning rate: 0.00563 
2025-06-04 02:02:50.191057: train_loss -0.7003 
2025-06-04 02:02:50.323103: val_loss -0.6496 
2025-06-04 02:02:50.340436: Pseudo dice [np.float32(0.7737)] 
2025-06-04 02:02:50.355894: Epoch time: 133.66 s 
2025-06-04 02:02:54.623946:  
2025-06-04 02:02:54.644745: Epoch 473 
2025-06-04 02:02:54.659738: Current learning rate: 0.00562 
2025-06-04 02:05:05.294562: train_loss -0.6839 
2025-06-04 02:05:05.611771: val_loss -0.6565 
2025-06-04 02:05:06.013463: Pseudo dice [np.float32(0.7756)] 
2025-06-04 02:05:06.324361: Epoch time: 130.67 s 
2025-06-04 02:05:09.656647:  
2025-06-04 02:05:09.674681: Epoch 474 
2025-06-04 02:05:09.692624: Current learning rate: 0.00561 
2025-06-04 02:07:22.129279: train_loss -0.6835 
2025-06-04 02:07:22.149009: val_loss -0.6423 
2025-06-04 02:07:22.163875: Pseudo dice [np.float32(0.6881)] 
2025-06-04 02:07:22.178334: Epoch time: 132.48 s 
2025-06-04 02:07:25.111319:  
2025-06-04 02:07:25.137939: Epoch 475 
2025-06-04 02:07:25.159291: Current learning rate: 0.0056 
2025-06-04 02:09:33.215581: train_loss -0.6746 
2025-06-04 02:09:33.551072: val_loss -0.6395 
2025-06-04 02:09:33.845796: Pseudo dice [np.float32(0.7445)] 
2025-06-04 02:09:34.113888: Epoch time: 128.11 s 
2025-06-04 02:09:36.224703:  
2025-06-04 02:09:36.244321: Epoch 476 
2025-06-04 02:09:36.263134: Current learning rate: 0.00559 
2025-06-04 02:11:45.279890: train_loss -0.6963 
2025-06-04 02:11:45.559148: val_loss -0.6511 
2025-06-04 02:11:45.815569: Pseudo dice [np.float32(0.7445)] 
2025-06-04 02:11:46.071491: Epoch time: 129.06 s 
2025-06-04 02:11:48.103688:  
2025-06-04 02:11:48.129007: Epoch 477 
2025-06-04 02:11:48.147892: Current learning rate: 0.00558 
2025-06-04 02:13:57.223718: train_loss -0.6972 
2025-06-04 02:13:57.507525: val_loss -0.678 
2025-06-04 02:13:57.845095: Pseudo dice [np.float32(0.8261)] 
2025-06-04 02:13:58.091355: Epoch time: 129.12 s 
2025-06-04 02:14:00.948969:  
2025-06-04 02:14:00.962501: Epoch 478 
2025-06-04 02:14:00.994897: Current learning rate: 0.00557 
2025-06-04 02:16:10.232592: train_loss -0.6703 
2025-06-04 02:16:10.459364: val_loss -0.6176 
2025-06-04 02:16:10.885598: Pseudo dice [np.float32(0.76)] 
2025-06-04 02:16:11.176802: Epoch time: 129.29 s 
2025-06-04 02:16:13.645352:  
2025-06-04 02:16:13.729378: Epoch 479 
2025-06-04 02:16:13.743701: Current learning rate: 0.00556 
2025-06-04 02:18:25.513878: train_loss -0.6815 
2025-06-04 02:18:25.533579: val_loss -0.6679 
2025-06-04 02:18:25.549243: Pseudo dice [np.float32(0.7572)] 
2025-06-04 02:18:25.564553: Epoch time: 131.87 s 
2025-06-04 02:18:28.694374:  
2025-06-04 02:18:28.709277: Epoch 480 
2025-06-04 02:18:28.724744: Current learning rate: 0.00555 
2025-06-04 02:20:42.574301: train_loss -0.6873 
2025-06-04 02:20:42.792650: val_loss -0.6596 
2025-06-04 02:20:43.055050: Pseudo dice [np.float32(0.7844)] 
2025-06-04 02:20:43.284086: Epoch time: 133.88 s 
2025-06-04 02:20:45.682966:  
2025-06-04 02:20:45.698303: Epoch 481 
2025-06-04 02:20:45.713980: Current learning rate: 0.00554 
2025-06-04 02:22:52.815927: train_loss -0.6344 
2025-06-04 02:22:53.042449: val_loss -0.6788 
2025-06-04 02:22:53.291266: Pseudo dice [np.float32(0.7095)] 
2025-06-04 02:22:53.440757: Epoch time: 127.13 s 
2025-06-04 02:22:55.649247:  
2025-06-04 02:22:55.710552: Epoch 482 
2025-06-04 02:22:55.752132: Current learning rate: 0.00553 
2025-06-04 02:25:09.319135: train_loss -0.6354 
2025-06-04 02:25:09.916951: val_loss -0.7114 
2025-06-04 02:25:10.354788: Pseudo dice [np.float32(0.7724)] 
2025-06-04 02:25:10.741335: Epoch time: 133.67 s 
2025-06-04 02:25:13.125144:  
2025-06-04 02:25:13.141804: Epoch 483 
2025-06-04 02:25:13.156990: Current learning rate: 0.00552 
2025-06-04 02:27:25.632512: train_loss -0.666 
2025-06-04 02:27:26.236724: val_loss -0.6579 
2025-06-04 02:27:26.799421: Pseudo dice [np.float32(0.7388)] 
2025-06-04 02:27:27.367598: Epoch time: 132.51 s 
2025-06-04 02:27:30.662295:  
2025-06-04 02:27:30.792039: Epoch 484 
2025-06-04 02:27:30.855772: Current learning rate: 0.00551 
2025-06-04 02:29:38.050203: train_loss -0.6971 
2025-06-04 02:29:38.074175: val_loss -0.7 
2025-06-04 02:29:38.091864: Pseudo dice [np.float32(0.7662)] 
2025-06-04 02:29:38.108139: Epoch time: 127.39 s 
2025-06-04 02:29:44.612639:  
2025-06-04 02:29:44.634453: Epoch 485 
2025-06-04 02:29:44.650856: Current learning rate: 0.0055 
2025-06-04 02:31:53.035048: train_loss -0.6778 
2025-06-04 02:31:53.062015: val_loss -0.6819 
2025-06-04 02:31:53.083334: Pseudo dice [np.float32(0.7324)] 
2025-06-04 02:31:53.097654: Epoch time: 128.42 s 
2025-06-04 02:31:59.117028:  
2025-06-04 02:31:59.233111: Epoch 486 
2025-06-04 02:31:59.298904: Current learning rate: 0.00549 
2025-06-04 02:34:07.075174: train_loss -0.6824 
2025-06-04 02:34:07.627146: val_loss -0.6075 
2025-06-04 02:34:07.646120: Pseudo dice [np.float32(0.6307)] 
2025-06-04 02:34:08.299479: Epoch time: 127.96 s 
2025-06-04 02:34:13.311831:  
2025-06-04 02:34:13.337939: Epoch 487 
2025-06-04 02:34:13.353046: Current learning rate: 0.00548 
2025-06-04 02:36:24.547526: train_loss -0.67 
2025-06-04 02:36:25.096813: val_loss -0.6158 
2025-06-04 02:36:25.624886: Pseudo dice [np.float32(0.6738)] 
2025-06-04 02:36:26.111049: Epoch time: 131.24 s 
2025-06-04 02:36:29.053033:  
2025-06-04 02:36:29.303574: Epoch 488 
2025-06-04 02:36:29.472770: Current learning rate: 0.00547 
2025-06-04 02:38:40.519343: train_loss -0.6912 
2025-06-04 02:38:40.538809: val_loss -0.6996 
2025-06-04 02:38:40.553696: Pseudo dice [np.float32(0.8048)] 
2025-06-04 02:38:40.569385: Epoch time: 131.47 s 
2025-06-04 02:38:44.134133:  
2025-06-04 02:38:44.229021: Epoch 489 
2025-06-04 02:38:44.447688: Current learning rate: 0.00546 
2025-06-04 02:40:55.368375: train_loss -0.6897 
2025-06-04 02:40:55.390176: val_loss -0.6273 
2025-06-04 02:40:55.405132: Pseudo dice [np.float32(0.7349)] 
2025-06-04 02:40:55.421414: Epoch time: 131.24 s 
2025-06-04 02:40:59.068409:  
2025-06-04 02:40:59.109140: Epoch 490 
2025-06-04 02:40:59.132697: Current learning rate: 0.00546 
2025-06-04 02:43:07.791955: train_loss -0.6452 
2025-06-04 02:43:08.164629: val_loss -0.6584 
2025-06-04 02:43:08.525217: Pseudo dice [np.float32(0.7535)] 
2025-06-04 02:43:08.541701: Epoch time: 128.73 s 
2025-06-04 02:43:12.945043:  
2025-06-04 02:43:12.996406: Epoch 491 
2025-06-04 02:43:13.016708: Current learning rate: 0.00545 
2025-06-04 02:45:22.885882: train_loss -0.6866 
2025-06-04 02:45:23.228514: val_loss -0.6592 
2025-06-04 02:45:23.740561: Pseudo dice [np.float32(0.7256)] 
2025-06-04 02:45:24.211706: Epoch time: 129.94 s 
2025-06-04 02:45:27.793115:  
2025-06-04 02:45:27.816699: Epoch 492 
2025-06-04 02:45:27.833233: Current learning rate: 0.00544 
2025-06-04 02:47:34.345376: train_loss -0.6867 
2025-06-04 02:47:34.635367: val_loss -0.6823 
2025-06-04 02:47:35.212929: Pseudo dice [np.float32(0.7461)] 
2025-06-04 02:47:35.761554: Epoch time: 126.55 s 
2025-06-04 02:47:39.607723:  
2025-06-04 02:47:39.625896: Epoch 493 
2025-06-04 02:47:39.654805: Current learning rate: 0.00543 
2025-06-04 02:49:47.641531: train_loss -0.7011 
2025-06-04 02:49:48.207620: val_loss -0.6134 
2025-06-04 02:49:48.786984: Pseudo dice [np.float32(0.7317)] 
2025-06-04 02:49:49.089090: Epoch time: 128.03 s 
2025-06-04 02:49:54.714400:  
2025-06-04 02:49:54.734123: Epoch 494 
2025-06-04 02:49:54.746646: Current learning rate: 0.00542 
2025-06-04 02:52:03.128901: train_loss -0.7112 
2025-06-04 02:52:03.681799: val_loss -0.6425 
2025-06-04 02:52:04.235126: Pseudo dice [np.float32(0.7084)] 
2025-06-04 02:52:04.610886: Epoch time: 128.42 s 
2025-06-04 02:52:09.481082:  
2025-06-04 02:52:09.531488: Epoch 495 
2025-06-04 02:52:09.550124: Current learning rate: 0.00541 
2025-06-04 02:54:22.630338: train_loss -0.7018 
2025-06-04 02:54:22.930117: val_loss -0.679 
2025-06-04 02:54:23.492918: Pseudo dice [np.float32(0.7895)] 
2025-06-04 02:54:23.510221: Epoch time: 133.15 s 
2025-06-04 02:54:26.897275:  
2025-06-04 02:54:27.032723: Epoch 496 
2025-06-04 02:54:27.054070: Current learning rate: 0.0054 
2025-06-04 02:56:35.719943: train_loss -0.694 
2025-06-04 02:56:35.737554: val_loss -0.6818 
2025-06-04 02:56:35.753706: Pseudo dice [np.float32(0.7532)] 
2025-06-04 02:56:35.773149: Epoch time: 128.82 s 
2025-06-04 02:56:39.353862:  
2025-06-04 02:56:39.372500: Epoch 497 
2025-06-04 02:56:39.386598: Current learning rate: 0.00539 
2025-06-04 02:58:47.025169: train_loss -0.7092 
2025-06-04 02:58:47.146572: val_loss -0.6504 
2025-06-04 02:58:47.403321: Pseudo dice [np.float32(0.734)] 
2025-06-04 02:58:47.658792: Epoch time: 127.67 s 
2025-06-04 02:58:49.513040:  
2025-06-04 02:58:49.526105: Epoch 498 
2025-06-04 02:58:49.539874: Current learning rate: 0.00538 
2025-06-04 03:01:02.782586: train_loss -0.6704 
2025-06-04 03:01:03.186701: val_loss -0.651 
2025-06-04 03:01:03.550171: Pseudo dice [np.float32(0.7221)] 
2025-06-04 03:01:03.878190: Epoch time: 133.27 s 
2025-06-04 03:01:07.380985:  
2025-06-04 03:01:07.428505: Epoch 499 
2025-06-04 03:01:07.498166: Current learning rate: 0.00537 
2025-06-04 03:03:18.559814: train_loss -0.6905 
2025-06-04 03:03:18.761677: val_loss -0.6567 
2025-06-04 03:03:19.120510: Pseudo dice [np.float32(0.7597)] 
2025-06-04 03:03:19.473875: Epoch time: 131.18 s 
2025-06-04 03:03:24.025572:  
2025-06-04 03:03:24.123253: Epoch 500 
2025-06-04 03:03:24.193506: Current learning rate: 0.00536 
2025-06-04 03:05:33.957585: train_loss -0.7021 
2025-06-04 03:05:34.227918: val_loss -0.672 
2025-06-04 03:05:34.245865: Pseudo dice [np.float32(0.7758)] 
2025-06-04 03:05:34.260200: Epoch time: 129.93 s 
2025-06-04 03:05:37.169348:  
2025-06-04 03:05:37.227767: Epoch 501 
2025-06-04 03:05:37.316133: Current learning rate: 0.00535 
2025-06-04 03:07:49.575440: train_loss -0.6873 
2025-06-04 03:07:49.601251: val_loss -0.6783 
2025-06-04 03:07:49.915619: Pseudo dice [np.float32(0.7306)] 
2025-06-04 03:07:50.480836: Epoch time: 132.41 s 
2025-06-04 03:07:55.617769:  
2025-06-04 03:07:55.664385: Epoch 502 
2025-06-04 03:07:55.681560: Current learning rate: 0.00534 
2025-06-04 03:10:08.250011: train_loss -0.703 
2025-06-04 03:10:08.735774: val_loss -0.6349 
2025-06-04 03:10:09.069547: Pseudo dice [np.float32(0.7816)] 
2025-06-04 03:10:09.464052: Epoch time: 132.63 s 
2025-06-04 03:10:13.195315:  
2025-06-04 03:10:13.269094: Epoch 503 
2025-06-04 03:10:13.294802: Current learning rate: 0.00533 
2025-06-04 03:12:28.665215: train_loss -0.6886 
2025-06-04 03:12:28.693218: val_loss -0.6347 
2025-06-04 03:12:29.100489: Pseudo dice [np.float32(0.7086)] 
2025-06-04 03:12:29.119994: Epoch time: 135.47 s 
2025-06-04 03:12:33.995018:  
2025-06-04 03:12:34.014601: Epoch 504 
2025-06-04 03:12:34.032168: Current learning rate: 0.00532 
2025-06-04 03:14:47.166414: train_loss -0.7049 
2025-06-04 03:14:47.544422: val_loss -0.6995 
2025-06-04 03:14:47.850784: Pseudo dice [np.float32(0.7578)] 
2025-06-04 03:14:47.870875: Epoch time: 133.17 s 
2025-06-04 03:14:54.220281:  
2025-06-04 03:14:54.317171: Epoch 505 
2025-06-04 03:14:54.341172: Current learning rate: 0.00531 
2025-06-04 03:17:07.795777: train_loss -0.6978 
2025-06-04 03:17:07.820885: val_loss -0.6709 
2025-06-04 03:17:07.837465: Pseudo dice [np.float32(0.7394)] 
2025-06-04 03:17:07.853060: Epoch time: 133.58 s 
2025-06-04 03:17:15.032720:  
2025-06-04 03:17:15.105781: Epoch 506 
2025-06-04 03:17:15.203666: Current learning rate: 0.0053 
2025-06-04 03:19:22.569702: train_loss -0.6812 
2025-06-04 03:19:22.987920: val_loss -0.6311 
2025-06-04 03:19:23.489217: Pseudo dice [np.float32(0.7027)] 
2025-06-04 03:19:23.939426: Epoch time: 127.54 s 
2025-06-04 03:19:29.110653:  
2025-06-04 03:19:29.139994: Epoch 507 
2025-06-04 03:19:29.161008: Current learning rate: 0.00529 
2025-06-04 03:21:41.865280: train_loss -0.6858 
2025-06-04 03:21:42.145195: val_loss -0.6933 
2025-06-04 03:21:42.640529: Pseudo dice [np.float32(0.813)] 
2025-06-04 03:21:43.190209: Epoch time: 132.76 s 
2025-06-04 03:21:46.823457:  
2025-06-04 03:21:46.838593: Epoch 508 
2025-06-04 03:21:46.853423: Current learning rate: 0.00528 
2025-06-04 03:23:55.572352: train_loss -0.6929 
2025-06-04 03:23:55.763160: val_loss -0.6438 
2025-06-04 03:23:56.320921: Pseudo dice [np.float32(0.728)] 
2025-06-04 03:23:56.339403: Epoch time: 128.75 s 
2025-06-04 03:24:01.130751:  
2025-06-04 03:24:01.147127: Epoch 509 
2025-06-04 03:24:01.162336: Current learning rate: 0.00527 
2025-06-04 03:26:10.782500: train_loss -0.6706 
2025-06-04 03:26:11.302975: val_loss -0.6468 
2025-06-04 03:26:11.829037: Pseudo dice [np.float32(0.7558)] 
2025-06-04 03:26:12.323467: Epoch time: 129.65 s 
2025-06-04 03:26:16.173402:  
2025-06-04 03:26:16.194914: Epoch 510 
2025-06-04 03:26:16.216052: Current learning rate: 0.00526 
2025-06-04 03:28:26.388674: train_loss -0.6919 
2025-06-04 03:28:27.076314: val_loss -0.6946 
2025-06-04 03:28:27.601207: Pseudo dice [np.float32(0.7855)] 
2025-06-04 03:28:28.102668: Epoch time: 130.22 s 
2025-06-04 03:28:31.786853:  
2025-06-04 03:28:31.810273: Epoch 511 
2025-06-04 03:28:31.831648: Current learning rate: 0.00525 
2025-06-04 03:30:45.078255: train_loss -0.6895 
2025-06-04 03:30:45.097543: val_loss -0.6781 
2025-06-04 03:30:45.112917: Pseudo dice [np.float32(0.7437)] 
2025-06-04 03:30:45.127260: Epoch time: 133.29 s 
2025-06-04 03:30:48.496478:  
2025-06-04 03:30:48.540029: Epoch 512 
2025-06-04 03:30:48.589783: Current learning rate: 0.00524 
2025-06-04 03:32:59.910885: train_loss -0.6893 
2025-06-04 03:33:00.214692: val_loss -0.6724 
2025-06-04 03:33:00.637049: Pseudo dice [np.float32(0.7001)] 
2025-06-04 03:33:01.147431: Epoch time: 131.42 s 
2025-06-04 03:33:05.196863:  
2025-06-04 03:33:05.224233: Epoch 513 
2025-06-04 03:33:05.371007: Current learning rate: 0.00523 
2025-06-04 03:35:15.914209: train_loss -0.6854 
2025-06-04 03:35:15.933111: val_loss -0.6971 
2025-06-04 03:35:15.948722: Pseudo dice [np.float32(0.7678)] 
2025-06-04 03:35:15.965222: Epoch time: 130.72 s 
2025-06-04 03:35:19.453639:  
2025-06-04 03:35:19.474779: Epoch 514 
2025-06-04 03:35:19.492644: Current learning rate: 0.00522 
2025-06-04 03:37:32.791744: train_loss -0.6869 
2025-06-04 03:37:32.809878: val_loss -0.6202 
2025-06-04 03:37:32.851710: Pseudo dice [np.float32(0.6111)] 
2025-06-04 03:37:32.867727: Epoch time: 133.34 s 
2025-06-04 03:37:36.841860:  
2025-06-04 03:37:36.862198: Epoch 515 
2025-06-04 03:37:36.877540: Current learning rate: 0.00521 
2025-06-04 03:39:47.294380: train_loss -0.6944 
2025-06-04 03:39:47.585868: val_loss -0.6369 
2025-06-04 03:39:48.040480: Pseudo dice [np.float32(0.7292)] 
2025-06-04 03:39:48.556843: Epoch time: 130.45 s 
2025-06-04 03:39:54.200274:  
2025-06-04 03:39:54.246717: Epoch 516 
2025-06-04 03:39:54.267652: Current learning rate: 0.0052 
2025-06-04 03:41:58.461652: train_loss -0.6915 
2025-06-04 03:41:58.796945: val_loss -0.6491 
2025-06-04 03:41:58.813871: Pseudo dice [np.float32(0.7357)] 
2025-06-04 03:41:59.481629: Epoch time: 124.26 s 
2025-06-04 03:42:06.380398:  
2025-06-04 03:42:06.446239: Epoch 517 
2025-06-04 03:42:06.482674: Current learning rate: 0.00519 
2025-06-04 03:44:13.485558: train_loss -0.6777 
2025-06-04 03:44:13.659339: val_loss -0.6179 
2025-06-04 03:44:13.941716: Pseudo dice [np.float32(0.7284)] 
2025-06-04 03:44:14.108231: Epoch time: 127.11 s 
2025-06-04 03:44:16.381497:  
2025-06-04 03:44:16.395396: Epoch 518 
2025-06-04 03:44:16.407299: Current learning rate: 0.00518 
2025-06-04 03:46:25.438530: train_loss -0.7025 
2025-06-04 03:46:25.709607: val_loss -0.7301 
2025-06-04 03:46:26.064771: Pseudo dice [np.float32(0.6719)] 
2025-06-04 03:46:26.346977: Epoch time: 129.06 s 
2025-06-04 03:46:29.751843:  
2025-06-04 03:46:29.766187: Epoch 519 
2025-06-04 03:46:29.778110: Current learning rate: 0.00518 
2025-06-04 03:48:39.227729: train_loss -0.7112 
2025-06-04 03:48:39.309250: val_loss -0.6605 
2025-06-04 03:48:39.332311: Pseudo dice [np.float32(0.7365)] 
2025-06-04 03:48:39.347288: Epoch time: 129.48 s 
2025-06-04 03:48:43.019722:  
2025-06-04 03:48:43.042442: Epoch 520 
2025-06-04 03:48:43.059614: Current learning rate: 0.00517 
2025-06-04 03:50:55.148308: train_loss -0.6713 
2025-06-04 03:50:55.420339: val_loss -0.7056 
2025-06-04 03:50:55.735177: Pseudo dice [np.float32(0.7723)] 
2025-06-04 03:50:55.946271: Epoch time: 132.13 s 
2025-06-04 03:51:00.132836:  
2025-06-04 03:51:00.202415: Epoch 521 
2025-06-04 03:51:00.249058: Current learning rate: 0.00516 
2025-06-04 03:53:15.796934: train_loss -0.7213 
2025-06-04 03:53:16.149573: val_loss -0.66 
2025-06-04 03:53:16.586887: Pseudo dice [np.float32(0.7135)] 
2025-06-04 03:53:16.943095: Epoch time: 135.67 s 
2025-06-04 03:53:20.447733:  
2025-06-04 03:53:20.467256: Epoch 522 
2025-06-04 03:53:20.482153: Current learning rate: 0.00515 
2025-06-04 03:55:31.203202: train_loss -0.6944 
2025-06-04 03:55:31.336401: val_loss -0.747 
2025-06-04 03:55:31.351482: Pseudo dice [np.float32(0.8474)] 
2025-06-04 03:55:31.367011: Epoch time: 130.76 s 
2025-06-04 03:55:35.010522:  
2025-06-04 03:55:35.083556: Epoch 523 
2025-06-04 03:55:35.116419: Current learning rate: 0.00514 
2025-06-04 03:57:47.818363: train_loss -0.6943 
2025-06-04 03:57:47.839606: val_loss -0.6461 
2025-06-04 03:57:47.858936: Pseudo dice [np.float32(0.6758)] 
2025-06-04 03:57:47.874780: Epoch time: 132.81 s 
2025-06-04 03:57:52.131040:  
2025-06-04 03:57:52.146300: Epoch 524 
2025-06-04 03:57:52.161059: Current learning rate: 0.00513 
2025-06-04 03:59:57.741897: train_loss -0.7014 
2025-06-04 03:59:57.766235: val_loss -0.6736 
2025-06-04 03:59:57.782723: Pseudo dice [np.float32(0.7115)] 
2025-06-04 03:59:57.798550: Epoch time: 125.61 s 
2025-06-04 04:00:05.348960:  
2025-06-04 04:00:05.440236: Epoch 525 
2025-06-04 04:00:05.578641: Current learning rate: 0.00512 
2025-06-04 04:02:16.392625: train_loss -0.6977 
2025-06-04 04:02:16.704249: val_loss -0.6085 
2025-06-04 04:02:17.031728: Pseudo dice [np.float32(0.6953)] 
2025-06-04 04:02:17.339183: Epoch time: 131.05 s 
2025-06-04 04:02:23.923185:  
2025-06-04 04:02:24.021459: Epoch 526 
2025-06-04 04:02:24.079669: Current learning rate: 0.00511 
2025-06-04 04:04:34.093440: train_loss -0.681 
2025-06-04 04:04:34.436121: val_loss -0.6787 
2025-06-04 04:04:35.032606: Pseudo dice [np.float32(0.7454)] 
2025-06-04 04:04:35.567450: Epoch time: 130.17 s 
2025-06-04 04:04:41.845474:  
2025-06-04 04:04:42.000071: Epoch 527 
2025-06-04 04:04:42.017949: Current learning rate: 0.0051 
2025-06-04 04:06:53.669940: train_loss -0.6989 
2025-06-04 04:06:54.195432: val_loss -0.6789 
2025-06-04 04:06:54.533908: Pseudo dice [np.float32(0.7549)] 
2025-06-04 04:06:54.550476: Epoch time: 131.83 s 
2025-06-04 04:07:00.413915:  
2025-06-04 04:07:00.599552: Epoch 528 
2025-06-04 04:07:00.638562: Current learning rate: 0.00509 
2025-06-04 04:09:10.546773: train_loss -0.689 
2025-06-04 04:09:10.900119: val_loss -0.6944 
2025-06-04 04:09:11.411235: Pseudo dice [np.float32(0.7776)] 
2025-06-04 04:09:11.753842: Epoch time: 130.13 s 
2025-06-04 04:09:17.059385:  
2025-06-04 04:09:17.251501: Epoch 529 
2025-06-04 04:09:17.340223: Current learning rate: 0.00508 
2025-06-04 04:11:26.545339: train_loss -0.7147 
2025-06-04 04:11:27.042800: val_loss -0.729 
2025-06-04 04:11:27.587660: Pseudo dice [np.float32(0.8282)] 
2025-06-04 04:11:28.073616: Epoch time: 129.49 s 
2025-06-04 04:11:33.685415:  
2025-06-04 04:11:33.707724: Epoch 530 
2025-06-04 04:11:33.750307: Current learning rate: 0.00507 
2025-06-04 04:13:42.890995: train_loss -0.6748 
2025-06-04 04:13:43.066237: val_loss -0.6446 
2025-06-04 04:13:43.553354: Pseudo dice [np.float32(0.762)] 
2025-06-04 04:13:43.570519: Epoch time: 129.21 s 
2025-06-04 04:13:47.231921:  
2025-06-04 04:13:47.304031: Epoch 531 
2025-06-04 04:13:47.322102: Current learning rate: 0.00506 
2025-06-04 04:15:58.683549: train_loss -0.6997 
2025-06-04 04:15:58.703823: val_loss -0.6641 
2025-06-04 04:15:58.718535: Pseudo dice [np.float32(0.7263)] 
2025-06-04 04:15:58.733058: Epoch time: 131.45 s 
2025-06-04 04:16:03.342175:  
2025-06-04 04:16:03.369003: Epoch 532 
2025-06-04 04:16:03.384744: Current learning rate: 0.00505 
2025-06-04 04:18:12.714047: train_loss -0.6932 
2025-06-04 04:18:13.327971: val_loss -0.6411 
2025-06-04 04:18:13.344851: Pseudo dice [np.float32(0.7568)] 
2025-06-04 04:18:13.362261: Epoch time: 129.37 s 
2025-06-04 04:18:16.898601:  
2025-06-04 04:18:16.925409: Epoch 533 
2025-06-04 04:18:16.944001: Current learning rate: 0.00504 
2025-06-04 04:20:27.449469: train_loss -0.6817 
2025-06-04 04:20:27.788198: val_loss -0.6353 
2025-06-04 04:20:28.147852: Pseudo dice [np.float32(0.7054)] 
2025-06-04 04:20:28.168385: Epoch time: 130.55 s 
2025-06-04 04:20:32.882134:  
2025-06-04 04:20:32.895121: Epoch 534 
2025-06-04 04:20:32.908626: Current learning rate: 0.00503 
2025-06-04 04:22:48.486822: train_loss -0.6684 
2025-06-04 04:22:49.258753: val_loss -0.6689 
2025-06-04 04:22:49.775976: Pseudo dice [np.float32(0.7268)] 
2025-06-04 04:22:49.887784: Epoch time: 135.61 s 
2025-06-04 04:22:53.974721:  
2025-06-04 04:22:54.007669: Epoch 535 
2025-06-04 04:22:54.033217: Current learning rate: 0.00502 
2025-06-04 04:25:00.062612: train_loss -0.6769 
2025-06-04 04:25:00.083059: val_loss -0.6439 
2025-06-04 04:25:00.099376: Pseudo dice [np.float32(0.6576)] 
2025-06-04 04:25:00.114600: Epoch time: 126.09 s 
2025-06-04 04:25:05.127093:  
2025-06-04 04:25:05.166386: Epoch 536 
2025-06-04 04:25:05.186532: Current learning rate: 0.00501 
2025-06-04 04:27:14.245463: train_loss -0.6766 
2025-06-04 04:27:14.594223: val_loss -0.59 
2025-06-04 04:27:15.043164: Pseudo dice [np.float32(0.7205)] 
2025-06-04 04:27:15.484018: Epoch time: 129.12 s 
2025-06-04 04:27:20.214501:  
2025-06-04 04:27:20.283247: Epoch 537 
2025-06-04 04:27:20.368695: Current learning rate: 0.005 
2025-06-04 04:29:32.032274: train_loss -0.6923 
2025-06-04 04:29:32.200763: val_loss -0.7 
2025-06-04 04:29:32.216127: Pseudo dice [np.float32(0.8084)] 
2025-06-04 04:29:32.231017: Epoch time: 131.82 s 
2025-06-04 04:29:36.698977:  
2025-06-04 04:29:36.733020: Epoch 538 
2025-06-04 04:29:36.753657: Current learning rate: 0.00499 
2025-06-04 04:31:46.972481: train_loss -0.6841 
2025-06-04 04:31:46.992287: val_loss -0.6803 
2025-06-04 04:31:47.009058: Pseudo dice [np.float32(0.7845)] 
2025-06-04 04:31:47.023995: Epoch time: 130.28 s 
2025-06-04 04:31:52.688464:  
2025-06-04 04:31:52.726472: Epoch 539 
2025-06-04 04:31:52.763104: Current learning rate: 0.00498 
2025-06-04 04:33:58.739430: train_loss -0.7006 
2025-06-04 04:33:58.766608: val_loss -0.7039 
2025-06-04 04:33:58.786667: Pseudo dice [np.float32(0.8533)] 
2025-06-04 04:33:58.802092: Epoch time: 126.05 s 
2025-06-04 04:34:04.853390:  
2025-06-04 04:34:04.873755: Epoch 540 
2025-06-04 04:34:04.892037: Current learning rate: 0.00497 
2025-06-04 04:36:08.431534: train_loss -0.6742 
2025-06-04 04:36:08.697106: val_loss -0.6107 
2025-06-04 04:36:08.914130: Pseudo dice [np.float32(0.6427)] 
2025-06-04 04:36:09.066892: Epoch time: 123.58 s 
2025-06-04 04:36:10.742729:  
2025-06-04 04:36:10.762089: Epoch 541 
2025-06-04 04:36:10.774296: Current learning rate: 0.00496 
2025-06-04 04:38:17.822780: train_loss -0.6789 
2025-06-04 04:38:18.120217: val_loss -0.6403 
2025-06-04 04:38:18.406640: Pseudo dice [np.float32(0.7136)] 
2025-06-04 04:38:18.710340: Epoch time: 127.08 s 
2025-06-04 04:38:22.078056:  
2025-06-04 04:38:22.096694: Epoch 542 
2025-06-04 04:38:22.110504: Current learning rate: 0.00495 
2025-06-04 04:40:34.308898: train_loss -0.6803 
2025-06-04 04:40:34.590377: val_loss -0.7268 
2025-06-04 04:40:34.809548: Pseudo dice [np.float32(0.8179)] 
2025-06-04 04:40:35.028632: Epoch time: 132.23 s 
2025-06-04 04:40:37.558938:  
2025-06-04 04:40:37.571721: Epoch 543 
2025-06-04 04:40:37.584524: Current learning rate: 0.00494 
2025-06-04 04:42:44.736928: train_loss -0.6885 
2025-06-04 04:42:45.041212: val_loss -0.636 
2025-06-04 04:42:45.346982: Pseudo dice [np.float32(0.7591)] 
2025-06-04 04:42:45.754482: Epoch time: 127.18 s 
2025-06-04 04:42:48.874929:  
2025-06-04 04:42:48.893260: Epoch 544 
2025-06-04 04:42:48.950248: Current learning rate: 0.00493 
2025-06-04 04:44:57.726836: train_loss -0.695 
2025-06-04 04:44:57.849411: val_loss -0.6251 
2025-06-04 04:44:57.866277: Pseudo dice [np.float32(0.7056)] 
2025-06-04 04:44:57.882133: Epoch time: 128.86 s 
2025-06-04 04:45:00.824037:  
2025-06-04 04:45:00.920823: Epoch 545 
2025-06-04 04:45:01.065108: Current learning rate: 0.00492 
2025-06-04 04:47:15.851881: train_loss -0.7023 
2025-06-04 04:47:16.092435: val_loss -0.6789 
2025-06-04 04:47:16.304977: Pseudo dice [np.float32(0.7695)] 
2025-06-04 04:47:16.495145: Epoch time: 135.03 s 
2025-06-04 04:47:18.889755:  
2025-06-04 04:47:18.908865: Epoch 546 
2025-06-04 04:47:18.931764: Current learning rate: 0.00491 
2025-06-04 04:49:33.225367: train_loss -0.7052 
2025-06-04 04:49:33.442364: val_loss -0.6655 
2025-06-04 04:49:33.779979: Pseudo dice [np.float32(0.6932)] 
2025-06-04 04:49:34.147705: Epoch time: 134.34 s 
2025-06-04 04:49:36.626148:  
2025-06-04 04:49:36.649489: Epoch 547 
2025-06-04 04:49:36.703029: Current learning rate: 0.0049 
2025-06-04 04:51:52.071837: train_loss -0.7203 
2025-06-04 04:51:52.443403: val_loss -0.7133 
2025-06-04 04:51:52.877051: Pseudo dice [np.float32(0.8053)] 
2025-06-04 04:51:52.893700: Epoch time: 135.45 s 
2025-06-04 04:51:56.637107:  
2025-06-04 04:51:56.696379: Epoch 548 
2025-06-04 04:51:56.856583: Current learning rate: 0.00489 
2025-06-04 04:54:06.439082: train_loss -0.7183 
2025-06-04 04:54:06.567104: val_loss -0.6547 
2025-06-04 04:54:06.935826: Pseudo dice [np.float32(0.757)] 
2025-06-04 04:54:07.354441: Epoch time: 129.8 s 
2025-06-04 04:54:10.786100:  
2025-06-04 04:54:10.879584: Epoch 549 
2025-06-04 04:54:10.943070: Current learning rate: 0.00488 
2025-06-04 04:56:22.590240: train_loss -0.7016 
2025-06-04 04:56:22.962809: val_loss -0.646 
2025-06-04 04:56:23.271415: Pseudo dice [np.float32(0.771)] 
2025-06-04 04:56:23.615993: Epoch time: 131.81 s 
2025-06-04 04:56:28.050056:  
2025-06-04 04:56:28.156164: Epoch 550 
2025-06-04 04:56:28.238813: Current learning rate: 0.00487 
2025-06-04 04:58:38.957370: train_loss -0.6865 
2025-06-04 04:58:39.164958: val_loss -0.6915 
2025-06-04 04:58:39.546968: Pseudo dice [np.float32(0.7239)] 
2025-06-04 04:58:39.877037: Epoch time: 130.91 s 
2025-06-04 04:58:42.969680:  
2025-06-04 04:58:43.026445: Epoch 551 
2025-06-04 04:58:43.048132: Current learning rate: 0.00486 
2025-06-04 05:00:53.975415: train_loss -0.6869 
2025-06-04 05:00:54.195120: val_loss -0.6697 
2025-06-04 05:00:54.491550: Pseudo dice [np.float32(0.7178)] 
2025-06-04 05:00:54.508009: Epoch time: 131.01 s 
2025-06-04 05:00:57.997329:  
2025-06-04 05:00:58.016888: Epoch 552 
2025-06-04 05:00:58.031656: Current learning rate: 0.00485 
2025-06-04 05:03:10.646288: train_loss -0.6735 
2025-06-04 05:03:10.827453: val_loss -0.6869 
2025-06-04 05:03:11.033623: Pseudo dice [np.float32(0.7481)] 
2025-06-04 05:03:11.263489: Epoch time: 132.65 s 
2025-06-04 05:03:13.700671:  
2025-06-04 05:03:13.736936: Epoch 553 
2025-06-04 05:03:13.759830: Current learning rate: 0.00484 
2025-06-04 05:05:22.931417: train_loss -0.6799 
2025-06-04 05:05:23.023613: val_loss -0.7084 
2025-06-04 05:05:23.147789: Pseudo dice [np.float32(0.8181)] 
2025-06-04 05:05:23.250614: Epoch time: 129.23 s 
2025-06-04 05:05:27.193126:  
2025-06-04 05:05:27.228847: Epoch 554 
2025-06-04 05:05:27.382164: Current learning rate: 0.00484 
2025-06-04 05:07:39.491072: train_loss -0.6937 
2025-06-04 05:07:39.860417: val_loss -0.6407 
2025-06-04 05:07:39.965459: Pseudo dice [np.float32(0.7449)] 
2025-06-04 05:07:39.983252: Epoch time: 132.3 s 
2025-06-04 05:07:44.857200:  
2025-06-04 05:07:44.911059: Epoch 555 
2025-06-04 05:07:44.982340: Current learning rate: 0.00483 
2025-06-04 05:09:59.936722: train_loss -0.6849 
2025-06-04 05:09:59.957022: val_loss -0.6837 
2025-06-04 05:09:59.972478: Pseudo dice [np.float32(0.7822)] 
2025-06-04 05:09:59.986863: Epoch time: 135.08 s 
2025-06-04 05:10:04.463023:  
2025-06-04 05:10:04.560696: Epoch 556 
2025-06-04 05:10:04.728533: Current learning rate: 0.00482 
2025-06-04 05:12:16.071033: train_loss -0.6778 
2025-06-04 05:12:16.090219: val_loss -0.6277 
2025-06-04 05:12:16.113112: Pseudo dice [np.float32(0.7022)] 
2025-06-04 05:12:16.129278: Epoch time: 131.61 s 
2025-06-04 05:12:19.410332:  
2025-06-04 05:12:19.640299: Epoch 557 
2025-06-04 05:12:19.924181: Current learning rate: 0.00481 
2025-06-04 05:14:30.695213: train_loss -0.6851 
2025-06-04 05:14:31.063547: val_loss -0.6932 
2025-06-04 05:14:31.535156: Pseudo dice [np.float32(0.7369)] 
2025-06-04 05:14:31.921110: Epoch time: 131.29 s 
2025-06-04 05:14:36.380164:  
2025-06-04 05:14:36.403659: Epoch 558 
2025-06-04 05:14:36.425502: Current learning rate: 0.0048 
2025-06-04 05:16:44.735552: train_loss -0.6956 
2025-06-04 05:16:45.114014: val_loss -0.6398 
2025-06-04 05:16:45.369994: Pseudo dice [np.float32(0.7052)] 
2025-06-04 05:16:45.388715: Epoch time: 128.36 s 
2025-06-04 05:16:49.437857:  
2025-06-04 05:16:49.546926: Epoch 559 
2025-06-04 05:16:49.686704: Current learning rate: 0.00479 
2025-06-04 05:19:01.935571: train_loss -0.6765 
2025-06-04 05:19:02.265822: val_loss -0.7121 
2025-06-04 05:19:02.282338: Pseudo dice [np.float32(0.8169)] 
2025-06-04 05:19:02.297136: Epoch time: 132.5 s 
2025-06-04 05:19:06.075219:  
2025-06-04 05:19:06.250742: Epoch 560 
2025-06-04 05:19:06.577822: Current learning rate: 0.00478 
2025-06-04 05:21:17.395391: train_loss -0.6853 
2025-06-04 05:21:17.745750: val_loss -0.628 
2025-06-04 05:21:17.767760: Pseudo dice [np.float32(0.7025)] 
2025-06-04 05:21:17.783165: Epoch time: 131.32 s 
2025-06-04 05:21:22.477684:  
2025-06-04 05:21:22.634837: Epoch 561 
2025-06-04 05:21:22.905925: Current learning rate: 0.00477 
2025-06-04 05:23:34.197160: train_loss -0.7089 
2025-06-04 05:23:34.619515: val_loss -0.686 
2025-06-04 05:23:34.913647: Pseudo dice [np.float32(0.701)] 
2025-06-04 05:23:34.930712: Epoch time: 131.72 s 
2025-06-04 05:23:39.362025:  
2025-06-04 05:23:39.441938: Epoch 562 
2025-06-04 05:23:39.472394: Current learning rate: 0.00476 
2025-06-04 05:25:52.439360: train_loss -0.6842 
2025-06-04 05:25:52.459197: val_loss -0.6675 
2025-06-04 05:25:52.475542: Pseudo dice [np.float32(0.6915)] 
2025-06-04 05:25:52.491408: Epoch time: 133.08 s 
2025-06-04 05:25:56.191869:  
2025-06-04 05:25:56.253960: Epoch 563 
2025-06-04 05:25:56.273321: Current learning rate: 0.00475 
2025-06-04 05:28:07.664359: train_loss -0.6668 
2025-06-04 05:28:07.682955: val_loss -0.6672 
2025-06-04 05:28:07.699470: Pseudo dice [np.float32(0.7107)] 
2025-06-04 05:28:07.714239: Epoch time: 131.47 s 
2025-06-04 05:28:11.896004:  
2025-06-04 05:28:12.120203: Epoch 564 
2025-06-04 05:28:12.382983: Current learning rate: 0.00474 
2025-06-04 05:30:25.532605: train_loss -0.6919 
2025-06-04 05:30:25.552047: val_loss -0.6729 
2025-06-04 05:30:25.567187: Pseudo dice [np.float32(0.6746)] 
2025-06-04 05:30:25.580626: Epoch time: 133.64 s 
2025-06-04 05:30:29.733636:  
2025-06-04 05:30:29.988652: Epoch 565 
2025-06-04 05:30:30.311799: Current learning rate: 0.00473 
2025-06-04 05:32:37.921965: train_loss -0.6846 
2025-06-04 05:32:37.942216: val_loss -0.6391 
2025-06-04 05:32:37.960314: Pseudo dice [np.float32(0.7168)] 
2025-06-04 05:32:37.979158: Epoch time: 128.19 s 
2025-06-04 05:32:41.538652:  
2025-06-04 05:32:41.692013: Epoch 566 
2025-06-04 05:32:42.066068: Current learning rate: 0.00472 
2025-06-04 05:34:51.382472: train_loss -0.7157 
2025-06-04 05:34:51.401994: val_loss -0.6917 
2025-06-04 05:34:51.418365: Pseudo dice [np.float32(0.8001)] 
2025-06-04 05:34:51.433560: Epoch time: 129.85 s 
2025-06-04 05:34:55.669412:  
2025-06-04 05:34:55.688507: Epoch 567 
2025-06-04 05:34:55.704306: Current learning rate: 0.00471 
2025-06-04 05:37:04.653388: train_loss -0.7023 
2025-06-04 05:37:05.106110: val_loss -0.6857 
2025-06-04 05:37:05.250682: Pseudo dice [np.float32(0.7533)] 
2025-06-04 05:37:05.266817: Epoch time: 128.99 s 
2025-06-04 05:37:08.688305:  
2025-06-04 05:37:08.715455: Epoch 568 
2025-06-04 05:37:08.730516: Current learning rate: 0.0047 
2025-06-04 05:39:17.837906: train_loss -0.684 
2025-06-04 05:39:18.004510: val_loss -0.6501 
2025-06-04 05:39:18.111653: Pseudo dice [np.float32(0.7287)] 
2025-06-04 05:39:18.181947: Epoch time: 129.15 s 
2025-06-04 05:39:19.574283:  
2025-06-04 05:39:19.592295: Epoch 569 
2025-06-04 05:39:19.612612: Current learning rate: 0.00469 
2025-06-04 05:41:29.708680: train_loss -0.7009 
2025-06-04 05:41:30.085542: val_loss -0.6588 
2025-06-04 05:41:30.445688: Pseudo dice [np.float32(0.6953)] 
2025-06-04 05:41:30.707091: Epoch time: 130.14 s 
2025-06-04 05:41:34.308839:  
2025-06-04 05:41:34.326144: Epoch 570 
2025-06-04 05:41:34.340911: Current learning rate: 0.00468 
2025-06-04 05:43:49.323862: train_loss -0.6846 
2025-06-04 05:43:49.341203: val_loss -0.6374 
2025-06-04 05:43:49.362978: Pseudo dice [np.float32(0.6723)] 
2025-06-04 05:43:49.378350: Epoch time: 135.02 s 
2025-06-04 05:43:51.998755:  
2025-06-04 05:43:52.015517: Epoch 571 
2025-06-04 05:43:52.035018: Current learning rate: 0.00467 
2025-06-04 05:46:04.057234: train_loss -0.6737 
2025-06-04 05:46:04.471869: val_loss -0.695 
2025-06-04 05:46:04.882879: Pseudo dice [np.float32(0.7925)] 
2025-06-04 05:46:05.259678: Epoch time: 132.06 s 
2025-06-04 05:46:09.219182:  
2025-06-04 05:46:09.277065: Epoch 572 
2025-06-04 05:46:09.480066: Current learning rate: 0.00466 
2025-06-04 05:48:20.023046: train_loss -0.7064 
2025-06-04 05:48:20.322346: val_loss -0.7116 
2025-06-04 05:48:20.340759: Pseudo dice [np.float32(0.8054)] 
2025-06-04 05:48:20.356864: Epoch time: 130.81 s 
2025-06-04 05:48:23.766936:  
2025-06-04 05:48:23.899237: Epoch 573 
2025-06-04 05:48:23.966023: Current learning rate: 0.00465 
2025-06-04 05:50:35.654018: train_loss -0.6972 
2025-06-04 05:50:36.036672: val_loss -0.6903 
2025-06-04 05:50:36.273689: Pseudo dice [np.float32(0.7708)] 
2025-06-04 05:50:36.633728: Epoch time: 131.89 s 
2025-06-04 05:50:39.418488:  
2025-06-04 05:50:39.439809: Epoch 574 
2025-06-04 05:50:39.454757: Current learning rate: 0.00464 
2025-06-04 05:52:51.456626: train_loss -0.6906 
2025-06-04 05:52:51.809888: val_loss -0.6445 
2025-06-04 05:52:52.070890: Pseudo dice [np.float32(0.7566)] 
2025-06-04 05:52:52.088916: Epoch time: 132.1 s 
2025-06-04 05:52:55.690353:  
2025-06-04 05:52:55.787093: Epoch 575 
2025-06-04 05:52:55.826539: Current learning rate: 0.00463 
2025-06-04 05:55:13.085039: train_loss -0.6821 
2025-06-04 05:55:13.103977: val_loss -0.6719 
2025-06-04 05:55:13.119312: Pseudo dice [np.float32(0.789)] 
2025-06-04 05:55:13.134663: Epoch time: 137.4 s 
2025-06-04 05:55:16.654152:  
2025-06-04 05:55:16.885452: Epoch 576 
2025-06-04 05:55:17.013521: Current learning rate: 0.00462 
2025-06-04 05:57:29.332202: train_loss -0.6804 
2025-06-04 05:57:29.445134: val_loss -0.6702 
2025-06-04 05:57:29.676209: Pseudo dice [np.float32(0.8088)] 
2025-06-04 05:57:29.975359: Epoch time: 132.68 s 
2025-06-04 05:57:32.741473:  
2025-06-04 05:57:32.911929: Epoch 577 
2025-06-04 05:57:33.093678: Current learning rate: 0.00461 
2025-06-04 05:59:46.432767: train_loss -0.7201 
2025-06-04 05:59:46.454816: val_loss -0.6645 
2025-06-04 05:59:46.472300: Pseudo dice [np.float32(0.7847)] 
2025-06-04 05:59:46.490892: Epoch time: 133.69 s 
2025-06-04 05:59:46.508050: Yayy! New best EMA pseudo Dice: 0.7577000260353088 
2025-06-04 05:59:50.949105:  
2025-06-04 05:59:51.102937: Epoch 578 
2025-06-04 05:59:51.307271: Current learning rate: 0.0046 
2025-06-04 06:02:04.046092: train_loss -0.7013 
2025-06-04 06:02:04.485968: val_loss -0.6532 
2025-06-04 06:02:04.956991: Pseudo dice [np.float32(0.7917)] 
2025-06-04 06:02:05.470847: Epoch time: 133.1 s 
2025-06-04 06:02:05.490577: Yayy! New best EMA pseudo Dice: 0.7610999941825867 
2025-06-04 06:02:09.093673:  
2025-06-04 06:02:09.350848: Epoch 579 
2025-06-04 06:02:09.661505: Current learning rate: 0.00459 
2025-06-04 06:04:22.656363: train_loss -0.68 
2025-06-04 06:04:22.827112: val_loss -0.6507 
2025-06-04 06:04:22.850672: Pseudo dice [np.float32(0.7353)] 
2025-06-04 06:04:22.879099: Epoch time: 133.56 s 
2025-06-04 06:04:28.180589:  
2025-06-04 06:04:28.241132: Epoch 580 
2025-06-04 06:04:28.256414: Current learning rate: 0.00458 
2025-06-04 06:06:41.550962: train_loss -0.7111 
2025-06-04 06:06:41.571570: val_loss -0.6334 
2025-06-04 06:06:41.589422: Pseudo dice [np.float32(0.6706)] 
2025-06-04 06:06:41.606765: Epoch time: 133.37 s 
2025-06-04 06:06:45.332927:  
2025-06-04 06:06:45.391551: Epoch 581 
2025-06-04 06:06:45.408465: Current learning rate: 0.00457 
2025-06-04 06:08:55.727933: train_loss -0.6764 
2025-06-04 06:08:56.124650: val_loss -0.6721 
2025-06-04 06:08:56.431189: Pseudo dice [np.float32(0.757)] 
2025-06-04 06:08:57.081030: Epoch time: 130.4 s 
2025-06-04 06:09:00.832080:  
2025-06-04 06:09:00.885475: Epoch 582 
2025-06-04 06:09:00.901667: Current learning rate: 0.00456 
2025-06-04 06:11:15.591870: train_loss -0.667 
2025-06-04 06:11:15.611771: val_loss -0.6783 
2025-06-04 06:11:15.628277: Pseudo dice [np.float32(0.7218)] 
2025-06-04 06:11:15.646112: Epoch time: 134.76 s 
2025-06-04 06:11:21.487060:  
2025-06-04 06:11:21.619117: Epoch 583 
2025-06-04 06:11:21.764931: Current learning rate: 0.00455 
2025-06-04 06:13:29.745242: train_loss -0.706 
2025-06-04 06:13:29.764685: val_loss -0.684 
2025-06-04 06:13:29.781094: Pseudo dice [np.float32(0.7634)] 
2025-06-04 06:13:29.799125: Epoch time: 128.26 s 
2025-06-04 06:13:33.165025:  
2025-06-04 06:13:33.185256: Epoch 584 
2025-06-04 06:13:33.227196: Current learning rate: 0.00454 
2025-06-04 06:15:44.841048: train_loss -0.7205 
2025-06-04 06:15:44.860475: val_loss -0.7055 
2025-06-04 06:15:44.875887: Pseudo dice [np.float32(0.7798)] 
2025-06-04 06:15:44.891232: Epoch time: 131.68 s 
2025-06-04 06:15:48.316963:  
2025-06-04 06:15:48.334898: Epoch 585 
2025-06-04 06:15:48.349997: Current learning rate: 0.00453 
2025-06-04 06:17:58.899396: train_loss -0.7255 
2025-06-04 06:17:59.319705: val_loss -0.6775 
2025-06-04 06:17:59.832751: Pseudo dice [np.float32(0.7868)] 
2025-06-04 06:18:00.098806: Epoch time: 130.58 s 
2025-06-04 06:18:05.115886:  
2025-06-04 06:18:05.361328: Epoch 586 
2025-06-04 06:18:05.475787: Current learning rate: 0.00452 
2025-06-04 06:20:16.422025: train_loss -0.7086 
2025-06-04 06:20:16.454716: val_loss -0.7047 
2025-06-04 06:20:16.475212: Pseudo dice [np.float32(0.7772)] 
2025-06-04 06:20:16.496078: Epoch time: 131.31 s 
2025-06-04 06:20:21.271382:  
2025-06-04 06:20:21.294505: Epoch 587 
2025-06-04 06:20:21.313550: Current learning rate: 0.00451 
2025-06-04 06:22:29.522963: train_loss -0.7171 
2025-06-04 06:22:29.546593: val_loss -0.6502 
2025-06-04 06:22:29.563682: Pseudo dice [np.float32(0.7216)] 
2025-06-04 06:22:29.579889: Epoch time: 128.25 s 
2025-06-04 06:22:33.601671:  
2025-06-04 06:22:33.629199: Epoch 588 
2025-06-04 06:22:33.652115: Current learning rate: 0.0045 
2025-06-04 06:24:43.120551: train_loss -0.6946 
2025-06-04 06:24:43.570104: val_loss -0.6553 
2025-06-04 06:24:44.080581: Pseudo dice [np.float32(0.784)] 
2025-06-04 06:24:44.575141: Epoch time: 129.52 s 
2025-06-04 06:24:50.014165:  
2025-06-04 06:24:50.040362: Epoch 589 
2025-06-04 06:24:50.060050: Current learning rate: 0.00449 
2025-06-04 06:27:01.521537: train_loss -0.6901 
2025-06-04 06:27:01.877985: val_loss -0.63 
2025-06-04 06:27:02.258479: Pseudo dice [np.float32(0.7463)] 
2025-06-04 06:27:02.674515: Epoch time: 131.51 s 
2025-06-04 06:27:05.047970:  
2025-06-04 06:27:05.098652: Epoch 590 
2025-06-04 06:27:05.116239: Current learning rate: 0.00448 
2025-06-04 06:29:13.134804: train_loss -0.6894 
2025-06-04 06:29:13.154338: val_loss -0.6487 
2025-06-04 06:29:13.169841: Pseudo dice [np.float32(0.7151)] 
2025-06-04 06:29:13.185841: Epoch time: 128.09 s 
2025-06-04 06:29:18.913579:  
2025-06-04 06:29:19.048026: Epoch 591 
2025-06-04 06:29:19.278210: Current learning rate: 0.00447 
2025-06-04 06:31:29.247436: train_loss -0.69 
2025-06-04 06:31:29.267711: val_loss -0.6507 
2025-06-04 06:31:29.284064: Pseudo dice [np.float32(0.7562)] 
2025-06-04 06:31:29.299309: Epoch time: 130.34 s 
2025-06-04 06:31:32.300635:  
2025-06-04 06:31:32.362074: Epoch 592 
2025-06-04 06:31:32.414048: Current learning rate: 0.00446 
2025-06-04 06:33:43.926170: train_loss -0.6688 
2025-06-04 06:33:43.947640: val_loss -0.674 
2025-06-04 06:33:43.969026: Pseudo dice [np.float32(0.7896)] 
2025-06-04 06:33:44.199911: Epoch time: 131.63 s 
2025-06-04 06:33:48.791688:  
2025-06-04 06:33:49.005686: Epoch 593 
2025-06-04 06:33:49.163496: Current learning rate: 0.00445 
2025-06-04 06:36:03.019978: train_loss -0.7036 
2025-06-04 06:36:03.039142: val_loss -0.6791 
2025-06-04 06:36:03.065901: Pseudo dice [np.float32(0.7145)] 
2025-06-04 06:36:03.082329: Epoch time: 134.23 s 
2025-06-04 06:36:06.539768:  
2025-06-04 06:36:06.686870: Epoch 594 
2025-06-04 06:36:06.784512: Current learning rate: 0.00444 
2025-06-04 06:38:15.192265: train_loss -0.7151 
2025-06-04 06:38:15.211438: val_loss -0.6936 
2025-06-04 06:38:15.227165: Pseudo dice [np.float32(0.7605)] 
2025-06-04 06:38:15.353487: Epoch time: 128.65 s 
2025-06-04 06:38:18.155728:  
2025-06-04 06:38:18.190602: Epoch 595 
2025-06-04 06:38:18.268778: Current learning rate: 0.00443 
2025-06-04 06:40:26.056278: train_loss -0.6965 
2025-06-04 06:40:26.287713: val_loss -0.5903 
2025-06-04 06:40:26.416353: Pseudo dice [np.float32(0.6462)] 
2025-06-04 06:40:26.605174: Epoch time: 127.9 s 
2025-06-04 06:40:28.274737:  
2025-06-04 06:40:28.290000: Epoch 596 
2025-06-04 06:40:28.303731: Current learning rate: 0.00442 
2025-06-04 06:42:37.865771: train_loss -0.7032 
2025-06-04 06:42:38.259664: val_loss -0.6729 
2025-06-04 06:42:38.586487: Pseudo dice [np.float32(0.7916)] 
2025-06-04 06:42:38.878716: Epoch time: 129.59 s 
2025-06-04 06:42:41.320335:  
2025-06-04 06:42:41.335823: Epoch 597 
2025-06-04 06:42:41.351817: Current learning rate: 0.00441 
2025-06-04 06:44:47.705536: train_loss -0.7024 
2025-06-04 06:44:47.723099: val_loss -0.7019 
2025-06-04 06:44:47.739272: Pseudo dice [np.float32(0.75)] 
2025-06-04 06:44:47.755030: Epoch time: 126.39 s 
2025-06-04 06:44:50.910439:  
2025-06-04 06:44:50.933280: Epoch 598 
2025-06-04 06:44:50.951916: Current learning rate: 0.0044 
2025-06-04 06:46:59.608536: train_loss -0.7028 
2025-06-04 06:46:59.940192: val_loss -0.6902 
2025-06-04 06:47:00.377011: Pseudo dice [np.float32(0.6989)] 
2025-06-04 06:47:00.727767: Epoch time: 128.7 s 
2025-06-04 06:47:05.346667:  
2025-06-04 06:47:05.417312: Epoch 599 
2025-06-04 06:47:05.436335: Current learning rate: 0.00439 
2025-06-04 06:49:11.759611: train_loss -0.7224 
2025-06-04 06:49:12.077791: val_loss -0.6887 
2025-06-04 06:49:12.446209: Pseudo dice [np.float32(0.7103)] 
2025-06-04 06:49:12.816896: Epoch time: 126.41 s 
2025-06-04 06:49:17.499769:  
2025-06-04 06:49:17.617199: Epoch 600 
2025-06-04 06:49:17.652712: Current learning rate: 0.00438 
2025-06-04 06:51:31.948256: train_loss -0.7233 
2025-06-04 06:51:31.967165: val_loss -0.6915 
2025-06-04 06:51:31.982111: Pseudo dice [np.float32(0.7941)] 
2025-06-04 06:51:32.226389: Epoch time: 134.45 s 
2025-06-04 06:51:35.775730:  
2025-06-04 06:51:35.875215: Epoch 601 
2025-06-04 06:51:36.000927: Current learning rate: 0.00437 
2025-06-04 06:53:49.405666: train_loss -0.7019 
2025-06-04 06:53:49.572325: val_loss -0.6839 
2025-06-04 06:53:49.811536: Pseudo dice [np.float32(0.7707)] 
2025-06-04 06:53:50.080286: Epoch time: 133.63 s 
2025-06-04 06:53:52.719618:  
2025-06-04 06:53:52.831716: Epoch 602 
2025-06-04 06:53:52.852782: Current learning rate: 0.00436 
2025-06-04 06:56:02.307905: train_loss -0.7257 
2025-06-04 06:56:02.555387: val_loss -0.642 
2025-06-04 06:56:02.803715: Pseudo dice [np.float32(0.7537)] 
2025-06-04 06:56:02.821604: Epoch time: 129.59 s 
2025-06-04 06:56:06.540304:  
2025-06-04 06:56:06.561804: Epoch 603 
2025-06-04 06:56:06.578016: Current learning rate: 0.00435 
2025-06-04 06:58:16.286992: train_loss -0.7139 
2025-06-04 06:58:16.609872: val_loss -0.6532 
2025-06-04 06:58:16.905420: Pseudo dice [np.float32(0.6794)] 
2025-06-04 06:58:17.233922: Epoch time: 129.75 s 
2025-06-04 06:58:20.522274:  
2025-06-04 06:58:20.579175: Epoch 604 
2025-06-04 06:58:20.600355: Current learning rate: 0.00434 
2025-06-04 07:00:28.384710: train_loss -0.6958 
2025-06-04 07:00:28.771561: val_loss -0.6387 
2025-06-04 07:00:29.239867: Pseudo dice [np.float32(0.7098)] 
2025-06-04 07:00:29.818179: Epoch time: 127.86 s 
2025-06-04 07:00:35.647934:  
2025-06-04 07:00:35.682427: Epoch 605 
2025-06-04 07:00:35.702587: Current learning rate: 0.00433 
2025-06-04 07:02:43.566406: train_loss -0.687 
2025-06-04 07:02:43.590251: val_loss -0.6847 
2025-06-04 07:02:43.605770: Pseudo dice [np.float32(0.7119)] 
2025-06-04 07:02:43.620944: Epoch time: 127.92 s 
2025-06-04 07:02:48.810725:  
2025-06-04 07:02:48.835400: Epoch 606 
2025-06-04 07:02:48.853920: Current learning rate: 0.00432 
2025-06-04 07:04:58.958897: train_loss -0.632 
2025-06-04 07:04:59.492026: val_loss -0.698 
2025-06-04 07:04:59.665454: Pseudo dice [np.float32(0.7668)] 
2025-06-04 07:04:59.681826: Epoch time: 130.15 s 
2025-06-04 07:05:06.626443:  
2025-06-04 07:05:06.874804: Epoch 607 
2025-06-04 07:05:07.194695: Current learning rate: 0.00431 
2025-06-04 07:07:18.922309: train_loss -0.7007 
2025-06-04 07:07:18.946848: val_loss -0.6518 
2025-06-04 07:07:19.256509: Pseudo dice [np.float32(0.7515)] 
2025-06-04 07:07:19.433894: Epoch time: 132.3 s 
2025-06-04 07:07:24.233904:  
2025-06-04 07:07:24.300995: Epoch 608 
2025-06-04 07:07:24.383259: Current learning rate: 0.0043 
2025-06-04 07:09:36.099713: train_loss -0.7109 
2025-06-04 07:09:36.381284: val_loss -0.6709 
2025-06-04 07:09:36.397659: Pseudo dice [np.float32(0.7781)] 
2025-06-04 07:09:36.413266: Epoch time: 131.87 s 
2025-06-04 07:09:39.692127:  
2025-06-04 07:09:39.815532: Epoch 609 
2025-06-04 07:09:39.861627: Current learning rate: 0.00429 
2025-06-04 07:11:53.466907: train_loss -0.7 
2025-06-04 07:11:53.488468: val_loss -0.6501 
2025-06-04 07:11:53.506108: Pseudo dice [np.float32(0.7401)] 
2025-06-04 07:11:53.523842: Epoch time: 133.78 s 
2025-06-04 07:11:57.893432:  
2025-06-04 07:11:57.968260: Epoch 610 
2025-06-04 07:11:58.044312: Current learning rate: 0.00429 
2025-06-04 07:14:03.471971: train_loss -0.699 
2025-06-04 07:14:03.866794: val_loss -0.6486 
2025-06-04 07:14:04.301354: Pseudo dice [np.float32(0.6688)] 
2025-06-04 07:14:04.593031: Epoch time: 125.58 s 
2025-06-04 07:14:09.434034:  
2025-06-04 07:14:09.457488: Epoch 611 
2025-06-04 07:14:09.475016: Current learning rate: 0.00428 
2025-06-04 07:16:21.694345: train_loss -0.6862 
2025-06-04 07:16:21.862314: val_loss -0.6166 
2025-06-04 07:16:21.877734: Pseudo dice [np.float32(0.621)] 
2025-06-04 07:16:21.892563: Epoch time: 132.26 s 
2025-06-04 07:16:25.864053:  
2025-06-04 07:16:25.942598: Epoch 612 
2025-06-04 07:16:25.997058: Current learning rate: 0.00427 
2025-06-04 07:18:33.865278: train_loss -0.7031 
2025-06-04 07:18:34.170033: val_loss -0.7214 
2025-06-04 07:18:34.601217: Pseudo dice [np.float32(0.8197)] 
2025-06-04 07:18:35.041617: Epoch time: 128.0 s 
2025-06-04 07:18:38.637956:  
2025-06-04 07:18:38.658105: Epoch 613 
2025-06-04 07:18:38.674520: Current learning rate: 0.00426 
2025-06-04 07:20:51.478283: train_loss -0.7349 
2025-06-04 07:20:51.674230: val_loss -0.6553 
2025-06-04 07:20:51.888277: Pseudo dice [np.float32(0.7753)] 
2025-06-04 07:20:52.059337: Epoch time: 132.84 s 
2025-06-04 07:20:54.487436:  
2025-06-04 07:20:54.506539: Epoch 614 
2025-06-04 07:20:54.525506: Current learning rate: 0.00425 
2025-06-04 07:23:06.816848: train_loss -0.7045 
2025-06-04 07:23:06.839881: val_loss -0.6807 
2025-06-04 07:23:07.302679: Pseudo dice [np.float32(0.7695)] 
2025-06-04 07:23:07.489294: Epoch time: 132.33 s 
2025-06-04 07:23:11.719977:  
2025-06-04 07:23:11.744770: Epoch 615 
2025-06-04 07:23:11.764839: Current learning rate: 0.00424 
2025-06-04 07:25:23.933798: train_loss -0.7074 
2025-06-04 07:25:23.951404: val_loss -0.6689 
2025-06-04 07:25:23.966121: Pseudo dice [np.float32(0.7472)] 
2025-06-04 07:25:23.980494: Epoch time: 132.22 s 
2025-06-04 07:25:28.504731:  
2025-06-04 07:25:28.581526: Epoch 616 
2025-06-04 07:25:28.603492: Current learning rate: 0.00423 
2025-06-04 07:27:39.642262: train_loss -0.7012 
2025-06-04 07:27:39.797774: val_loss -0.6632 
2025-06-04 07:27:40.012634: Pseudo dice [np.float32(0.7385)] 
2025-06-04 07:27:40.030522: Epoch time: 131.14 s 
2025-06-04 07:27:44.612591:  
2025-06-04 07:27:44.633450: Epoch 617 
2025-06-04 07:27:44.654571: Current learning rate: 0.00422 
2025-06-04 07:29:52.679396: train_loss -0.7186 
2025-06-04 07:29:52.698283: val_loss -0.7145 
2025-06-04 07:29:52.715206: Pseudo dice [np.float32(0.7927)] 
2025-06-04 07:29:52.731630: Epoch time: 128.07 s 
2025-06-04 07:29:57.891056:  
2025-06-04 07:29:58.036315: Epoch 618 
2025-06-04 07:29:58.241118: Current learning rate: 0.00421 
2025-06-04 07:32:06.439262: train_loss -0.6845 
2025-06-04 07:32:06.813022: val_loss -0.5933 
2025-06-04 07:32:07.306655: Pseudo dice [np.float32(0.7121)] 
2025-06-04 07:32:07.814045: Epoch time: 128.55 s 
2025-06-04 07:32:11.033265:  
2025-06-04 07:32:11.053530: Epoch 619 
2025-06-04 07:32:11.066190: Current learning rate: 0.0042 
2025-06-04 07:34:20.066924: train_loss -0.7072 
2025-06-04 07:34:20.084806: val_loss -0.6694 
2025-06-04 07:34:20.100142: Pseudo dice [np.float32(0.7241)] 
2025-06-04 07:34:20.114925: Epoch time: 129.04 s 
2025-06-04 07:34:24.123260:  
2025-06-04 07:34:24.168842: Epoch 620 
2025-06-04 07:34:24.188593: Current learning rate: 0.00419 
2025-06-04 07:36:31.916171: train_loss -0.7218 
2025-06-04 07:36:31.934068: val_loss -0.6933 
2025-06-04 07:36:31.948426: Pseudo dice [np.float32(0.752)] 
2025-06-04 07:36:31.964231: Epoch time: 127.8 s 
2025-06-04 07:36:34.232867:  
2025-06-04 07:36:34.252497: Epoch 621 
2025-06-04 07:36:34.272321: Current learning rate: 0.00418 
2025-06-04 07:38:42.949945: train_loss -0.6749 
2025-06-04 07:38:43.355567: val_loss -0.6517 
2025-06-04 07:38:43.719809: Pseudo dice [np.float32(0.7789)] 
2025-06-04 07:38:44.020000: Epoch time: 128.72 s 
2025-06-04 07:38:47.116693:  
2025-06-04 07:38:47.130294: Epoch 622 
2025-06-04 07:38:47.141694: Current learning rate: 0.00417 
2025-06-04 07:40:55.855643: train_loss -0.707 
2025-06-04 07:40:56.118487: val_loss -0.6704 
2025-06-04 07:40:56.565686: Pseudo dice [np.float32(0.7682)] 
2025-06-04 07:40:56.915051: Epoch time: 128.74 s 
2025-06-04 07:41:01.262336:  
2025-06-04 07:41:01.292657: Epoch 623 
2025-06-04 07:41:01.310032: Current learning rate: 0.00416 
2025-06-04 07:43:15.284567: train_loss -0.6939 
2025-06-04 07:43:15.611965: val_loss -0.6505 
2025-06-04 07:43:15.784870: Pseudo dice [np.float32(0.7028)] 
2025-06-04 07:43:16.021341: Epoch time: 134.02 s 
2025-06-04 07:43:18.684208:  
2025-06-04 07:43:18.854683: Epoch 624 
2025-06-04 07:43:18.947706: Current learning rate: 0.00415 
2025-06-04 07:45:30.602380: train_loss -0.7101 
2025-06-04 07:45:30.906066: val_loss -0.7061 
2025-06-04 07:45:31.168100: Pseudo dice [np.float32(0.8037)] 
2025-06-04 07:45:31.393588: Epoch time: 131.92 s 
2025-06-04 07:45:33.832277:  
2025-06-04 07:45:34.032579: Epoch 625 
2025-06-04 07:45:34.048641: Current learning rate: 0.00414 
2025-06-04 07:47:43.293257: train_loss -0.7116 
2025-06-04 07:47:43.313660: val_loss -0.6222 
2025-06-04 07:47:43.330715: Pseudo dice [np.float32(0.6847)] 
2025-06-04 07:47:43.345571: Epoch time: 129.46 s 
2025-06-04 07:47:46.590903:  
2025-06-04 07:47:46.620813: Epoch 626 
2025-06-04 07:47:46.641817: Current learning rate: 0.00413 
2025-06-04 07:50:02.081623: train_loss -0.6912 
2025-06-04 07:50:02.293628: val_loss -0.6907 
2025-06-04 07:50:02.312976: Pseudo dice [np.float32(0.7666)] 
2025-06-04 07:50:02.327822: Epoch time: 135.49 s 
2025-06-04 07:50:07.857724:  
2025-06-04 07:50:07.890928: Epoch 627 
2025-06-04 07:50:07.960904: Current learning rate: 0.00412 
2025-06-04 07:52:22.789925: train_loss -0.6996 
2025-06-04 07:52:23.385859: val_loss -0.6364 
2025-06-04 07:52:23.972696: Pseudo dice [np.float32(0.7353)] 
2025-06-04 07:52:24.593990: Epoch time: 134.93 s 
2025-06-04 07:52:28.017763:  
2025-06-04 07:52:28.088357: Epoch 628 
2025-06-04 07:52:28.208593: Current learning rate: 0.00411 
2025-06-04 07:54:42.107720: train_loss -0.6918 
2025-06-04 07:54:42.756776: val_loss -0.6608 
2025-06-04 07:54:43.227649: Pseudo dice [np.float32(0.6565)] 
2025-06-04 07:54:43.245469: Epoch time: 134.09 s 
2025-06-04 07:54:45.978774:  
2025-06-04 07:54:45.993689: Epoch 629 
2025-06-04 07:54:46.008637: Current learning rate: 0.0041 
2025-06-04 07:56:55.722870: train_loss -0.6965 
2025-06-04 07:56:56.131379: val_loss -0.655 
2025-06-04 07:56:56.428708: Pseudo dice [np.float32(0.7396)] 
2025-06-04 07:56:56.446529: Epoch time: 129.75 s 
2025-06-04 07:57:01.676694:  
2025-06-04 07:57:01.710680: Epoch 630 
2025-06-04 07:57:01.732567: Current learning rate: 0.00409 
2025-06-04 07:59:13.819672: train_loss -0.6719 
2025-06-04 07:59:14.053269: val_loss -0.6222 
2025-06-04 07:59:14.339033: Pseudo dice [np.float32(0.7823)] 
2025-06-04 07:59:14.359395: Epoch time: 132.15 s 
2025-06-04 07:59:18.786646:  
2025-06-04 07:59:18.832834: Epoch 631 
2025-06-04 07:59:18.855053: Current learning rate: 0.00408 
2025-06-04 08:01:31.488079: train_loss -0.7113 
2025-06-04 08:01:31.771569: val_loss -0.673 
2025-06-04 08:01:32.059943: Pseudo dice [np.float32(0.7084)] 
2025-06-04 08:01:32.334994: Epoch time: 132.7 s 
2025-06-04 08:01:35.409986:  
2025-06-04 08:01:35.429422: Epoch 632 
2025-06-04 08:01:35.444757: Current learning rate: 0.00407 
2025-06-04 08:03:41.622818: train_loss -0.7094 
2025-06-04 08:03:41.647578: val_loss -0.6606 
2025-06-04 08:03:41.663250: Pseudo dice [np.float32(0.8095)] 
2025-06-04 08:03:41.678490: Epoch time: 126.21 s 
2025-06-04 08:03:46.509595:  
2025-06-04 08:03:46.531752: Epoch 633 
2025-06-04 08:03:46.549650: Current learning rate: 0.00406 
2025-06-04 08:05:59.079028: train_loss -0.6593 
2025-06-04 08:05:59.591203: val_loss -0.611 
2025-06-04 08:05:59.888674: Pseudo dice [np.float32(0.6438)] 
2025-06-04 08:05:59.906627: Epoch time: 132.57 s 
2025-06-04 08:06:04.666084:  
2025-06-04 08:06:04.776447: Epoch 634 
2025-06-04 08:06:04.956542: Current learning rate: 0.00405 
2025-06-04 08:08:15.133838: train_loss -0.696 
2025-06-04 08:08:15.157545: val_loss -0.6591 
2025-06-04 08:08:15.174390: Pseudo dice [np.float32(0.7297)] 
2025-06-04 08:08:15.190759: Epoch time: 130.47 s 
2025-06-04 08:08:19.648755:  
2025-06-04 08:08:19.669476: Epoch 635 
2025-06-04 08:08:19.688272: Current learning rate: 0.00404 
2025-06-04 08:10:32.313205: train_loss -0.6871 
2025-06-04 08:10:32.862914: val_loss -0.6987 
2025-06-04 08:10:33.279604: Pseudo dice [np.float32(0.7642)] 
2025-06-04 08:10:33.544790: Epoch time: 132.67 s 
2025-06-04 08:10:36.746966:  
2025-06-04 08:10:36.909243: Epoch 636 
2025-06-04 08:10:37.154658: Current learning rate: 0.00403 
2025-06-04 08:12:46.185819: train_loss -0.6987 
2025-06-04 08:12:46.391664: val_loss -0.6903 
2025-06-04 08:12:46.607909: Pseudo dice [np.float32(0.7695)] 
2025-06-04 08:12:46.810244: Epoch time: 129.44 s 
2025-06-04 08:12:49.811321:  
2025-06-04 08:12:49.829731: Epoch 637 
2025-06-04 08:12:49.846105: Current learning rate: 0.00402 
2025-06-04 08:15:00.951460: train_loss -0.6894 
2025-06-04 08:15:00.971433: val_loss -0.6707 
2025-06-04 08:15:00.989916: Pseudo dice [np.float32(0.6704)] 
2025-06-04 08:15:01.007594: Epoch time: 131.14 s 
2025-06-04 08:15:05.551723:  
2025-06-04 08:15:05.690639: Epoch 638 
2025-06-04 08:15:05.821228: Current learning rate: 0.00401 
2025-06-04 08:17:10.743047: train_loss -0.738 
2025-06-04 08:17:11.261904: val_loss -0.6219 
2025-06-04 08:17:11.607323: Pseudo dice [np.float32(0.7009)] 
2025-06-04 08:17:11.624541: Epoch time: 125.19 s 
2025-06-04 08:17:14.821263:  
2025-06-04 08:17:14.863094: Epoch 639 
2025-06-04 08:17:14.890428: Current learning rate: 0.004 
2025-06-04 08:19:22.531053: train_loss -0.6798 
2025-06-04 08:19:22.550328: val_loss -0.69 
2025-06-04 08:19:22.708442: Pseudo dice [np.float32(0.706)] 
2025-06-04 08:19:23.043565: Epoch time: 127.71 s 
2025-06-04 08:19:26.769963:  
2025-06-04 08:19:26.926952: Epoch 640 
2025-06-04 08:19:27.214097: Current learning rate: 0.00399 
2025-06-04 08:21:37.353026: train_loss -0.7028 
2025-06-04 08:21:37.855688: val_loss -0.6573 
2025-06-04 08:21:37.873033: Pseudo dice [np.float32(0.6992)] 
2025-06-04 08:21:37.888431: Epoch time: 130.58 s 
2025-06-04 08:21:42.223868:  
2025-06-04 08:21:42.291847: Epoch 641 
2025-06-04 08:21:42.409027: Current learning rate: 0.00398 
2025-06-04 08:23:47.013879: train_loss -0.7252 
2025-06-04 08:23:47.200796: val_loss -0.6942 
2025-06-04 08:23:47.333515: Pseudo dice [np.float32(0.8392)] 
2025-06-04 08:23:47.353855: Epoch time: 124.79 s 
2025-06-04 08:23:53.310495:  
2025-06-04 08:23:53.340238: Epoch 642 
2025-06-04 08:23:53.356917: Current learning rate: 0.00397 
2025-06-04 08:26:01.577731: train_loss -0.7054 
2025-06-04 08:26:01.768623: val_loss -0.678 
2025-06-04 08:26:02.026088: Pseudo dice [np.float32(0.7104)] 
2025-06-04 08:26:02.207019: Epoch time: 128.27 s 
2025-06-04 08:26:05.202719:  
2025-06-04 08:26:05.219799: Epoch 643 
2025-06-04 08:26:05.231508: Current learning rate: 0.00396 
2025-06-04 08:28:17.672277: train_loss -0.6991 
2025-06-04 08:28:17.919289: val_loss -0.6884 
2025-06-04 08:28:18.265086: Pseudo dice [np.float32(0.7647)] 
2025-06-04 08:28:18.495949: Epoch time: 132.47 s 
2025-06-04 08:28:21.700517:  
2025-06-04 08:28:21.718096: Epoch 644 
2025-06-04 08:28:21.732900: Current learning rate: 0.00395 
2025-06-04 08:30:27.820785: train_loss -0.696 
2025-06-04 08:30:27.844774: val_loss -0.6506 
2025-06-04 08:30:27.859777: Pseudo dice [np.float32(0.6946)] 
2025-06-04 08:30:27.875260: Epoch time: 126.12 s 
2025-06-04 08:30:32.544554:  
2025-06-04 08:30:32.663598: Epoch 645 
2025-06-04 08:30:32.807669: Current learning rate: 0.00394 
2025-06-04 08:32:44.078535: train_loss -0.7179 
2025-06-04 08:32:44.099093: val_loss -0.7077 
2025-06-04 08:32:44.114555: Pseudo dice [np.float32(0.7489)] 
2025-06-04 08:32:44.130697: Epoch time: 131.54 s 
2025-06-04 08:32:47.045082:  
2025-06-04 08:32:47.139508: Epoch 646 
2025-06-04 08:32:47.348893: Current learning rate: 0.00393 
2025-06-04 08:35:04.315892: train_loss -0.7034 
2025-06-04 08:35:04.772163: val_loss -0.6315 
2025-06-04 08:35:05.032601: Pseudo dice [np.float32(0.735)] 
2025-06-04 08:35:05.065881: Epoch time: 137.27 s 
2025-06-04 08:35:07.672835:  
2025-06-04 08:35:07.727995: Epoch 647 
2025-06-04 08:35:07.842911: Current learning rate: 0.00392 
2025-06-04 08:37:16.759501: train_loss -0.6894 
2025-06-04 08:37:17.311873: val_loss -0.6605 
2025-06-04 08:37:17.803684: Pseudo dice [np.float32(0.7525)] 
2025-06-04 08:37:18.303791: Epoch time: 129.09 s 
2025-06-04 08:37:22.348054:  
2025-06-04 08:37:22.450490: Epoch 648 
2025-06-04 08:37:22.536504: Current learning rate: 0.00391 
2025-06-04 08:39:36.382073: train_loss -0.7032 
2025-06-04 08:39:36.399873: val_loss -0.6893 
2025-06-04 08:39:36.414371: Pseudo dice [np.float32(0.8214)] 
2025-06-04 08:39:36.428485: Epoch time: 134.04 s 
2025-06-04 08:39:39.844944:  
2025-06-04 08:39:39.922611: Epoch 649 
2025-06-04 08:39:39.944062: Current learning rate: 0.0039 
2025-06-04 08:41:48.118073: train_loss -0.7168 
2025-06-04 08:41:48.664781: val_loss -0.6709 
2025-06-04 08:41:48.684993: Pseudo dice [np.float32(0.7145)] 
2025-06-04 08:41:48.700701: Epoch time: 128.28 s 
2025-06-04 08:41:54.765687:  
2025-06-04 08:41:54.818998: Epoch 650 
2025-06-04 08:41:54.938402: Current learning rate: 0.00389 
2025-06-04 08:44:06.044741: train_loss -0.6589 
2025-06-04 08:44:06.277338: val_loss -0.6422 
2025-06-04 08:44:06.294218: Pseudo dice [np.float32(0.7418)] 
2025-06-04 08:44:06.309635: Epoch time: 131.28 s 
2025-06-04 08:44:10.560374:  
2025-06-04 08:44:10.580251: Epoch 651 
2025-06-04 08:44:10.596002: Current learning rate: 0.00388 
2025-06-04 08:46:21.118910: train_loss -0.6645 
2025-06-04 08:46:21.459402: val_loss -0.6548 
2025-06-04 08:46:21.966633: Pseudo dice [np.float32(0.7497)] 
2025-06-04 08:46:22.382764: Epoch time: 130.56 s 
2025-06-04 08:46:26.442677:  
2025-06-04 08:46:26.464641: Epoch 652 
2025-06-04 08:46:26.481765: Current learning rate: 0.00387 
2025-06-04 08:48:36.343323: train_loss -0.7092 
2025-06-04 08:48:36.718758: val_loss -0.6385 
2025-06-04 08:48:37.101226: Pseudo dice [np.float32(0.7477)] 
2025-06-04 08:48:37.581195: Epoch time: 129.9 s 
2025-06-04 08:48:43.959364:  
2025-06-04 08:48:43.983038: Epoch 653 
2025-06-04 08:48:44.000041: Current learning rate: 0.00386 
2025-06-04 08:50:54.394295: train_loss -0.7238 
2025-06-04 08:50:54.418835: val_loss -0.6533 
2025-06-04 08:50:54.433769: Pseudo dice [np.float32(0.7054)] 
2025-06-04 08:50:54.449039: Epoch time: 130.44 s 
2025-06-04 08:50:59.531907:  
2025-06-04 08:50:59.549240: Epoch 654 
2025-06-04 08:50:59.570541: Current learning rate: 0.00385 
2025-06-04 08:53:11.221301: train_loss -0.697 
2025-06-04 08:53:11.247419: val_loss -0.6426 
2025-06-04 08:53:11.267705: Pseudo dice [np.float32(0.7193)] 
2025-06-04 08:53:11.284061: Epoch time: 131.69 s 
2025-06-04 08:53:15.894074:  
2025-06-04 08:53:15.910813: Epoch 655 
2025-06-04 08:53:15.926533: Current learning rate: 0.00384 
2025-06-04 08:55:22.550633: train_loss -0.6966 
2025-06-04 08:55:23.094525: val_loss -0.6583 
2025-06-04 08:55:23.748692: Pseudo dice [np.float32(0.7379)] 
2025-06-04 08:55:23.767412: Epoch time: 126.66 s 
2025-06-04 08:55:27.142140:  
2025-06-04 08:55:27.219500: Epoch 656 
2025-06-04 08:55:27.273585: Current learning rate: 0.00383 
2025-06-04 08:57:34.497937: train_loss -0.7148 
2025-06-04 08:57:34.524024: val_loss -0.6483 
2025-06-04 08:57:34.540197: Pseudo dice [np.float32(0.7353)] 
2025-06-04 08:57:34.557210: Epoch time: 127.36 s 
2025-06-04 08:57:40.158626:  
2025-06-04 08:57:40.180975: Epoch 657 
2025-06-04 08:57:40.197727: Current learning rate: 0.00382 
2025-06-04 08:59:50.612632: train_loss -0.7065 
2025-06-04 08:59:50.634561: val_loss -0.7029 
2025-06-04 08:59:50.650001: Pseudo dice [np.float32(0.7623)] 
2025-06-04 08:59:50.664376: Epoch time: 130.46 s 
2025-06-04 08:59:57.854886:  
2025-06-04 08:59:57.902003: Epoch 658 
2025-06-04 08:59:57.953410: Current learning rate: 0.00381 
2025-06-04 09:02:07.409992: train_loss -0.7005 
2025-06-04 09:02:07.431909: val_loss -0.685 
2025-06-04 09:02:07.449999: Pseudo dice [np.float32(0.7638)] 
2025-06-04 09:02:07.466966: Epoch time: 129.56 s 
2025-06-04 09:02:12.052912:  
2025-06-04 09:02:12.108382: Epoch 659 
2025-06-04 09:02:12.139505: Current learning rate: 0.0038 
2025-06-04 09:04:18.823487: train_loss -0.6882 
2025-06-04 09:04:18.843565: val_loss -0.6807 
2025-06-04 09:04:18.859260: Pseudo dice [np.float32(0.703)] 
2025-06-04 09:04:18.875587: Epoch time: 126.77 s 
2025-06-04 09:04:23.787710:  
2025-06-04 09:04:23.811699: Epoch 660 
2025-06-04 09:04:23.830316: Current learning rate: 0.00379 
2025-06-04 09:06:29.913293: train_loss -0.7322 
2025-06-04 09:06:29.934298: val_loss -0.6341 
2025-06-04 09:06:29.952224: Pseudo dice [np.float32(0.7864)] 
2025-06-04 09:06:30.261079: Epoch time: 126.13 s 
2025-06-04 09:06:35.580916:  
2025-06-04 09:06:35.603084: Epoch 661 
2025-06-04 09:06:35.620013: Current learning rate: 0.00378 
2025-06-04 09:08:39.340384: train_loss -0.6954 
2025-06-04 09:08:39.586103: val_loss -0.6496 
2025-06-04 09:08:39.992847: Pseudo dice [np.float32(0.7052)] 
2025-06-04 09:08:40.293855: Epoch time: 123.76 s 
2025-06-04 09:08:46.472777:  
2025-06-04 09:08:46.495300: Epoch 662 
2025-06-04 09:08:46.513636: Current learning rate: 0.00377 
2025-06-04 09:10:57.065989: train_loss -0.7143 
2025-06-04 09:10:57.328191: val_loss -0.7329 
2025-06-04 09:10:57.715595: Pseudo dice [np.float32(0.8356)] 
2025-06-04 09:10:57.958628: Epoch time: 130.59 s 
2025-06-04 09:10:59.776188:  
2025-06-04 09:10:59.793903: Epoch 663 
2025-06-04 09:10:59.809945: Current learning rate: 0.00376 
2025-06-04 09:13:12.188306: train_loss -0.7073 
2025-06-04 09:13:12.213693: val_loss -0.6898 
2025-06-04 09:13:12.228896: Pseudo dice [np.float32(0.7698)] 
2025-06-04 09:13:12.244001: Epoch time: 132.41 s 
2025-06-04 09:13:15.844770:  
2025-06-04 09:13:15.894355: Epoch 664 
2025-06-04 09:13:15.930489: Current learning rate: 0.00375 
2025-06-04 09:15:30.915687: train_loss -0.715 
2025-06-04 09:15:30.934246: val_loss -0.7306 
2025-06-04 09:15:31.209956: Pseudo dice [np.float32(0.7951)] 
2025-06-04 09:15:31.516386: Epoch time: 135.07 s 
2025-06-04 09:15:35.565863:  
2025-06-04 09:15:35.621188: Epoch 665 
2025-06-04 09:15:35.681992: Current learning rate: 0.00374 
2025-06-04 09:17:44.780068: train_loss -0.7243 
2025-06-04 09:17:44.800334: val_loss -0.6999 
2025-06-04 09:17:44.816229: Pseudo dice [np.float32(0.7473)] 
2025-06-04 09:17:44.831528: Epoch time: 129.22 s 
2025-06-04 09:17:47.405844:  
2025-06-04 09:17:47.433444: Epoch 666 
2025-06-04 09:17:47.452020: Current learning rate: 0.00373 
2025-06-04 09:20:00.569833: train_loss -0.7162 
2025-06-04 09:20:00.946168: val_loss -0.6866 
2025-06-04 09:20:01.251983: Pseudo dice [np.float32(0.7949)] 
2025-06-04 09:20:01.520243: Epoch time: 133.17 s 
2025-06-04 09:20:04.915420:  
2025-06-04 09:20:05.002086: Epoch 667 
2025-06-04 09:20:05.190321: Current learning rate: 0.00372 
2025-06-04 09:22:18.337808: train_loss -0.6862 
2025-06-04 09:22:18.913457: val_loss -0.6815 
2025-06-04 09:22:19.356105: Pseudo dice [np.float32(0.7886)] 
2025-06-04 09:22:19.622968: Epoch time: 133.42 s 
2025-06-04 09:22:19.832197: Yayy! New best EMA pseudo Dice: 0.7616000175476074 
2025-06-04 09:22:22.911294:  
2025-06-04 09:22:22.932850: Epoch 668 
2025-06-04 09:22:22.949569: Current learning rate: 0.00371 
2025-06-04 09:24:34.701292: train_loss -0.7178 
2025-06-04 09:24:35.018831: val_loss -0.6491 
2025-06-04 09:24:35.412805: Pseudo dice [np.float32(0.6921)] 
2025-06-04 09:24:35.623871: Epoch time: 131.79 s 
2025-06-04 09:24:38.613761:  
2025-06-04 09:24:38.642675: Epoch 669 
2025-06-04 09:24:38.658697: Current learning rate: 0.0037 
2025-06-04 09:26:47.578928: train_loss -0.711 
2025-06-04 09:26:47.897471: val_loss -0.6277 
2025-06-04 09:26:48.270227: Pseudo dice [np.float32(0.666)] 
2025-06-04 09:26:48.608772: Epoch time: 128.97 s 
2025-06-04 09:26:52.869697:  
2025-06-04 09:26:52.990768: Epoch 670 
2025-06-04 09:26:53.071721: Current learning rate: 0.00369 
2025-06-04 09:29:04.183168: train_loss -0.6955 
2025-06-04 09:29:04.448974: val_loss -0.6568 
2025-06-04 09:29:04.813633: Pseudo dice [np.float32(0.6836)] 
2025-06-04 09:29:05.060086: Epoch time: 131.32 s 
2025-06-04 09:29:08.671448:  
2025-06-04 09:29:08.688118: Epoch 671 
2025-06-04 09:29:08.749975: Current learning rate: 0.00368 
2025-06-04 09:31:23.872780: train_loss -0.7001 
2025-06-04 09:31:24.129368: val_loss -0.6652 
2025-06-04 09:31:24.511816: Pseudo dice [np.float32(0.7587)] 
2025-06-04 09:31:24.684875: Epoch time: 135.2 s 
2025-06-04 09:31:27.852357:  
2025-06-04 09:31:27.872249: Epoch 672 
2025-06-04 09:31:27.953133: Current learning rate: 0.00367 
2025-06-04 09:33:38.380571: train_loss -0.7064 
2025-06-04 09:33:38.664900: val_loss -0.5992 
2025-06-04 09:33:39.054095: Pseudo dice [np.float32(0.6818)] 
2025-06-04 09:33:39.430825: Epoch time: 130.53 s 
2025-06-04 09:33:43.177591:  
2025-06-04 09:33:43.197466: Epoch 673 
2025-06-04 09:33:43.212726: Current learning rate: 0.00366 
2025-06-04 09:35:55.700604: train_loss -0.706 
2025-06-04 09:35:55.729614: val_loss -0.6628 
2025-06-04 09:35:56.088210: Pseudo dice [np.float32(0.7242)] 
2025-06-04 09:35:56.579057: Epoch time: 132.53 s 
2025-06-04 09:36:00.423000:  
2025-06-04 09:36:00.444766: Epoch 674 
2025-06-04 09:36:00.460365: Current learning rate: 0.00365 
2025-06-04 09:38:11.250075: train_loss -0.7002 
2025-06-04 09:38:11.276315: val_loss -0.6599 
2025-06-04 09:38:11.507522: Pseudo dice [np.float32(0.7335)] 
2025-06-04 09:38:11.526098: Epoch time: 130.83 s 
2025-06-04 09:38:16.925652:  
2025-06-04 09:38:17.035704: Epoch 675 
2025-06-04 09:38:17.151592: Current learning rate: 0.00364 
2025-06-04 09:40:29.924329: train_loss -0.7047 
2025-06-04 09:40:29.942249: val_loss -0.647 
2025-06-04 09:40:29.956518: Pseudo dice [np.float32(0.6982)] 
2025-06-04 09:40:29.972479: Epoch time: 133.0 s 
2025-06-04 09:40:33.708783:  
2025-06-04 09:40:33.841043: Epoch 676 
2025-06-04 09:40:33.889102: Current learning rate: 0.00363 
2025-06-04 09:42:43.753635: train_loss -0.7069 
2025-06-04 09:42:43.778470: val_loss -0.6014 
2025-06-04 09:42:43.795328: Pseudo dice [np.float32(0.671)] 
2025-06-04 09:42:43.809161: Epoch time: 130.05 s 
2025-06-04 09:42:49.011296:  
2025-06-04 09:42:49.119546: Epoch 677 
2025-06-04 09:42:49.143141: Current learning rate: 0.00362 
2025-06-04 09:44:58.546787: train_loss -0.6974 
2025-06-04 09:44:58.626348: val_loss -0.6665 
2025-06-04 09:44:58.808039: Pseudo dice [np.float32(0.6779)] 
2025-06-04 09:44:59.162601: Epoch time: 129.54 s 
2025-06-04 09:45:03.402340:  
2025-06-04 09:45:03.447703: Epoch 678 
2025-06-04 09:45:03.470093: Current learning rate: 0.00361 
2025-06-04 09:47:16.053356: train_loss -0.7009 
2025-06-04 09:47:16.422441: val_loss -0.5937 
2025-06-04 09:47:16.742349: Pseudo dice [np.float32(0.7034)] 
2025-06-04 09:47:16.760001: Epoch time: 132.65 s 
2025-06-04 09:47:20.541174:  
2025-06-04 09:47:20.649280: Epoch 679 
2025-06-04 09:47:20.856028: Current learning rate: 0.0036 
2025-06-04 09:49:32.114081: train_loss -0.6677 
2025-06-04 09:49:32.507008: val_loss -0.6707 
2025-06-04 09:49:32.838850: Pseudo dice [np.float32(0.7594)] 
2025-06-04 09:49:33.360286: Epoch time: 131.58 s 
2025-06-04 09:49:36.662772:  
2025-06-04 09:49:36.751806: Epoch 680 
2025-06-04 09:49:36.809484: Current learning rate: 0.00359 
2025-06-04 09:51:50.348721: train_loss -0.69 
2025-06-04 09:51:50.644793: val_loss -0.6659 
2025-06-04 09:51:50.662609: Pseudo dice [np.float32(0.7974)] 
2025-06-04 09:51:50.679384: Epoch time: 133.69 s 
2025-06-04 09:51:55.165847:  
2025-06-04 09:51:55.188907: Epoch 681 
2025-06-04 09:51:55.207704: Current learning rate: 0.00358 
2025-06-04 09:54:05.848815: train_loss -0.7151 
2025-06-04 09:54:06.036529: val_loss -0.6784 
2025-06-04 09:54:06.052098: Pseudo dice [np.float32(0.7154)] 
2025-06-04 09:54:06.067658: Epoch time: 130.69 s 
2025-06-04 09:54:11.308459:  
2025-06-04 09:54:11.342931: Epoch 682 
2025-06-04 09:54:11.381236: Current learning rate: 0.00357 
2025-06-04 09:56:24.298394: train_loss -0.7197 
2025-06-04 09:56:24.616727: val_loss -0.6655 
2025-06-04 09:56:24.635542: Pseudo dice [np.float32(0.7099)] 
2025-06-04 09:56:25.093862: Epoch time: 132.99 s 
2025-06-04 09:56:29.256134:  
2025-06-04 09:56:29.333688: Epoch 683 
2025-06-04 09:56:29.387567: Current learning rate: 0.00356 
2025-06-04 09:58:39.267275: train_loss -0.702 
2025-06-04 09:58:39.385787: val_loss -0.7536 
2025-06-04 09:58:39.449799: Pseudo dice [np.float32(0.7844)] 
2025-06-04 09:58:39.469852: Epoch time: 130.01 s 
2025-06-04 09:58:42.045191:  
2025-06-04 09:58:42.064876: Epoch 684 
2025-06-04 09:58:42.084463: Current learning rate: 0.00355 
2025-06-04 10:00:51.313616: train_loss -0.7044 
2025-06-04 10:00:51.334367: val_loss -0.7244 
2025-06-04 10:00:51.350215: Pseudo dice [np.float32(0.8379)] 
2025-06-04 10:00:51.366620: Epoch time: 129.27 s 
2025-06-04 10:00:55.075658:  
2025-06-04 10:00:55.157435: Epoch 685 
2025-06-04 10:00:55.176974: Current learning rate: 0.00354 
2025-06-04 10:03:00.756385: train_loss -0.7076 
2025-06-04 10:03:00.898940: val_loss -0.7373 
2025-06-04 10:03:01.361928: Pseudo dice [np.float32(0.8301)] 
2025-06-04 10:03:01.828954: Epoch time: 125.68 s 
2025-06-04 10:03:05.398249:  
2025-06-04 10:03:05.417899: Epoch 686 
2025-06-04 10:03:05.436629: Current learning rate: 0.00353 
2025-06-04 10:05:17.187227: train_loss -0.6913 
2025-06-04 10:05:17.207928: val_loss -0.6245 
2025-06-04 10:05:17.223599: Pseudo dice [np.float32(0.7597)] 
2025-06-04 10:05:17.240146: Epoch time: 131.79 s 
2025-06-04 10:05:21.204952:  
2025-06-04 10:05:21.222395: Epoch 687 
2025-06-04 10:05:21.243712: Current learning rate: 0.00352 
2025-06-04 10:07:28.962592: train_loss -0.675 
2025-06-04 10:07:29.474904: val_loss -0.7128 
2025-06-04 10:07:29.919397: Pseudo dice [np.float32(0.7308)] 
2025-06-04 10:07:30.402567: Epoch time: 127.76 s 
2025-06-04 10:07:34.908066:  
2025-06-04 10:07:34.929612: Epoch 688 
2025-06-04 10:07:35.036716: Current learning rate: 0.00351 
2025-06-04 10:09:44.645134: train_loss -0.7097 
2025-06-04 10:09:44.775596: val_loss -0.6503 
2025-06-04 10:09:44.999829: Pseudo dice [np.float32(0.7311)] 
2025-06-04 10:09:45.310059: Epoch time: 129.74 s 
2025-06-04 10:09:48.094473:  
2025-06-04 10:09:48.114967: Epoch 689 
2025-06-04 10:09:48.170056: Current learning rate: 0.0035 
2025-06-04 10:11:55.419640: train_loss -0.7203 
2025-06-04 10:11:55.713122: val_loss -0.6932 
2025-06-04 10:11:55.951564: Pseudo dice [np.float32(0.825)] 
2025-06-04 10:11:56.231019: Epoch time: 127.33 s 
2025-06-04 10:11:58.170670:  
2025-06-04 10:11:58.184554: Epoch 690 
2025-06-04 10:11:58.206540: Current learning rate: 0.00349 
2025-06-04 10:14:05.675696: train_loss -0.7051 
2025-06-04 10:14:05.889174: val_loss -0.6474 
2025-06-04 10:14:06.284333: Pseudo dice [np.float32(0.7452)] 
2025-06-04 10:14:06.615093: Epoch time: 127.51 s 
2025-06-04 10:14:09.767849:  
2025-06-04 10:14:09.883420: Epoch 691 
2025-06-04 10:14:09.990450: Current learning rate: 0.00348 
2025-06-04 10:16:18.747145: train_loss -0.6918 
2025-06-04 10:16:19.011650: val_loss -0.6934 
2025-06-04 10:16:19.361415: Pseudo dice [np.float32(0.7472)] 
2025-06-04 10:16:19.379205: Epoch time: 128.98 s 
2025-06-04 10:16:23.117550:  
2025-06-04 10:16:23.177672: Epoch 692 
2025-06-04 10:16:23.192956: Current learning rate: 0.00346 
2025-06-04 10:18:36.466183: train_loss -0.7067 
2025-06-04 10:18:36.842891: val_loss -0.7236 
2025-06-04 10:18:37.238714: Pseudo dice [np.float32(0.7497)] 
2025-06-04 10:18:37.469037: Epoch time: 133.35 s 
2025-06-04 10:18:41.098668:  
2025-06-04 10:18:41.292127: Epoch 693 
2025-06-04 10:18:41.374825: Current learning rate: 0.00345 
2025-06-04 10:20:53.685424: train_loss -0.7064 
2025-06-04 10:20:53.924994: val_loss -0.7375 
2025-06-04 10:20:54.107346: Pseudo dice [np.float32(0.7883)] 
2025-06-04 10:20:54.303826: Epoch time: 132.59 s 
2025-06-04 10:20:58.309275:  
2025-06-04 10:20:58.571726: Epoch 694 
2025-06-04 10:20:58.896277: Current learning rate: 0.00344 
2025-06-04 10:23:19.060506: train_loss -0.6943 
2025-06-04 10:23:19.286968: val_loss -0.6816 
2025-06-04 10:23:19.586693: Pseudo dice [np.float32(0.7385)] 
2025-06-04 10:23:19.831025: Epoch time: 140.75 s 
2025-06-04 10:23:22.708008:  
2025-06-04 10:23:22.961447: Epoch 695 
2025-06-04 10:23:23.276757: Current learning rate: 0.00343 
2025-06-04 10:25:43.251896: train_loss -0.7251 
2025-06-04 10:25:43.582415: val_loss -0.6274 
2025-06-04 10:25:44.051556: Pseudo dice [np.float32(0.695)] 
2025-06-04 10:25:44.070525: Epoch time: 140.55 s 
2025-06-04 10:25:50.423113:  
2025-06-04 10:25:50.795782: Epoch 696 
2025-06-04 10:25:51.202117: Current learning rate: 0.00342 
2025-06-04 10:28:11.067467: train_loss -0.7013 
2025-06-04 10:28:11.298124: val_loss -0.6664 
2025-06-04 10:28:11.316477: Pseudo dice [np.float32(0.6762)] 
2025-06-04 10:28:11.612665: Epoch time: 140.65 s 
2025-06-04 10:28:17.105830:  
2025-06-04 10:28:17.745985: Epoch 697 
2025-06-04 10:28:18.286467: Current learning rate: 0.00341 
2025-06-04 10:30:36.378206: train_loss -0.7092 
2025-06-04 10:30:36.725171: val_loss -0.6011 
2025-06-04 10:30:36.743289: Pseudo dice [np.float32(0.6977)] 
2025-06-04 10:30:36.758632: Epoch time: 139.27 s 
2025-06-04 10:30:40.144292:  
2025-06-04 10:30:40.245566: Epoch 698 
2025-06-04 10:30:40.264587: Current learning rate: 0.0034 
2025-06-04 10:32:57.114745: train_loss -0.7287 
2025-06-04 10:32:57.141754: val_loss -0.6675 
2025-06-04 10:32:57.157558: Pseudo dice [np.float32(0.8043)] 
2025-06-04 10:32:57.175432: Epoch time: 136.97 s 
2025-06-04 10:33:03.770235:  
2025-06-04 10:33:03.820108: Epoch 699 
2025-06-04 10:33:03.850490: Current learning rate: 0.00339 
2025-06-04 10:35:22.003597: train_loss -0.7278 
2025-06-04 10:35:22.024335: val_loss -0.632 
2025-06-04 10:35:22.039481: Pseudo dice [np.float32(0.6877)] 
2025-06-04 10:35:22.054828: Epoch time: 138.24 s 
2025-06-04 10:35:30.197315:  
2025-06-04 10:35:30.227635: Epoch 700 
2025-06-04 10:35:30.276705: Current learning rate: 0.00338 
2025-06-04 10:37:51.054006: train_loss -0.7182 
2025-06-04 10:37:51.078274: val_loss -0.6278 
2025-06-04 10:37:51.094200: Pseudo dice [np.float32(0.7241)] 
2025-06-04 10:37:51.278712: Epoch time: 140.86 s 
2025-06-04 10:37:58.162687:  
2025-06-04 10:37:58.185991: Epoch 701 
2025-06-04 10:37:58.285290: Current learning rate: 0.00337 
2025-06-04 10:40:15.335802: train_loss -0.6967 
2025-06-04 10:40:15.742688: val_loss -0.7071 
2025-06-04 10:40:16.312045: Pseudo dice [np.float32(0.8186)] 
2025-06-04 10:40:16.926718: Epoch time: 137.18 s 
2025-06-04 10:40:23.357347:  
2025-06-04 10:40:23.528777: Epoch 702 
2025-06-04 10:40:23.545352: Current learning rate: 0.00336 
2025-06-04 10:42:47.215386: train_loss -0.7012 
2025-06-04 10:42:47.783104: val_loss -0.7392 
2025-06-04 10:42:47.933991: Pseudo dice [np.float32(0.8007)] 
2025-06-04 10:42:47.950276: Epoch time: 143.86 s 
2025-06-04 10:42:55.009100:  
2025-06-04 10:42:55.501154: Epoch 703 
2025-06-04 10:42:55.923702: Current learning rate: 0.00335 
2025-06-04 10:45:14.342387: train_loss -0.7027 
2025-06-04 10:45:14.898549: val_loss -0.6785 
2025-06-04 10:45:15.215399: Pseudo dice [np.float32(0.8124)] 
2025-06-04 10:45:15.236858: Epoch time: 139.34 s 
2025-06-04 10:45:23.549565:  
2025-06-04 10:45:23.851745: Epoch 704 
2025-06-04 10:45:24.157167: Current learning rate: 0.00334 
2025-06-04 10:47:45.364769: train_loss -0.7011 
2025-06-04 10:47:45.643786: val_loss -0.6787 
2025-06-04 10:47:45.663298: Pseudo dice [np.float32(0.778)] 
2025-06-04 10:47:45.684452: Epoch time: 141.82 s 
2025-06-04 10:47:52.411412:  
2025-06-04 10:47:52.626947: Epoch 705 
2025-06-04 10:47:53.046383: Current learning rate: 0.00333 
2025-06-04 10:50:11.663034: train_loss -0.7126 
2025-06-04 10:50:11.978854: val_loss -0.6657 
2025-06-04 10:50:12.005610: Pseudo dice [np.float32(0.7851)] 
2025-06-04 10:50:12.029663: Epoch time: 139.25 s 
2025-06-04 10:50:12.334534: Yayy! New best EMA pseudo Dice: 0.7616999745368958 
2025-06-04 10:50:19.916115:  
2025-06-04 10:50:20.000448: Epoch 706 
2025-06-04 10:50:20.022235: Current learning rate: 0.00332 
2025-06-04 10:52:40.814889: train_loss -0.6989 
2025-06-04 10:52:41.087435: val_loss -0.6608 
2025-06-04 10:52:41.106512: Pseudo dice [np.float32(0.7632)] 
2025-06-04 10:52:41.122922: Epoch time: 140.9 s 
2025-06-04 10:52:41.340713: Yayy! New best EMA pseudo Dice: 0.7617999911308289 
2025-06-04 10:52:47.919926:  
2025-06-04 10:52:48.184880: Epoch 707 
2025-06-04 10:52:48.573466: Current learning rate: 0.00331 
2025-06-04 10:55:08.479177: train_loss -0.7225 
2025-06-04 10:55:08.583027: val_loss -0.6295 
2025-06-04 10:55:08.636596: Pseudo dice [np.float32(0.6985)] 
2025-06-04 10:55:08.656698: Epoch time: 140.56 s 
2025-06-04 10:55:12.806981:  
2025-06-04 10:55:13.140814: Epoch 708 
2025-06-04 10:55:13.525526: Current learning rate: 0.0033 
2025-06-04 10:57:31.199898: train_loss -0.6949 
2025-06-04 10:57:31.535535: val_loss -0.6635 
2025-06-04 10:57:31.834555: Pseudo dice [np.float32(0.7964)] 
2025-06-04 10:57:31.854102: Epoch time: 138.39 s 
2025-06-04 10:57:35.850669:  
2025-06-04 10:57:35.928813: Epoch 709 
2025-06-04 10:57:35.949323: Current learning rate: 0.00329 
2025-06-04 11:00:00.281051: train_loss -0.7174 
2025-06-04 11:00:00.299621: val_loss -0.6711 
2025-06-04 11:00:00.315059: Pseudo dice [np.float32(0.7569)] 
2025-06-04 11:00:00.329225: Epoch time: 144.43 s 
2025-06-04 11:00:03.359671:  
2025-06-04 11:00:03.402782: Epoch 710 
2025-06-04 11:00:03.580087: Current learning rate: 0.00328 
2025-06-04 11:02:24.528399: train_loss -0.6854 
2025-06-04 11:02:24.646000: val_loss -0.6327 
2025-06-04 11:02:24.664467: Pseudo dice [np.float32(0.6996)] 
2025-06-04 11:02:24.679864: Epoch time: 141.17 s 
2025-06-04 11:02:30.572903:  
2025-06-04 11:02:30.804774: Epoch 711 
2025-06-04 11:02:30.826135: Current learning rate: 0.00327 
2025-06-04 11:04:53.388004: train_loss -0.7254 
2025-06-04 11:04:53.412911: val_loss -0.636 
2025-06-04 11:04:53.436547: Pseudo dice [np.float32(0.7251)] 
2025-06-04 11:04:53.469079: Epoch time: 142.82 s 
2025-06-04 11:04:58.881907:  
2025-06-04 11:04:59.001912: Epoch 712 
2025-06-04 11:04:59.041115: Current learning rate: 0.00326 
2025-06-04 11:07:23.109412: train_loss -0.7268 
2025-06-04 11:07:23.511266: val_loss -0.6676 
2025-06-04 11:07:23.904442: Pseudo dice [np.float32(0.7502)] 
2025-06-04 11:07:24.366702: Epoch time: 144.23 s 
2025-06-04 11:07:27.399520:  
2025-06-04 11:07:27.497439: Epoch 713 
2025-06-04 11:07:27.532758: Current learning rate: 0.00325 
2025-06-04 11:09:49.159973: train_loss -0.7126 
2025-06-04 11:09:49.184522: val_loss -0.688 
2025-06-04 11:09:49.199889: Pseudo dice [np.float32(0.7194)] 
2025-06-04 11:09:49.215143: Epoch time: 141.76 s 
2025-06-04 11:09:53.656634:  
2025-06-04 11:09:53.897953: Epoch 714 
2025-06-04 11:09:54.167067: Current learning rate: 0.00324 
2025-06-04 11:12:13.342548: train_loss -0.7224 
2025-06-04 11:12:13.363479: val_loss -0.6974 
2025-06-04 11:12:13.379189: Pseudo dice [np.float32(0.7535)] 
2025-06-04 11:12:13.394248: Epoch time: 139.69 s 
2025-06-04 11:12:19.641214:  
2025-06-04 11:12:19.837260: Epoch 715 
2025-06-04 11:12:19.945533: Current learning rate: 0.00323 
2025-06-04 11:14:41.758621: train_loss -0.7155 
2025-06-04 11:14:42.254990: val_loss -0.6887 
2025-06-04 11:14:42.595451: Pseudo dice [np.float32(0.7514)] 
2025-06-04 11:14:42.616116: Epoch time: 142.12 s 
2025-06-04 11:14:48.555703:  
2025-06-04 11:14:48.573805: Epoch 716 
2025-06-04 11:14:48.592337: Current learning rate: 0.00322 
2025-06-04 11:17:07.070983: train_loss -0.7405 
2025-06-04 11:17:07.530940: val_loss -0.6695 
2025-06-04 11:17:07.988060: Pseudo dice [np.float32(0.7749)] 
2025-06-04 11:17:08.510478: Epoch time: 138.52 s 
2025-06-04 11:17:16.569574:  
2025-06-04 11:17:16.729635: Epoch 717 
2025-06-04 11:17:16.751957: Current learning rate: 0.00321 
2025-06-04 11:19:31.723354: train_loss -0.7101 
2025-06-04 11:19:32.160448: val_loss -0.6109 
2025-06-04 11:19:32.177260: Pseudo dice [np.float32(0.7418)] 
2025-06-04 11:19:32.195645: Epoch time: 135.16 s 
2025-06-04 11:19:41.280731:  
2025-06-04 11:19:41.300233: Epoch 718 
2025-06-04 11:19:41.339537: Current learning rate: 0.0032 
2025-06-04 11:22:01.401384: train_loss -0.697 
2025-06-04 11:22:01.831159: val_loss -0.7026 
2025-06-04 11:22:02.249679: Pseudo dice [np.float32(0.7898)] 
2025-06-04 11:22:02.785385: Epoch time: 140.12 s 
2025-06-04 11:22:09.287768:  
2025-06-04 11:22:09.311107: Epoch 719 
2025-06-04 11:22:09.327679: Current learning rate: 0.00319 
2025-06-04 11:24:32.181157: train_loss -0.7217 
2025-06-04 11:24:32.528769: val_loss -0.6522 
2025-06-04 11:24:32.701179: Pseudo dice [np.float32(0.8079)] 
2025-06-04 11:24:32.718356: Epoch time: 142.9 s 
2025-06-04 11:24:38.252998:  
2025-06-04 11:24:38.565914: Epoch 720 
2025-06-04 11:24:38.784369: Current learning rate: 0.00318 
2025-06-04 11:27:00.370217: train_loss -0.7277 
2025-06-04 11:27:00.923579: val_loss -0.605 
2025-06-04 11:27:01.433890: Pseudo dice [np.float32(0.6554)] 
2025-06-04 11:27:02.175084: Epoch time: 142.12 s 
2025-06-04 11:27:08.757610:  
2025-06-04 11:27:08.800578: Epoch 721 
2025-06-04 11:27:08.984821: Current learning rate: 0.00317 
2025-06-04 11:29:26.354348: train_loss -0.6967 
2025-06-04 11:29:27.020660: val_loss -0.6742 
2025-06-04 11:29:27.547734: Pseudo dice [np.float32(0.786)] 
2025-06-04 11:29:28.081094: Epoch time: 137.6 s 
2025-06-04 11:29:33.719919:  
2025-06-04 11:29:33.984603: Epoch 722 
2025-06-04 11:29:34.156776: Current learning rate: 0.00316 
2025-06-04 11:31:54.464972: train_loss -0.7318 
2025-06-04 11:31:54.486089: val_loss -0.6925 
2025-06-04 11:31:54.502178: Pseudo dice [np.float32(0.7773)] 
2025-06-04 11:31:54.519214: Epoch time: 140.76 s 
2025-06-04 11:32:02.034850:  
2025-06-04 11:32:02.346478: Epoch 723 
2025-06-04 11:32:02.735525: Current learning rate: 0.00315 
2025-06-04 11:34:23.622156: train_loss -0.7118 
2025-06-04 11:34:23.642547: val_loss -0.7061 
2025-06-04 11:34:23.659544: Pseudo dice [np.float32(0.8207)] 
2025-06-04 11:34:23.674866: Epoch time: 141.59 s 
2025-06-04 11:34:29.684264:  
2025-06-04 11:34:29.706962: Epoch 724 
2025-06-04 11:34:29.737587: Current learning rate: 0.00314 
2025-06-04 11:36:36.051414: train_loss -0.7148 
2025-06-04 11:36:36.208590: val_loss -0.7123 
2025-06-04 11:36:36.224914: Pseudo dice [np.float32(0.7798)] 
2025-06-04 11:36:36.239220: Epoch time: 126.37 s 
2025-06-04 11:36:36.253059: Yayy! New best EMA pseudo Dice: 0.7634999752044678 
2025-06-04 11:36:44.712683:  
2025-06-04 11:36:44.733722: Epoch 725 
2025-06-04 11:36:44.751667: Current learning rate: 0.00313 
2025-06-04 11:38:54.730983: train_loss -0.7041 
2025-06-04 11:38:55.077647: val_loss -0.6693 
2025-06-04 11:38:55.620502: Pseudo dice [np.float32(0.7905)] 
2025-06-04 11:38:55.861201: Epoch time: 130.02 s 
2025-06-04 11:38:56.194963: Yayy! New best EMA pseudo Dice: 0.7662000060081482 
2025-06-04 11:38:59.508507:  
2025-06-04 11:38:59.528271: Epoch 726 
2025-06-04 11:38:59.542714: Current learning rate: 0.00312 
2025-06-04 11:41:16.313564: train_loss -0.7341 
2025-06-04 11:41:16.661478: val_loss -0.6967 
2025-06-04 11:41:17.134543: Pseudo dice [np.float32(0.7085)] 
2025-06-04 11:41:17.684432: Epoch time: 136.81 s 
2025-06-04 11:41:20.755084:  
2025-06-04 11:41:20.778063: Epoch 727 
2025-06-04 11:41:20.798996: Current learning rate: 0.00311 
2025-06-04 11:43:38.909489: train_loss -0.7047 
2025-06-04 11:43:39.522707: val_loss -0.6769 
2025-06-04 11:43:39.970424: Pseudo dice [np.float32(0.7481)] 
2025-06-04 11:43:40.417418: Epoch time: 138.16 s 
2025-06-04 11:43:45.599470:  
2025-06-04 11:43:45.701040: Epoch 728 
2025-06-04 11:43:45.732289: Current learning rate: 0.0031 
2025-06-04 11:46:11.251635: train_loss -0.7096 
2025-06-04 11:46:11.550823: val_loss -0.6479 
2025-06-04 11:46:12.029358: Pseudo dice [np.float32(0.8015)] 
2025-06-04 11:46:12.510512: Epoch time: 145.65 s 
2025-06-04 11:46:17.226800:  
2025-06-04 11:46:17.576807: Epoch 729 
2025-06-04 11:46:17.698217: Current learning rate: 0.00309 
2025-06-04 11:48:38.236742: train_loss -0.7163 
2025-06-04 11:48:38.255269: val_loss -0.6756 
2025-06-04 11:48:38.270598: Pseudo dice [np.float32(0.7354)] 
2025-06-04 11:48:38.286146: Epoch time: 141.01 s 
2025-06-04 11:48:42.787084:  
2025-06-04 11:48:43.080429: Epoch 730 
2025-06-04 11:48:43.493745: Current learning rate: 0.00308 
2025-06-04 11:51:08.328134: train_loss -0.7128 
2025-06-04 11:51:08.830888: val_loss -0.6815 
2025-06-04 11:51:09.225110: Pseudo dice [np.float32(0.7451)] 
2025-06-04 11:51:09.243042: Epoch time: 145.54 s 
2025-06-04 11:51:15.223329:  
2025-06-04 11:51:15.423739: Epoch 731 
2025-06-04 11:51:15.650347: Current learning rate: 0.00307 
2025-06-04 11:53:36.765715: train_loss -0.7176 
2025-06-04 11:53:36.783579: val_loss -0.6639 
2025-06-04 11:53:36.798956: Pseudo dice [np.float32(0.7587)] 
2025-06-04 11:53:36.814261: Epoch time: 141.55 s 
2025-06-04 11:53:42.501787:  
2025-06-04 11:53:42.664234: Epoch 732 
2025-06-04 11:53:42.686709: Current learning rate: 0.00306 
2025-06-04 11:56:01.946741: train_loss -0.7063 
2025-06-04 11:56:01.972923: val_loss -0.6144 
2025-06-04 11:56:01.989335: Pseudo dice [np.float32(0.7457)] 
2025-06-04 11:56:02.005316: Epoch time: 139.45 s 
2025-06-04 11:56:07.749835:  
2025-06-04 11:56:08.094642: Epoch 733 
2025-06-04 11:56:08.128913: Current learning rate: 0.00305 
2025-06-04 11:58:24.725368: train_loss -0.6777 
2025-06-04 11:58:24.744521: val_loss -0.7012 
2025-06-04 11:58:24.759250: Pseudo dice [np.float32(0.8016)] 
2025-06-04 11:58:24.773468: Epoch time: 136.98 s 
2025-06-04 11:58:30.828429:  
2025-06-04 11:58:31.228949: Epoch 734 
2025-06-04 11:58:31.464483: Current learning rate: 0.00304 
2025-06-04 12:00:51.935233: train_loss -0.6846 
2025-06-04 12:00:52.162409: val_loss -0.6788 
2025-06-04 12:00:52.653622: Pseudo dice [np.float32(0.7727)] 
2025-06-04 12:00:52.974542: Epoch time: 141.11 s 
2025-06-04 12:00:57.621608:  
2025-06-04 12:00:57.692767: Epoch 735 
2025-06-04 12:00:57.720873: Current learning rate: 0.00303 
2025-06-04 12:03:19.700944: train_loss -0.6845 
2025-06-04 12:03:20.034739: val_loss -0.7397 
2025-06-04 12:03:20.169935: Pseudo dice [np.float32(0.7725)] 
2025-06-04 12:03:20.184351: Epoch time: 142.08 s 
2025-06-04 12:03:25.380343:  
2025-06-04 12:03:25.401179: Epoch 736 
2025-06-04 12:03:25.417876: Current learning rate: 0.00302 
2025-06-04 12:05:52.677493: train_loss -0.7137 
2025-06-04 12:05:52.702106: val_loss -0.6811 
2025-06-04 12:05:52.716749: Pseudo dice [np.float32(0.8086)] 
2025-06-04 12:05:52.731446: Epoch time: 147.3 s 
2025-06-04 12:05:52.746958: Yayy! New best EMA pseudo Dice: 0.7684999704360962 
2025-06-04 12:05:58.911546:  
2025-06-04 12:05:59.033798: Epoch 737 
2025-06-04 12:05:59.143479: Current learning rate: 0.00301 
2025-06-04 12:08:19.472539: train_loss -0.7395 
2025-06-04 12:08:20.056320: val_loss -0.6767 
2025-06-04 12:08:20.505709: Pseudo dice [np.float32(0.7511)] 
2025-06-04 12:08:20.927545: Epoch time: 140.56 s 
2025-06-04 12:08:24.949468:  
2025-06-04 12:08:24.982802: Epoch 738 
2025-06-04 12:08:25.017232: Current learning rate: 0.003 
2025-06-04 12:10:47.432765: train_loss -0.7378 
2025-06-04 12:10:47.963472: val_loss -0.7266 
2025-06-04 12:10:48.140330: Pseudo dice [np.float32(0.7538)] 
2025-06-04 12:10:48.458661: Epoch time: 142.49 s 
2025-06-04 12:10:52.383232:  
2025-06-04 12:10:52.498038: Epoch 739 
2025-06-04 12:10:52.576680: Current learning rate: 0.00299 
2025-06-04 12:13:20.224572: train_loss -0.6896 
2025-06-04 12:13:20.680948: val_loss -0.689 
2025-06-04 12:13:21.171813: Pseudo dice [np.float32(0.8445)] 
2025-06-04 12:13:21.490653: Epoch time: 147.84 s 
2025-06-04 12:13:21.900299: Yayy! New best EMA pseudo Dice: 0.7734000086784363 
2025-06-04 12:13:27.519596:  
2025-06-04 12:13:27.538528: Epoch 740 
2025-06-04 12:13:27.554977: Current learning rate: 0.00297 
2025-06-04 12:15:50.090463: train_loss -0.7212 
2025-06-04 12:15:51.091867: val_loss -0.6191 
2025-06-04 12:15:51.812637: Pseudo dice [np.float32(0.7614)] 
2025-06-04 12:15:51.941050: Epoch time: 142.57 s 
2025-06-04 12:15:55.416369:  
2025-06-04 12:15:55.660786: Epoch 741 
2025-06-04 12:15:55.940041: Current learning rate: 0.00296 
2025-06-04 12:18:16.015007: train_loss -0.7293 
2025-06-04 12:18:16.033018: val_loss -0.6589 
2025-06-04 12:18:16.188128: Pseudo dice [np.float32(0.6962)] 
2025-06-04 12:18:16.205559: Epoch time: 140.6 s 
2025-06-04 12:18:20.719833:  
2025-06-04 12:18:21.016477: Epoch 742 
2025-06-04 12:18:21.065381: Current learning rate: 0.00295 
2025-06-04 12:20:43.775187: train_loss -0.7249 
2025-06-04 12:20:44.485543: val_loss -0.6965 
2025-06-04 12:20:45.324787: Pseudo dice [np.float32(0.7264)] 
2025-06-04 12:20:45.588782: Epoch time: 143.06 s 
2025-06-04 12:20:49.319072:  
2025-06-04 12:20:49.493612: Epoch 743 
2025-06-04 12:20:49.526828: Current learning rate: 0.00294 
2025-06-04 12:23:11.718068: train_loss -0.7097 
2025-06-04 12:23:11.736547: val_loss -0.6538 
2025-06-04 12:23:11.752945: Pseudo dice [np.float32(0.6575)] 
2025-06-04 12:23:11.768358: Epoch time: 142.4 s 
2025-06-04 12:23:18.105329:  
2025-06-04 12:23:18.128599: Epoch 744 
2025-06-04 12:23:18.154118: Current learning rate: 0.00293 
2025-06-04 12:25:42.113296: train_loss -0.7384 
2025-06-04 12:25:42.137408: val_loss -0.6262 
2025-06-04 12:25:42.158239: Pseudo dice [np.float32(0.7351)] 
2025-06-04 12:25:42.173956: Epoch time: 144.01 s 
2025-06-04 12:25:49.851333:  
2025-06-04 12:25:49.964905: Epoch 745 
2025-06-04 12:25:50.002526: Current learning rate: 0.00292 
2025-06-04 12:28:10.528596: train_loss -0.6969 
2025-06-04 12:28:11.066237: val_loss -0.6776 
2025-06-04 12:28:11.533041: Pseudo dice [np.float32(0.7015)] 
2025-06-04 12:28:12.082267: Epoch time: 140.68 s 
2025-06-04 12:28:19.151263:  
2025-06-04 12:28:19.406375: Epoch 746 
2025-06-04 12:28:19.629312: Current learning rate: 0.00291 
2025-06-04 12:30:38.883902: train_loss -0.7339 
2025-06-04 12:30:39.875626: val_loss -0.6595 
2025-06-04 12:30:40.525537: Pseudo dice [np.float32(0.7981)] 
2025-06-04 12:30:40.920230: Epoch time: 139.73 s 
2025-06-04 12:30:45.914227:  
2025-06-04 12:30:46.179041: Epoch 747 
2025-06-04 12:30:46.330461: Current learning rate: 0.0029 
2025-06-04 12:33:06.730194: train_loss -0.7126 
2025-06-04 12:33:06.817456: val_loss -0.7096 
2025-06-04 12:33:07.184264: Pseudo dice [np.float32(0.8572)] 
2025-06-04 12:33:07.461991: Epoch time: 140.82 s 
2025-06-04 12:33:11.444797:  
2025-06-04 12:33:11.661008: Epoch 748 
2025-06-04 12:33:11.770425: Current learning rate: 0.00289 
2025-06-04 12:35:30.819663: train_loss -0.7217 
2025-06-04 12:35:30.841466: val_loss -0.6847 
2025-06-04 12:35:30.857673: Pseudo dice [np.float32(0.8068)] 
2025-06-04 12:35:30.872345: Epoch time: 139.38 s 
2025-06-04 12:35:39.099717:  
2025-06-04 12:35:39.528211: Epoch 749 
2025-06-04 12:35:39.749872: Current learning rate: 0.00288 
2025-06-04 12:38:00.731872: train_loss -0.7329 
2025-06-04 12:38:01.144974: val_loss -0.66 
2025-06-04 12:38:01.357728: Pseudo dice [np.float32(0.7496)] 
2025-06-04 12:38:01.373731: Epoch time: 141.63 s 
2025-06-04 12:38:09.131282:  
2025-06-04 12:38:09.152767: Epoch 750 
2025-06-04 12:38:09.172228: Current learning rate: 0.00287 
2025-06-04 12:40:28.881456: train_loss -0.7451 
2025-06-04 12:40:29.539077: val_loss -0.6778 
2025-06-04 12:40:29.813862: Pseudo dice [np.float32(0.8395)] 
2025-06-04 12:40:30.382340: Epoch time: 139.75 s 
2025-06-04 12:40:34.210752:  
2025-06-04 12:40:34.237069: Epoch 751 
2025-06-04 12:40:34.275296: Current learning rate: 0.00286 
2025-06-04 12:42:53.395050: train_loss -0.735 
2025-06-04 12:42:53.530013: val_loss -0.6942 
2025-06-04 12:42:53.905632: Pseudo dice [np.float32(0.8151)] 
2025-06-04 12:42:54.231266: Epoch time: 139.19 s 
2025-06-04 12:42:54.556563: Yayy! New best EMA pseudo Dice: 0.7754999995231628 
2025-06-04 12:43:01.618577:  
2025-06-04 12:43:01.959148: Epoch 752 
2025-06-04 12:43:01.981798: Current learning rate: 0.00285 
2025-06-04 12:45:24.834034: train_loss -0.7089 
2025-06-04 12:45:24.975215: val_loss -0.7073 
2025-06-04 12:45:24.991255: Pseudo dice [np.float32(0.7602)] 
2025-06-04 12:45:25.005860: Epoch time: 143.22 s 
2025-06-04 12:45:29.130184:  
2025-06-04 12:45:29.160233: Epoch 753 
2025-06-04 12:45:29.193251: Current learning rate: 0.00284 
2025-06-04 12:47:54.027363: train_loss -0.7249 
2025-06-04 12:47:54.045310: val_loss -0.7221 
2025-06-04 12:47:54.060618: Pseudo dice [np.float32(0.7732)] 
2025-06-04 12:47:54.075937: Epoch time: 144.9 s 
2025-06-04 12:47:58.445030:  
2025-06-04 12:47:58.467916: Epoch 754 
2025-06-04 12:47:58.489544: Current learning rate: 0.00283 
2025-06-04 12:50:22.503028: train_loss -0.6988 
2025-06-04 12:50:23.079547: val_loss -0.6886 
2025-06-04 12:50:23.909821: Pseudo dice [np.float32(0.7281)] 
2025-06-04 12:50:24.288481: Epoch time: 144.06 s 
2025-06-04 12:50:29.954799:  
2025-06-04 12:50:30.234310: Epoch 755 
2025-06-04 12:50:30.416740: Current learning rate: 0.00282 
2025-06-04 12:52:51.203506: train_loss -0.7064 
2025-06-04 12:52:51.228755: val_loss -0.6382 
2025-06-04 12:52:51.247589: Pseudo dice [np.float32(0.676)] 
2025-06-04 12:52:51.265419: Epoch time: 141.25 s 
2025-06-04 12:52:56.278008:  
2025-06-04 12:52:56.301460: Epoch 756 
2025-06-04 12:52:56.333006: Current learning rate: 0.00281 
2025-06-04 12:55:16.053686: train_loss -0.6861 
2025-06-04 12:55:16.075169: val_loss -0.6287 
2025-06-04 12:55:16.449876: Pseudo dice [np.float32(0.7136)] 
2025-06-04 12:55:17.010728: Epoch time: 139.78 s 
2025-06-04 12:55:22.710654:  
2025-06-04 12:55:22.790732: Epoch 757 
2025-06-04 12:55:22.814020: Current learning rate: 0.0028 
2025-06-04 12:57:43.983241: train_loss -0.7182 
2025-06-04 12:57:44.010006: val_loss -0.6288 
2025-06-04 12:57:44.024835: Pseudo dice [np.float32(0.7038)] 
2025-06-04 12:57:44.041111: Epoch time: 141.33 s 
2025-06-04 12:57:49.329349:  
2025-06-04 12:57:49.480751: Epoch 758 
2025-06-04 12:57:49.767947: Current learning rate: 0.00279 
2025-06-04 13:00:13.798043: train_loss -0.6945 
2025-06-04 13:00:13.833569: val_loss -0.6724 
2025-06-04 13:00:13.857662: Pseudo dice [np.float32(0.8164)] 
2025-06-04 13:00:13.891493: Epoch time: 144.47 s 
2025-06-04 13:00:21.459523:  
2025-06-04 13:00:21.490669: Epoch 759 
2025-06-04 13:00:21.513192: Current learning rate: 0.00278 
2025-06-04 13:02:40.989839: train_loss -0.6955 
2025-06-04 13:02:41.011087: val_loss -0.7184 
2025-06-04 13:02:41.026621: Pseudo dice [np.float32(0.7768)] 
2025-06-04 13:02:41.042467: Epoch time: 139.53 s 
2025-06-04 13:02:45.793516:  
2025-06-04 13:02:45.818688: Epoch 760 
2025-06-04 13:02:45.837145: Current learning rate: 0.00277 
2025-06-04 13:05:04.124091: train_loss -0.6961 
2025-06-04 13:05:04.142476: val_loss -0.6779 
2025-06-04 13:05:04.160361: Pseudo dice [np.float32(0.741)] 
2025-06-04 13:05:04.175263: Epoch time: 138.33 s 
2025-06-04 13:05:08.469452:  
2025-06-04 13:05:08.489851: Epoch 761 
2025-06-04 13:05:08.505932: Current learning rate: 0.00276 
2025-06-04 13:07:29.302820: train_loss -0.7162 
2025-06-04 13:07:29.574767: val_loss -0.6639 
2025-06-04 13:07:29.836020: Pseudo dice [np.float32(0.7473)] 
2025-06-04 13:07:29.856395: Epoch time: 140.87 s 
2025-06-04 13:07:32.435647:  
2025-06-04 13:07:32.460261: Epoch 762 
2025-06-04 13:07:32.500115: Current learning rate: 0.00275 
2025-06-04 13:09:56.545992: train_loss -0.7138 
2025-06-04 13:09:56.585677: val_loss -0.6752 
2025-06-04 13:09:56.601956: Pseudo dice [np.float32(0.7883)] 
2025-06-04 13:09:56.617721: Epoch time: 144.11 s 
2025-06-04 13:10:01.652509:  
2025-06-04 13:10:01.951103: Epoch 763 
2025-06-04 13:10:01.984121: Current learning rate: 0.00274 
2025-06-04 13:12:21.880370: train_loss -0.7074 
2025-06-04 13:12:22.278582: val_loss -0.682 
2025-06-04 13:12:22.697943: Pseudo dice [np.float32(0.7089)] 
2025-06-04 13:12:23.123503: Epoch time: 140.23 s 
2025-06-04 13:12:28.803838:  
2025-06-04 13:12:28.933254: Epoch 764 
2025-06-04 13:12:29.037107: Current learning rate: 0.00273 
2025-06-04 13:14:54.440471: train_loss -0.7295 
2025-06-04 13:14:54.462389: val_loss -0.7566 
2025-06-04 13:14:54.478712: Pseudo dice [np.float32(0.8479)] 
2025-06-04 13:14:54.495370: Epoch time: 145.64 s 
2025-06-04 13:14:58.043123:  
2025-06-04 13:14:58.063278: Epoch 765 
2025-06-04 13:14:58.080304: Current learning rate: 0.00272 
2025-06-04 13:17:21.234064: train_loss -0.718 
2025-06-04 13:17:21.256666: val_loss -0.6097 
2025-06-04 13:17:21.271981: Pseudo dice [np.float32(0.6563)] 
2025-06-04 13:17:21.287847: Epoch time: 143.19 s 
2025-06-04 13:17:26.785937:  
2025-06-04 13:17:26.802950: Epoch 766 
2025-06-04 13:17:26.822057: Current learning rate: 0.00271 
2025-06-04 13:19:47.765836: train_loss -0.7446 
2025-06-04 13:19:48.374127: val_loss -0.7041 
2025-06-04 13:19:48.395012: Pseudo dice [np.float32(0.7919)] 
2025-06-04 13:19:48.411843: Epoch time: 140.98 s 
2025-06-04 13:19:53.073489:  
2025-06-04 13:19:53.286578: Epoch 767 
2025-06-04 13:19:53.436780: Current learning rate: 0.0027 
2025-06-04 13:22:16.355505: train_loss -0.7291 
2025-06-04 13:22:16.377040: val_loss -0.6872 
2025-06-04 13:22:16.391405: Pseudo dice [np.float32(0.7304)] 
2025-06-04 13:22:16.407756: Epoch time: 143.29 s 
2025-06-04 13:22:19.828804:  
2025-06-04 13:22:19.938209: Epoch 768 
2025-06-04 13:22:20.121962: Current learning rate: 0.00268 
2025-06-04 13:24:42.703179: train_loss -0.71 
2025-06-04 13:24:42.972123: val_loss -0.7346 
2025-06-04 13:24:43.260886: Pseudo dice [np.float32(0.8297)] 
2025-06-04 13:24:43.280924: Epoch time: 142.88 s 
2025-06-04 13:24:48.954057:  
2025-06-04 13:24:48.977609: Epoch 769 
2025-06-04 13:24:48.993203: Current learning rate: 0.00267 
2025-06-04 13:27:10.069615: train_loss -0.7301 
2025-06-04 13:27:10.462774: val_loss -0.6731 
2025-06-04 13:27:11.226991: Pseudo dice [np.float32(0.7748)] 
2025-06-04 13:27:11.762015: Epoch time: 141.12 s 
2025-06-04 13:27:16.035999:  
2025-06-04 13:27:16.116193: Epoch 770 
2025-06-04 13:27:16.144171: Current learning rate: 0.00266 
2025-06-04 13:29:38.036933: train_loss -0.7316 
2025-06-04 13:29:38.629925: val_loss -0.7159 
2025-06-04 13:29:39.278388: Pseudo dice [np.float32(0.788)] 
2025-06-04 13:29:39.815057: Epoch time: 142.0 s 
2025-06-04 13:29:44.686142:  
2025-06-04 13:29:44.711614: Epoch 771 
2025-06-04 13:29:44.741193: Current learning rate: 0.00265 
2025-06-04 13:32:05.710114: train_loss -0.7161 
2025-06-04 13:32:06.109888: val_loss -0.7449 
2025-06-04 13:32:06.522811: Pseudo dice [np.float32(0.8166)] 
2025-06-04 13:32:06.550549: Epoch time: 141.04 s 
2025-06-04 13:32:12.078110:  
2025-06-04 13:32:12.194845: Epoch 772 
2025-06-04 13:32:12.504864: Current learning rate: 0.00264 
2025-06-04 13:34:35.656431: train_loss -0.7052 
2025-06-04 13:34:36.243754: val_loss -0.6591 
2025-06-04 13:34:36.715226: Pseudo dice [np.float32(0.7319)] 
2025-06-04 13:34:37.185368: Epoch time: 143.58 s 
2025-06-04 13:34:43.589067:  
2025-06-04 13:34:43.835613: Epoch 773 
2025-06-04 13:34:44.039223: Current learning rate: 0.00263 
2025-06-04 13:37:05.357036: train_loss -0.7034 
2025-06-04 13:37:05.377831: val_loss -0.6456 
2025-06-04 13:37:05.395795: Pseudo dice [np.float32(0.7674)] 
2025-06-04 13:37:05.413373: Epoch time: 141.77 s 
2025-06-04 13:37:10.942710:  
2025-06-04 13:37:11.281338: Epoch 774 
2025-06-04 13:37:11.665396: Current learning rate: 0.00262 
2025-06-04 13:39:32.513965: train_loss -0.6984 
2025-06-04 13:39:32.534407: val_loss -0.6567 
2025-06-04 13:39:32.549751: Pseudo dice [np.float32(0.7)] 
2025-06-04 13:39:32.564087: Epoch time: 141.57 s 
2025-06-04 13:39:37.467639:  
2025-06-04 13:39:37.840472: Epoch 775 
2025-06-04 13:39:38.091529: Current learning rate: 0.00261 
2025-06-04 13:42:00.138803: train_loss -0.7259 
2025-06-04 13:42:00.554850: val_loss -0.6946 
2025-06-04 13:42:00.891114: Pseudo dice [np.float32(0.7822)] 
2025-06-04 13:42:00.912329: Epoch time: 142.67 s 
2025-06-04 13:42:06.731130:  
2025-06-04 13:42:06.965969: Epoch 776 
2025-06-04 13:42:07.152385: Current learning rate: 0.0026 
2025-06-04 13:44:29.899337: train_loss -0.724 
2025-06-04 13:44:29.924892: val_loss -0.6802 
2025-06-04 13:44:29.942852: Pseudo dice [np.float32(0.8306)] 
2025-06-04 13:44:29.958241: Epoch time: 143.17 s 
2025-06-04 13:44:37.089439:  
2025-06-04 13:44:37.437210: Epoch 777 
2025-06-04 13:44:37.473282: Current learning rate: 0.00259 
2025-06-04 13:46:59.649630: train_loss -0.7112 
2025-06-04 13:46:59.920450: val_loss -0.7425 
2025-06-04 13:47:00.135882: Pseudo dice [np.float32(0.7813)] 
2025-06-04 13:47:00.720095: Epoch time: 142.56 s 
2025-06-04 13:47:06.948370:  
2025-06-04 13:47:06.987130: Epoch 778 
2025-06-04 13:47:07.009556: Current learning rate: 0.00258 
2025-06-04 13:49:26.646779: train_loss -0.703 
2025-06-04 13:49:27.153726: val_loss -0.6406 
2025-06-04 13:49:27.491561: Pseudo dice [np.float32(0.7641)] 
2025-06-04 13:49:27.508857: Epoch time: 139.7 s 
2025-06-04 13:49:33.408978:  
2025-06-04 13:49:33.475367: Epoch 779 
2025-06-04 13:49:33.544893: Current learning rate: 0.00257 
2025-06-04 13:51:55.690356: train_loss -0.7242 
2025-06-04 13:51:56.211365: val_loss -0.6796 
2025-06-04 13:51:56.409010: Pseudo dice [np.float32(0.7324)] 
2025-06-04 13:51:56.425805: Epoch time: 142.28 s 
2025-06-04 13:52:03.838325:  
2025-06-04 13:52:03.856767: Epoch 780 
2025-06-04 13:52:03.872307: Current learning rate: 0.00256 
2025-06-04 13:54:23.675636: train_loss -0.7063 
2025-06-04 13:54:23.860106: val_loss -0.6837 
2025-06-04 13:54:23.880762: Pseudo dice [np.float32(0.7413)] 
2025-06-04 13:54:23.896523: Epoch time: 139.84 s 
2025-06-04 13:54:29.045825:  
2025-06-04 13:54:29.295488: Epoch 781 
2025-06-04 13:54:29.339942: Current learning rate: 0.00255 
2025-06-04 13:56:48.489719: train_loss -0.7017 
2025-06-04 13:56:48.831471: val_loss -0.6653 
2025-06-04 13:56:49.412072: Pseudo dice [np.float32(0.7416)] 
2025-06-04 13:56:49.856943: Epoch time: 139.45 s 
2025-06-04 13:56:56.656705:  
2025-06-04 13:56:56.694690: Epoch 782 
2025-06-04 13:56:56.722843: Current learning rate: 0.00254 
2025-06-04 13:59:17.636900: train_loss -0.6992 
2025-06-04 13:59:17.778211: val_loss -0.6454 
2025-06-04 13:59:18.125075: Pseudo dice [np.float32(0.7588)] 
2025-06-04 13:59:18.668309: Epoch time: 141.04 s 
2025-06-04 13:59:24.806990:  
2025-06-04 13:59:24.844503: Epoch 783 
2025-06-04 13:59:24.881050: Current learning rate: 0.00253 
2025-06-04 14:01:48.029672: train_loss -0.7171 
2025-06-04 14:01:48.407547: val_loss -0.6732 
2025-06-04 14:01:48.426233: Pseudo dice [np.float32(0.7503)] 
2025-06-04 14:01:48.441699: Epoch time: 143.23 s 
2025-06-04 14:01:58.947851:  
2025-06-04 14:01:59.311008: Epoch 784 
2025-06-04 14:01:59.487818: Current learning rate: 0.00252 
2025-06-04 14:04:22.252806: train_loss -0.6984 
2025-06-04 14:04:22.663944: val_loss -0.7152 
2025-06-04 14:04:22.860404: Pseudo dice [np.float32(0.7578)] 
2025-06-04 14:04:22.876801: Epoch time: 143.31 s 
2025-06-04 14:04:30.265947:  
2025-06-04 14:04:30.287791: Epoch 785 
2025-06-04 14:04:30.307466: Current learning rate: 0.00251 
2025-06-04 14:06:50.294892: train_loss -0.7396 
2025-06-04 14:06:50.490052: val_loss -0.7078 
2025-06-04 14:06:50.507741: Pseudo dice [np.float32(0.7759)] 
2025-06-04 14:06:51.100987: Epoch time: 140.03 s 
2025-06-04 14:06:57.044862:  
2025-06-04 14:06:57.066723: Epoch 786 
2025-06-04 14:06:57.325343: Current learning rate: 0.0025 
2025-06-04 14:09:13.354235: train_loss -0.722 
2025-06-04 14:09:13.993931: val_loss -0.6563 
2025-06-04 14:09:14.628486: Pseudo dice [np.float32(0.813)] 
2025-06-04 14:09:15.205781: Epoch time: 136.31 s 
2025-06-04 14:09:26.687789:  
2025-06-04 14:09:26.940943: Epoch 787 
2025-06-04 14:09:27.189906: Current learning rate: 0.00249 
2025-06-04 14:11:44.655179: train_loss -0.719 
2025-06-04 14:11:44.675490: val_loss -0.7481 
2025-06-04 14:11:44.691688: Pseudo dice [np.float32(0.8684)] 
2025-06-04 14:11:44.706844: Epoch time: 137.97 s 
2025-06-04 14:11:44.722431: Yayy! New best EMA pseudo Dice: 0.7767000198364258 
2025-06-04 14:11:52.471622:  
2025-06-04 14:11:52.525807: Epoch 788 
2025-06-04 14:11:52.573638: Current learning rate: 0.00248 
2025-06-04 14:14:08.705428: train_loss -0.732 
2025-06-04 14:14:08.788219: val_loss -0.6707 
2025-06-04 14:14:08.806413: Pseudo dice [np.float32(0.7319)] 
2025-06-04 14:14:08.821756: Epoch time: 136.23 s 
2025-06-04 14:14:14.217153:  
2025-06-04 14:14:14.395405: Epoch 789 
2025-06-04 14:14:14.578340: Current learning rate: 0.00247 
2025-06-04 14:16:30.740787: train_loss -0.7325 
2025-06-04 14:16:30.908633: val_loss -0.6809 
2025-06-04 14:16:30.926279: Pseudo dice [np.float32(0.7539)] 
2025-06-04 14:16:31.538041: Epoch time: 136.53 s 
2025-06-04 14:16:38.166373:  
2025-06-04 14:16:38.328068: Epoch 790 
2025-06-04 14:16:38.479255: Current learning rate: 0.00245 
2025-06-04 14:18:58.170239: train_loss -0.7187 
2025-06-04 14:18:58.729227: val_loss -0.7534 
2025-06-04 14:18:59.181222: Pseudo dice [np.float32(0.7626)] 
2025-06-04 14:18:59.597492: Epoch time: 140.01 s 
2025-06-04 14:19:03.802630:  
2025-06-04 14:19:03.826185: Epoch 791 
2025-06-04 14:19:03.843500: Current learning rate: 0.00244 
2025-06-04 14:21:24.525067: train_loss -0.7528 
2025-06-04 14:21:24.552110: val_loss -0.6444 
2025-06-04 14:21:24.572991: Pseudo dice [np.float32(0.7331)] 
2025-06-04 14:21:24.588181: Epoch time: 140.72 s 
2025-06-04 14:21:29.908810:  
2025-06-04 14:21:29.944034: Epoch 792 
2025-06-04 14:21:30.049999: Current learning rate: 0.00243 
2025-06-04 14:23:51.400219: train_loss -0.7091 
2025-06-04 14:23:51.424427: val_loss -0.6709 
2025-06-04 14:23:51.439602: Pseudo dice [np.float32(0.7986)] 
2025-06-04 14:23:51.454208: Epoch time: 141.49 s 
2025-06-04 14:23:57.157574:  
2025-06-04 14:23:57.240433: Epoch 793 
2025-06-04 14:23:57.339138: Current learning rate: 0.00242 
2025-06-04 14:26:21.731031: train_loss -0.7077 
2025-06-04 14:26:21.752870: val_loss -0.7148 
2025-06-04 14:26:22.186344: Pseudo dice [np.float32(0.775)] 
2025-06-04 14:26:22.565218: Epoch time: 144.58 s 
2025-06-04 14:26:31.060608:  
2025-06-04 14:26:31.186860: Epoch 794 
2025-06-04 14:26:31.342493: Current learning rate: 0.00241 
2025-06-04 14:28:48.996982: train_loss -0.7299 
2025-06-04 14:28:49.303933: val_loss -0.6942 
2025-06-04 14:28:49.720653: Pseudo dice [np.float32(0.7966)] 
2025-06-04 14:28:50.087126: Epoch time: 137.94 s 
2025-06-04 14:28:55.394493:  
2025-06-04 14:28:55.570967: Epoch 795 
2025-06-04 14:28:55.883695: Current learning rate: 0.0024 
2025-06-04 14:31:20.021485: train_loss -0.7258 
2025-06-04 14:31:20.050925: val_loss -0.7083 
2025-06-04 14:31:20.082090: Pseudo dice [np.float32(0.8016)] 
2025-06-04 14:31:20.100286: Epoch time: 144.63 s 
2025-06-04 14:31:25.375203:  
2025-06-04 14:31:25.665343: Epoch 796 
2025-06-04 14:31:25.843075: Current learning rate: 0.00239 
2025-06-04 14:33:49.701441: train_loss -0.7421 
2025-06-04 14:33:50.101486: val_loss -0.697 
2025-06-04 14:33:50.282188: Pseudo dice [np.float32(0.6653)] 
2025-06-04 14:33:50.300012: Epoch time: 144.33 s 
2025-06-04 14:33:54.533636:  
2025-06-04 14:33:54.565856: Epoch 797 
2025-06-04 14:33:54.804634: Current learning rate: 0.00238 
2025-06-04 14:36:10.513310: train_loss -0.7382 
2025-06-04 14:36:10.860070: val_loss -0.6895 
2025-06-04 14:36:11.499115: Pseudo dice [np.float32(0.7591)] 
2025-06-04 14:36:12.070371: Epoch time: 135.98 s 
2025-06-04 14:36:18.708321:  
2025-06-04 14:36:18.730423: Epoch 798 
2025-06-04 14:36:18.747260: Current learning rate: 0.00237 
2025-06-04 14:38:39.979031: train_loss -0.7088 
2025-06-04 14:38:40.165377: val_loss -0.7027 
2025-06-04 14:38:40.575485: Pseudo dice [np.float32(0.7752)] 
2025-06-04 14:38:41.161149: Epoch time: 141.3 s 
2025-06-04 14:38:47.780282:  
2025-06-04 14:38:47.928484: Epoch 799 
2025-06-04 14:38:47.943595: Current learning rate: 0.00236 
2025-06-04 14:41:10.908322: train_loss -0.7081 
2025-06-04 14:41:11.459101: val_loss -0.6655 
2025-06-04 14:41:12.029532: Pseudo dice [np.float32(0.7347)] 
2025-06-04 14:41:12.635793: Epoch time: 143.13 s 
2025-06-04 14:41:19.131423:  
2025-06-04 14:41:19.153384: Epoch 800 
2025-06-04 14:41:19.168325: Current learning rate: 0.00235 
2025-06-04 14:43:44.479577: train_loss -0.7099 
2025-06-04 14:43:44.886794: val_loss -0.6464 
2025-06-04 14:43:44.904063: Pseudo dice [np.float32(0.7396)] 
2025-06-04 14:43:44.919483: Epoch time: 145.35 s 
2025-06-04 14:43:49.687568:  
2025-06-04 14:43:49.854914: Epoch 801 
2025-06-04 14:43:50.154099: Current learning rate: 0.00234 
2025-06-04 14:46:11.653917: train_loss -0.7032 
2025-06-04 14:46:12.108828: val_loss -0.6202 
2025-06-04 14:46:12.635998: Pseudo dice [np.float32(0.7882)] 
2025-06-04 14:46:13.050165: Epoch time: 141.97 s 
2025-06-04 14:46:16.429274:  
2025-06-04 14:46:16.551764: Epoch 802 
2025-06-04 14:46:16.622581: Current learning rate: 0.00233 
2025-06-04 14:48:38.303633: train_loss -0.6864 
2025-06-04 14:48:38.834517: val_loss -0.6964 
2025-06-04 14:48:39.384331: Pseudo dice [np.float32(0.8245)] 
2025-06-04 14:48:39.532408: Epoch time: 141.88 s 
2025-06-04 14:48:44.158175:  
2025-06-04 14:48:44.195795: Epoch 803 
2025-06-04 14:48:44.227786: Current learning rate: 0.00232 
2025-06-04 14:51:05.230447: train_loss -0.7299 
2025-06-04 14:51:05.492973: val_loss -0.6951 
2025-06-04 14:51:06.191461: Pseudo dice [np.float32(0.7487)] 
2025-06-04 14:51:06.574439: Epoch time: 141.07 s 
2025-06-04 14:51:10.990724:  
2025-06-04 14:51:11.298877: Epoch 804 
2025-06-04 14:51:11.548813: Current learning rate: 0.00231 
2025-06-04 14:53:31.544929: train_loss -0.7141 
2025-06-04 14:53:31.565417: val_loss -0.6626 
2025-06-04 14:53:31.581230: Pseudo dice [np.float32(0.7817)] 
2025-06-04 14:53:31.598253: Epoch time: 140.55 s 
2025-06-04 14:53:36.337543:  
2025-06-04 14:53:36.358747: Epoch 805 
2025-06-04 14:53:36.378305: Current learning rate: 0.0023 
2025-06-04 14:55:56.648692: train_loss -0.7184 
2025-06-04 14:55:56.676488: val_loss -0.6581 
2025-06-04 14:55:56.693310: Pseudo dice [np.float32(0.7758)] 
2025-06-04 14:55:56.711821: Epoch time: 140.31 s 
2025-06-04 14:56:01.449749:  
2025-06-04 14:56:01.492825: Epoch 806 
2025-06-04 14:56:01.516335: Current learning rate: 0.00229 
2025-06-04 14:58:21.100803: train_loss -0.7235 
2025-06-04 14:58:21.539025: val_loss -0.642 
2025-06-04 14:58:22.052585: Pseudo dice [np.float32(0.7353)] 
2025-06-04 14:58:22.491038: Epoch time: 139.65 s 
2025-06-04 14:58:28.166924:  
2025-06-04 14:58:28.191536: Epoch 807 
2025-06-04 14:58:28.271046: Current learning rate: 0.00228 
2025-06-04 15:00:43.931223: train_loss -0.7199 
2025-06-04 15:00:43.953709: val_loss -0.6887 
2025-06-04 15:00:43.968736: Pseudo dice [np.float32(0.752)] 
2025-06-04 15:00:43.984502: Epoch time: 135.77 s 
2025-06-04 15:00:52.647703:  
2025-06-04 15:00:52.699968: Epoch 808 
2025-06-04 15:00:52.717429: Current learning rate: 0.00226 
2025-06-04 15:03:15.259236: train_loss -0.7582 
2025-06-04 15:03:15.281107: val_loss -0.6817 
2025-06-04 15:03:15.296813: Pseudo dice [np.float32(0.8197)] 
2025-06-04 15:03:15.312044: Epoch time: 142.61 s 
2025-06-04 15:03:21.931409:  
2025-06-04 15:03:21.954113: Epoch 809 
2025-06-04 15:03:21.970770: Current learning rate: 0.00225 
2025-06-04 15:05:44.214933: train_loss -0.7238 
2025-06-04 15:05:44.583519: val_loss -0.7144 
2025-06-04 15:05:44.609038: Pseudo dice [np.float32(0.8017)] 
2025-06-04 15:05:44.629391: Epoch time: 142.29 s 
2025-06-04 15:05:49.038998:  
2025-06-04 15:05:49.236400: Epoch 810 
2025-06-04 15:05:49.317792: Current learning rate: 0.00224 
2025-06-04 15:08:11.181746: train_loss -0.7133 
2025-06-04 15:08:11.763395: val_loss -0.6613 
2025-06-04 15:08:11.781502: Pseudo dice [np.float32(0.7139)] 
2025-06-04 15:08:11.797243: Epoch time: 142.14 s 
2025-06-04 15:08:17.751449:  
2025-06-04 15:08:17.782595: Epoch 811 
2025-06-04 15:08:17.803680: Current learning rate: 0.00223 
2025-06-04 15:10:35.569857: train_loss -0.733 
2025-06-04 15:10:36.373580: val_loss -0.6591 
2025-06-04 15:10:36.772745: Pseudo dice [np.float32(0.7469)] 
2025-06-04 15:10:37.237098: Epoch time: 137.82 s 
2025-06-04 15:10:43.637079:  
2025-06-04 15:10:43.705019: Epoch 812 
2025-06-04 15:10:43.857310: Current learning rate: 0.00222 
2025-06-04 15:12:58.143491: train_loss -0.7475 
2025-06-04 15:12:58.501197: val_loss -0.7063 
2025-06-04 15:12:58.526859: Pseudo dice [np.float32(0.8568)] 
2025-06-04 15:12:58.542941: Epoch time: 134.51 s 
2025-06-04 15:13:05.264719:  
2025-06-04 15:13:05.331797: Epoch 813 
2025-06-04 15:13:05.502242: Current learning rate: 0.00221 
2025-06-04 15:15:24.506146: train_loss -0.7106 
2025-06-04 15:15:25.037502: val_loss -0.7274 
2025-06-04 15:15:25.510559: Pseudo dice [np.float32(0.7964)] 
2025-06-04 15:15:25.923251: Epoch time: 139.24 s 
2025-06-04 15:15:32.922514:  
2025-06-04 15:15:33.162545: Epoch 814 
2025-06-04 15:15:33.608010: Current learning rate: 0.0022 
2025-06-04 15:17:53.155886: train_loss -0.7232 
2025-06-04 15:17:53.176737: val_loss -0.6896 
2025-06-04 15:17:53.223897: Pseudo dice [np.float32(0.8043)] 
2025-06-04 15:17:53.242353: Epoch time: 140.24 s 
2025-06-04 15:17:53.257865: Yayy! New best EMA pseudo Dice: 0.7792999744415283 
2025-06-04 15:18:03.604678:  
2025-06-04 15:18:04.154444: Epoch 815 
2025-06-04 15:18:04.433006: Current learning rate: 0.00219 
2025-06-04 15:20:23.650931: train_loss -0.7406 
2025-06-04 15:20:23.795356: val_loss -0.6304 
2025-06-04 15:20:23.850109: Pseudo dice [np.float32(0.7782)] 
2025-06-04 15:20:23.915912: Epoch time: 140.05 s 
2025-06-04 15:20:27.538279:  
2025-06-04 15:20:27.701921: Epoch 816 
2025-06-04 15:20:27.864104: Current learning rate: 0.00218 
2025-06-04 15:22:46.866321: train_loss -0.7102 
2025-06-04 15:22:46.890708: val_loss -0.6978 
2025-06-04 15:22:46.909508: Pseudo dice [np.float32(0.7455)] 
2025-06-04 15:22:46.929770: Epoch time: 139.33 s 
2025-06-04 15:22:51.578550:  
2025-06-04 15:22:51.611060: Epoch 817 
2025-06-04 15:22:51.630903: Current learning rate: 0.00217 
2025-06-04 15:25:17.030264: train_loss -0.7386 
2025-06-04 15:25:17.167534: val_loss -0.6683 
2025-06-04 15:25:17.239188: Pseudo dice [np.float32(0.8011)] 
2025-06-04 15:25:17.633184: Epoch time: 145.45 s 
2025-06-04 15:25:21.161590:  
2025-06-04 15:25:21.182629: Epoch 818 
2025-06-04 15:25:21.199271: Current learning rate: 0.00216 
2025-06-04 15:27:40.396297: train_loss -0.7172 
2025-06-04 15:27:40.415653: val_loss -0.6868 
2025-06-04 15:27:40.431038: Pseudo dice [np.float32(0.7001)] 
2025-06-04 15:27:40.446097: Epoch time: 139.24 s 
2025-06-04 15:27:42.934602:  
2025-06-04 15:27:43.114497: Epoch 819 
2025-06-04 15:27:43.259531: Current learning rate: 0.00215 
2025-06-04 15:30:03.879530: train_loss -0.7253 
2025-06-04 15:30:04.193211: val_loss -0.7434 
2025-06-04 15:30:04.683386: Pseudo dice [np.float32(0.8556)] 
2025-06-04 15:30:05.055159: Epoch time: 140.95 s 
2025-06-04 15:30:09.485340:  
2025-06-04 15:30:09.645903: Epoch 820 
2025-06-04 15:30:09.856505: Current learning rate: 0.00214 
2025-06-04 15:32:30.121242: train_loss -0.733 
2025-06-04 15:32:30.542683: val_loss -0.6706 
2025-06-04 15:32:30.980997: Pseudo dice [np.float32(0.7567)] 
2025-06-04 15:32:31.342972: Epoch time: 140.64 s 
2025-06-04 15:32:35.933903:  
2025-06-04 15:32:35.992466: Epoch 821 
2025-06-04 15:32:36.050282: Current learning rate: 0.00213 
2025-06-04 15:34:58.560020: train_loss -0.7258 
2025-06-04 15:34:58.781354: val_loss -0.6569 
2025-06-04 15:34:58.806409: Pseudo dice [np.float32(0.7183)] 
2025-06-04 15:34:58.862375: Epoch time: 142.63 s 
2025-06-04 15:35:04.676904:  
2025-06-04 15:35:04.822303: Epoch 822 
2025-06-04 15:35:04.956931: Current learning rate: 0.00212 
2025-06-04 15:37:25.968357: train_loss -0.7175 
2025-06-04 15:37:25.991205: val_loss -0.6956 
2025-06-04 15:37:26.006819: Pseudo dice [np.float32(0.8108)] 
2025-06-04 15:37:26.022142: Epoch time: 141.29 s 
2025-06-04 15:37:31.124328:  
2025-06-04 15:37:31.144543: Epoch 823 
2025-06-04 15:37:31.159929: Current learning rate: 0.0021 
2025-06-04 15:39:51.278304: train_loss -0.7207 
2025-06-04 15:39:51.874768: val_loss -0.6487 
2025-06-04 15:39:52.187680: Pseudo dice [np.float32(0.7578)] 
2025-06-04 15:39:52.206192: Epoch time: 140.16 s 
2025-06-04 15:39:57.507405:  
2025-06-04 15:39:57.527893: Epoch 824 
2025-06-04 15:39:57.546247: Current learning rate: 0.00209 
2025-06-04 15:42:19.740968: train_loss -0.7303 
2025-06-04 15:42:19.920061: val_loss -0.7088 
2025-06-04 15:42:20.465790: Pseudo dice [np.float32(0.7511)] 
2025-06-04 15:42:20.884344: Epoch time: 142.24 s 
2025-06-04 15:42:25.140411:  
2025-06-04 15:42:25.205860: Epoch 825 
2025-06-04 15:42:25.276376: Current learning rate: 0.00208 
2025-06-04 15:44:45.774048: train_loss -0.7531 
2025-06-04 15:44:46.348801: val_loss -0.6661 
2025-06-04 15:44:46.366547: Pseudo dice [np.float32(0.6594)] 
2025-06-04 15:44:46.381771: Epoch time: 140.64 s 
2025-06-04 15:44:51.932002:  
2025-06-04 15:44:52.018692: Epoch 826 
2025-06-04 15:44:52.040735: Current learning rate: 0.00207 
2025-06-04 15:47:09.996531: train_loss -0.6983 
2025-06-04 15:47:10.528692: val_loss -0.7208 
2025-06-04 15:47:10.547926: Pseudo dice [np.float32(0.821)] 
2025-06-04 15:47:10.572157: Epoch time: 138.07 s 
2025-06-04 15:47:14.838506:  
2025-06-04 15:47:14.855048: Epoch 827 
2025-06-04 15:47:14.874770: Current learning rate: 0.00206 
2025-06-04 15:49:34.143546: train_loss -0.7345 
2025-06-04 15:49:34.562694: val_loss -0.6989 
2025-06-04 15:49:35.165657: Pseudo dice [np.float32(0.6557)] 
2025-06-04 15:49:35.693449: Epoch time: 139.31 s 
2025-06-04 15:49:40.459570:  
2025-06-04 15:49:40.575801: Epoch 828 
2025-06-04 15:49:40.717243: Current learning rate: 0.00205 
2025-06-04 15:51:57.952871: train_loss -0.752 
2025-06-04 15:51:58.145385: val_loss -0.6472 
2025-06-04 15:51:58.495106: Pseudo dice [np.float32(0.7466)] 
2025-06-04 15:51:59.110490: Epoch time: 137.5 s 
2025-06-04 15:52:04.411620:  
2025-06-04 15:52:04.473844: Epoch 829 
2025-06-04 15:52:04.488723: Current learning rate: 0.00204 
2025-06-04 15:54:28.062703: train_loss -0.7194 
2025-06-04 15:54:28.385588: val_loss -0.6289 
2025-06-04 15:54:28.584357: Pseudo dice [np.float32(0.7709)] 
2025-06-04 15:54:29.160978: Epoch time: 143.65 s 
2025-06-04 15:54:37.408185:  
2025-06-04 15:54:37.753183: Epoch 830 
2025-06-04 15:54:38.144478: Current learning rate: 0.00203 
2025-06-04 15:57:00.257417: train_loss -0.7473 
2025-06-04 15:57:00.639947: val_loss -0.6764 
2025-06-04 15:57:00.656045: Pseudo dice [np.float32(0.8221)] 
2025-06-04 15:57:00.671116: Epoch time: 142.85 s 
2025-06-04 15:57:05.122571:  
2025-06-04 15:57:05.298338: Epoch 831 
2025-06-04 15:57:05.411166: Current learning rate: 0.00202 
2025-06-04 15:59:22.150017: train_loss -0.7609 
2025-06-04 15:59:22.176175: val_loss -0.7066 
2025-06-04 15:59:22.191678: Pseudo dice [np.float32(0.8037)] 
2025-06-04 15:59:22.206345: Epoch time: 137.03 s 
2025-06-04 15:59:26.964186:  
2025-06-04 15:59:26.997622: Epoch 832 
2025-06-04 15:59:27.011395: Current learning rate: 0.00201 
2025-06-04 16:01:49.500771: train_loss -0.731 
2025-06-04 16:01:49.856304: val_loss -0.682 
2025-06-04 16:01:49.876470: Pseudo dice [np.float32(0.7122)] 
2025-06-04 16:01:49.894608: Epoch time: 142.54 s 
2025-06-04 16:01:56.009911:  
2025-06-04 16:01:56.122642: Epoch 833 
2025-06-04 16:01:56.589195: Current learning rate: 0.002 
2025-06-04 16:04:19.650861: train_loss -0.7476 
2025-06-04 16:04:19.695730: val_loss -0.7431 
2025-06-04 16:04:19.730219: Pseudo dice [np.float32(0.7953)] 
2025-06-04 16:04:19.752191: Epoch time: 143.64 s 
2025-06-04 16:04:24.800367:  
2025-06-04 16:04:25.018988: Epoch 834 
2025-06-04 16:04:25.372319: Current learning rate: 0.00199 
2025-06-04 16:06:45.250239: train_loss -0.7214 
2025-06-04 16:06:45.268397: val_loss -0.6937 
2025-06-04 16:06:45.283892: Pseudo dice [np.float32(0.813)] 
2025-06-04 16:06:45.298760: Epoch time: 140.45 s 
2025-06-04 16:06:50.380777:  
2025-06-04 16:06:50.585806: Epoch 835 
2025-06-04 16:06:50.701350: Current learning rate: 0.00198 
2025-06-04 16:09:08.411716: train_loss -0.7329 
2025-06-04 16:09:08.546629: val_loss -0.6843 
2025-06-04 16:09:08.566308: Pseudo dice [np.float32(0.7379)] 
2025-06-04 16:09:08.586881: Epoch time: 138.03 s 
2025-06-04 16:09:13.443216:  
2025-06-04 16:09:13.578406: Epoch 836 
2025-06-04 16:09:13.751994: Current learning rate: 0.00196 
2025-06-04 16:11:34.261315: train_loss -0.7437 
2025-06-04 16:11:34.881256: val_loss -0.7054 
2025-06-04 16:11:35.605380: Pseudo dice [np.float32(0.8251)] 
2025-06-04 16:11:35.623390: Epoch time: 140.82 s 
2025-06-04 16:11:40.622346:  
2025-06-04 16:11:40.643455: Epoch 837 
2025-06-04 16:11:40.677617: Current learning rate: 0.00195 
2025-06-04 16:14:02.332213: train_loss -0.7415 
2025-06-04 16:14:02.516616: val_loss -0.6937 
2025-06-04 16:14:02.539822: Pseudo dice [np.float32(0.7688)] 
2025-06-04 16:14:02.555701: Epoch time: 141.71 s 
2025-06-04 16:14:08.680801:  
2025-06-04 16:14:08.817474: Epoch 838 
2025-06-04 16:14:08.954131: Current learning rate: 0.00194 
2025-06-04 16:16:26.717743: train_loss -0.7254 
2025-06-04 16:16:27.362349: val_loss -0.6735 
2025-06-04 16:16:28.056175: Pseudo dice [np.float32(0.7816)] 
2025-06-04 16:16:28.727292: Epoch time: 138.04 s 
2025-06-04 16:16:33.276930:  
2025-06-04 16:16:33.361161: Epoch 839 
2025-06-04 16:16:33.387802: Current learning rate: 0.00193 
2025-06-04 16:18:52.698783: train_loss -0.7056 
2025-06-04 16:18:52.800116: val_loss -0.672 
2025-06-04 16:18:53.115930: Pseudo dice [np.float32(0.7521)] 
2025-06-04 16:18:53.482338: Epoch time: 139.42 s 
2025-06-04 16:18:56.292469:  
2025-06-04 16:18:56.325096: Epoch 840 
2025-06-04 16:18:56.371317: Current learning rate: 0.00192 
2025-06-04 16:21:11.695922: train_loss -0.7031 
2025-06-04 16:21:12.112891: val_loss -0.6579 
2025-06-04 16:21:12.290245: Pseudo dice [np.float32(0.8008)] 
2025-06-04 16:21:12.305928: Epoch time: 135.41 s 
2025-06-04 16:21:18.868983:  
2025-06-04 16:21:18.978445: Epoch 841 
2025-06-04 16:21:19.122291: Current learning rate: 0.00191 
2025-06-04 16:23:39.606318: train_loss -0.7267 
2025-06-04 16:23:39.874642: val_loss -0.6713 
2025-06-04 16:23:40.391438: Pseudo dice [np.float32(0.7546)] 
2025-06-04 16:23:40.730763: Epoch time: 140.74 s 
2025-06-04 16:23:44.548894:  
2025-06-04 16:23:44.620466: Epoch 842 
2025-06-04 16:23:44.637421: Current learning rate: 0.0019 
2025-06-04 16:26:09.888258: train_loss -0.7036 
2025-06-04 16:26:09.909781: val_loss -0.7223 
2025-06-04 16:26:09.928675: Pseudo dice [np.float32(0.7682)] 
2025-06-04 16:26:09.945559: Epoch time: 145.34 s 
2025-06-04 16:26:13.433361:  
2025-06-04 16:26:13.503893: Epoch 843 
2025-06-04 16:26:13.574961: Current learning rate: 0.00189 
2025-06-04 16:28:32.855148: train_loss -0.7372 
2025-06-04 16:28:32.874483: val_loss -0.6814 
2025-06-04 16:28:32.889904: Pseudo dice [np.float32(0.7065)] 
2025-06-04 16:28:32.904934: Epoch time: 139.42 s 
2025-06-04 16:28:37.237507:  
2025-06-04 16:28:37.255973: Epoch 844 
2025-06-04 16:28:37.272356: Current learning rate: 0.00188 
2025-06-04 16:31:04.203379: train_loss -0.7328 
2025-06-04 16:31:04.223461: val_loss -0.6512 
2025-06-04 16:31:04.240028: Pseudo dice [np.float32(0.7488)] 
2025-06-04 16:31:04.255657: Epoch time: 146.97 s 
2025-06-04 16:31:10.472418:  
2025-06-04 16:31:10.621046: Epoch 845 
2025-06-04 16:31:10.841140: Current learning rate: 0.00187 
2025-06-04 16:33:29.880873: train_loss -0.7447 
2025-06-04 16:33:30.175225: val_loss -0.7306 
2025-06-04 16:33:30.194313: Pseudo dice [np.float32(0.8253)] 
2025-06-04 16:33:30.213841: Epoch time: 139.41 s 
2025-06-04 16:33:34.032835:  
2025-06-04 16:33:34.050969: Epoch 846 
2025-06-04 16:33:34.065309: Current learning rate: 0.00186 
2025-06-04 16:35:52.484148: train_loss -0.7284 
2025-06-04 16:35:53.077913: val_loss -0.7394 
2025-06-04 16:35:53.731052: Pseudo dice [np.float32(0.7558)] 
2025-06-04 16:35:54.281955: Epoch time: 138.45 s 
2025-06-04 16:35:58.676393:  
2025-06-04 16:35:58.802827: Epoch 847 
2025-06-04 16:35:58.821589: Current learning rate: 0.00185 
2025-06-04 16:38:15.354820: train_loss -0.7255 
2025-06-04 16:38:15.922503: val_loss -0.6591 
2025-06-04 16:38:15.946622: Pseudo dice [np.float32(0.8362)] 
2025-06-04 16:38:15.963805: Epoch time: 136.68 s 
2025-06-04 16:38:23.960231:  
2025-06-04 16:38:24.382782: Epoch 848 
2025-06-04 16:38:24.402722: Current learning rate: 0.00184 
2025-06-04 16:40:43.084578: train_loss -0.7389 
2025-06-04 16:40:43.649721: val_loss -0.6815 
2025-06-04 16:40:44.211825: Pseudo dice [np.float32(0.7476)] 
2025-06-04 16:40:44.697212: Epoch time: 139.13 s 
2025-06-04 16:40:54.089733:  
2025-06-04 16:40:54.323437: Epoch 849 
2025-06-04 16:40:54.752057: Current learning rate: 0.00182 
2025-06-04 16:43:09.745811: train_loss -0.7215 
2025-06-04 16:43:10.346536: val_loss -0.6703 
2025-06-04 16:43:10.754596: Pseudo dice [np.float32(0.7715)] 
2025-06-04 16:43:10.951685: Epoch time: 135.66 s 
2025-06-04 16:43:19.054356:  
2025-06-04 16:43:19.137021: Epoch 850 
2025-06-04 16:43:19.366751: Current learning rate: 0.00181 
2025-06-04 16:45:38.536110: train_loss -0.7353 
2025-06-04 16:45:38.562149: val_loss -0.7002 
2025-06-04 16:45:38.578819: Pseudo dice [np.float32(0.7879)] 
2025-06-04 16:45:38.594079: Epoch time: 139.48 s 
2025-06-04 16:45:44.240017:  
2025-06-04 16:45:44.543614: Epoch 851 
2025-06-04 16:45:44.567223: Current learning rate: 0.0018 
2025-06-04 16:48:05.510594: train_loss -0.7254 
2025-06-04 16:48:05.987736: val_loss -0.6487 
2025-06-04 16:48:06.366751: Pseudo dice [np.float32(0.7558)] 
2025-06-04 16:48:06.384668: Epoch time: 141.27 s 
2025-06-04 16:48:13.631580:  
2025-06-04 16:48:14.262370: Epoch 852 
2025-06-04 16:48:14.602311: Current learning rate: 0.00179 
2025-06-04 16:50:36.848401: train_loss -0.742 
2025-06-04 16:50:36.869460: val_loss -0.6889 
2025-06-04 16:50:36.883839: Pseudo dice [np.float32(0.7755)] 
2025-06-04 16:50:36.898699: Epoch time: 143.22 s 
2025-06-04 16:50:47.418371:  
2025-06-04 16:50:47.632628: Epoch 853 
2025-06-04 16:50:47.838372: Current learning rate: 0.00178 
2025-06-04 16:53:07.554735: train_loss -0.7015 
2025-06-04 16:53:07.579401: val_loss -0.6923 
2025-06-04 16:53:07.594577: Pseudo dice [np.float32(0.7574)] 
2025-06-04 16:53:07.609781: Epoch time: 140.14 s 
2025-06-04 16:53:15.652701:  
2025-06-04 16:53:16.037681: Epoch 854 
2025-06-04 16:53:16.439060: Current learning rate: 0.00177 
2025-06-04 16:55:38.176927: train_loss -0.7066 
2025-06-04 16:55:38.197846: val_loss -0.6316 
2025-06-04 16:55:38.213153: Pseudo dice [np.float32(0.6918)] 
2025-06-04 16:55:38.228486: Epoch time: 142.53 s 
2025-06-04 16:55:46.922452:  
2025-06-04 16:55:47.260240: Epoch 855 
2025-06-04 16:55:47.625747: Current learning rate: 0.00176 
2025-06-04 16:58:07.952335: train_loss -0.7369 
2025-06-04 16:58:08.453093: val_loss -0.6909 
2025-06-04 16:58:08.856544: Pseudo dice [np.float32(0.8525)] 
2025-06-04 16:58:08.874479: Epoch time: 141.03 s 
2025-06-04 16:58:14.831836:  
2025-06-04 16:58:14.962468: Epoch 856 
2025-06-04 16:58:15.138443: Current learning rate: 0.00175 
2025-06-04 17:00:29.881074: train_loss -0.7187 
2025-06-04 17:00:30.503621: val_loss -0.6789 
2025-06-04 17:00:31.027569: Pseudo dice [np.float32(0.7681)] 
2025-06-04 17:00:31.601872: Epoch time: 135.05 s 
2025-06-04 17:00:41.905813:  
2025-06-04 17:00:42.278649: Epoch 857 
2025-06-04 17:00:42.642096: Current learning rate: 0.00174 
2025-06-04 17:03:01.356026: train_loss -0.7044 
2025-06-04 17:03:01.910826: val_loss -0.6511 
2025-06-04 17:03:01.930653: Pseudo dice [np.float32(0.7497)] 
2025-06-04 17:03:01.945263: Epoch time: 139.45 s 
2025-06-04 17:03:09.632379:  
2025-06-04 17:03:10.059118: Epoch 858 
2025-06-04 17:03:10.526737: Current learning rate: 0.00173 
2025-06-04 17:05:30.949948: train_loss -0.7116 
2025-06-04 17:05:31.389656: val_loss -0.6466 
2025-06-04 17:05:31.801684: Pseudo dice [np.float32(0.7179)] 
2025-06-04 17:05:32.387140: Epoch time: 141.32 s 
2025-06-04 17:05:39.928800:  
2025-06-04 17:05:40.003962: Epoch 859 
2025-06-04 17:05:40.250267: Current learning rate: 0.00172 
2025-06-04 17:08:01.333345: train_loss -0.7399 
2025-06-04 17:08:01.678570: val_loss -0.7425 
2025-06-04 17:08:01.839319: Pseudo dice [np.float32(0.8013)] 
2025-06-04 17:08:01.856829: Epoch time: 141.41 s 
2025-06-04 17:08:07.974945:  
2025-06-04 17:08:08.454232: Epoch 860 
2025-06-04 17:08:08.726350: Current learning rate: 0.0017 
2025-06-04 17:10:30.899008: train_loss -0.7391 
2025-06-04 17:10:31.514157: val_loss -0.7039 
2025-06-04 17:10:32.045047: Pseudo dice [np.float32(0.8048)] 
2025-06-04 17:10:32.416252: Epoch time: 142.93 s 
2025-06-04 17:10:38.415183:  
2025-06-04 17:10:38.851449: Epoch 861 
2025-06-04 17:10:39.424011: Current learning rate: 0.00169 
2025-06-04 17:12:55.346571: train_loss -0.7437 
2025-06-04 17:12:55.969263: val_loss -0.715 
2025-06-04 17:12:55.987225: Pseudo dice [np.float32(0.8298)] 
2025-06-04 17:12:56.003268: Epoch time: 136.93 s 
2025-06-04 17:13:02.913126:  
2025-06-04 17:13:02.945881: Epoch 862 
2025-06-04 17:13:02.966276: Current learning rate: 0.00168 
2025-06-04 17:15:22.047724: train_loss -0.7376 
2025-06-04 17:15:22.252009: val_loss -0.7227 
2025-06-04 17:15:22.460634: Pseudo dice [np.float32(0.8433)] 
2025-06-04 17:15:22.763295: Epoch time: 139.14 s 
2025-06-04 17:15:22.871126: Yayy! New best EMA pseudo Dice: 0.7839999794960022 
2025-06-04 17:15:28.418082:  
2025-06-04 17:15:28.438618: Epoch 863 
2025-06-04 17:15:28.471733: Current learning rate: 0.00167 
2025-06-04 17:17:53.062671: train_loss -0.7532 
2025-06-04 17:17:53.275674: val_loss -0.7329 
2025-06-04 17:17:53.483719: Pseudo dice [np.float32(0.8052)] 
2025-06-04 17:17:53.703525: Epoch time: 144.65 s 
2025-06-04 17:17:53.855738: Yayy! New best EMA pseudo Dice: 0.7860999703407288 
2025-06-04 17:17:58.391764:  
2025-06-04 17:17:58.623084: Epoch 864 
2025-06-04 17:17:58.876527: Current learning rate: 0.00166 
2025-06-04 17:20:22.381326: train_loss -0.7425 
2025-06-04 17:20:22.689799: val_loss -0.6617 
2025-06-04 17:20:23.141847: Pseudo dice [np.float32(0.6968)] 
2025-06-04 17:20:23.449241: Epoch time: 143.99 s 
2025-06-04 17:20:25.649631:  
2025-06-04 17:20:25.668253: Epoch 865 
2025-06-04 17:20:25.680244: Current learning rate: 0.00165 
2025-06-04 17:22:44.948055: train_loss -0.7221 
2025-06-04 17:22:45.231903: val_loss -0.6771 
2025-06-04 17:22:45.583236: Pseudo dice [np.float32(0.8317)] 
2025-06-04 17:22:45.847492: Epoch time: 139.3 s 
2025-06-04 17:22:51.008144:  
2025-06-04 17:22:51.148364: Epoch 866 
2025-06-04 17:22:51.320343: Current learning rate: 0.00164 
2025-06-04 17:25:15.701310: train_loss -0.7361 
2025-06-04 17:25:16.030244: val_loss -0.63 
2025-06-04 17:25:16.616516: Pseudo dice [np.float32(0.6974)] 
2025-06-04 17:25:16.902682: Epoch time: 144.69 s 
2025-06-04 17:25:20.721025:  
2025-06-04 17:25:21.030104: Epoch 867 
2025-06-04 17:25:21.335372: Current learning rate: 0.00163 
2025-06-04 17:27:47.728435: train_loss -0.7557 
2025-06-04 17:27:48.030320: val_loss -0.6729 
2025-06-04 17:27:48.156425: Pseudo dice [np.float32(0.7773)] 
2025-06-04 17:27:48.528347: Epoch time: 147.01 s 
2025-06-04 17:27:52.821722:  
2025-06-04 17:27:53.138530: Epoch 868 
2025-06-04 17:27:53.338411: Current learning rate: 0.00162 
2025-06-04 17:30:16.106208: train_loss -0.7288 
2025-06-04 17:30:16.560220: val_loss -0.6915 
2025-06-04 17:30:17.171409: Pseudo dice [np.float32(0.849)] 
2025-06-04 17:30:17.705690: Epoch time: 143.29 s 
2025-06-04 17:30:21.850844:  
2025-06-04 17:30:21.984375: Epoch 869 
2025-06-04 17:30:22.001532: Current learning rate: 0.00161 
2025-06-04 17:32:44.548575: train_loss -0.7245 
2025-06-04 17:32:44.569467: val_loss -0.6588 
2025-06-04 17:32:44.584728: Pseudo dice [np.float32(0.7371)] 
2025-06-04 17:32:44.600622: Epoch time: 142.7 s 
2025-06-04 17:32:49.175918:  
2025-06-04 17:32:49.194396: Epoch 870 
2025-06-04 17:32:49.209193: Current learning rate: 0.00159 
2025-06-04 17:35:14.301269: train_loss -0.7327 
2025-06-04 17:35:14.843722: val_loss -0.7223 
2025-06-04 17:35:15.367130: Pseudo dice [np.float32(0.8398)] 
2025-06-04 17:35:15.546839: Epoch time: 145.13 s 
2025-06-04 17:35:21.830215:  
2025-06-04 17:35:21.853841: Epoch 871 
2025-06-04 17:35:21.874265: Current learning rate: 0.00158 
2025-06-04 17:37:42.349885: train_loss -0.7487 
2025-06-04 17:37:42.376017: val_loss -0.7316 
2025-06-04 17:37:42.393908: Pseudo dice [np.float32(0.8206)] 
2025-06-04 17:37:42.411265: Epoch time: 140.53 s 
2025-06-04 17:37:42.429298: Yayy! New best EMA pseudo Dice: 0.7872999906539917 
2025-06-04 17:37:50.188942:  
2025-06-04 17:37:50.448190: Epoch 872 
2025-06-04 17:37:50.466148: Current learning rate: 0.00157 
2025-06-04 17:40:12.080368: train_loss -0.7281 
2025-06-04 17:40:12.560156: val_loss -0.7291 
2025-06-04 17:40:12.921965: Pseudo dice [np.float32(0.8155)] 
2025-06-04 17:40:12.940574: Epoch time: 141.89 s 
2025-06-04 17:40:12.956783: Yayy! New best EMA pseudo Dice: 0.7901999950408936 
2025-06-04 17:40:20.983686:  
2025-06-04 17:40:21.016392: Epoch 873 
2025-06-04 17:40:21.049645: Current learning rate: 0.00156 
2025-06-04 17:42:43.334008: train_loss -0.7428 
2025-06-04 17:42:43.894896: val_loss -0.726 
2025-06-04 17:42:44.600367: Pseudo dice [np.float32(0.8209)] 
2025-06-04 17:42:45.163282: Epoch time: 142.35 s 
2025-06-04 17:42:45.734695: Yayy! New best EMA pseudo Dice: 0.7932000160217285 
2025-06-04 17:42:54.248673:  
2025-06-04 17:42:54.269938: Epoch 874 
2025-06-04 17:42:54.291220: Current learning rate: 0.00155 
2025-06-04 17:45:14.490566: train_loss -0.7187 
2025-06-04 17:45:15.167074: val_loss -0.7452 
2025-06-04 17:45:15.185517: Pseudo dice [np.float32(0.7987)] 
2025-06-04 17:45:15.207342: Epoch time: 140.24 s 
2025-06-04 17:45:15.237521: Yayy! New best EMA pseudo Dice: 0.7937999963760376 
2025-06-04 17:45:20.198362:  
2025-06-04 17:45:20.239617: Epoch 875 
2025-06-04 17:45:20.265727: Current learning rate: 0.00154 
2025-06-04 17:47:37.421528: train_loss -0.7417 
2025-06-04 17:47:37.851970: val_loss -0.6593 
2025-06-04 17:47:38.139453: Pseudo dice [np.float32(0.7389)] 
2025-06-04 17:47:38.679852: Epoch time: 137.22 s 
2025-06-04 17:47:43.102437:  
2025-06-04 17:47:43.422653: Epoch 876 
2025-06-04 17:47:43.523130: Current learning rate: 0.00153 
2025-06-04 17:50:03.412067: train_loss -0.7503 
2025-06-04 17:50:03.430978: val_loss -0.7049 
2025-06-04 17:50:03.447333: Pseudo dice [np.float32(0.7666)] 
2025-06-04 17:50:03.462839: Epoch time: 140.31 s 
2025-06-04 17:50:08.478638:  
2025-06-04 17:50:08.597659: Epoch 877 
2025-06-04 17:50:08.756671: Current learning rate: 0.00152 
2025-06-04 17:52:31.620650: train_loss -0.7281 
2025-06-04 17:52:31.805986: val_loss -0.6595 
2025-06-04 17:52:31.823016: Pseudo dice [np.float32(0.7105)] 
2025-06-04 17:52:31.839528: Epoch time: 143.14 s 
2025-06-04 17:52:35.916377:  
2025-06-04 17:52:36.090358: Epoch 878 
2025-06-04 17:52:36.223557: Current learning rate: 0.00151 
2025-06-04 17:54:55.513229: train_loss -0.7102 
2025-06-04 17:54:55.540956: val_loss -0.6672 
2025-06-04 17:54:55.559642: Pseudo dice [np.float32(0.78)] 
2025-06-04 17:54:55.575663: Epoch time: 139.6 s 
2025-06-04 17:55:01.230796:  
2025-06-04 17:55:01.442629: Epoch 879 
2025-06-04 17:55:01.929565: Current learning rate: 0.00149 
2025-06-04 17:57:22.690909: train_loss -0.7329 
2025-06-04 17:57:22.712254: val_loss -0.6969 
2025-06-04 17:57:22.728952: Pseudo dice [np.float32(0.8495)] 
2025-06-04 17:57:22.746214: Epoch time: 141.46 s 
2025-06-04 17:57:27.573493:  
2025-06-04 17:57:27.593739: Epoch 880 
2025-06-04 17:57:27.680944: Current learning rate: 0.00148 
2025-06-04 17:59:46.680722: train_loss -0.7175 
2025-06-04 17:59:47.143845: val_loss -0.6947 
2025-06-04 17:59:47.880080: Pseudo dice [np.float32(0.7901)] 
2025-06-04 17:59:48.304049: Epoch time: 139.11 s 
2025-06-04 17:59:53.682206:  
2025-06-04 17:59:53.991895: Epoch 881 
2025-06-04 17:59:54.424979: Current learning rate: 0.00147 
2025-06-04 18:02:15.280038: train_loss -0.7269 
2025-06-04 18:02:15.300465: val_loss -0.7011 
2025-06-04 18:02:15.317307: Pseudo dice [np.float32(0.7916)] 
2025-06-04 18:02:15.332247: Epoch time: 141.6 s 
2025-06-04 18:02:21.499609:  
2025-06-04 18:02:21.565284: Epoch 882 
2025-06-04 18:02:21.607785: Current learning rate: 0.00146 
2025-06-04 18:04:42.835222: train_loss -0.7238 
2025-06-04 18:04:43.322796: val_loss -0.6351 
2025-06-04 18:04:43.926472: Pseudo dice [np.float32(0.7609)] 
2025-06-04 18:04:44.421281: Epoch time: 141.34 s 
2025-06-04 18:04:50.472832:  
2025-06-04 18:04:50.767457: Epoch 883 
2025-06-04 18:04:51.155251: Current learning rate: 0.00145 
2025-06-04 18:07:13.285450: train_loss -0.72 
2025-06-04 18:07:13.307057: val_loss -0.6968 
2025-06-04 18:07:13.323166: Pseudo dice [np.float32(0.7333)] 
2025-06-04 18:07:13.658478: Epoch time: 142.81 s 
2025-06-04 18:07:20.979280:  
2025-06-04 18:07:21.096208: Epoch 884 
2025-06-04 18:07:21.126993: Current learning rate: 0.00144 
2025-06-04 18:09:43.759722: train_loss -0.7396 
2025-06-04 18:09:44.225721: val_loss -0.7349 
2025-06-04 18:09:44.647732: Pseudo dice [np.float32(0.7639)] 
2025-06-04 18:09:44.974506: Epoch time: 142.78 s 
2025-06-04 18:09:49.351296:  
2025-06-04 18:09:49.682331: Epoch 885 
2025-06-04 18:09:50.079908: Current learning rate: 0.00143 
2025-06-04 18:12:07.244074: train_loss -0.7291 
2025-06-04 18:12:07.650621: val_loss -0.6045 
2025-06-04 18:12:07.790680: Pseudo dice [np.float32(0.7892)] 
2025-06-04 18:12:08.181005: Epoch time: 137.89 s 
2025-06-04 18:12:11.658749:  
2025-06-04 18:12:11.732244: Epoch 886 
2025-06-04 18:12:11.852058: Current learning rate: 0.00142 
2025-06-04 18:14:28.680418: train_loss -0.7326 
2025-06-04 18:14:28.899835: val_loss -0.7156 
2025-06-04 18:14:29.131652: Pseudo dice [np.float32(0.7288)] 
2025-06-04 18:14:29.147851: Epoch time: 137.02 s 
2025-06-04 18:14:31.834761:  
2025-06-04 18:14:31.928492: Epoch 887 
2025-06-04 18:14:31.949134: Current learning rate: 0.00141 
2025-06-04 18:16:52.979931: train_loss -0.7394 
2025-06-04 18:16:53.238626: val_loss -0.6433 
2025-06-04 18:16:53.511998: Pseudo dice [np.float32(0.7583)] 
2025-06-04 18:16:53.702931: Epoch time: 141.15 s 
2025-06-04 18:16:56.888200:  
2025-06-04 18:16:56.906823: Epoch 888 
2025-06-04 18:16:56.927593: Current learning rate: 0.00139 
2025-06-04 18:19:17.298096: train_loss -0.7443 
2025-06-04 18:19:17.324080: val_loss -0.7147 
2025-06-04 18:19:17.338436: Pseudo dice [np.float32(0.8102)] 
2025-06-04 18:19:17.353814: Epoch time: 140.41 s 
2025-06-04 18:19:21.685824:  
2025-06-04 18:19:21.899662: Epoch 889 
2025-06-04 18:19:21.934117: Current learning rate: 0.00138 
2025-06-04 18:21:44.273001: train_loss -0.733 
2025-06-04 18:21:44.599550: val_loss -0.6837 
2025-06-04 18:21:45.094434: Pseudo dice [np.float32(0.7503)] 
2025-06-04 18:21:45.481107: Epoch time: 142.59 s 
2025-06-04 18:21:49.058324:  
2025-06-04 18:21:49.111463: Epoch 890 
2025-06-04 18:21:49.170622: Current learning rate: 0.00137 
2025-06-04 18:24:14.029772: train_loss -0.7366 
2025-06-04 18:24:14.047373: val_loss -0.7068 
2025-06-04 18:24:14.063590: Pseudo dice [np.float32(0.8308)] 
2025-06-04 18:24:14.079098: Epoch time: 144.97 s 
2025-06-04 18:24:18.345743:  
2025-06-04 18:24:18.365440: Epoch 891 
2025-06-04 18:24:18.380875: Current learning rate: 0.00136 
2025-06-04 18:26:40.924106: train_loss -0.7378 
2025-06-04 18:26:41.329209: val_loss -0.6901 
2025-06-04 18:26:41.812935: Pseudo dice [np.float32(0.7471)] 
2025-06-04 18:26:41.831204: Epoch time: 142.58 s 
2025-06-04 18:26:48.668329:  
2025-06-04 18:26:48.756386: Epoch 892 
2025-06-04 18:26:48.984493: Current learning rate: 0.00135 
2025-06-04 18:29:06.289091: train_loss -0.7072 
2025-06-04 18:29:06.840533: val_loss -0.7286 
2025-06-04 18:29:07.390241: Pseudo dice [np.float32(0.8426)] 
2025-06-04 18:29:07.569565: Epoch time: 137.62 s 
2025-06-04 18:29:13.638681:  
2025-06-04 18:29:13.731089: Epoch 893 
2025-06-04 18:29:13.747898: Current learning rate: 0.00134 
2025-06-04 18:31:39.481077: train_loss -0.7441 
2025-06-04 18:31:39.503292: val_loss -0.7207 
2025-06-04 18:31:39.519157: Pseudo dice [np.float32(0.7978)] 
2025-06-04 18:31:39.536572: Epoch time: 145.84 s 
2025-06-04 18:31:44.535150:  
2025-06-04 18:31:44.635619: Epoch 894 
2025-06-04 18:31:44.678144: Current learning rate: 0.00133 
2025-06-04 18:34:06.964053: train_loss -0.7554 
2025-06-04 18:34:07.439134: val_loss -0.6184 
2025-06-04 18:34:08.036294: Pseudo dice [np.float32(0.7408)] 
2025-06-04 18:34:08.697419: Epoch time: 142.43 s 
2025-06-04 18:34:14.438808:  
2025-06-04 18:34:14.513033: Epoch 895 
2025-06-04 18:34:14.607921: Current learning rate: 0.00132 
2025-06-04 18:36:31.057441: train_loss -0.7287 
2025-06-04 18:36:31.713245: val_loss -0.7288 
2025-06-04 18:36:32.138343: Pseudo dice [np.float32(0.8648)] 
2025-06-04 18:36:32.156411: Epoch time: 136.62 s 
2025-06-04 18:36:39.750520:  
2025-06-04 18:36:39.834008: Epoch 896 
2025-06-04 18:36:39.855853: Current learning rate: 0.0013 
2025-06-04 18:38:59.547532: train_loss -0.7393 
2025-06-04 18:38:59.571404: val_loss -0.664 
2025-06-04 18:38:59.593350: Pseudo dice [np.float32(0.7389)] 
2025-06-04 18:38:59.621742: Epoch time: 139.8 s 
2025-06-04 18:39:04.814481:  
2025-06-04 18:39:04.919619: Epoch 897 
2025-06-04 18:39:05.108299: Current learning rate: 0.00129 
2025-06-04 18:41:25.706378: train_loss -0.7274 
2025-06-04 18:41:26.317459: val_loss -0.7172 
2025-06-04 18:41:26.868532: Pseudo dice [np.float32(0.8173)] 
2025-06-04 18:41:27.342756: Epoch time: 140.89 s 
2025-06-04 18:41:31.800275:  
2025-06-04 18:41:31.828513: Epoch 898 
2025-06-04 18:41:31.855417: Current learning rate: 0.00128 
2025-06-04 18:43:50.545121: train_loss -0.7427 
2025-06-04 18:43:50.920558: val_loss -0.7425 
2025-06-04 18:43:51.460213: Pseudo dice [np.float32(0.8205)] 
2025-06-04 18:43:51.908491: Epoch time: 138.75 s 
2025-06-04 18:43:56.408233:  
2025-06-04 18:43:56.537187: Epoch 899 
2025-06-04 18:43:56.574368: Current learning rate: 0.00127 
2025-06-04 18:46:15.123820: train_loss -0.7546 
2025-06-04 18:46:15.281603: val_loss -0.672 
2025-06-04 18:46:16.041671: Pseudo dice [np.float32(0.7336)] 
2025-06-04 18:46:16.521905: Epoch time: 138.72 s 
2025-06-04 18:46:22.606669:  
2025-06-04 18:46:22.656011: Epoch 900 
2025-06-04 18:46:22.682887: Current learning rate: 0.00126 
2025-06-04 18:48:40.852679: train_loss -0.7469 
2025-06-04 18:48:41.292077: val_loss -0.7472 
2025-06-04 18:48:41.650959: Pseudo dice [np.float32(0.7762)] 
2025-06-04 18:48:41.833231: Epoch time: 138.25 s 
2025-06-04 18:48:46.517878:  
2025-06-04 18:48:46.540500: Epoch 901 
2025-06-04 18:48:46.581625: Current learning rate: 0.00125 
2025-06-04 18:51:05.692808: train_loss -0.7307 
2025-06-04 18:51:06.429577: val_loss -0.6493 
2025-06-04 18:51:06.448535: Pseudo dice [np.float32(0.7606)] 
2025-06-04 18:51:06.465592: Epoch time: 139.18 s 
2025-06-04 18:51:13.186127:  
2025-06-04 18:51:13.412267: Epoch 902 
2025-06-04 18:51:13.879453: Current learning rate: 0.00124 
2025-06-04 18:53:34.939796: train_loss -0.7188 
2025-06-04 18:53:35.258656: val_loss -0.6766 
2025-06-04 18:53:35.619754: Pseudo dice [np.float32(0.7865)] 
2025-06-04 18:53:35.640076: Epoch time: 141.76 s 
2025-06-04 18:53:41.633032:  
2025-06-04 18:53:41.749464: Epoch 903 
2025-06-04 18:53:41.847775: Current learning rate: 0.00122 
2025-06-04 18:56:04.096153: train_loss -0.7427 
2025-06-04 18:56:04.444397: val_loss -0.6576 
2025-06-04 18:56:04.618768: Pseudo dice [np.float32(0.7901)] 
2025-06-04 18:56:04.635013: Epoch time: 142.47 s 
2025-06-04 18:56:10.393962:  
2025-06-04 18:56:10.638988: Epoch 904 
2025-06-04 18:56:10.772845: Current learning rate: 0.00121 
2025-06-04 18:58:31.367637: train_loss -0.7568 
2025-06-04 18:58:31.856548: val_loss -0.6829 
2025-06-04 18:58:32.008863: Pseudo dice [np.float32(0.7689)] 
2025-06-04 18:58:32.399072: Epoch time: 140.98 s 
2025-06-04 18:58:36.812763:  
2025-06-04 18:58:36.921758: Epoch 905 
2025-06-04 18:58:36.941090: Current learning rate: 0.0012 
2025-06-04 19:00:58.570231: train_loss -0.7354 
2025-06-04 19:00:59.117009: val_loss -0.6539 
2025-06-04 19:00:59.543685: Pseudo dice [np.float32(0.8184)] 
2025-06-04 19:00:59.562199: Epoch time: 141.76 s 
2025-06-04 19:01:05.110827:  
2025-06-04 19:01:05.666334: Epoch 906 
2025-06-04 19:01:05.732403: Current learning rate: 0.00119 
2025-06-04 19:03:30.561010: train_loss -0.7423 
2025-06-04 19:03:31.023677: val_loss -0.6894 
2025-06-04 19:03:31.538127: Pseudo dice [np.float32(0.7831)] 
2025-06-04 19:03:31.557152: Epoch time: 145.45 s 
2025-06-04 19:03:37.000675:  
2025-06-04 19:03:37.299005: Epoch 907 
2025-06-04 19:03:37.343494: Current learning rate: 0.00118 
2025-06-04 19:05:52.915061: train_loss -0.7637 
2025-06-04 19:05:53.305456: val_loss -0.7752 
2025-06-04 19:05:53.666527: Pseudo dice [np.float32(0.8056)] 
2025-06-04 19:05:54.056149: Epoch time: 135.92 s 
2025-06-04 19:06:00.355451:  
2025-06-04 19:06:00.377516: Epoch 908 
2025-06-04 19:06:00.483201: Current learning rate: 0.00117 
2025-06-04 19:08:19.043358: train_loss -0.7398 
2025-06-04 19:08:19.063126: val_loss -0.6238 
2025-06-04 19:08:19.079661: Pseudo dice [np.float32(0.6873)] 
2025-06-04 19:08:19.095120: Epoch time: 138.69 s 
2025-06-04 19:08:21.504160:  
2025-06-04 19:08:21.544613: Epoch 909 
2025-06-04 19:08:21.565997: Current learning rate: 0.00116 
2025-06-04 19:10:45.843408: train_loss -0.7119 
2025-06-04 19:10:46.141999: val_loss -0.6539 
2025-06-04 19:10:46.484880: Pseudo dice [np.float32(0.765)] 
2025-06-04 19:10:46.737082: Epoch time: 144.34 s 
2025-06-04 19:10:49.808786:  
2025-06-04 19:10:49.845611: Epoch 910 
2025-06-04 19:10:49.968010: Current learning rate: 0.00115 
2025-06-04 19:13:05.050060: train_loss -0.742 
2025-06-04 19:13:05.069845: val_loss -0.7122 
2025-06-04 19:13:05.085276: Pseudo dice [np.float32(0.7997)] 
2025-06-04 19:13:05.100789: Epoch time: 135.24 s 
2025-06-04 19:13:09.106594:  
2025-06-04 19:13:09.195437: Epoch 911 
2025-06-04 19:13:09.269948: Current learning rate: 0.00113 
2025-06-04 19:15:24.707124: train_loss -0.7351 
2025-06-04 19:15:24.726810: val_loss -0.6659 
2025-06-04 19:15:24.741212: Pseudo dice [np.float32(0.8074)] 
2025-06-04 19:15:24.756824: Epoch time: 135.6 s 
2025-06-04 19:15:28.005418:  
2025-06-04 19:15:28.253947: Epoch 912 
2025-06-04 19:15:28.372072: Current learning rate: 0.00112 
2025-06-04 19:17:43.089826: train_loss -0.7341 
2025-06-04 19:17:43.333710: val_loss -0.7174 
2025-06-04 19:17:43.795672: Pseudo dice [np.float32(0.8676)] 
2025-06-04 19:17:44.043965: Epoch time: 135.09 s 
2025-06-04 19:17:48.373899:  
2025-06-04 19:17:48.515326: Epoch 913 
2025-06-04 19:17:48.551239: Current learning rate: 0.00111 
2025-06-04 19:20:06.094239: train_loss -0.7223 
2025-06-04 19:20:06.113725: val_loss -0.6996 
2025-06-04 19:20:06.129742: Pseudo dice [np.float32(0.7614)] 
2025-06-04 19:20:06.143902: Epoch time: 137.72 s 
2025-06-04 19:20:09.181898:  
2025-06-04 19:20:09.201491: Epoch 914 
2025-06-04 19:20:09.261250: Current learning rate: 0.0011 
2025-06-04 19:22:19.515093: train_loss -0.7423 
2025-06-04 19:22:19.922936: val_loss -0.7058 
2025-06-04 19:22:20.834086: Pseudo dice [np.float32(0.7983)] 
2025-06-04 19:22:21.460168: Epoch time: 130.34 s 
2025-06-04 19:22:27.146828:  
2025-06-04 19:22:27.292499: Epoch 915 
2025-06-04 19:22:27.486389: Current learning rate: 0.00109 
2025-06-04 19:24:41.826881: train_loss -0.7555 
2025-06-04 19:24:42.335801: val_loss -0.6644 
2025-06-04 19:24:42.873218: Pseudo dice [np.float32(0.7951)] 
2025-06-04 19:24:43.312196: Epoch time: 134.68 s 
2025-06-04 19:24:47.876497:  
2025-06-04 19:24:47.990887: Epoch 916 
2025-06-04 19:24:48.133504: Current learning rate: 0.00108 
2025-06-04 19:27:03.380844: train_loss -0.7372 
2025-06-04 19:27:03.779052: val_loss -0.7132 
2025-06-04 19:27:04.127421: Pseudo dice [np.float32(0.8545)] 
2025-06-04 19:27:04.448822: Epoch time: 135.51 s 
2025-06-04 19:27:04.780546: Yayy! New best EMA pseudo Dice: 0.7953000068664551 
2025-06-04 19:27:08.574435:  
2025-06-04 19:27:08.671092: Epoch 917 
2025-06-04 19:27:08.711673: Current learning rate: 0.00106 
2025-06-04 19:29:26.508819: train_loss -0.7486 
2025-06-04 19:29:26.714161: val_loss -0.7305 
2025-06-04 19:29:26.733223: Pseudo dice [np.float32(0.7322)] 
2025-06-04 19:29:26.749825: Epoch time: 137.94 s 
2025-06-04 19:29:31.202082:  
2025-06-04 19:29:31.406296: Epoch 918 
2025-06-04 19:29:31.554693: Current learning rate: 0.00105 
2025-06-04 19:31:44.896987: train_loss -0.754 
2025-06-04 19:31:45.244770: val_loss -0.703 
2025-06-04 19:31:45.598370: Pseudo dice [np.float32(0.7325)] 
2025-06-04 19:31:45.630376: Epoch time: 133.7 s 
2025-06-04 19:31:49.522690:  
2025-06-04 19:31:49.541501: Epoch 919 
2025-06-04 19:31:49.560332: Current learning rate: 0.00104 
2025-06-04 19:34:03.382718: train_loss -0.7442 
2025-06-04 19:34:03.757993: val_loss -0.7038 
2025-06-04 19:34:04.345849: Pseudo dice [np.float32(0.79)] 
2025-06-04 19:34:04.920476: Epoch time: 133.86 s 
2025-06-04 19:34:10.163271:  
2025-06-04 19:34:10.248179: Epoch 920 
2025-06-04 19:34:10.352587: Current learning rate: 0.00103 
2025-06-04 19:36:22.713859: train_loss -0.7417 
2025-06-04 19:36:22.738136: val_loss -0.7074 
2025-06-04 19:36:23.263273: Pseudo dice [np.float32(0.8445)] 
2025-06-04 19:36:23.867148: Epoch time: 132.55 s 
2025-06-04 19:36:30.349122:  
2025-06-04 19:36:30.370612: Epoch 921 
2025-06-04 19:36:30.391437: Current learning rate: 0.00102 
2025-06-04 19:38:46.050502: train_loss -0.7395 
2025-06-04 19:38:46.072032: val_loss -0.6392 
2025-06-04 19:38:46.087631: Pseudo dice [np.float32(0.6885)] 
2025-06-04 19:38:46.103661: Epoch time: 135.7 s 
2025-06-04 19:38:51.864911:  
2025-06-04 19:38:52.003601: Epoch 922 
2025-06-04 19:38:52.252497: Current learning rate: 0.00101 
2025-06-04 19:41:08.689398: train_loss -0.7468 
2025-06-04 19:41:08.710836: val_loss -0.7027 
2025-06-04 19:41:08.727453: Pseudo dice [np.float32(0.8054)] 
2025-06-04 19:41:08.742586: Epoch time: 136.83 s 
2025-06-04 19:41:14.871725:  
2025-06-04 19:41:15.078282: Epoch 923 
2025-06-04 19:41:15.134245: Current learning rate: 0.001 
2025-06-04 19:43:26.808420: train_loss -0.7479 
2025-06-04 19:43:27.274443: val_loss -0.6858 
2025-06-04 19:43:27.891985: Pseudo dice [np.float32(0.7629)] 
2025-06-04 19:43:28.226192: Epoch time: 131.94 s 
2025-06-04 19:43:34.720689:  
2025-06-04 19:43:34.907978: Epoch 924 
2025-06-04 19:43:35.023629: Current learning rate: 0.00098 
2025-06-04 19:45:47.945054: train_loss -0.7518 
2025-06-04 19:45:48.287750: val_loss -0.6739 
2025-06-04 19:45:48.964411: Pseudo dice [np.float32(0.8246)] 
2025-06-04 19:45:49.285405: Epoch time: 133.23 s 
2025-06-04 19:45:53.241413:  
2025-06-04 19:45:53.279403: Epoch 925 
2025-06-04 19:45:53.324556: Current learning rate: 0.00097 
2025-06-04 19:48:04.651830: train_loss -0.7255 
2025-06-04 19:48:04.844619: val_loss -0.6461 
2025-06-04 19:48:04.862011: Pseudo dice [np.float32(0.7244)] 
2025-06-04 19:48:04.877428: Epoch time: 131.41 s 
2025-06-04 19:48:09.107828:  
2025-06-04 19:48:09.131953: Epoch 926 
2025-06-04 19:48:09.164845: Current learning rate: 0.00096 
2025-06-04 19:50:26.115513: train_loss -0.7532 
2025-06-04 19:50:26.686095: val_loss -0.7073 
2025-06-04 19:50:27.083180: Pseudo dice [np.float32(0.8396)] 
2025-06-04 19:50:27.102891: Epoch time: 137.01 s 
2025-06-04 19:50:31.680686:  
2025-06-04 19:50:31.859540: Epoch 927 
2025-06-04 19:50:31.879119: Current learning rate: 0.00095 
2025-06-04 19:52:46.389968: train_loss -0.7582 
2025-06-04 19:52:46.411600: val_loss -0.6922 
2025-06-04 19:52:46.426843: Pseudo dice [np.float32(0.7698)] 
2025-06-04 19:52:46.441055: Epoch time: 134.71 s 
2025-06-04 19:52:51.782448:  
2025-06-04 19:52:51.798728: Epoch 928 
2025-06-04 19:52:51.813208: Current learning rate: 0.00094 
2025-06-04 19:55:07.817779: train_loss -0.7365 
2025-06-04 19:55:07.837137: val_loss -0.6818 
2025-06-04 19:55:07.850789: Pseudo dice [np.float32(0.7337)] 
2025-06-04 19:55:07.866996: Epoch time: 136.04 s 
2025-06-04 19:55:16.903209:  
2025-06-04 19:55:17.466006: Epoch 929 
2025-06-04 19:55:17.567190: Current learning rate: 0.00092 
2025-06-04 19:57:34.894927: train_loss -0.7421 
2025-06-04 19:57:34.914789: val_loss -0.6481 
2025-06-04 19:57:34.929435: Pseudo dice [np.float32(0.7674)] 
2025-06-04 19:57:34.944488: Epoch time: 138.0 s 
2025-06-04 19:57:42.477422:  
2025-06-04 19:57:42.799733: Epoch 930 
2025-06-04 19:57:42.922648: Current learning rate: 0.00091 
2025-06-04 20:00:01.599618: train_loss -0.7353 
2025-06-04 20:00:02.024282: val_loss -0.7201 
2025-06-04 20:00:02.536188: Pseudo dice [np.float32(0.7976)] 
2025-06-04 20:00:03.192817: Epoch time: 139.13 s 
2025-06-04 20:00:07.048713:  
2025-06-04 20:00:07.097628: Epoch 931 
2025-06-04 20:00:07.154001: Current learning rate: 0.0009 
2025-06-04 20:02:31.371769: train_loss -0.7373 
2025-06-04 20:02:31.389362: val_loss -0.7124 
2025-06-04 20:02:31.404798: Pseudo dice [np.float32(0.8319)] 
2025-06-04 20:02:31.421653: Epoch time: 144.33 s 
2025-06-04 20:02:37.498969:  
2025-06-04 20:02:37.759911: Epoch 932 
2025-06-04 20:02:38.057561: Current learning rate: 0.00089 
2025-06-04 20:04:53.285385: train_loss -0.7526 
2025-06-04 20:04:53.526148: val_loss -0.6905 
2025-06-04 20:04:53.776371: Pseudo dice [np.float32(0.8148)] 
2025-06-04 20:04:54.128246: Epoch time: 135.79 s 
2025-06-04 20:04:57.251102:  
2025-06-04 20:04:57.416256: Epoch 933 
2025-06-04 20:04:57.639761: Current learning rate: 0.00088 
2025-06-04 20:07:13.138464: train_loss -0.7684 
2025-06-04 20:07:13.156540: val_loss -0.7445 
2025-06-04 20:07:13.170154: Pseudo dice [np.float32(0.8077)] 
2025-06-04 20:07:13.182680: Epoch time: 135.89 s 
2025-06-04 20:07:15.730107:  
2025-06-04 20:07:15.858232: Epoch 934 
2025-06-04 20:07:16.056575: Current learning rate: 0.00087 
2025-06-04 20:09:31.150809: train_loss -0.737 
2025-06-04 20:09:31.492951: val_loss -0.6866 
2025-06-04 20:09:31.736129: Pseudo dice [np.float32(0.7867)] 
2025-06-04 20:09:31.753564: Epoch time: 135.42 s 
2025-06-04 20:09:35.194211:  
2025-06-04 20:09:35.209702: Epoch 935 
2025-06-04 20:09:35.219943: Current learning rate: 0.00085 
2025-06-04 20:11:51.367366: train_loss -0.7279 
2025-06-04 20:11:51.726445: val_loss -0.6734 
2025-06-04 20:11:52.064302: Pseudo dice [np.float32(0.7063)] 
2025-06-04 20:11:52.389717: Epoch time: 136.17 s 
2025-06-04 20:11:57.201364:  
2025-06-04 20:11:57.214975: Epoch 936 
2025-06-04 20:11:57.231342: Current learning rate: 0.00084 
2025-06-04 20:14:19.630676: train_loss -0.7252 
2025-06-04 20:14:19.884145: val_loss -0.7264 
2025-06-04 20:14:20.272033: Pseudo dice [np.float32(0.8224)] 
2025-06-04 20:14:20.474122: Epoch time: 142.43 s 
2025-06-04 20:14:23.065078:  
2025-06-04 20:14:23.084095: Epoch 937 
2025-06-04 20:14:23.099825: Current learning rate: 0.00083 
2025-06-04 20:16:40.229103: train_loss -0.7578 
2025-06-04 20:16:40.460321: val_loss -0.7411 
2025-06-04 20:16:40.777456: Pseudo dice [np.float32(0.7899)] 
2025-06-04 20:16:41.019266: Epoch time: 137.17 s 
2025-06-04 20:16:44.094784:  
2025-06-04 20:16:44.204506: Epoch 938 
2025-06-04 20:16:44.298203: Current learning rate: 0.00082 
2025-06-04 20:19:04.062438: train_loss -0.7371 
2025-06-04 20:19:04.085903: val_loss -0.7247 
2025-06-04 20:19:04.099699: Pseudo dice [np.float32(0.7692)] 
2025-06-04 20:19:04.113961: Epoch time: 139.97 s 
2025-06-04 20:19:09.628034:  
2025-06-04 20:19:09.648163: Epoch 939 
2025-06-04 20:19:09.693886: Current learning rate: 0.00081 
2025-06-04 20:21:12.032903: train_loss -0.7687 
2025-06-04 20:21:12.386049: val_loss -0.6422 
2025-06-04 20:21:12.404495: Pseudo dice [np.float32(0.7506)] 
2025-06-04 20:21:12.417915: Epoch time: 122.41 s 
2025-06-04 20:21:18.738109:  
2025-06-04 20:21:18.922395: Epoch 940 
2025-06-04 20:21:19.096331: Current learning rate: 0.00079 
2025-06-04 20:23:03.233751: train_loss -0.7318 
2025-06-04 20:23:03.653208: val_loss -0.742 
2025-06-04 20:23:04.098170: Pseudo dice [np.float32(0.8164)] 
2025-06-04 20:23:04.470027: Epoch time: 104.5 s 
2025-06-04 20:23:09.803282:  
2025-06-04 20:23:09.869962: Epoch 941 
2025-06-04 20:23:10.026266: Current learning rate: 0.00078 
2025-06-04 20:25:27.172585: train_loss -0.7432 
2025-06-04 20:25:27.860371: val_loss -0.7225 
2025-06-04 20:25:27.882876: Pseudo dice [np.float32(0.7863)] 
2025-06-04 20:25:27.897444: Epoch time: 137.37 s 
2025-06-04 20:25:32.822089:  
2025-06-04 20:25:32.840563: Epoch 942 
2025-06-04 20:25:32.854287: Current learning rate: 0.00077 
2025-06-04 20:27:50.807867: train_loss -0.7461 
2025-06-04 20:27:50.827575: val_loss -0.6617 
2025-06-04 20:27:50.841455: Pseudo dice [np.float32(0.7675)] 
2025-06-04 20:27:50.853343: Epoch time: 137.99 s 
2025-06-04 20:27:57.000542:  
2025-06-04 20:27:57.016888: Epoch 943 
2025-06-04 20:27:57.035161: Current learning rate: 0.00076 
2025-06-04 20:30:03.500407: train_loss -0.7405 
2025-06-04 20:30:03.526434: val_loss -0.7216 
2025-06-04 20:30:03.547161: Pseudo dice [np.float32(0.7783)] 
2025-06-04 20:30:03.574906: Epoch time: 126.5 s 
2025-06-04 20:30:09.102274:  
2025-06-04 20:30:09.140437: Epoch 944 
2025-06-04 20:30:09.176955: Current learning rate: 0.00075 
2025-06-04 20:32:20.191658: train_loss -0.7463 
2025-06-04 20:32:20.212769: val_loss -0.7238 
2025-06-04 20:32:20.226043: Pseudo dice [np.float32(0.7708)] 
2025-06-04 20:32:20.240215: Epoch time: 131.09 s 
2025-06-04 20:32:24.838705:  
2025-06-04 20:32:24.935314: Epoch 945 
2025-06-04 20:32:25.052465: Current learning rate: 0.00074 
2025-06-04 20:34:42.666865: train_loss -0.7221 
2025-06-04 20:34:43.027378: val_loss -0.6926 
2025-06-04 20:34:43.584594: Pseudo dice [np.float32(0.8489)] 
2025-06-04 20:34:43.920589: Epoch time: 137.83 s 
2025-06-04 20:34:48.108134:  
2025-06-04 20:34:48.254317: Epoch 946 
2025-06-04 20:34:48.461720: Current learning rate: 0.00072 
2025-06-04 20:37:00.962811: train_loss -0.7605 
2025-06-04 20:37:00.982947: val_loss -0.7374 
2025-06-04 20:37:00.996478: Pseudo dice [np.float32(0.7251)] 
2025-06-04 20:37:01.009514: Epoch time: 132.86 s 
2025-06-04 20:37:05.557756:  
2025-06-04 20:37:05.660636: Epoch 947 
2025-06-04 20:37:05.917553: Current learning rate: 0.00071 
2025-06-04 20:39:21.294630: train_loss -0.7618 
2025-06-04 20:39:21.326477: val_loss -0.7296 
2025-06-04 20:39:21.346210: Pseudo dice [np.float32(0.8491)] 
2025-06-04 20:39:21.363624: Epoch time: 135.74 s 
2025-06-04 20:39:25.046917:  
2025-06-04 20:39:25.138655: Epoch 948 
2025-06-04 20:39:25.186581: Current learning rate: 0.0007 
2025-06-04 20:41:39.438262: train_loss -0.7553 
2025-06-04 20:41:39.463448: val_loss -0.6942 
2025-06-04 20:41:39.476970: Pseudo dice [np.float32(0.7717)] 
2025-06-04 20:41:39.490952: Epoch time: 134.39 s 
2025-06-04 20:41:44.944421:  
2025-06-04 20:41:45.059698: Epoch 949 
2025-06-04 20:41:45.280988: Current learning rate: 0.00069 
2025-06-04 20:44:01.652176: train_loss -0.7486 
2025-06-04 20:44:02.264840: val_loss -0.6627 
2025-06-04 20:44:02.798812: Pseudo dice [np.float32(0.7081)] 
2025-06-04 20:44:03.479081: Epoch time: 136.71 s 
2025-06-04 20:44:09.156923:  
2025-06-04 20:44:09.178144: Epoch 950 
2025-06-04 20:44:09.212137: Current learning rate: 0.00067 
2025-06-04 20:46:27.129272: train_loss -0.761 
2025-06-04 20:46:27.666937: val_loss -0.7027 
2025-06-04 20:46:27.958710: Pseudo dice [np.float32(0.7592)] 
2025-06-04 20:46:27.976218: Epoch time: 137.98 s 
2025-06-04 20:46:32.069684:  
2025-06-04 20:46:32.367237: Epoch 951 
2025-06-04 20:46:32.448974: Current learning rate: 0.00066 
2025-06-04 20:48:47.835877: train_loss -0.7488 
2025-06-04 20:48:47.856188: val_loss -0.7192 
2025-06-04 20:48:47.872563: Pseudo dice [np.float32(0.8507)] 
2025-06-04 20:48:47.888822: Epoch time: 135.77 s 
2025-06-04 20:48:53.127513:  
2025-06-04 20:48:53.237563: Epoch 952 
2025-06-04 20:48:53.281050: Current learning rate: 0.00065 
2025-06-04 20:51:08.471622: train_loss -0.768 
2025-06-04 20:51:09.030385: val_loss -0.7058 
2025-06-04 20:51:09.728609: Pseudo dice [np.float32(0.8082)] 
2025-06-04 20:51:09.746856: Epoch time: 135.35 s 
2025-06-04 20:51:15.631120:  
2025-06-04 20:51:15.658294: Epoch 953 
2025-06-04 20:51:15.675209: Current learning rate: 0.00064 
2025-06-04 20:53:28.559247: train_loss -0.7532 
2025-06-04 20:53:28.579042: val_loss -0.6395 
2025-06-04 20:53:28.592412: Pseudo dice [np.float32(0.7114)] 
2025-06-04 20:53:28.605368: Epoch time: 132.93 s 
2025-06-04 20:53:31.595984:  
2025-06-04 20:53:31.612454: Epoch 954 
2025-06-04 20:53:31.625720: Current learning rate: 0.00063 
2025-06-04 20:55:45.189037: train_loss -0.7608 
2025-06-04 20:55:45.458447: val_loss -0.705 
2025-06-04 20:55:45.476730: Pseudo dice [np.float32(0.7767)] 
2025-06-04 20:55:45.934683: Epoch time: 133.59 s 
2025-06-04 20:55:50.004081:  
2025-06-04 20:55:50.022325: Epoch 955 
2025-06-04 20:55:50.036420: Current learning rate: 0.00061 
2025-06-04 20:58:05.877127: train_loss -0.7509 
2025-06-04 20:58:06.163855: val_loss -0.6761 
2025-06-04 20:58:06.430120: Pseudo dice [np.float32(0.758)] 
2025-06-04 20:58:06.446146: Epoch time: 135.87 s 
2025-06-04 20:58:10.461133:  
2025-06-04 20:58:10.604403: Epoch 956 
2025-06-04 20:58:10.621604: Current learning rate: 0.0006 
2025-06-04 21:00:29.001048: train_loss -0.7459 
2025-06-04 21:00:29.020948: val_loss -0.6984 
2025-06-04 21:00:29.035008: Pseudo dice [np.float32(0.8308)] 
2025-06-04 21:00:29.049989: Epoch time: 138.54 s 
2025-06-04 21:00:34.328817:  
2025-06-04 21:00:34.361183: Epoch 957 
2025-06-04 21:00:34.409703: Current learning rate: 0.00059 
2025-06-04 21:02:49.428901: train_loss -0.7522 
2025-06-04 21:02:49.454556: val_loss -0.6963 
2025-06-04 21:02:49.472907: Pseudo dice [np.float32(0.8191)] 
2025-06-04 21:02:49.486557: Epoch time: 135.1 s 
2025-06-04 21:02:56.518484:  
2025-06-04 21:02:56.580900: Epoch 958 
2025-06-04 21:02:56.737042: Current learning rate: 0.00058 
2025-06-04 21:05:15.935513: train_loss -0.7558 
2025-06-04 21:05:16.488698: val_loss -0.7093 
2025-06-04 21:05:17.016001: Pseudo dice [np.float32(0.8129)] 
2025-06-04 21:05:17.616643: Epoch time: 139.42 s 
2025-06-04 21:05:23.179827:  
2025-06-04 21:05:23.292022: Epoch 959 
2025-06-04 21:05:23.336944: Current learning rate: 0.00056 
2025-06-04 21:07:38.845303: train_loss -0.7544 
2025-06-04 21:07:38.863249: val_loss -0.7135 
2025-06-04 21:07:38.878811: Pseudo dice [np.float32(0.8158)] 
2025-06-04 21:07:38.894481: Epoch time: 135.67 s 
2025-06-04 21:07:43.634734:  
2025-06-04 21:07:43.939394: Epoch 960 
2025-06-04 21:07:44.151469: Current learning rate: 0.00055 
2025-06-04 21:09:56.908135: train_loss -0.7472 
2025-06-04 21:09:57.090491: val_loss -0.6805 
2025-06-04 21:09:57.107847: Pseudo dice [np.float32(0.759)] 
2025-06-04 21:09:57.121194: Epoch time: 133.28 s 
2025-06-04 21:10:04.706435:  
2025-06-04 21:10:04.795868: Epoch 961 
2025-06-04 21:10:04.920845: Current learning rate: 0.00054 
2025-06-04 21:12:23.597111: train_loss -0.7619 
2025-06-04 21:12:24.501626: val_loss -0.6746 
2025-06-04 21:12:25.141696: Pseudo dice [np.float32(0.7367)] 
2025-06-04 21:12:25.590039: Epoch time: 138.89 s 
2025-06-04 21:12:29.024623:  
2025-06-04 21:12:29.117729: Epoch 962 
2025-06-04 21:12:29.133322: Current learning rate: 0.00053 
2025-06-04 21:14:43.032428: train_loss -0.777 
2025-06-04 21:14:43.361102: val_loss -0.6577 
2025-06-04 21:14:43.624114: Pseudo dice [np.float32(0.7527)] 
2025-06-04 21:14:43.638623: Epoch time: 134.01 s 
2025-06-04 21:14:48.371368:  
2025-06-04 21:14:48.392620: Epoch 963 
2025-06-04 21:14:48.413888: Current learning rate: 0.00051 
2025-06-04 21:17:01.990976: train_loss -0.7362 
2025-06-04 21:17:02.630970: val_loss -0.6941 
2025-06-04 21:17:03.117753: Pseudo dice [np.float32(0.8321)] 
2025-06-04 21:17:03.779383: Epoch time: 133.62 s 
2025-06-04 21:17:08.131283:  
2025-06-04 21:17:08.321167: Epoch 964 
2025-06-04 21:17:08.466260: Current learning rate: 0.0005 
2025-06-04 21:19:22.382427: train_loss -0.7531 
2025-06-04 21:19:22.898180: val_loss -0.7305 
2025-06-04 21:19:23.090584: Pseudo dice [np.float32(0.8504)] 
2025-06-04 21:19:23.104256: Epoch time: 134.25 s 
2025-06-04 21:19:27.349701:  
2025-06-04 21:19:27.462150: Epoch 965 
2025-06-04 21:19:27.507840: Current learning rate: 0.00049 
2025-06-04 21:21:45.433412: train_loss -0.7604 
2025-06-04 21:21:45.450657: val_loss -0.6568 
2025-06-04 21:21:45.465547: Pseudo dice [np.float32(0.8026)] 
2025-06-04 21:21:45.478478: Epoch time: 138.09 s 
2025-06-04 21:21:49.676967:  
2025-06-04 21:21:49.829527: Epoch 966 
2025-06-04 21:21:50.085376: Current learning rate: 0.00048 
2025-06-04 21:24:10.223440: train_loss -0.7727 
2025-06-04 21:24:10.701377: val_loss -0.6943 
2025-06-04 21:24:11.240733: Pseudo dice [np.float32(0.8333)] 
2025-06-04 21:24:11.755396: Epoch time: 140.55 s 
2025-06-04 21:24:12.064276: Yayy! New best EMA pseudo Dice: 0.7968000173568726 
2025-06-04 21:24:17.947807:  
2025-06-04 21:24:17.966521: Epoch 967 
2025-06-04 21:24:17.981051: Current learning rate: 0.00046 
2025-06-04 21:26:35.070549: train_loss -0.7723 
2025-06-04 21:26:35.257141: val_loss -0.6414 
2025-06-04 21:26:35.493566: Pseudo dice [np.float32(0.7316)] 
2025-06-04 21:26:35.510537: Epoch time: 137.21 s 
2025-06-04 21:26:38.762985:  
2025-06-04 21:26:38.944002: Epoch 968 
2025-06-04 21:26:38.971409: Current learning rate: 0.00045 
2025-06-04 21:28:53.375725: train_loss -0.7312 
2025-06-04 21:28:53.722787: val_loss -0.7112 
2025-06-04 21:28:54.177549: Pseudo dice [np.float32(0.8451)] 
2025-06-04 21:28:54.559719: Epoch time: 134.62 s 
2025-06-04 21:28:58.014692:  
2025-06-04 21:28:58.273104: Epoch 969 
2025-06-04 21:28:58.454797: Current learning rate: 0.00044 
2025-06-04 21:31:09.034576: train_loss -0.7554 
2025-06-04 21:31:09.174634: val_loss -0.6561 
2025-06-04 21:31:09.193786: Pseudo dice [np.float32(0.7743)] 
2025-06-04 21:31:09.207772: Epoch time: 131.02 s 
2025-06-04 21:31:12.399025:  
2025-06-04 21:31:12.418039: Epoch 970 
2025-06-04 21:31:12.433487: Current learning rate: 0.00043 
2025-06-04 21:33:26.504238: train_loss -0.7625 
2025-06-04 21:33:26.523658: val_loss -0.6857 
2025-06-04 21:33:26.537036: Pseudo dice [np.float32(0.7779)] 
2025-06-04 21:33:26.549960: Epoch time: 134.11 s 
2025-06-04 21:33:30.056441:  
2025-06-04 21:33:30.077106: Epoch 971 
2025-06-04 21:33:30.093896: Current learning rate: 0.00041 
2025-06-04 21:35:43.892350: train_loss -0.7588 
2025-06-04 21:35:43.911837: val_loss -0.6688 
2025-06-04 21:35:43.925141: Pseudo dice [np.float32(0.762)] 
2025-06-04 21:35:43.938144: Epoch time: 133.84 s 
2025-06-04 21:35:48.010134:  
2025-06-04 21:35:48.117790: Epoch 972 
2025-06-04 21:35:48.175488: Current learning rate: 0.0004 
2025-06-04 21:38:03.665601: train_loss -0.7508 
2025-06-04 21:38:04.129818: val_loss -0.6964 
2025-06-04 21:38:04.456113: Pseudo dice [np.float32(0.8174)] 
2025-06-04 21:38:04.711272: Epoch time: 135.66 s 
2025-06-04 21:38:09.209110:  
2025-06-04 21:38:09.347654: Epoch 973 
2025-06-04 21:38:09.431631: Current learning rate: 0.00039 
2025-06-04 21:40:24.323821: train_loss -0.7525 
2025-06-04 21:40:24.601466: val_loss -0.7049 
2025-06-04 21:40:24.901701: Pseudo dice [np.float32(0.666)] 
2025-06-04 21:40:24.917436: Epoch time: 135.12 s 
2025-06-04 21:40:29.896275:  
2025-06-04 21:40:30.031467: Epoch 974 
2025-06-04 21:40:30.211657: Current learning rate: 0.00037 
2025-06-04 21:42:47.443859: train_loss -0.7541 
2025-06-04 21:42:47.463268: val_loss -0.6792 
2025-06-04 21:42:47.479156: Pseudo dice [np.float32(0.7865)] 
2025-06-04 21:42:47.492813: Epoch time: 137.55 s 
2025-06-04 21:42:51.505614:  
2025-06-04 21:42:51.524031: Epoch 975 
2025-06-04 21:42:51.537756: Current learning rate: 0.00036 
2025-06-04 21:45:08.153165: train_loss -0.7509 
2025-06-04 21:45:08.468360: val_loss -0.7474 
2025-06-04 21:45:08.870002: Pseudo dice [np.float32(0.8781)] 
2025-06-04 21:45:09.300855: Epoch time: 136.65 s 
2025-06-04 21:45:13.169390:  
2025-06-04 21:45:13.222026: Epoch 976 
2025-06-04 21:45:13.323529: Current learning rate: 0.00035 
2025-06-04 21:47:26.612133: train_loss -0.7768 
2025-06-04 21:47:26.940908: val_loss -0.6362 
2025-06-04 21:47:27.211081: Pseudo dice [np.float32(0.7244)] 
2025-06-04 21:47:27.232822: Epoch time: 133.45 s 
2025-06-04 21:47:31.032453:  
2025-06-04 21:47:31.189411: Epoch 977 
2025-06-04 21:47:31.344499: Current learning rate: 0.00034 
2025-06-04 21:49:51.412315: train_loss -0.7666 
2025-06-04 21:49:51.589337: val_loss -0.6959 
2025-06-04 21:49:51.604753: Pseudo dice [np.float32(0.7893)] 
2025-06-04 21:49:51.619565: Epoch time: 140.38 s 
2025-06-04 21:49:57.192428:  
2025-06-04 21:49:57.207892: Epoch 978 
2025-06-04 21:49:57.223350: Current learning rate: 0.00032 
2025-06-04 21:52:15.788372: train_loss -0.7581 
2025-06-04 21:52:15.806849: val_loss -0.6778 
2025-06-04 21:52:15.820192: Pseudo dice [np.float32(0.7219)] 
2025-06-04 21:52:15.832423: Epoch time: 138.6 s 
2025-06-04 21:52:20.340476:  
2025-06-04 21:52:20.463372: Epoch 979 
2025-06-04 21:52:20.595007: Current learning rate: 0.00031 
2025-06-04 21:54:39.667895: train_loss -0.7543 
2025-06-04 21:54:39.897735: val_loss -0.7286 
2025-06-04 21:54:39.914985: Pseudo dice [np.float32(0.836)] 
2025-06-04 21:54:39.933146: Epoch time: 139.33 s 
2025-06-04 21:54:43.736499:  
2025-06-04 21:54:43.838353: Epoch 980 
2025-06-04 21:54:43.856708: Current learning rate: 0.0003 
2025-06-04 21:57:00.823131: train_loss -0.7569 
2025-06-04 21:57:01.056353: val_loss -0.7033 
2025-06-04 21:57:01.122811: Pseudo dice [np.float32(0.7184)] 
2025-06-04 21:57:01.182188: Epoch time: 137.09 s 
2025-06-04 21:57:05.458086:  
2025-06-04 21:57:05.565901: Epoch 981 
2025-06-04 21:57:05.591643: Current learning rate: 0.00028 
2025-06-04 21:59:18.138786: train_loss -0.7637 
2025-06-04 21:59:18.162909: val_loss -0.6674 
2025-06-04 21:59:18.179766: Pseudo dice [np.float32(0.7055)] 
2025-06-04 21:59:18.195546: Epoch time: 132.68 s 
2025-06-04 21:59:23.021983:  
2025-06-04 21:59:23.044253: Epoch 982 
2025-06-04 21:59:23.060832: Current learning rate: 0.00027 
2025-06-04 22:01:29.970432: train_loss -0.7695 
2025-06-04 22:01:29.996744: val_loss -0.6824 
2025-06-04 22:01:30.017766: Pseudo dice [np.float32(0.8806)] 
2025-06-04 22:01:30.033339: Epoch time: 126.95 s 
2025-06-04 22:01:35.681576:  
2025-06-04 22:01:35.870127: Epoch 983 
2025-06-04 22:01:36.047004: Current learning rate: 0.00026 
2025-06-04 22:03:43.944270: train_loss -0.7477 
2025-06-04 22:03:44.293222: val_loss -0.6963 
2025-06-04 22:03:44.607159: Pseudo dice [np.float32(0.8638)] 
2025-06-04 22:03:44.623681: Epoch time: 128.26 s 
2025-06-04 22:03:50.327075:  
2025-06-04 22:03:50.586897: Epoch 984 
2025-06-04 22:03:50.722790: Current learning rate: 0.00024 
2025-06-04 22:06:03.997295: train_loss -0.7621 
2025-06-04 22:06:04.020334: val_loss -0.6587 
2025-06-04 22:06:04.034055: Pseudo dice [np.float32(0.7526)] 
2025-06-04 22:06:04.047761: Epoch time: 133.67 s 
2025-06-04 22:06:09.260762:  
2025-06-04 22:06:09.439493: Epoch 985 
2025-06-04 22:06:09.612049: Current learning rate: 0.00023 
2025-06-04 22:08:24.108524: train_loss -0.765 
2025-06-04 22:08:24.138561: val_loss -0.6724 
2025-06-04 22:08:24.164914: Pseudo dice [np.float32(0.6625)] 
2025-06-04 22:08:24.555503: Epoch time: 134.85 s 
2025-06-04 22:08:29.111737:  
2025-06-04 22:08:29.218095: Epoch 986 
2025-06-04 22:08:29.262234: Current learning rate: 0.00021 
2025-06-04 22:10:41.712537: train_loss -0.7742 
2025-06-04 22:10:42.048721: val_loss -0.6416 
2025-06-04 22:10:42.386826: Pseudo dice [np.float32(0.6921)] 
2025-06-04 22:10:42.404557: Epoch time: 132.6 s 
2025-06-04 22:10:46.692534:  
2025-06-04 22:10:46.738092: Epoch 987 
2025-06-04 22:10:46.751937: Current learning rate: 0.0002 
2025-06-04 22:12:58.378961: train_loss -0.7445 
2025-06-04 22:12:58.399287: val_loss -0.6759 
2025-06-04 22:12:58.414742: Pseudo dice [np.float32(0.7845)] 
2025-06-04 22:12:58.430520: Epoch time: 131.69 s 
2025-06-04 22:13:02.898560:  
2025-06-04 22:13:02.914880: Epoch 988 
2025-06-04 22:13:02.928112: Current learning rate: 0.00019 
2025-06-04 22:15:15.013518: train_loss -0.7676 
2025-06-04 22:15:15.526454: val_loss -0.7338 
2025-06-04 22:15:15.704334: Pseudo dice [np.float32(0.8438)] 
2025-06-04 22:15:16.075409: Epoch time: 132.12 s 
2025-06-04 22:15:20.265541:  
2025-06-04 22:15:20.313199: Epoch 989 
2025-06-04 22:15:20.330034: Current learning rate: 0.00017 
2025-06-04 22:17:32.249462: train_loss -0.7571 
2025-06-04 22:17:32.266085: val_loss -0.7025 
2025-06-04 22:17:32.280457: Pseudo dice [np.float32(0.814)] 
2025-06-04 22:17:32.297053: Epoch time: 132.0 s 
2025-06-04 22:17:37.248193:  
2025-06-04 22:17:37.278821: Epoch 990 
2025-06-04 22:17:37.301016: Current learning rate: 0.00016 
2025-06-04 22:19:47.789627: train_loss -0.7423 
2025-06-04 22:19:48.144828: val_loss -0.6924 
2025-06-04 22:19:48.647185: Pseudo dice [np.float32(0.8194)] 
2025-06-04 22:19:48.899156: Epoch time: 130.54 s 
2025-06-04 22:19:52.389946:  
2025-06-04 22:19:52.409898: Epoch 991 
2025-06-04 22:19:52.425373: Current learning rate: 0.00014 
2025-06-04 22:22:01.636773: train_loss -0.7599 
2025-06-04 22:22:01.655262: val_loss -0.6831 
2025-06-04 22:22:01.668922: Pseudo dice [np.float32(0.7731)] 
2025-06-04 22:22:01.682257: Epoch time: 129.25 s 
2025-06-04 22:22:03.486972:  
2025-06-04 22:22:03.504921: Epoch 992 
2025-06-04 22:22:03.519773: Current learning rate: 0.00013 
2025-06-04 22:24:13.220154: train_loss -0.7514 
2025-06-04 22:24:13.344923: val_loss -0.6363 
2025-06-04 22:24:13.361019: Pseudo dice [np.float32(0.6689)] 
2025-06-04 22:24:13.374413: Epoch time: 129.74 s 
2025-06-04 22:24:17.000296:  
2025-06-04 22:24:17.014795: Epoch 993 
2025-06-04 22:24:17.028283: Current learning rate: 0.00011 
2025-06-04 22:26:27.865630: train_loss -0.766 
2025-06-04 22:26:28.088346: val_loss -0.7358 
2025-06-04 22:26:28.108110: Pseudo dice [np.float32(0.827)] 
2025-06-04 22:26:28.120778: Epoch time: 130.87 s 
2025-06-04 22:26:31.231383:  
2025-06-04 22:26:31.244340: Epoch 994 
2025-06-04 22:26:31.257855: Current learning rate: 0.0001 
2025-06-04 22:28:40.960031: train_loss -0.7492 
2025-06-04 22:28:41.153898: val_loss -0.7182 
2025-06-04 22:28:41.513081: Pseudo dice [np.float32(0.8032)] 
2025-06-04 22:28:41.900377: Epoch time: 129.73 s 
2025-06-04 22:28:45.294962:  
2025-06-04 22:28:45.314375: Epoch 995 
2025-06-04 22:28:45.329015: Current learning rate: 8e-05 
2025-06-04 22:30:56.369714: train_loss -0.7498 
2025-06-04 22:30:56.596196: val_loss -0.6814 
2025-06-04 22:30:56.877051: Pseudo dice [np.float32(0.7073)] 
2025-06-04 22:30:57.215691: Epoch time: 131.08 s 
2025-06-04 22:31:00.612075:  
2025-06-04 22:31:00.631070: Epoch 996 
2025-06-04 22:31:00.705642: Current learning rate: 7e-05 
2025-06-04 22:33:07.455089: train_loss -0.7563 
2025-06-04 22:33:07.472374: val_loss -0.7227 
2025-06-04 22:33:07.485743: Pseudo dice [np.float32(0.7282)] 
2025-06-04 22:33:07.499785: Epoch time: 126.84 s 
2025-06-04 22:33:10.837172:  
2025-06-04 22:33:11.000715: Epoch 997 
2025-06-04 22:33:11.182693: Current learning rate: 5e-05 
2025-06-04 22:35:18.372320: train_loss -0.7697 
2025-06-04 22:35:18.641118: val_loss -0.654 
2025-06-04 22:35:19.033221: Pseudo dice [np.float32(0.7977)] 
2025-06-04 22:35:19.326052: Epoch time: 127.54 s 
2025-06-04 22:35:23.412366:  
2025-06-04 22:35:23.496920: Epoch 998 
2025-06-04 22:35:23.566651: Current learning rate: 4e-05 
2025-06-04 22:36:55.893381: train_loss -0.7521 
2025-06-04 22:36:55.911421: val_loss -0.7118 
2025-06-04 22:36:55.925395: Pseudo dice [np.float32(0.789)] 
2025-06-04 22:36:55.938796: Epoch time: 92.48 s 
2025-06-04 22:36:59.065916:  
2025-06-04 22:36:59.081350: Epoch 999 
2025-06-04 22:36:59.093201: Current learning rate: 2e-05 
2025-06-04 22:38:30.831146: train_loss -0.7531 
2025-06-04 22:38:30.849087: val_loss -0.6954 
2025-06-04 22:38:30.863369: Pseudo dice [np.float32(0.8082)] 
2025-06-04 22:38:30.875682: Epoch time: 91.77 s 
2025-06-04 22:38:37.066429: Training done. 
2025-06-04 22:38:37.173832: Using splits from existing split file: C:\Users\usuario\Documents\Mama_Mia\nnUNet_preprocessed\Dataset112\splits_final.json 
2025-06-04 22:38:37.206180: The split file contains 5 splits. 
2025-06-04 22:38:37.216518: Desired fold for training: 0 
2025-06-04 22:38:37.227689: This split has 960 training and 240 validation cases. 
2025-06-04 22:38:37.240534: predicting case_000 
2025-06-04 22:38:37.447809: case_000, shape torch.Size([1, 88, 512, 512]), rank 0 
2025-06-04 22:39:00.960986: predicting case_006 
2025-06-04 22:39:01.260623: case_006, shape torch.Size([1, 88, 469, 469]), rank 0 
2025-06-04 22:39:15.254428: predicting case_010 
2025-06-04 22:39:15.507280: case_010, shape torch.Size([1, 84, 498, 498]), rank 0 
2025-06-04 22:39:30.249192: predicting case_017 
2025-06-04 22:39:30.482398: case_017, shape torch.Size([1, 81, 469, 469]), rank 0 
2025-06-04 22:39:39.970668: predicting case_020 
2025-06-04 22:39:40.661844: case_020, shape torch.Size([1, 97, 484, 484]), rank 0 
2025-06-04 22:40:02.871799: predicting case_022 
2025-06-04 22:40:03.181840: case_022, shape torch.Size([1, 88, 484, 484]), rank 0 
2025-06-04 22:40:24.977874: predicting case_025 
2025-06-04 22:40:25.297635: case_025, shape torch.Size([1, 88, 512, 512]), rank 0 
2025-06-04 22:40:47.445897: predicting case_029 
2025-06-04 22:40:47.913762: case_029, shape torch.Size([1, 88, 484, 484]), rank 0 
2025-06-04 22:41:09.439237: predicting case_030 
2025-06-04 22:41:09.686650: case_030, shape torch.Size([1, 100, 484, 484]), rank 0 
2025-06-04 22:41:31.170990: predicting case_033 
2025-06-04 22:41:31.535399: case_033, shape torch.Size([1, 94, 526, 526]), rank 0 
2025-06-04 22:41:53.065755: predicting case_041 
2025-06-04 22:41:53.335413: case_041, shape torch.Size([1, 80, 484, 484]), rank 0 
2025-06-04 22:42:07.688603: predicting case_047 
2025-06-04 22:42:07.992071: case_047, shape torch.Size([1, 83, 498, 498]), rank 0 
2025-06-04 22:42:22.375273: predicting case_052 
2025-06-04 22:42:22.676721: case_052, shape torch.Size([1, 88, 512, 512]), rank 0 
2025-06-04 22:42:44.231278: predicting case_056 
2025-06-04 22:42:44.484616: case_056, shape torch.Size([1, 72, 455, 455]), rank 0 
2025-06-04 22:42:53.700953: predicting case_058 
2025-06-04 22:42:54.055739: case_058, shape torch.Size([1, 88, 512, 512]), rank 0 
2025-06-04 22:43:15.573012: predicting case_059 
2025-06-04 22:43:15.939842: case_059, shape torch.Size([1, 93, 569, 569]), rank 0 
2025-06-04 22:43:37.487453: predicting case_065 
2025-06-04 22:43:37.828774: case_065, shape torch.Size([1, 92, 540, 540]), rank 0 
2025-06-04 22:43:59.302481: predicting case_068 
2025-06-04 22:43:59.522903: case_068, shape torch.Size([1, 80, 427, 427]), rank 0 
2025-06-04 22:44:08.745665: predicting case_070 
2025-06-04 22:44:09.076688: case_070, shape torch.Size([1, 96, 484, 484]), rank 0 
2025-06-04 22:44:30.640123: predicting case_072 
2025-06-04 22:44:31.042833: case_072, shape torch.Size([1, 112, 498, 498]), rank 0 
2025-06-04 22:44:52.599733: predicting case_073 
2025-06-04 22:44:52.949139: case_073, shape torch.Size([1, 88, 512, 512]), rank 0 
2025-06-04 22:45:14.488958: predicting case_076 
2025-06-04 22:45:14.770607: case_076, shape torch.Size([1, 88, 512, 512]), rank 0 
2025-06-04 22:45:36.333670: predicting case_082 
2025-06-04 22:45:36.546538: case_082, shape torch.Size([1, 79, 455, 455]), rank 0 
2025-06-04 22:45:45.768422: predicting case_089 
2025-06-04 22:45:46.101382: case_089, shape torch.Size([1, 104, 498, 498]), rank 0 
2025-06-04 22:46:07.611882: predicting case_090 
2025-06-04 22:46:07.840158: case_090, shape torch.Size([1, 78, 441, 441]), rank 0 
2025-06-04 22:46:17.039079: predicting case_092 
2025-06-04 22:46:17.301505: case_092, shape torch.Size([1, 94, 441, 441]), rank 0 
2025-06-04 22:46:31.645077: predicting case_097 
2025-06-04 22:46:32.157306: case_097, shape torch.Size([1, 100, 512, 512]), rank 0 
2025-06-04 22:46:53.704810: predicting case_1000 
2025-06-04 22:46:53.913351: case_1000, shape torch.Size([1, 80, 427, 427]), rank 0 
2025-06-04 22:47:03.148893: predicting case_1003 
2025-06-04 22:47:03.232667: case_1003, shape torch.Size([1, 80, 213, 213]), rank 0 
2025-06-04 22:47:05.570231: predicting case_1013 
2025-06-04 22:47:05.689980: case_1013, shape torch.Size([1, 90, 320, 320]), rank 0 
2025-06-04 22:47:13.455493: predicting case_1016 
2025-06-04 22:47:13.693958: case_1016, shape torch.Size([1, 80, 427, 427]), rank 0 
2025-06-04 22:47:22.901453: predicting case_1020 
2025-06-04 22:47:23.039955: case_1020, shape torch.Size([1, 80, 256, 256]), rank 0 
2025-06-04 22:47:25.386726: predicting case_1032 
2025-06-04 22:47:25.732260: case_1032, shape torch.Size([1, 97, 512, 512]), rank 0 
2025-06-04 22:47:47.248733: predicting case_1034 
2025-06-04 22:47:47.334729: case_1034, shape torch.Size([1, 79, 220, 220]), rank 0 
2025-06-04 22:47:49.720628: predicting case_1043 
2025-06-04 22:47:50.017793: case_1043, shape torch.Size([1, 80, 455, 455]), rank 0 
2025-06-04 22:47:59.249329: predicting case_1044 
2025-06-04 22:47:59.352495: case_1044, shape torch.Size([1, 80, 243, 243]), rank 0 
2025-06-04 22:48:01.689471: predicting case_1045 
2025-06-04 22:48:01.964093: case_1045, shape torch.Size([1, 80, 512, 512]), rank 0 
2025-06-04 22:48:16.318465: predicting case_1046 
2025-06-04 22:48:16.441090: case_1046, shape torch.Size([1, 80, 270, 270]), rank 0 
2025-06-04 22:48:18.776739: predicting case_1048 
2025-06-04 22:48:19.039826: case_1048, shape torch.Size([1, 86, 512, 512]), rank 0 
2025-06-04 22:48:40.563320: predicting case_1049 
2025-06-04 22:48:40.664701: case_1049, shape torch.Size([1, 80, 235, 235]), rank 0 
2025-06-04 22:48:43.011145: predicting case_1056 
2025-06-04 22:48:43.102233: case_1056, shape torch.Size([1, 79, 256, 256]), rank 0 
2025-06-04 22:48:45.992692: predicting case_1066 
2025-06-04 22:48:46.108535: case_1066, shape torch.Size([1, 79, 192, 192]), rank 0 
2025-06-04 22:48:47.080720: predicting case_1070 
2025-06-04 22:48:47.265771: case_1070, shape torch.Size([1, 80, 263, 263]), rank 0 
2025-06-04 22:48:50.063103: predicting case_1079 
2025-06-04 22:48:50.272902: case_1079, shape torch.Size([1, 80, 206, 206]), rank 0 
2025-06-04 22:48:52.648204: predicting case_1081 
2025-06-04 22:48:52.694635: case_1081, shape torch.Size([1, 80, 221, 221]), rank 0 
2025-06-04 22:48:55.012498: predicting case_1084 
2025-06-04 22:48:55.105544: case_1084, shape torch.Size([1, 80, 209, 209]), rank 0 
2025-06-04 22:48:57.496199: predicting case_1089 
2025-06-04 22:48:57.574855: case_1089, shape torch.Size([1, 80, 256, 256]), rank 0 
2025-06-04 22:48:59.906738: predicting case_1091 
2025-06-04 22:49:00.011391: case_1091, shape torch.Size([1, 80, 213, 213]), rank 0 
2025-06-04 22:49:02.351643: predicting case_1096 
2025-06-04 22:49:02.449286: case_1096, shape torch.Size([1, 79, 256, 256]), rank 0 
2025-06-04 22:49:04.817924: predicting case_1098 
2025-06-04 22:49:04.895468: case_1098, shape torch.Size([1, 80, 206, 206]), rank 0 
2025-06-04 22:49:07.225654: predicting case_1105 
2025-06-04 22:49:07.307440: case_1105, shape torch.Size([1, 80, 213, 213]), rank 0 
2025-06-04 22:49:09.640903: predicting case_111 
2025-06-04 22:49:09.895808: case_111, shape torch.Size([1, 89, 512, 512]), rank 0 
2025-06-04 22:49:31.350965: predicting case_1111 
2025-06-04 22:49:31.458333: case_1111, shape torch.Size([1, 80, 235, 235]), rank 0 
2025-06-04 22:49:33.816793: predicting case_1125 
2025-06-04 22:49:33.886962: case_1125, shape torch.Size([1, 79, 199, 199]), rank 0 
2025-06-04 22:49:36.216770: predicting case_1126 
2025-06-04 22:49:36.285225: case_1126, shape torch.Size([1, 80, 249, 249]), rank 0 
2025-06-04 22:49:38.616321: predicting case_113 
2025-06-04 22:49:38.872439: case_113, shape torch.Size([1, 79, 484, 484]), rank 0 
2025-06-04 22:49:53.256387: predicting case_1136 
2025-06-04 22:49:53.753842: case_1136, shape torch.Size([1, 97, 455, 455]), rank 0 
2025-06-04 22:50:07.726785: predicting case_1139 
2025-06-04 22:50:07.952999: case_1139, shape torch.Size([1, 86, 455, 455]), rank 0 
2025-06-04 22:50:21.729391: predicting case_1149 
2025-06-04 22:50:21.827740: case_1149, shape torch.Size([1, 80, 242, 242]), rank 0 
2025-06-04 22:50:24.185061: predicting case_115 
2025-06-04 22:50:24.449498: case_115, shape torch.Size([1, 80, 498, 498]), rank 0 
2025-06-04 22:50:38.787687: predicting case_1152 
2025-06-04 22:50:38.867277: case_1152, shape torch.Size([1, 79, 206, 206]), rank 0 
2025-06-04 22:50:41.216112: predicting case_1160 
2025-06-04 22:50:41.291357: case_1160, shape torch.Size([1, 60, 284, 284]), rank 0 
2025-06-04 22:50:43.647463: predicting case_1163 
2025-06-04 22:50:43.742327: case_1163, shape torch.Size([1, 60, 256, 256]), rank 0 
2025-06-04 22:50:46.074692: predicting case_1164 
2025-06-04 22:50:46.220511: case_1164, shape torch.Size([1, 69, 256, 256]), rank 0 
2025-06-04 22:50:48.577999: predicting case_1181 
2025-06-04 22:50:48.710525: case_1181, shape torch.Size([1, 60, 256, 256]), rank 0 
2025-06-04 22:50:51.039943: predicting case_1183 
2025-06-04 22:50:51.135966: case_1183, shape torch.Size([1, 70, 256, 256]), rank 0 
2025-06-04 22:50:53.479689: predicting case_1185 
2025-06-04 22:50:53.586014: case_1185, shape torch.Size([1, 60, 256, 256]), rank 0 
2025-06-04 22:50:55.920216: predicting case_1189 
2025-06-04 22:50:56.049233: case_1189, shape torch.Size([1, 66, 313, 313]), rank 0 
2025-06-04 22:51:01.902335: predicting case_1191 
2025-06-04 22:51:02.106759: case_1191, shape torch.Size([1, 60, 256, 256]), rank 0 
2025-06-04 22:51:04.660750: predicting case_122 
2025-06-04 22:51:05.435978: case_122, shape torch.Size([1, 107, 512, 512]), rank 0 
2025-06-04 22:51:26.991652: predicting case_128 
2025-06-04 22:51:27.188666: case_128, shape torch.Size([1, 71, 484, 484]), rank 0 
2025-06-04 22:51:41.515925: predicting case_139 
2025-06-04 22:51:41.818167: case_139, shape torch.Size([1, 88, 498, 498]), rank 0 
2025-06-04 22:52:03.312865: predicting case_143 
2025-06-04 22:52:03.592149: case_143, shape torch.Size([1, 88, 455, 455]), rank 0 
2025-06-04 22:52:17.387090: predicting case_147 
2025-06-04 22:52:17.587664: case_147, shape torch.Size([1, 85, 512, 512]), rank 0 
2025-06-04 22:52:39.146645: predicting case_158 
2025-06-04 22:52:39.416897: case_158, shape torch.Size([1, 88, 484, 484]), rank 0 
2025-06-04 22:53:00.911344: predicting case_159 
2025-06-04 22:53:01.424423: case_159, shape torch.Size([1, 90, 569, 569]), rank 0 
2025-06-04 22:53:23.056164: predicting case_180 
2025-06-04 22:53:23.671643: case_180, shape torch.Size([1, 87, 512, 512]), rank 0 
2025-06-04 22:53:45.322836: predicting case_181 
2025-06-04 22:53:45.597611: case_181, shape torch.Size([1, 88, 484, 484]), rank 0 
2025-06-04 22:54:07.073575: predicting case_190 
2025-06-04 22:54:07.298664: case_190, shape torch.Size([1, 95, 526, 526]), rank 0 
2025-06-04 22:54:29.399021: predicting case_199 
2025-06-04 22:54:29.797394: case_199, shape torch.Size([1, 97, 512, 512]), rank 0 
2025-06-04 22:54:51.490694: predicting case_208 
2025-06-04 22:54:51.591296: case_208, shape torch.Size([1, 63, 313, 313]), rank 0 
2025-06-04 22:54:56.827857: predicting case_211 
2025-06-04 22:54:56.896656: case_211, shape torch.Size([1, 45, 256, 256]), rank 0 
2025-06-04 22:54:58.096208: predicting case_214 
2025-06-04 22:54:58.193458: case_214, shape torch.Size([1, 69, 284, 284]), rank 0 
2025-06-04 22:55:00.528783: predicting case_219 
2025-06-04 22:55:00.627288: case_219, shape torch.Size([1, 60, 284, 284]), rank 0 
2025-06-04 22:55:02.954932: predicting case_223 
2025-06-04 22:55:03.090207: case_223, shape torch.Size([1, 80, 256, 256]), rank 0 
2025-06-04 22:55:05.431641: predicting case_234 
2025-06-04 22:55:05.537524: case_234, shape torch.Size([1, 60, 284, 284]), rank 0 
2025-06-04 22:55:07.867657: predicting case_236 
2025-06-04 22:55:07.957979: case_236, shape torch.Size([1, 70, 256, 256]), rank 0 
2025-06-04 22:55:10.299816: predicting case_249 
2025-06-04 22:55:10.440397: case_249, shape torch.Size([1, 72, 256, 256]), rank 0 
2025-06-04 22:55:12.781046: predicting case_255 
2025-06-04 22:55:12.860845: case_255, shape torch.Size([1, 60, 284, 284]), rank 0 
2025-06-04 22:55:15.201281: predicting case_256 
2025-06-04 22:55:15.298322: case_256, shape torch.Size([1, 60, 284, 284]), rank 0 
2025-06-04 22:55:17.639575: predicting case_268 
2025-06-04 22:55:17.728620: case_268, shape torch.Size([1, 60, 284, 284]), rank 0 
2025-06-04 22:55:20.057938: predicting case_289 
2025-06-04 22:55:20.170124: case_289, shape torch.Size([1, 73, 256, 256]), rank 0 
2025-06-04 22:55:22.512299: predicting case_293 
2025-06-04 22:55:22.580692: case_293, shape torch.Size([1, 60, 284, 284]), rank 0 
2025-06-04 22:55:24.913451: predicting case_299 
2025-06-04 22:55:25.135702: case_299, shape torch.Size([1, 192, 313, 313]), rank 0 
2025-06-04 22:55:40.916356: predicting case_302 
2025-06-04 22:55:41.031531: case_302, shape torch.Size([1, 66, 284, 284]), rank 0 
2025-06-04 22:55:43.384291: predicting case_310 
2025-06-04 22:55:43.466176: case_310, shape torch.Size([1, 80, 228, 228]), rank 0 
2025-06-04 22:55:45.811693: predicting case_311 
2025-06-04 22:55:46.184197: case_311, shape torch.Size([1, 97, 540, 540]), rank 0 
2025-06-04 22:56:07.701607: predicting case_321 
2025-06-04 22:56:07.826106: case_321, shape torch.Size([1, 88, 263, 263]), rank 0 
2025-06-04 22:56:11.334733: predicting case_322 
2025-06-04 22:56:11.453788: case_322, shape torch.Size([1, 80, 329, 329]), rank 0 
2025-06-04 22:56:16.651413: predicting case_330 
2025-06-04 22:56:16.755385: case_330, shape torch.Size([1, 80, 270, 270]), rank 0 
2025-06-04 22:56:19.094807: predicting case_339 
2025-06-04 22:56:19.166787: case_339, shape torch.Size([1, 80, 213, 213]), rank 0 
2025-06-04 22:56:21.497425: predicting case_341 
2025-06-04 22:56:21.606989: case_341, shape torch.Size([1, 80, 328, 328]), rank 0 
2025-06-04 22:56:26.822935: predicting case_345 
2025-06-04 22:56:26.885244: case_345, shape torch.Size([1, 80, 228, 228]), rank 0 
2025-06-04 22:56:29.229646: predicting case_357 
2025-06-04 22:56:29.303020: case_357, shape torch.Size([1, 80, 249, 249]), rank 0 
2025-06-04 22:56:31.640243: predicting case_378 
2025-06-04 22:56:31.712793: case_378, shape torch.Size([1, 80, 242, 242]), rank 0 
2025-06-04 22:56:34.048687: predicting case_387 
2025-06-04 22:56:34.107878: case_387, shape torch.Size([1, 80, 220, 220]), rank 0 
2025-06-04 22:56:36.449209: predicting case_388 
2025-06-04 22:56:36.517430: case_388, shape torch.Size([1, 80, 206, 206]), rank 0 
2025-06-04 22:56:38.857304: predicting case_393 
2025-06-04 22:56:39.134210: case_393, shape torch.Size([1, 86, 469, 469]), rank 0 
2025-06-04 22:56:52.887017: predicting case_396 
2025-06-04 22:56:52.956239: case_396, shape torch.Size([1, 80, 228, 228]), rank 0 
2025-06-04 22:56:55.300005: predicting case_398 
2025-06-04 22:56:55.381424: case_398, shape torch.Size([1, 80, 242, 242]), rank 0 
2025-06-04 22:56:57.791182: predicting case_399 
2025-06-04 22:56:57.884329: case_399, shape torch.Size([1, 80, 242, 242]), rank 0 
2025-06-04 22:57:00.235841: predicting case_404 
2025-06-04 22:57:00.307986: case_404, shape torch.Size([1, 80, 220, 220]), rank 0 
2025-06-04 22:57:02.632459: predicting case_427 
2025-06-04 22:57:02.725103: case_427, shape torch.Size([1, 80, 235, 235]), rank 0 
2025-06-04 22:57:05.061627: predicting case_435 
2025-06-04 22:57:05.129872: case_435, shape torch.Size([1, 80, 256, 256]), rank 0 
2025-06-04 22:57:07.455123: predicting case_437 
2025-06-04 22:57:07.554049: case_437, shape torch.Size([1, 79, 256, 256]), rank 0 
2025-06-04 22:57:09.891411: predicting case_445 
2025-06-04 22:57:09.976027: case_445, shape torch.Size([1, 80, 249, 249]), rank 0 
2025-06-04 22:57:12.311933: predicting case_446 
2025-06-04 22:57:12.376085: case_446, shape torch.Size([1, 79, 206, 206]), rank 0 
2025-06-04 22:57:14.729116: predicting case_448 
2025-06-04 22:57:14.827316: case_448, shape torch.Size([1, 80, 328, 328]), rank 0 
2025-06-04 22:57:20.044392: predicting case_458 
2025-06-04 22:57:20.137405: case_458, shape torch.Size([1, 80, 220, 220]), rank 0 
2025-06-04 22:57:22.472316: predicting case_473 
2025-06-04 22:57:22.549743: case_473, shape torch.Size([1, 80, 199, 199]), rank 0 
2025-06-04 22:57:24.874374: predicting case_476 
2025-06-04 22:57:24.978381: case_476, shape torch.Size([1, 80, 228, 228]), rank 0 
2025-06-04 22:57:27.315232: predicting case_477 
2025-06-04 22:57:27.412610: case_477, shape torch.Size([1, 80, 228, 228]), rank 0 
2025-06-04 22:57:29.846516: predicting case_482 
2025-06-04 22:57:29.966477: case_482, shape torch.Size([1, 79, 256, 256]), rank 0 
2025-06-04 22:57:32.306912: predicting case_486 
2025-06-04 22:57:32.395711: case_486, shape torch.Size([1, 80, 228, 228]), rank 0 
2025-06-04 22:57:34.729383: predicting case_498 
2025-06-04 22:57:34.826205: case_498, shape torch.Size([1, 80, 313, 313]), rank 0 
2025-06-04 22:57:40.017518: predicting case_500 
2025-06-04 22:57:40.082815: case_500, shape torch.Size([1, 80, 213, 213]), rank 0 
2025-06-04 22:57:42.426636: predicting case_503 
2025-06-04 22:57:42.493571: case_503, shape torch.Size([1, 79, 213, 213]), rank 0 
2025-06-04 22:57:44.834173: predicting case_505 
2025-06-04 22:57:45.037578: case_505, shape torch.Size([1, 80, 398, 398]), rank 0 
2025-06-04 22:57:54.881253: predicting case_508 
2025-06-04 22:57:54.987443: case_508, shape torch.Size([1, 79, 256, 256]), rank 0 
2025-06-04 22:57:57.399879: predicting case_515 
2025-06-04 22:57:57.457515: case_515, shape torch.Size([1, 80, 220, 220]), rank 0 
2025-06-04 22:57:59.797215: predicting case_518 
2025-06-04 22:58:00.102903: case_518, shape torch.Size([1, 88, 455, 455]), rank 0 
2025-06-04 22:58:13.860840: predicting case_525 
2025-06-04 22:58:13.957467: case_525, shape torch.Size([1, 80, 235, 235]), rank 0 
2025-06-04 22:58:16.274776: predicting case_526 
2025-06-04 22:58:16.341828: case_526, shape torch.Size([1, 80, 220, 220]), rank 0 
2025-06-04 22:58:18.664837: predicting case_528 
2025-06-04 22:58:19.062512: case_528, shape torch.Size([1, 97, 540, 540]), rank 0 
2025-06-04 22:58:40.570527: predicting case_536 
2025-06-04 22:58:40.832846: case_536, shape torch.Size([1, 86, 512, 512]), rank 0 
2025-06-04 22:59:02.826059: predicting case_538 
2025-06-04 22:59:03.046448: case_538, shape torch.Size([1, 80, 256, 256]), rank 0 
2025-06-04 22:59:05.463975: predicting case_539 
2025-06-04 22:59:05.556398: case_539, shape torch.Size([1, 80, 329, 329]), rank 0 
2025-06-04 22:59:10.768040: predicting case_540 
2025-06-04 22:59:10.900188: case_540, shape torch.Size([1, 90, 329, 329]), rank 0 
2025-06-04 22:59:18.711088: predicting case_556 
2025-06-04 22:59:18.939379: case_556, shape torch.Size([1, 96, 427, 427]), rank 0 
2025-06-04 22:59:32.731488: predicting case_568 
2025-06-04 22:59:32.826437: case_568, shape torch.Size([1, 80, 213, 213]), rank 0 
2025-06-04 22:59:35.175524: predicting case_572 
2025-06-04 22:59:35.279443: case_572, shape torch.Size([1, 80, 256, 256]), rank 0 
2025-06-04 22:59:37.617193: predicting case_577 
2025-06-04 22:59:37.696276: case_577, shape torch.Size([1, 80, 249, 249]), rank 0 
2025-06-04 22:59:40.033093: predicting case_584 
2025-06-04 22:59:40.322003: case_584, shape torch.Size([1, 97, 441, 441]), rank 0 
2025-06-04 22:59:54.093600: predicting case_585 
2025-06-04 22:59:54.342626: case_585, shape torch.Size([1, 97, 455, 455]), rank 0 
2025-06-04 23:00:08.499562: predicting case_587 
2025-06-04 23:00:08.680379: case_587, shape torch.Size([1, 80, 235, 235]), rank 0 
2025-06-04 23:00:11.277007: predicting case_592 
2025-06-04 23:00:11.582405: case_592, shape torch.Size([1, 80, 328, 328]), rank 0 
2025-06-04 23:00:16.858534: predicting case_594 
2025-06-04 23:00:16.949840: case_594, shape torch.Size([1, 91, 231, 231]), rank 0 
2025-06-04 23:00:20.445208: predicting case_595 
2025-06-04 23:00:20.511031: case_595, shape torch.Size([1, 80, 228, 228]), rank 0 
2025-06-04 23:00:22.857612: predicting case_599 
2025-06-04 23:00:23.090287: case_599, shape torch.Size([1, 102, 455, 455]), rank 0 
2025-06-04 23:00:36.845860: predicting case_603 
2025-06-04 23:00:37.112764: case_603, shape torch.Size([1, 88, 427, 427]), rank 0 
2025-06-04 23:00:50.897132: predicting case_604 
2025-06-04 23:00:50.974192: case_604, shape torch.Size([1, 80, 206, 206]), rank 0 
2025-06-04 23:00:53.330646: predicting case_609 
2025-06-04 23:00:53.476465: case_609, shape torch.Size([1, 100, 256, 256]), rank 0 
2025-06-04 23:00:56.971310: predicting case_612 
2025-06-04 23:00:57.090029: case_612, shape torch.Size([1, 80, 284, 284]), rank 0 
2025-06-04 23:00:59.428454: predicting case_614 
2025-06-04 23:00:59.489742: case_614, shape torch.Size([1, 79, 199, 199]), rank 0 
2025-06-04 23:01:01.823196: predicting case_615 
2025-06-04 23:01:01.898380: case_615, shape torch.Size([1, 79, 213, 213]), rank 0 
2025-06-04 23:01:04.225366: predicting case_616 
2025-06-04 23:01:04.300405: case_616, shape torch.Size([1, 80, 256, 256]), rank 0 
2025-06-04 23:01:06.643106: predicting case_621 
2025-06-04 23:01:06.728751: case_621, shape torch.Size([1, 81, 213, 213]), rank 0 
2025-06-04 23:01:09.063165: predicting case_623 
2025-06-04 23:01:09.154514: case_623, shape torch.Size([1, 79, 256, 256]), rank 0 
2025-06-04 23:01:11.506632: predicting case_624 
2025-06-04 23:01:11.859880: case_624, shape torch.Size([1, 100, 512, 512]), rank 0 
2025-06-04 23:01:33.384797: predicting case_636 
2025-06-04 23:01:33.469009: case_636, shape torch.Size([1, 79, 213, 213]), rank 0 
2025-06-04 23:01:35.830595: predicting case_641 
2025-06-04 23:01:36.010213: case_641, shape torch.Size([1, 79, 256, 256]), rank 0 
2025-06-04 23:01:38.345594: predicting case_646 
2025-06-04 23:01:38.397304: case_646, shape torch.Size([1, 79, 185, 185]), rank 0 
2025-06-04 23:01:39.024274: predicting case_648 
2025-06-04 23:01:39.081171: case_648, shape torch.Size([1, 80, 213, 213]), rank 0 
2025-06-04 23:01:41.421697: predicting case_653 
2025-06-04 23:01:41.519166: case_653, shape torch.Size([1, 80, 256, 256]), rank 0 
2025-06-04 23:01:43.875769: predicting case_654 
2025-06-04 23:01:43.968567: case_654, shape torch.Size([1, 80, 242, 242]), rank 0 
2025-06-04 23:01:46.307832: predicting case_657 
2025-06-04 23:01:46.407571: case_657, shape torch.Size([1, 80, 235, 235]), rank 0 
2025-06-04 23:01:48.763453: predicting case_660 
2025-06-04 23:01:48.867471: case_660, shape torch.Size([1, 79, 256, 256]), rank 0 
2025-06-04 23:01:51.211516: predicting case_663 
2025-06-04 23:01:51.313286: case_663, shape torch.Size([1, 80, 256, 256]), rank 0 
2025-06-04 23:01:53.672009: predicting case_667 
2025-06-04 23:01:53.757964: case_667, shape torch.Size([1, 80, 228, 228]), rank 0 
2025-06-04 23:01:56.103522: predicting case_673 
2025-06-04 23:01:56.236945: case_673, shape torch.Size([1, 80, 256, 256]), rank 0 
2025-06-04 23:01:58.573271: predicting case_677 
2025-06-04 23:01:58.919688: case_677, shape torch.Size([1, 90, 512, 512]), rank 0 
2025-06-04 23:02:20.413535: predicting case_678 
2025-06-04 23:02:20.536837: case_678, shape torch.Size([1, 79, 256, 256]), rank 0 
2025-06-04 23:02:23.389552: predicting case_679 
2025-06-04 23:02:23.624377: case_679, shape torch.Size([1, 80, 277, 277]), rank 0 
2025-06-04 23:02:26.185157: predicting case_680 
2025-06-04 23:02:26.473604: case_680, shape torch.Size([1, 80, 256, 256]), rank 0 
2025-06-04 23:02:29.102661: predicting case_681 
2025-06-04 23:02:29.494987: case_681, shape torch.Size([1, 80, 398, 398]), rank 0 
2025-06-04 23:02:38.716507: predicting case_690 
2025-06-04 23:02:38.799527: case_690, shape torch.Size([1, 79, 220, 220]), rank 0 
2025-06-04 23:02:41.145136: predicting case_695 
2025-06-04 23:02:41.277978: case_695, shape torch.Size([1, 77, 302, 302]), rank 0 
2025-06-04 23:02:46.478948: predicting case_698 
2025-06-04 23:02:46.568085: case_698, shape torch.Size([1, 80, 213, 213]), rank 0 
2025-06-04 23:02:48.998916: predicting case_700 
2025-06-04 23:02:49.164391: case_700, shape torch.Size([1, 90, 356, 356]), rank 0 
2025-06-04 23:02:56.941470: predicting case_701 
2025-06-04 23:02:57.024881: case_701, shape torch.Size([1, 80, 256, 256]), rank 0 
2025-06-04 23:02:59.368306: predicting case_707 
2025-06-04 23:02:59.513749: case_707, shape torch.Size([1, 80, 256, 256]), rank 0 
2025-06-04 23:03:01.854602: predicting case_714 
2025-06-04 23:03:01.920511: case_714, shape torch.Size([1, 80, 199, 199]), rank 0 
2025-06-04 23:03:04.256527: predicting case_726 
2025-06-04 23:03:04.331888: case_726, shape torch.Size([1, 80, 220, 220]), rank 0 
2025-06-04 23:03:06.660919: predicting case_728 
2025-06-04 23:03:06.795164: case_728, shape torch.Size([1, 90, 284, 284]), rank 0 
2025-06-04 23:03:10.303926: predicting case_733 
2025-06-04 23:03:10.377138: case_733, shape torch.Size([1, 80, 228, 228]), rank 0 
2025-06-04 23:03:12.702520: predicting case_735 
2025-06-04 23:03:12.786583: case_735, shape torch.Size([1, 79, 256, 256]), rank 0 
2025-06-04 23:03:15.140262: predicting case_738 
2025-06-04 23:03:15.191106: case_738, shape torch.Size([1, 79, 213, 213]), rank 0 
2025-06-04 23:03:17.513153: predicting case_741 
2025-06-04 23:03:17.592629: case_741, shape torch.Size([1, 79, 256, 256]), rank 0 
2025-06-04 23:03:19.941391: predicting case_747 
2025-06-04 23:03:20.341596: case_747, shape torch.Size([1, 86, 569, 569]), rank 0 
2025-06-04 23:03:41.859225: predicting case_758 
2025-06-04 23:03:41.949359: case_758, shape torch.Size([1, 80, 235, 235]), rank 0 
2025-06-04 23:03:44.328199: predicting case_761 
2025-06-04 23:03:44.432086: case_761, shape torch.Size([1, 80, 256, 256]), rank 0 
2025-06-04 23:03:46.792650: predicting case_765 
2025-06-04 23:03:46.876920: case_765, shape torch.Size([1, 80, 243, 243]), rank 0 
2025-06-04 23:03:49.226779: predicting case_766 
2025-06-04 23:03:49.310663: case_766, shape torch.Size([1, 80, 256, 256]), rank 0 
2025-06-04 23:03:51.653531: predicting case_774 
2025-06-04 23:03:51.911844: case_774, shape torch.Size([1, 80, 455, 455]), rank 0 
2025-06-04 23:04:01.200323: predicting case_776 
2025-06-04 23:04:01.482738: case_776, shape torch.Size([1, 88, 512, 512]), rank 0 
2025-06-04 23:04:23.025052: predicting case_783 
2025-06-04 23:04:23.168363: case_783, shape torch.Size([1, 80, 256, 256]), rank 0 
2025-06-04 23:04:25.535215: predicting case_786 
2025-06-04 23:04:25.643182: case_786, shape torch.Size([1, 79, 256, 256]), rank 0 
2025-06-04 23:04:27.985919: predicting case_790 
2025-06-04 23:04:28.059963: case_790, shape torch.Size([1, 79, 228, 228]), rank 0 
2025-06-04 23:04:30.405955: predicting case_792 
2025-06-04 23:04:30.513300: case_792, shape torch.Size([1, 79, 256, 256]), rank 0 
2025-06-04 23:04:32.859046: predicting case_798 
2025-06-04 23:04:32.991545: case_798, shape torch.Size([1, 80, 242, 242]), rank 0 
2025-06-04 23:04:35.348343: predicting case_801 
2025-06-04 23:04:35.419115: case_801, shape torch.Size([1, 79, 213, 213]), rank 0 
2025-06-04 23:04:37.768776: predicting case_803 
2025-06-04 23:04:37.881142: case_803, shape torch.Size([1, 80, 270, 270]), rank 0 
2025-06-04 23:04:40.875255: predicting case_810 
2025-06-04 23:04:41.188836: case_810, shape torch.Size([1, 84, 299, 299]), rank 0 
2025-06-04 23:04:46.786010: predicting case_811 
2025-06-04 23:04:46.923392: case_811, shape torch.Size([1, 80, 256, 256]), rank 0 
2025-06-04 23:04:49.258408: predicting case_812 
2025-06-04 23:04:49.388520: case_812, shape torch.Size([1, 80, 256, 256]), rank 0 
2025-06-04 23:04:51.719166: predicting case_816 
2025-06-04 23:04:51.778032: case_816, shape torch.Size([1, 80, 213, 213]), rank 0 
2025-06-04 23:04:54.120845: predicting case_823 
2025-06-04 23:04:54.344337: case_823, shape torch.Size([1, 96, 455, 455]), rank 0 
2025-06-04 23:05:08.116803: predicting case_830 
2025-06-04 23:05:08.222667: case_830, shape torch.Size([1, 80, 242, 242]), rank 0 
2025-06-04 23:05:10.616794: predicting case_831 
2025-06-04 23:05:10.735356: case_831, shape torch.Size([1, 80, 328, 328]), rank 0 
2025-06-04 23:05:15.935615: predicting case_832 
2025-06-04 23:05:16.010035: case_832, shape torch.Size([1, 81, 213, 213]), rank 0 
2025-06-04 23:05:18.332967: predicting case_836 
2025-06-04 23:05:18.509040: case_836, shape torch.Size([1, 80, 427, 427]), rank 0 
2025-06-04 23:05:27.699422: predicting case_838 
2025-06-04 23:05:27.796314: case_838, shape torch.Size([1, 80, 242, 242]), rank 0 
2025-06-04 23:05:30.161823: predicting case_840 
2025-06-04 23:05:30.239046: case_840, shape torch.Size([1, 80, 249, 249]), rank 0 
2025-06-04 23:05:32.579302: predicting case_846 
2025-06-04 23:05:32.640007: case_846, shape torch.Size([1, 80, 213, 213]), rank 0 
2025-06-04 23:05:34.968479: predicting case_847 
2025-06-04 23:05:35.055287: case_847, shape torch.Size([1, 80, 228, 228]), rank 0 
2025-06-04 23:05:37.378995: predicting case_857 
2025-06-04 23:05:37.479239: case_857, shape torch.Size([1, 80, 242, 242]), rank 0 
2025-06-04 23:05:39.827672: predicting case_858 
2025-06-04 23:05:39.952841: case_858, shape torch.Size([1, 80, 256, 256]), rank 0 
2025-06-04 23:05:42.304161: predicting case_862 
2025-06-04 23:05:42.390350: case_862, shape torch.Size([1, 80, 242, 242]), rank 0 
2025-06-04 23:05:44.731248: predicting case_867 
2025-06-04 23:05:44.838500: case_867, shape torch.Size([1, 90, 320, 320]), rank 0 
2025-06-04 23:05:52.986994: predicting case_868 
2025-06-04 23:05:53.381415: case_868, shape torch.Size([1, 80, 256, 256]), rank 0 
2025-06-04 23:05:55.749827: predicting case_870 
2025-06-04 23:05:55.839461: case_870, shape torch.Size([1, 80, 256, 256]), rank 0 
2025-06-04 23:05:58.183383: predicting case_877 
2025-06-04 23:05:58.284652: case_877, shape torch.Size([1, 79, 235, 235]), rank 0 
2025-06-04 23:06:00.621821: predicting case_878 
2025-06-04 23:06:00.708215: case_878, shape torch.Size([1, 79, 256, 256]), rank 0 
2025-06-04 23:06:03.075162: predicting case_888 
2025-06-04 23:06:03.253798: case_888, shape torch.Size([1, 79, 256, 256]), rank 0 
2025-06-04 23:06:05.604213: predicting case_893 
2025-06-04 23:06:05.708810: case_893, shape torch.Size([1, 80, 270, 270]), rank 0 
2025-06-04 23:06:08.070409: predicting case_899 
2025-06-04 23:06:08.177606: case_899, shape torch.Size([1, 80, 256, 256]), rank 0 
2025-06-04 23:06:10.538270: predicting case_912 
2025-06-04 23:06:10.650465: case_912, shape torch.Size([1, 90, 289, 289]), rank 0 
2025-06-04 23:06:18.412787: predicting case_916 
2025-06-04 23:06:18.626709: case_916, shape torch.Size([1, 80, 398, 398]), rank 0 
2025-06-04 23:06:27.837727: predicting case_929 
2025-06-04 23:06:28.060295: case_929, shape torch.Size([1, 86, 427, 427]), rank 0 
2025-06-04 23:06:41.882350: predicting case_930 
2025-06-04 23:06:42.096305: case_930, shape torch.Size([1, 89, 302, 302]), rank 0 
2025-06-04 23:06:49.943217: predicting case_940 
2025-06-04 23:06:50.034361: case_940, shape torch.Size([1, 80, 213, 213]), rank 0 
2025-06-04 23:06:52.369719: predicting case_943 
2025-06-04 23:06:52.453979: case_943, shape torch.Size([1, 80, 277, 277]), rank 0 
2025-06-04 23:06:54.800812: predicting case_960 
2025-06-04 23:06:54.870557: case_960, shape torch.Size([1, 80, 199, 199]), rank 0 
2025-06-04 23:06:57.351995: predicting case_970 
2025-06-04 23:06:57.496288: case_970, shape torch.Size([1, 80, 242, 242]), rank 0 
2025-06-04 23:07:00.297305: predicting case_976 
2025-06-04 23:07:00.497798: case_976, shape torch.Size([1, 80, 256, 256]), rank 0 
2025-06-04 23:07:02.857317: predicting case_977 
2025-06-04 23:07:02.968573: case_977, shape torch.Size([1, 80, 228, 228]), rank 0 
2025-06-04 23:07:05.333102: predicting case_979 
2025-06-04 23:07:05.428295: case_979, shape torch.Size([1, 90, 258, 258]), rank 0 
2025-06-04 23:07:08.920006: predicting case_985 
2025-06-04 23:07:09.018367: case_985, shape torch.Size([1, 79, 256, 256]), rank 0 
2025-06-04 23:07:11.364881: predicting case_990 
2025-06-04 23:07:11.471603: case_990, shape torch.Size([1, 80, 242, 242]), rank 0 
2025-06-04 23:07:13.825807: predicting case_995 
2025-06-04 23:07:13.915744: case_995, shape torch.Size([1, 80, 235, 235]), rank 0 
2025-06-04 23:07:43.586180: Validation complete 
2025-06-04 23:07:43.606275: Mean Validation Dice:  0.7792363429263551 
