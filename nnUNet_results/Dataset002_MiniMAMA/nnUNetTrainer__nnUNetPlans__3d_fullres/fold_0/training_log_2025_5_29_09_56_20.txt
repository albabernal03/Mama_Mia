
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2025-05-29 09:56:20.744246: do_dummy_2d_data_aug: False 
2025-05-29 09:56:20.744246: Creating new 5-fold cross-validation split... 
2025-05-29 09:56:20.744246: Desired fold for training: 0 
2025-05-29 09:56:20.751755: This split has 4 training and 1 validation cases. 

This is the configuration used by this training:
Configuration name: 3d_fullres
 {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [32, 64, 64], 'median_image_size_in_voxels': [32.0, 64.0, 64.0], 'spacing': [1.0, 1.0, 1.0], 'normalization_schemes': ['ZScoreNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 5, 'features_per_stage': [32, 64, 128, 256, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': False} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset002_MiniMAMA', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [1.0, 1.0, 1.0], 'original_median_shape_after_transp': [32, 64, 64], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 10.435477256774902, 'mean': 3.7096824645996094, 'median': 3.4724202156066895, 'min': -0.4275595247745514, 'percentile_00_5': -0.30167457461357117, 'percentile_99_5': 8.861649513244629, 'std': 1.8995821475982666}}} 
 
2025-05-29 09:56:30.886042: Unable to plot network architecture: 
2025-05-29 09:56:30.886042: No module named 'IPython' 
2025-05-29 09:56:30.996994:  
2025-05-29 09:56:30.996994: Epoch 0 
2025-05-29 09:56:30.996994: Current learning rate: 0.01 
2025-05-29 09:56:49.007626: train_loss -0.2338 
2025-05-29 09:56:49.008134: val_loss -0.5206 
2025-05-29 09:56:49.008660: Pseudo dice [np.float32(0.6305)] 
2025-05-29 09:56:49.009709: Epoch time: 18.01 s 
2025-05-29 09:56:49.010230: Yayy! New best EMA pseudo Dice: 0.6305000185966492 
2025-05-29 09:56:50.371136:  
2025-05-29 09:56:50.371655: Epoch 1 
2025-05-29 09:56:50.372297: Current learning rate: 0.00999 
2025-05-29 09:57:05.729670: train_loss -0.5182 
2025-05-29 09:57:05.730193: val_loss -0.5423 
2025-05-29 09:57:05.730716: Pseudo dice [np.float32(0.6414)] 
2025-05-29 09:57:05.731234: Epoch time: 15.36 s 
2025-05-29 09:57:05.731764: Yayy! New best EMA pseudo Dice: 0.631600022315979 
2025-05-29 09:57:07.187331:  
2025-05-29 09:57:07.188369: Epoch 2 
2025-05-29 09:57:07.189398: Current learning rate: 0.00998 
2025-05-29 09:57:21.239833: train_loss -0.5624 
2025-05-29 09:57:21.240355: val_loss -0.579 
2025-05-29 09:57:21.240876: Pseudo dice [np.float32(0.7678)] 
2025-05-29 09:57:21.241405: Epoch time: 14.05 s 
2025-05-29 09:57:21.241405: Yayy! New best EMA pseudo Dice: 0.6452000141143799 
2025-05-29 09:57:22.938323:  
2025-05-29 09:57:22.938843: Epoch 3 
2025-05-29 09:57:22.939375: Current learning rate: 0.00997 
2025-05-29 09:57:39.696052: train_loss -0.5728 
2025-05-29 09:57:39.697160: val_loss -0.5855 
2025-05-29 09:57:39.697684: Pseudo dice [np.float32(0.6233)] 
2025-05-29 09:57:39.698743: Epoch time: 16.76 s 
2025-05-29 09:57:41.713195:  
2025-05-29 09:57:41.713712: Epoch 4 
2025-05-29 09:57:41.714233: Current learning rate: 0.00996 
2025-05-29 09:58:01.613064: train_loss -0.6458 
2025-05-29 09:58:01.614139: val_loss -0.6598 
2025-05-29 09:58:01.614747: Pseudo dice [np.float32(0.5391)] 
2025-05-29 09:58:01.615255: Epoch time: 19.9 s 
2025-05-29 09:58:04.018779:  
2025-05-29 09:58:04.019297: Epoch 5 
2025-05-29 09:58:04.020360: Current learning rate: 0.00995 
2025-05-29 09:58:23.348783: train_loss -0.6368 
2025-05-29 09:58:23.349330: val_loss -0.6646 
2025-05-29 09:58:23.349330: Pseudo dice [np.float32(0.6339)] 
2025-05-29 09:58:23.350355: Epoch time: 19.33 s 
2025-05-29 09:58:24.618613:  
2025-05-29 09:58:24.619633: Epoch 6 
2025-05-29 09:58:24.620148: Current learning rate: 0.00995 
2025-05-29 09:58:41.045300: train_loss -0.6073 
2025-05-29 09:58:41.046381: val_loss -0.5534 
2025-05-29 09:58:41.046919: Pseudo dice [np.float32(0.4618)] 
2025-05-29 09:58:41.047974: Epoch time: 16.43 s 
2025-05-29 09:58:43.266704:  
2025-05-29 09:58:43.267761: Epoch 7 
2025-05-29 09:58:43.268345: Current learning rate: 0.00994 
2025-05-29 09:59:03.632339: train_loss -0.6568 
2025-05-29 09:59:03.634499: val_loss -0.7023 
2025-05-29 09:59:03.637158: Pseudo dice [np.float32(0.6526)] 
2025-05-29 09:59:03.639213: Epoch time: 20.37 s 
2025-05-29 09:59:05.982515:  
2025-05-29 09:59:05.983038: Epoch 8 
2025-05-29 09:59:05.984092: Current learning rate: 0.00993 
2025-05-29 09:59:20.584232: train_loss -0.6753 
2025-05-29 09:59:20.584760: val_loss -0.637 
2025-05-29 09:59:20.585285: Pseudo dice [np.float32(0.6595)] 
2025-05-29 09:59:20.585811: Epoch time: 14.6 s 
2025-05-29 09:59:21.893913:  
2025-05-29 09:59:21.894941: Epoch 9 
2025-05-29 09:59:21.895984: Current learning rate: 0.00992 
2025-05-29 09:59:37.235053: train_loss -0.68 
2025-05-29 09:59:37.235587: val_loss -0.7778 
2025-05-29 09:59:37.236678: Pseudo dice [np.float32(0.7734)] 
2025-05-29 09:59:37.237208: Epoch time: 15.34 s 
2025-05-29 09:59:39.781150:  
2025-05-29 09:59:39.782276: Epoch 10 
2025-05-29 09:59:39.782811: Current learning rate: 0.00991 
2025-05-29 09:59:59.927441: train_loss -0.6881 
2025-05-29 09:59:59.928648: val_loss -0.7568 
2025-05-29 09:59:59.929052: Pseudo dice [np.float32(0.7055)] 
2025-05-29 09:59:59.929052: Epoch time: 20.15 s 
2025-05-29 10:00:02.141063:  
2025-05-29 10:00:02.142159: Epoch 11 
2025-05-29 10:00:02.142687: Current learning rate: 0.0099 
2025-05-29 10:00:20.217233: train_loss -0.6713 
2025-05-29 10:00:20.217751: val_loss -0.611 
2025-05-29 10:00:20.218272: Pseudo dice [np.float32(0.8095)] 
2025-05-29 10:00:20.218792: Epoch time: 18.08 s 
2025-05-29 10:00:20.219307: Yayy! New best EMA pseudo Dice: 0.6614999771118164 
2025-05-29 10:00:21.684056:  
2025-05-29 10:00:21.684570: Epoch 12 
2025-05-29 10:00:21.685091: Current learning rate: 0.00989 
2025-05-29 10:00:35.677945: train_loss -0.6833 
2025-05-29 10:00:35.678470: val_loss -0.8373 
2025-05-29 10:00:35.679001: Pseudo dice [np.float32(0.7821)] 
2025-05-29 10:00:35.679526: Epoch time: 13.99 s 
2025-05-29 10:00:35.680046: Yayy! New best EMA pseudo Dice: 0.6736000180244446 
2025-05-29 10:00:37.251722:  
2025-05-29 10:00:37.252238: Epoch 13 
2025-05-29 10:00:37.252754: Current learning rate: 0.00988 
2025-05-29 10:00:51.187515: train_loss -0.6811 
2025-05-29 10:00:51.188560: val_loss -0.6831 
2025-05-29 10:00:51.189079: Pseudo dice [np.float32(0.6358)] 
2025-05-29 10:00:51.189603: Epoch time: 13.94 s 
2025-05-29 10:00:52.724761:  
2025-05-29 10:00:52.725795: Epoch 14 
2025-05-29 10:00:52.726727: Current learning rate: 0.00987 
2025-05-29 10:01:06.767318: train_loss -0.7118 
2025-05-29 10:01:06.767838: val_loss -0.6846 
2025-05-29 10:01:06.768880: Pseudo dice [np.float32(0.664)] 
2025-05-29 10:01:06.768880: Epoch time: 14.04 s 
2025-05-29 10:01:08.101731:  
2025-05-29 10:01:08.102284: Epoch 15 
2025-05-29 10:01:08.102803: Current learning rate: 0.00986 
2025-05-29 10:01:22.251803: train_loss -0.7025 
2025-05-29 10:01:22.252335: val_loss -0.8529 
2025-05-29 10:01:22.252866: Pseudo dice [np.float32(0.8485)] 
2025-05-29 10:01:22.253386: Epoch time: 14.15 s 
2025-05-29 10:01:22.253909: Yayy! New best EMA pseudo Dice: 0.6872000098228455 
2025-05-29 10:01:23.849587:  
2025-05-29 10:01:23.850629: Epoch 16 
2025-05-29 10:01:23.851147: Current learning rate: 0.00986 
2025-05-29 10:01:38.359679: train_loss -0.7065 
2025-05-29 10:01:38.360244: val_loss -0.6991 
2025-05-29 10:01:38.360772: Pseudo dice [np.float32(0.7369)] 
2025-05-29 10:01:38.361302: Epoch time: 14.51 s 
2025-05-29 10:01:38.361826: Yayy! New best EMA pseudo Dice: 0.6920999884605408 
2025-05-29 10:01:39.870266:  
2025-05-29 10:01:39.870778: Epoch 17 
2025-05-29 10:01:39.871290: Current learning rate: 0.00985 
2025-05-29 10:01:53.993209: train_loss -0.6732 
2025-05-29 10:01:53.993209: val_loss -0.7212 
2025-05-29 10:01:53.993209: Pseudo dice [np.float32(0.757)] 
2025-05-29 10:01:53.994731: Epoch time: 14.12 s 
2025-05-29 10:01:53.995247: Yayy! New best EMA pseudo Dice: 0.6985999941825867 
2025-05-29 10:01:55.748075:  
2025-05-29 10:01:55.749091: Epoch 18 
2025-05-29 10:01:55.749608: Current learning rate: 0.00984 
2025-05-29 10:02:11.033996: train_loss -0.653 
2025-05-29 10:02:11.034517: val_loss -0.6762 
2025-05-29 10:02:11.035043: Pseudo dice [np.float32(0.6592)] 
2025-05-29 10:02:11.035043: Epoch time: 15.29 s 
2025-05-29 10:02:12.339611:  
2025-05-29 10:02:12.340378: Epoch 19 
2025-05-29 10:02:12.341203: Current learning rate: 0.00983 
2025-05-29 10:02:26.096007: train_loss -0.6892 
2025-05-29 10:02:26.096534: val_loss -0.7643 
2025-05-29 10:02:26.097065: Pseudo dice [np.float32(0.7607)] 
2025-05-29 10:02:26.097065: Epoch time: 13.76 s 
2025-05-29 10:02:26.097585: Yayy! New best EMA pseudo Dice: 0.7013000249862671 
2025-05-29 10:02:27.631639:  
2025-05-29 10:02:27.632685: Epoch 20 
2025-05-29 10:02:27.633200: Current learning rate: 0.00982 
2025-05-29 10:02:41.745175: train_loss -0.6882 
2025-05-29 10:02:41.745728: val_loss -0.7025 
2025-05-29 10:02:41.746265: Pseudo dice [np.float32(0.7472)] 
2025-05-29 10:02:41.746783: Epoch time: 14.11 s 
2025-05-29 10:02:41.747301: Yayy! New best EMA pseudo Dice: 0.7059000134468079 
2025-05-29 10:02:43.307394:  
2025-05-29 10:02:43.308417: Epoch 21 
2025-05-29 10:02:43.309959: Current learning rate: 0.00981 
2025-05-29 10:02:56.904800: train_loss -0.699 
2025-05-29 10:02:56.905320: val_loss -0.6879 
2025-05-29 10:02:56.905846: Pseudo dice [np.float32(0.8087)] 
2025-05-29 10:02:56.906385: Epoch time: 13.6 s 
2025-05-29 10:02:56.906914: Yayy! New best EMA pseudo Dice: 0.7160999774932861 
2025-05-29 10:02:58.404172:  
2025-05-29 10:02:58.404694: Epoch 22 
2025-05-29 10:02:58.405279: Current learning rate: 0.0098 
2025-05-29 10:03:13.077798: train_loss -0.7169 
2025-05-29 10:03:13.078853: val_loss -0.6826 
2025-05-29 10:03:13.078853: Pseudo dice [np.float32(0.725)] 
2025-05-29 10:03:13.079367: Epoch time: 14.67 s 
2025-05-29 10:03:13.079987: Yayy! New best EMA pseudo Dice: 0.7170000076293945 
2025-05-29 10:03:14.592293:  
2025-05-29 10:03:14.593840: Epoch 23 
2025-05-29 10:03:14.594355: Current learning rate: 0.00979 
2025-05-29 10:03:29.480414: train_loss -0.6985 
2025-05-29 10:03:29.480934: val_loss -0.7112 
2025-05-29 10:03:29.480934: Pseudo dice [np.float32(0.721)] 
2025-05-29 10:03:29.481448: Epoch time: 14.89 s 
2025-05-29 10:03:29.482113: Yayy! New best EMA pseudo Dice: 0.7174000144004822 
2025-05-29 10:03:31.131580:  
2025-05-29 10:03:31.131580: Epoch 24 
2025-05-29 10:03:31.132621: Current learning rate: 0.00978 
2025-05-29 10:03:45.252272: train_loss -0.7441 
2025-05-29 10:03:45.252797: val_loss -0.8244 
2025-05-29 10:03:45.253319: Pseudo dice [np.float32(0.7878)] 
2025-05-29 10:03:45.253842: Epoch time: 14.12 s 
2025-05-29 10:03:45.254371: Yayy! New best EMA pseudo Dice: 0.7245000004768372 
2025-05-29 10:03:46.750148:  
2025-05-29 10:03:46.750711: Epoch 25 
2025-05-29 10:03:46.751755: Current learning rate: 0.00977 
2025-05-29 10:04:05.227511: train_loss -0.7491 
2025-05-29 10:04:05.228277: val_loss -0.7267 
2025-05-29 10:04:05.229062: Pseudo dice [np.float32(0.7721)] 
2025-05-29 10:04:05.229617: Epoch time: 18.48 s 
2025-05-29 10:04:05.230673: Yayy! New best EMA pseudo Dice: 0.729200005531311 
2025-05-29 10:04:08.052878:  
2025-05-29 10:04:08.053924: Epoch 26 
2025-05-29 10:04:08.054958: Current learning rate: 0.00977 
2025-05-29 10:04:28.926480: train_loss -0.7328 
2025-05-29 10:04:28.927260: val_loss -0.7673 
2025-05-29 10:04:28.927739: Pseudo dice [np.float32(0.7353)] 
2025-05-29 10:04:28.928294: Epoch time: 20.88 s 
2025-05-29 10:04:28.928818: Yayy! New best EMA pseudo Dice: 0.7297999858856201 
2025-05-29 10:04:31.505209:  
2025-05-29 10:04:31.506236: Epoch 27 
2025-05-29 10:04:31.506751: Current learning rate: 0.00976 
2025-05-29 10:04:49.198893: train_loss -0.7126 
2025-05-29 10:04:49.199423: val_loss -0.8145 
2025-05-29 10:04:49.199978: Pseudo dice [np.float32(0.7804)] 
2025-05-29 10:04:49.201028: Epoch time: 17.7 s 
2025-05-29 10:04:49.201028: Yayy! New best EMA pseudo Dice: 0.7348999977111816 
2025-05-29 10:04:51.746848:  
2025-05-29 10:04:51.747368: Epoch 28 
2025-05-29 10:04:51.748406: Current learning rate: 0.00975 
2025-05-29 10:05:12.613420: train_loss -0.7128 
2025-05-29 10:05:12.614475: val_loss -0.661 
2025-05-29 10:05:12.615007: Pseudo dice [np.float32(0.7542)] 
2025-05-29 10:05:12.615529: Epoch time: 20.87 s 
2025-05-29 10:05:12.616048: Yayy! New best EMA pseudo Dice: 0.7368000149726868 
2025-05-29 10:05:15.356535:  
2025-05-29 10:05:15.357617: Epoch 29 
2025-05-29 10:05:15.358704: Current learning rate: 0.00974 
2025-05-29 10:05:34.284239: train_loss -0.7211 
2025-05-29 10:05:34.285292: val_loss -0.8483 
2025-05-29 10:05:34.285292: Pseudo dice [np.float32(0.8505)] 
2025-05-29 10:05:34.285292: Epoch time: 18.93 s 
2025-05-29 10:05:34.286308: Yayy! New best EMA pseudo Dice: 0.748199999332428 
2025-05-29 10:05:35.963320:  
2025-05-29 10:05:35.964872: Epoch 30 
2025-05-29 10:05:35.965391: Current learning rate: 0.00973 
2025-05-29 10:05:50.776557: train_loss -0.7104 
2025-05-29 10:05:50.776557: val_loss -0.7735 
2025-05-29 10:05:50.777595: Pseudo dice [np.float32(0.7742)] 
2025-05-29 10:05:50.777595: Epoch time: 14.81 s 
2025-05-29 10:05:50.777595: Yayy! New best EMA pseudo Dice: 0.7508000135421753 
2025-05-29 10:05:52.578589:  
2025-05-29 10:05:52.578589: Epoch 31 
2025-05-29 10:05:52.578589: Current learning rate: 0.00972 
2025-05-29 10:06:06.969208: train_loss -0.7051 
2025-05-29 10:06:06.969208: val_loss -0.7747 
2025-05-29 10:06:06.971216: Pseudo dice [np.float32(0.7175)] 
2025-05-29 10:06:06.971739: Epoch time: 14.39 s 
2025-05-29 10:06:08.894913:  
2025-05-29 10:06:08.895995: Epoch 32 
2025-05-29 10:06:08.895995: Current learning rate: 0.00971 
2025-05-29 10:06:24.144599: train_loss -0.7277 
2025-05-29 10:06:24.145153: val_loss -0.8258 
2025-05-29 10:06:24.145687: Pseudo dice [np.float32(0.8377)] 
2025-05-29 10:06:24.146204: Epoch time: 15.25 s 
2025-05-29 10:06:24.146731: Yayy! New best EMA pseudo Dice: 0.7565000057220459 
2025-05-29 10:06:26.029577:  
2025-05-29 10:06:26.030099: Epoch 33 
2025-05-29 10:06:26.030619: Current learning rate: 0.0097 
2025-05-29 10:06:40.467276: train_loss -0.7246 
2025-05-29 10:06:40.467803: val_loss -0.7425 
2025-05-29 10:06:40.468327: Pseudo dice [np.float32(0.7649)] 
2025-05-29 10:06:40.468852: Epoch time: 14.44 s 
2025-05-29 10:06:40.468852: Yayy! New best EMA pseudo Dice: 0.7573000192642212 
2025-05-29 10:06:42.355874:  
2025-05-29 10:06:42.357957: Epoch 34 
2025-05-29 10:06:42.358999: Current learning rate: 0.00969 
2025-05-29 10:07:02.543308: train_loss -0.7278 
2025-05-29 10:07:02.543831: val_loss -0.6738 
2025-05-29 10:07:02.544877: Pseudo dice [np.float32(0.8073)] 
2025-05-29 10:07:02.545411: Epoch time: 20.19 s 
2025-05-29 10:07:02.545951: Yayy! New best EMA pseudo Dice: 0.7623000144958496 
2025-05-29 10:07:05.379599:  
2025-05-29 10:07:05.383748: Epoch 35 
2025-05-29 10:07:05.384546: Current learning rate: 0.00968 
2025-05-29 10:07:25.340803: train_loss -0.725 
2025-05-29 10:07:25.341335: val_loss -0.8464 
2025-05-29 10:07:25.342397: Pseudo dice [np.float32(0.8691)] 
2025-05-29 10:07:25.342921: Epoch time: 19.96 s 
2025-05-29 10:07:25.343445: Yayy! New best EMA pseudo Dice: 0.7730000019073486 
2025-05-29 10:07:28.166687:  
2025-05-29 10:07:28.168230: Epoch 36 
2025-05-29 10:07:28.169308: Current learning rate: 0.00968 
2025-05-29 10:07:47.012328: train_loss -0.7488 
2025-05-29 10:07:47.012852: val_loss -0.8025 
2025-05-29 10:07:47.013876: Pseudo dice [np.float32(0.8556)] 
2025-05-29 10:07:47.013876: Epoch time: 18.85 s 
2025-05-29 10:07:47.013876: Yayy! New best EMA pseudo Dice: 0.7813000082969666 
2025-05-29 10:07:48.687899:  
2025-05-29 10:07:48.688421: Epoch 37 
2025-05-29 10:07:48.688940: Current learning rate: 0.00967 
2025-05-29 10:08:02.698943: train_loss -0.7344 
2025-05-29 10:08:02.699476: val_loss -0.8325 
2025-05-29 10:08:02.699995: Pseudo dice [np.float32(0.7997)] 
2025-05-29 10:08:02.699995: Epoch time: 14.01 s 
2025-05-29 10:08:02.700517: Yayy! New best EMA pseudo Dice: 0.7831000089645386 
2025-05-29 10:08:04.439276:  
2025-05-29 10:08:04.439801: Epoch 38 
2025-05-29 10:08:04.440312: Current learning rate: 0.00966 
2025-05-29 10:08:19.674911: train_loss -0.7577 
2025-05-29 10:08:19.675430: val_loss -0.7912 
2025-05-29 10:08:19.675953: Pseudo dice [np.float32(0.8705)] 
2025-05-29 10:08:19.676506: Epoch time: 15.24 s 
2025-05-29 10:08:19.677031: Yayy! New best EMA pseudo Dice: 0.7918000221252441 
2025-05-29 10:08:21.163335:  
2025-05-29 10:08:21.164378: Epoch 39 
2025-05-29 10:08:21.164895: Current learning rate: 0.00965 
2025-05-29 10:08:35.084820: train_loss -0.7583 
2025-05-29 10:08:35.085356: val_loss -0.8326 
2025-05-29 10:08:35.085895: Pseudo dice [np.float32(0.8314)] 
2025-05-29 10:08:35.086415: Epoch time: 13.92 s 
2025-05-29 10:08:35.086415: Yayy! New best EMA pseudo Dice: 0.795799970626831 
2025-05-29 10:08:36.742833:  
2025-05-29 10:08:36.743352: Epoch 40 
2025-05-29 10:08:36.743875: Current learning rate: 0.00964 
2025-05-29 10:08:51.952392: train_loss -0.7569 
2025-05-29 10:08:51.952914: val_loss -0.7584 
2025-05-29 10:08:51.953433: Pseudo dice [np.float32(0.7772)] 
2025-05-29 10:08:51.953950: Epoch time: 15.21 s 
2025-05-29 10:08:53.282521:  
2025-05-29 10:08:53.283036: Epoch 41 
2025-05-29 10:08:53.283553: Current learning rate: 0.00963 
2025-05-29 10:09:07.175812: train_loss -0.7518 
2025-05-29 10:09:07.176838: val_loss -0.7583 
2025-05-29 10:09:07.177370: Pseudo dice [np.float32(0.7226)] 
2025-05-29 10:09:07.177370: Epoch time: 13.89 s 
2025-05-29 10:09:08.477897:  
2025-05-29 10:09:08.478414: Epoch 42 
2025-05-29 10:09:08.478931: Current learning rate: 0.00962 
2025-05-29 10:09:23.540395: train_loss -0.737 
2025-05-29 10:09:23.541430: val_loss -0.8253 
2025-05-29 10:09:23.541430: Pseudo dice [np.float32(0.8133)] 
2025-05-29 10:09:23.541949: Epoch time: 15.06 s 
2025-05-29 10:09:24.854505:  
2025-05-29 10:09:24.854505: Epoch 43 
2025-05-29 10:09:24.856041: Current learning rate: 0.00961 
2025-05-29 10:09:38.830076: train_loss -0.7477 
2025-05-29 10:09:38.830593: val_loss -0.8502 
2025-05-29 10:09:38.831109: Pseudo dice [np.float32(0.8269)] 
2025-05-29 10:09:38.831109: Epoch time: 13.98 s 
2025-05-29 10:09:40.110570:  
2025-05-29 10:09:40.111088: Epoch 44 
2025-05-29 10:09:40.111603: Current learning rate: 0.0096 
2025-05-29 10:09:54.289734: train_loss -0.7449 
2025-05-29 10:09:54.290265: val_loss -0.8103 
2025-05-29 10:09:54.290807: Pseudo dice [np.float32(0.853)] 
2025-05-29 10:09:54.291326: Epoch time: 14.18 s 
2025-05-29 10:09:54.291326: Yayy! New best EMA pseudo Dice: 0.7991999983787537 
2025-05-29 10:09:55.735685:  
2025-05-29 10:09:55.736196: Epoch 45 
2025-05-29 10:09:55.736709: Current learning rate: 0.00959 
2025-05-29 10:10:10.919776: train_loss -0.7311 
2025-05-29 10:10:10.920291: val_loss -0.8227 
2025-05-29 10:10:10.920810: Pseudo dice [np.float32(0.7762)] 
2025-05-29 10:10:10.921337: Epoch time: 15.19 s 
2025-05-29 10:10:12.447587:  
2025-05-29 10:10:12.448113: Epoch 46 
2025-05-29 10:10:12.448639: Current learning rate: 0.00959 
2025-05-29 10:10:26.293270: train_loss -0.7355 
2025-05-29 10:10:26.293788: val_loss -0.8565 
2025-05-29 10:10:26.294314: Pseudo dice [np.float32(0.8006)] 
2025-05-29 10:10:26.294314: Epoch time: 13.85 s 
2025-05-29 10:10:27.589552:  
2025-05-29 10:10:27.590073: Epoch 47 
2025-05-29 10:10:27.590589: Current learning rate: 0.00958 
2025-05-29 10:10:42.405896: train_loss -0.742 
2025-05-29 10:10:42.406944: val_loss -0.8689 
2025-05-29 10:10:42.406944: Pseudo dice [np.float32(0.8834)] 
2025-05-29 10:10:42.407514: Epoch time: 14.82 s 
2025-05-29 10:10:42.408019: Yayy! New best EMA pseudo Dice: 0.805899977684021 
2025-05-29 10:10:43.867738:  
2025-05-29 10:10:43.868773: Epoch 48 
2025-05-29 10:10:43.868773: Current learning rate: 0.00957 
2025-05-29 10:11:16.244807: train_loss -0.7476 
2025-05-29 10:11:16.244807: val_loss -0.8481 
2025-05-29 10:11:16.245445: Pseudo dice [np.float32(0.8829)] 
2025-05-29 10:11:16.246093: Epoch time: 32.38 s 
2025-05-29 10:11:16.246743: Yayy! New best EMA pseudo Dice: 0.8136000037193298 
2025-05-29 10:11:17.780998:  
2025-05-29 10:11:17.781646: Epoch 49 
2025-05-29 10:11:17.782305: Current learning rate: 0.00956 
2025-05-29 10:11:31.989508: train_loss -0.7574 
2025-05-29 10:11:31.989508: val_loss -0.8508 
2025-05-29 10:11:31.990154: Pseudo dice [np.float32(0.8778)] 
2025-05-29 10:11:31.990791: Epoch time: 14.21 s 
2025-05-29 10:11:32.194750: Yayy! New best EMA pseudo Dice: 0.8199999928474426 
2025-05-29 10:11:33.748498:  
2025-05-29 10:11:33.749686: Epoch 50 
2025-05-29 10:11:33.750332: Current learning rate: 0.00955 
2025-05-29 10:11:47.561917: train_loss -0.7313 
2025-05-29 10:11:47.561917: val_loss -0.6732 
2025-05-29 10:11:47.562564: Pseudo dice [np.float32(0.7827)] 
2025-05-29 10:11:47.563206: Epoch time: 13.81 s 
2025-05-29 10:11:48.858577:  
2025-05-29 10:11:48.859226: Epoch 51 
2025-05-29 10:11:48.859226: Current learning rate: 0.00954 
2025-05-29 10:12:03.249071: train_loss -0.7652 
2025-05-29 10:12:03.249696: val_loss -0.7686 
2025-05-29 10:12:03.250346: Pseudo dice [np.float32(0.8097)] 
2025-05-29 10:12:03.250986: Epoch time: 14.39 s 
2025-05-29 10:12:04.562992:  
2025-05-29 10:12:04.564125: Epoch 52 
2025-05-29 10:12:04.564781: Current learning rate: 0.00953 
2025-05-29 10:12:18.361861: train_loss -0.7683 
2025-05-29 10:12:18.362503: val_loss -0.6347 
2025-05-29 10:12:18.362503: Pseudo dice [np.float32(0.8453)] 
2025-05-29 10:12:18.363146: Epoch time: 13.8 s 
2025-05-29 10:12:19.852855:  
2025-05-29 10:12:19.853495: Epoch 53 
2025-05-29 10:12:19.854129: Current learning rate: 0.00952 
2025-05-29 10:12:35.921483: train_loss -0.7588 
2025-05-29 10:12:35.922526: val_loss -0.8396 
2025-05-29 10:12:35.922526: Pseudo dice [np.float32(0.8336)] 
2025-05-29 10:12:35.923080: Epoch time: 16.07 s 
2025-05-29 10:12:35.924191: Yayy! New best EMA pseudo Dice: 0.8201000094413757 
2025-05-29 10:12:38.625495:  
2025-05-29 10:12:38.626781: Epoch 54 
2025-05-29 10:12:38.627441: Current learning rate: 0.00951 
2025-05-29 10:12:59.520119: train_loss -0.7395 
2025-05-29 10:12:59.521417: val_loss -0.8442 
2025-05-29 10:12:59.521417: Pseudo dice [np.float32(0.8547)] 
2025-05-29 10:12:59.522794: Epoch time: 20.9 s 
2025-05-29 10:12:59.522794: Yayy! New best EMA pseudo Dice: 0.8234999775886536 
2025-05-29 10:13:02.185102:  
2025-05-29 10:13:02.185708: Epoch 55 
2025-05-29 10:13:02.185708: Current learning rate: 0.0095 
2025-05-29 10:13:23.541568: train_loss -0.7488 
2025-05-29 10:13:23.542866: val_loss -0.8421 
2025-05-29 10:13:23.543518: Pseudo dice [np.float32(0.8349)] 
2025-05-29 10:13:23.544174: Epoch time: 21.36 s 
2025-05-29 10:13:23.545569: Yayy! New best EMA pseudo Dice: 0.8246999979019165 
2025-05-29 10:13:26.159963:  
2025-05-29 10:13:26.161256: Epoch 56 
2025-05-29 10:13:26.161918: Current learning rate: 0.00949 
2025-05-29 10:13:46.862275: train_loss -0.7399 
2025-05-29 10:13:46.864305: val_loss -0.8093 
2025-05-29 10:13:46.864923: Pseudo dice [np.float32(0.8538)] 
2025-05-29 10:13:46.864923: Epoch time: 20.7 s 
2025-05-29 10:13:46.867466: Yayy! New best EMA pseudo Dice: 0.8276000022888184 
2025-05-29 10:13:49.401628:  
2025-05-29 10:13:49.402757: Epoch 57 
2025-05-29 10:13:49.403300: Current learning rate: 0.00949 
2025-05-29 10:14:10.009130: train_loss -0.7352 
2025-05-29 10:14:10.010220: val_loss -0.7259 
2025-05-29 10:14:10.010819: Pseudo dice [np.float32(0.7346)] 
2025-05-29 10:14:10.011862: Epoch time: 20.61 s 
2025-05-29 10:14:12.319179:  
2025-05-29 10:14:12.320487: Epoch 58 
2025-05-29 10:14:12.321774: Current learning rate: 0.00948 
2025-05-29 10:14:32.861099: train_loss -0.7367 
2025-05-29 10:14:32.862411: val_loss -0.2031 
2025-05-29 10:14:32.863063: Pseudo dice [np.float32(0.3682)] 
2025-05-29 10:14:32.863732: Epoch time: 20.54 s 
2025-05-29 10:14:35.216881:  
2025-05-29 10:14:35.218174: Epoch 59 
2025-05-29 10:14:35.218824: Current learning rate: 0.00947 
2025-05-29 10:14:54.603398: train_loss -0.7355 
2025-05-29 10:14:54.604702: val_loss -0.6849 
2025-05-29 10:14:54.605344: Pseudo dice [np.float32(0.8039)] 
2025-05-29 10:14:54.605995: Epoch time: 19.39 s 
2025-05-29 10:14:57.002906:  
2025-05-29 10:14:57.005492: Epoch 60 
2025-05-29 10:14:57.006798: Current learning rate: 0.00946 
2025-05-29 10:15:16.196047: train_loss -0.7381 
2025-05-29 10:15:16.196047: val_loss -0.8219 
2025-05-29 10:15:16.197193: Pseudo dice [np.float32(0.8696)] 
2025-05-29 10:15:16.197832: Epoch time: 19.2 s 
2025-05-29 10:15:17.749340:  
2025-05-29 10:15:17.750002: Epoch 61 
2025-05-29 10:15:17.750002: Current learning rate: 0.00945 
2025-05-29 10:15:31.258546: train_loss -0.7624 
2025-05-29 10:15:31.258546: val_loss -0.8752 
2025-05-29 10:15:31.259192: Pseudo dice [np.float32(0.895)] 
2025-05-29 10:15:31.259855: Epoch time: 13.51 s 
2025-05-29 10:15:32.684891:  
2025-05-29 10:15:32.685528: Epoch 62 
2025-05-29 10:15:32.686163: Current learning rate: 0.00944 
2025-05-29 10:15:51.161393: train_loss -0.7641 
2025-05-29 10:15:51.162007: val_loss -0.6245 
2025-05-29 10:15:51.162559: Pseudo dice [np.float32(0.8645)] 
2025-05-29 10:15:51.163096: Epoch time: 18.48 s 
2025-05-29 10:15:53.682250:  
2025-05-29 10:15:53.683608: Epoch 63 
2025-05-29 10:15:53.684226: Current learning rate: 0.00943 
2025-05-29 10:16:14.082862: train_loss -0.7641 
2025-05-29 10:16:14.084096: val_loss -0.6494 
2025-05-29 10:16:14.084743: Pseudo dice [np.float32(0.789)] 
2025-05-29 10:16:14.085393: Epoch time: 20.4 s 
2025-05-29 10:16:16.423946:  
2025-05-29 10:16:16.425241: Epoch 64 
2025-05-29 10:16:16.426555: Current learning rate: 0.00942 
2025-05-29 10:16:37.139705: train_loss -0.7591 
2025-05-29 10:16:37.140248: val_loss -0.8152 
2025-05-29 10:16:37.141293: Pseudo dice [np.float32(0.8492)] 
2025-05-29 10:16:37.141885: Epoch time: 20.72 s 
2025-05-29 10:16:39.493062:  
2025-05-29 10:16:39.493679: Epoch 65 
2025-05-29 10:16:39.494326: Current learning rate: 0.00941 
2025-05-29 10:17:00.450992: train_loss -0.7419 
2025-05-29 10:17:00.452035: val_loss -0.7594 
2025-05-29 10:17:00.453109: Pseudo dice [np.float32(0.8711)] 
2025-05-29 10:17:00.453635: Epoch time: 20.96 s 
2025-05-29 10:17:02.842526:  
2025-05-29 10:17:02.843787: Epoch 66 
2025-05-29 10:17:02.844419: Current learning rate: 0.0094 
2025-05-29 10:17:24.032918: train_loss -0.7445 
2025-05-29 10:17:24.033576: val_loss -0.7307 
2025-05-29 10:17:24.034225: Pseudo dice [np.float32(0.8363)] 
2025-05-29 10:17:24.035525: Epoch time: 21.19 s 
2025-05-29 10:17:26.240139:  
2025-05-29 10:17:26.242491: Epoch 67 
2025-05-29 10:17:26.243726: Current learning rate: 0.00939 
2025-05-29 10:17:40.236662: train_loss -0.7476 
2025-05-29 10:17:40.237202: val_loss -0.7015 
2025-05-29 10:17:40.237202: Pseudo dice [np.float32(0.8818)] 
2025-05-29 10:17:40.237202: Epoch time: 14.0 s 
2025-05-29 10:17:41.762864:  
2025-05-29 10:17:41.763502: Epoch 68 
2025-05-29 10:17:41.764133: Current learning rate: 0.00939 
2025-05-29 10:17:55.517996: train_loss -0.7533 
2025-05-29 10:17:55.518533: val_loss -0.7396 
2025-05-29 10:17:55.518533: Pseudo dice [np.float32(0.8126)] 
2025-05-29 10:17:55.519051: Epoch time: 13.76 s 
2025-05-29 10:17:56.839637:  
2025-05-29 10:17:56.840274: Epoch 69 
2025-05-29 10:17:56.840928: Current learning rate: 0.00938 
2025-05-29 10:18:11.052040: train_loss -0.7575 
2025-05-29 10:18:11.052552: val_loss -0.8166 
2025-05-29 10:18:11.052552: Pseudo dice [np.float32(0.806)] 
2025-05-29 10:18:11.053570: Epoch time: 14.21 s 
2025-05-29 10:18:12.333143:  
2025-05-29 10:18:12.333800: Epoch 70 
2025-05-29 10:18:12.333800: Current learning rate: 0.00937 
2025-05-29 10:18:26.024662: train_loss -0.7468 
2025-05-29 10:18:26.024662: val_loss -0.1364 
2025-05-29 10:18:26.025831: Pseudo dice [np.float32(0.0)] 
2025-05-29 10:18:26.025831: Epoch time: 13.69 s 
2025-05-29 10:18:27.445926:  
2025-05-29 10:18:27.445926: Epoch 71 
2025-05-29 10:18:27.447059: Current learning rate: 0.00936 
2025-05-29 10:18:41.774925: train_loss -0.7407 
2025-05-29 10:18:41.775563: val_loss -0.83 
2025-05-29 10:18:41.775563: Pseudo dice [np.float32(0.8772)] 
2025-05-29 10:18:41.776207: Epoch time: 14.33 s 
2025-05-29 10:18:43.101207:  
2025-05-29 10:18:43.102370: Epoch 72 
2025-05-29 10:18:43.103019: Current learning rate: 0.00935 
2025-05-29 10:18:56.560694: train_loss -0.7366 
2025-05-29 10:18:56.561342: val_loss -0.8221 
2025-05-29 10:18:56.561995: Pseudo dice [np.float32(0.8619)] 
2025-05-29 10:18:56.562658: Epoch time: 13.46 s 
2025-05-29 10:18:57.900176:  
2025-05-29 10:18:57.900819: Epoch 73 
2025-05-29 10:18:57.901463: Current learning rate: 0.00934 
2025-05-29 10:19:12.001473: train_loss -0.7464 
2025-05-29 10:19:12.002121: val_loss -0.7344 
2025-05-29 10:19:12.002121: Pseudo dice [np.float32(0.7891)] 
2025-05-29 10:19:12.002764: Epoch time: 14.1 s 
2025-05-29 10:19:13.324932:  
2025-05-29 10:19:13.324932: Epoch 74 
2025-05-29 10:19:13.325581: Current learning rate: 0.00933 
